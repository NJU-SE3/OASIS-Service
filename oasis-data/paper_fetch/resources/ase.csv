"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,"Reference Count","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Keynotes","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","36","38","Provides an abstract for each of the keynote presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","","","10.1109/ASE.2019.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952191","","","","","","","","","","","","IEEE","IEEE Conferences"
"Big problems in industry (panel)","J. Penix","Google, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","3","3","Software Engineering in practice deals with scale in a variety of dimensions. We build large scale systems operating on vast amount of data. We have millions of customers with billions of queries and transactions. We have distributed teams making thousands of changes, running millions of tests and releasing multiple times per day. These dimensions of scale interact to provide challenges for software development tools and processes. The panelists will describe the challenging aspects of scale in their specific problem domains and discuss which software engineering methods work and which leave room for improvement.","","","10.1109/ASE.2013.6693060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693060","","","","","","1","","","","","","IEEE","IEEE Conferences"
"Toward Practical Automatic Program Repair","A. Ghanbari","University of Texas at Dallas","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1262","1264","Automated program repair (APR) reduces the burden of debugging by directly suggesting likely fixes for the bugs. We believe scalability, applicability, and accurate patch validation are among the main challenges for building practical APR techniques that the researchers in this area are dealing with. In this paper, we describe the steps that we are taking toward addressing these challenges.","","","10.1109/ASE.2019.00156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952355","Program Repair;JVM Bytecode;Mutation Testing","","","","","","54","","","","","IEEE","IEEE Conferences"
"TsmartGP: A Tool for Finding Memory Defects with Pointer Analysis","Y. Wang; G. Chen; M. Zhou; M. Gu; J. Sun","Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1170","1173","Precise pointer analysis is desired since it is a core technique to find memory defects. There are several dimensions of pointer analysis precision, flow sensitivity, context sensitivity, field sensitivity and path sensitivity. For static analysis tools utilizing pointer analysis, considering all dimensions is difficult because the trade-off between precision and efficiency should be balanced. This paper presents TsmartGP, a static analysis tool for finding memory defects in C programs with a precise and efficient pointer analysis. The pointer analysis algorithm is flow, context, field, and quasi path sensitive. Control flow automatons are the key structures for our analysis to be flow sensitive. Function summaries are applied to get context information and elements of aggregate structures are handled to improve precision. Path conditions are used to filter unreachable paths. For efficiency, a multi-entry mechanism is proposed. Utilizing the pointer analysis algorithm, we implement a checker in TsmartGP to find uninitialized pointer errors in 13 real-world applications. Cppcheck and Clang Static Analyzer are chosen for comparison. The experimental results show that TsmartGP can find more errors while its accuracy is also higher than Cppcheck and Clang Static Analyzer.","","","10.1109/ASE.2019.00129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952426","pointer analysis;uninitialized pointer;sensitivity;multi-entry","","","","","","12","","","","","IEEE","IEEE Conferences"
"Retrieve and Refine: Exemplar-Based Neural Comment Generation","B. Wei","Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1250","1252","Code comment generation is a crucial task in the field of automatic software development. Most previous neural comment generation systems used an encoder-decoder neural network and encoded only information from source code as input. Software reuse is common in software development. However, this feature has not been introduced to existing systems. Inspired by the traditional IR-based approaches, we propose to use the existing comments of similar source code as exemplars to guide the comment generation process. Based on an open source search engine, we first retrieve a similar code and treat its comment as an exemplar. Then we applied a seq2seq neural network to conduct an exemplar-based comment generation. We evaluate our approach on a large-scale Java corpus, and experimental results demonstrate that our model significantly outperforms the state-of-the-art methods.","","","10.1109/ASE.2019.00152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952536","comment generation;program comprehension;deep learning","","","","","","21","","","","","IEEE","IEEE Conferences"
"Humanoid: A Deep Learning-Based Approach to Automated Black-box Android App Testing","Y. Li; Z. Yang; Y. Guo; X. Chen","Peking University; Peking University; Peking University; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1070","1073","Automated input generators must constantly choose which UI element to interact with and how to interact with it, in order to achieve high coverage with a limited time budget. Currently, most black-box input generators adopt pseudo-random or brute-force searching strategies, which may take very long to find the correct combination of inputs that can drive the app into new and important states. We propose Humanoid, an automated black-box Android app testing tool based on deep learning. The key technique behind Humanoid is a deep neural network model that can learn how human users choose actions based on an app's GUI from human interaction traces. The learned model can then be used to guide test input generation to achieve higher coverage. Experiments on both open-source apps and market apps demonstrate that Humanoid is able to reach higher coverage, and faster as well, than the state-of-the-art test input generators. Humanoid is open-sourced at https://github.com/yzygitzh/Humanoid and a demo video can be found at https://youtu.be/PDRxDrkyORs.","","","10.1109/ASE.2019.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952324","software testing;automated test input generation;graphical user interface;deep learning;mobile application;Android","","","","","","14","","","","","IEEE","IEEE Conferences"
"A Machine Learning Based Approach to Identify SQL Injection Vulnerabilities","K. Zhang","Wayne State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1286","1288","This paper presents a machine learning classifier designed to identify SQL injection vulnerabilities in PHP code. Both classical and deep learning based machine learning algorithms were used to train and evaluate classifier models using input validation and sanitization features extracted from source code files. On ten-fold cross validations a model trained using Convolutional Neural Network(CNN) achieved the highest precision (95.4%), while a model based on Multilayer Perceptron(MLP) achieved the highest recall (63.7%) and the highest f-measure (0.746).","","","10.1109/ASE.2019.00164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952467","Deep learning;prediction model;SQL injection;vulnerability","","","","","","18","","","","","IEEE","IEEE Conferences"
"Test Automation and Its Limitations: A Case Study","A. Sung; S. Kim; Y. Kim; Y. Jang; J. Kim","Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1208","1209","Modern embedded systems are increasingly complex and contain multiple software layers from BSP (Board Support Packages) to OS to middleware to AI (Artificial Intelligence) algorithms like perception and voice recognition. Integrations of inter-layer and intra-layer in embedded systems provide dedicated services such as taking a picture or movie-streaming. Accordingly, it gets more complicated to find out the root cause of a system failure. This industrial proposal describes a difficulty of testing embedded systems, and presents a case study in terms of integration testing.","","","10.1109/ASE.2019.00139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952292","embedded system, software layer, integration test, test automation","","","","","","19","","","","","IEEE","IEEE Conferences"
"PHANTA: Diversified Test Code Quality Measurement for Modern Software Development","S. Tokumoto; K. Takayama","Fujitsu Laboratories Ltd.; Fujitsu Laboratories Ltd.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1206","1207","Test code is becoming more essential to the modern software development process. However, practitioners often pay inadequate attention to key aspects of test code quality, such as bug detectability, maintainability and speed. Existing tools also typically report a single test code quality measure, such as code coverage, rather than a diversified set of metrics. To measure and visualize quality of test code in a comprehensive fashion, we developed an integrated test code analysis tool called Phanta. In this show case, we posit that the enhancement of test code quality is key to modernizing software development, and show how Phanta's techniques measure the quality using mutation analysis, test code clone detection, and so on. Further, we present an industrial case study where Phanta was applied to analyze test code in a real Fujitsu project, and share lessons learned from the case study.","","","10.1109/ASE.2019.00138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952538","Software Testing;Test Code;Mutation Testing","","","","","","6","","","","","IEEE","IEEE Conferences"
"Enabling Continuous Improvement of a Continuous Integration Process","C. Vassallo","University of Zurich","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1246","1249","Continuous Integration (CI) is a widely-adopted software engineering practice. Despite its undisputed benefits, like higher software quality and improved developer productivity, mastering CI is not easy. Among the several barriers when transitioning to CI, developers need to face a new type of software failures (i.e., build failures) that requires them to understand complex build logs. Even when a team has successfully introduced a CI culture, living up to its principles and improving the CI practice are also challenging. In my research, I want to provide developers with the right support for establishing CI and the proper recommendations for continuously improving their CI process.","","","10.1109/ASE.2019.00151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952505","Continuous Integration, Build Failures, Anti patterns, Best Practices","","","","","","26","","","","","IEEE","IEEE Conferences"
"Better Development of Safety Critical Systems: Chinese High Speed Railway System Development Experience Report","Z. Wu; J. Liu; X. Chen","East China Normal University; East China Normal University; R&D Institute, CASCO Signal Ltd.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1216","1217","Ensure the correctness of safety critical systems play a key role in the worldwide software engineering. Over the past years we have been helping CASCO Signal Ltd which is the Chinese biggest high speed railway company to develop high speed railway safety critical software. We have also contributed specific methods for developing better safety critical software, including a search-based model-driven software development approach which uses SysML diagram refinement method to construct SysML model and SAT solver to check the model. This talk aims at sharing the challenge of developing high speed railway safety critical system, what we learn from develop a safety critical software with a Chinese high speed railway company, and we use ZC subsystem as a case study to show the systematic model-driven safety critical software development method.","","","10.1109/ASE.2019.00143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952294","SysML;Formal Method;Model-Driven;SAT","","","","","","7","","","","","IEEE","IEEE Conferences"
"User Preference Aware Multimedia Pricing Model using Game Theory and Prospect Theory for Wireless Communications","K. M. Kattiyan Ramamoorthy","San Diego State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1265","1267","Providing user satisfaction is a major concern for on-demand multimedia service providers and Internet carriers in Wireless Communications. Traditionally, user satisfaction was measured objectively in terms of throughput and latency. Nowadays the user satisfaction is measured using subjective metrices such as Quality of Experience (QoE). Recently, Smart Media Pricing (SMP) was conceptualized to price the QoE rather than the binary data traffic in multimedia services. In this research, we have leveraged the SMP concept to chalk up a QoE-sensitive multimedia pricing framework to allot price, based on the user preference and multimedia quality achieved by the customer. We begin by defining the utility equations for the provider-carrier and the customer. Then we translate the profit maximizing interplay between the parties into a two-stage Stackelberg game. We model the user personal preference using Prelec weighting function which follows the postulates Prospect Theory (PT). An algorithm has been developed to implement the proposed pricing scheme and determine the Nash Equilibrium. Finally, the proposed smart pricing scheme was tested against the traditional pricing method and simulation results indicate a significant boost in the utility achieved by the mobile customers.","","","10.1109/ASE.2019.00157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952218","Network Economics;Game Theory;Prospect Theory;Quality of Experience (QoE);Smart Multimedia Pricing","","","","","","11","","","","","IEEE","IEEE Conferences"
"Ares: Inferring Error Specifications through Static Analysis","C. Li; M. Zhou; Z. Gu; M. Gu; H. Zhang","Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1174","1177","Misuse of APIs happens frequently due to misunderstanding of API semantics and lack of documentation. An important category of API-related defects is the error handling defects, which may result in security and reliability flaws. These defects can be detected with the help of static program analysis, provided that error specifications are known. The error specification of an API function indicates how the function can fail. Writing error specifications manually is time-consuming and tedious. Therefore, automatic inferring the error specification from API usage code is preferred. In this paper, we present Ares, a tool for automatic inferring error specifications for C code through static analysis. We employ multiple heuristics to identify error handling blocks and infer error specifications by analyzing the corresponding condition logic. Ares is evaluated on 19 real world projects, and the results reveal that Ares outperforms the state-of-the-art tool APEx by 37% in precision. Ares can also identify more error specifications than APEx. Moreover, the specifications inferred from Ares help find dozens of API-related bugs in well-known projects such as OpenSSL, among them 10 bugs are confirmed by developers. Video: https://youtu.be/nf1QnFAmu8Q. Repository: https://github.com/lc3412/Ares.","","","10.1109/ASE.2019.00130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952222","Error Handling;Error Specification;Static Analysis","","","","","","12","","","","","IEEE","IEEE Conferences"
"Empirical Study of Python Call Graph","L. Yu","Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1274","1276","In recent years, the extensive application of the Python language has made its analysis work more and more valuable. Many static analysis algorithms need to rely on the construction of call graphs. In this paper, we did a comparative empirical analysis of several widely used Python static call graph tools both quantitatively and qualitatively. Experiments show that the existing Python static call graph tools have a large difference in the construction effectiveness, and there is still room for improvement.","","","10.1109/ASE.2019.00160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952190","Python, call graph, empirical study, quantitative, qualitative","","","","","","13","","","","","IEEE","IEEE Conferences"
"Verifying Determinism in Sequential Programs","R. Mudduluru","University of Washington","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1271","1273","A nondeterministic program is difficult to test and debug. Nondeterminism occurs even in sequential programs: for example, iterating over the elements of a hash table can result in diverging test results. We have created a type system that can express whether a computation is deterministic, nondeterministic, or ordernondeterministic (like a set). While state-of-the-art nondeterminism detection tools unsoundly rely on observing run-time output, our approach soundly verifies determinism at compile time. Our implementation found previously-unknown nondeterminism errors in a 24,000 line program that had been heavily vetted by its developers.","","","10.1109/ASE.2019.00159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952328","nondeterminism, type system, verification, specification","","","","","","9","","","","","IEEE","IEEE Conferences"
"Grading-Based Test Suite Augmentation","J. Osei-Owusu; A. Astorga; L. Butler; T. Xie; G. Challen","University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; Peking University; Ministry of Education; University of Illinois at Urbana-Champaign","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","226","229","Enrollment in introductory programming (CS1) courses continues to surge and hundreds of CS1 students can produce thousands of submissions for a single problem, all requiring timely and accurate grading. One way that instructors can efficiently grade is to construct a custom instructor test suite that compares a student submission to a reference solution over randomly generated or hand-crafted inputs. However, such test suite is often insufficient, causing incorrect submissions to be marked as correct. To address this issue, we propose the Grasa (GRAding-based test Suite Augmentation) approach consisting of two techniques. Grasa first detects and clusters incorrect submissions by approximating their behavioral equivalence to each other. To augment the existing instructor test suite, Grasa generates a minimal set of additional tests that help detect the incorrect submissions. We evaluate our Grasa approach on a dataset of CS1 student submissions for three programming problems. Our preliminary results show that Grasa can effectively identify incorrect student submissions and minimally augment the instructor test suite.","","","10.1109/ASE.2019.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952332","programming education;testing;clustering","","","","","","14","","","","","IEEE","IEEE Conferences"
"Crowdsourced Report Generation via Bug Screenshot Understanding","S. Yu","Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1277","1279","Quality control is a challenge of crowdsourcing, especially in software testing. As some unprofessional workers involved, low-quality yieldings may hinder crowdsourced testing from satisfying requesters' requirements. Therefore, it is in demand to assist crowdworkers to raise bug report quality. In this paper, we propose a novel auxiliary method, namely CroReG, to generate crowdsourcing bug reports by analyzing bug screenshots uploaded by crowdworkers with image understanding techniques. The preliminary experiment results show that CroReG can effectively generate bug reports containing accurate screenshot captions and providing positive guidance for crowdworkers.","","","10.1109/ASE.2019.00161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952296","Crowdsourced Testing;Mobile App Testing;Bug Report Generation","","","","","","11","","","","","IEEE","IEEE Conferences"
"How Do API Selections Affect the Runtime Performance of Data Analytics Tasks?","Y. Tao; S. Tang; Y. Liu; Z. Xu; S. Qin","Shenzhen University; Shenzhen University; Southern University of Science and Technology; Shenzhen University; Teesside University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","665","668","As data volume and complexity grow at an unprecedented rate, the performance of data analytics programs is becoming a major concern for developers. We observed that developers sometimes use alternative data analytics APIs to improve program runtime performance while preserving functional equivalence. However, little is known on the characteristics and performance attributes of alternative data analytics APIs. In this paper, we propose a novel approach to extracting alternative implementations that invoke different data analytics APIs to solve the same tasks. A key appeal of our approach is that it exploits the comparative structures in Stack Overflow discussions to discover programming alternatives. We show that our approach is promising, as 86% of the extracted code pairs were validated as true alternative implementations. In over 20% of these pairs, the faster implementation was reported to achieve a 10x or more speedup over its slower alternative. We hope that our study offers a new perspective of API recommendation and motivates future research on optimizing data analytics programs.","","","10.1109/ASE.2019.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952224","API selection, data analytics, performance optimization, Stack Overflow","","","","","","11","","","","","IEEE","IEEE Conferences"
"mCUTE: A Model-Level Concolic Unit Testing Engine for UML State Machines","R. Ahmadi; K. Jahed; J. Dingel","Queen's University; Queen's University; Queen's University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1182","1185","Model Driven Engineering (MDE) techniques raise the level of abstraction at which developers construct software. However, modern cyber-physical systems are becoming more prevalent and complex and hence software models that represent the structure and behavior of such systems still tend to be large and complex. These models may have numerous if not infinite possible behaviors, with complex communications between their components. Appropriate software testing techniques to generate test cases with high coverage rate to put these systems to test at the model-level (without the need to understand the underlying code generator or refer to the generated code) are therefore important. Concolic testing, a hybrid testing technique that benefits from both concrete and symbolic execution, gains a high execution coverage and is used extensively in the industry for program testing but not for software models. In this paper, we present a novel technique and its tool mCUTE1, an open source 2 model-level concolic testing engine. We describe the implementation of our tool in the context of Papyrus-RT, an open source Model Driven Engineering (MDE) tool based on UML-RT, and report the results of validating our tool using a set of benchmark models.","","","10.1109/ASE.2019.00132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952438","Concolic Testing, MDE, State machines, Unit Testing, UML","","","","","","22","","","","","IEEE","IEEE Conferences"
"LIRAT: Layout and Image Recognition Driving Automated Mobile Testing of Cross-Platform","S. Yu; C. Fang; Y. Feng; W. Zhao; Z. Chen","Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1066","1069","The fragmentation issue spreads over multiple mobile platforms such as Android, iOS, mobile web, and WeChat, which hinders test scripts from running across platforms. To reduce the cost of adapting scripts for various platforms, some existing tools apply conventional computer vision techniques to replay the same script on multiple platforms. However, because these solutions can hardly identify dynamic or similar widgets. It becomes difficult for engineers to apply them in practice. In this paper, we present an image-driven tool, namely LIRAT, to record and replay test scripts cross platforms, solving the problem of test script cross-platform replay for the first time. LIRAT records screenshots and layouts of the widgets, and leverages image understanding techniques to locate them in the replay process. Based on accurate widget localization, LIRAT supports replaying test scripts across devices and platforms. We employed LIRAT to replay 25 scripts from 5 application across 8 Android devices and 2 iOS devices. The results show that LIRAT can replay 88% scripts on Android platforms and 60% on iOS platforms. The demo can be found at: https: //github.com/YSC9848/LIRAT","","","10.1109/ASE.2019.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952513","Cross-Platform Testing;Image Recognition;Record and Replay","","","","","","11","","","","","IEEE","IEEE Conferences"
"Automatic Generation of Graphical User Interface Prototypes from Unrestricted Natural Language Requirements","K. Kolthoff","Institute for Enterprise Systems (InES), University of Mannheim","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1234","1237","High-fidelity GUI prototyping provides a meaningful manner for illustrating the developers' understanding of the requirements formulated by the customer and can be used for productive discussions and clarification of requirements and expectations. However, high-fidelity prototypes are time-consuming and expensive to develop. Furthermore, the interpretation of requirements expressed in informal natural language is often error-prone due to ambiguities and misunderstandings. In this dissertation project, we will develop a methodology based on Natural Language Processing (NLP) for supporting GUI prototyping by automatically translating Natural Language Requirements (NLR) into a formal Domain-Specific Language (DSL) describing the GUI and its navigational schema. The generated DSL can be further translated into corresponding target platform prototypes and directly provided to the user for inspection. Most related systems stop after generating artifacts, however, we introduce an intelligent and automatic interaction mechanism that allows users to provide natural language feedback on generated prototypes in an iterative fashion, which accordingly will be translated into respective prototype changes.","","","10.1109/ASE.2019.00148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952477","Graphical;User;Interface;Automatic;GUI;Generation;Processing;Natural;Language;Requirements;Intelligent;Interaction;Prototyping","","","","","","29","","","","","IEEE","IEEE Conferences"
"SPrinter: A Static Checker for Finding Smart Pointer Errors in C++ Programs","X. Ma; J. Yan; Y. Li; J. Yan; J. Zhang","Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences; Institute of Software, Chinese Academy of Sciences","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1122","1125","Smart pointers are widely used to prevent memory errors in modern C++ code. However, improper usage of smart pointers may also lead to common memory errors, which makes the code not as safe as expected. To avoid smart pointer errors as early as possible, we present a coding style checker to detect possible bad smart pointer usages during compile time, and notify programmers about bug-prone behaviors. The evaluation indicates that the currently available state-of-the-art static code checkers can only detect 25 out of 116 manually inserted errors, while our tool can detect all these errors. And we also found 521 bugs among 8 open source projects with only 4 false positives.","","","10.1109/ASE.2019.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952230","C++ Smart Pointer;Memory Error;Coding Styles","","","","","","12","","","","","IEEE","IEEE Conferences"
"PMExec: An Execution Engine of Partial UML-RT Models","M. Bagherzadeh; K. Jahed; N. Kahani; J. Dingel","Queen's University; Queen's University; Queen's University; Queen's University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1178","1181","This paper presents PMExec, a tool that supports the execution of partial UML-RT models. To this end, the tool implements the following steps: static analysis, automatic refinement, and input-driven execution. The static analysis that respects the execution semantics of UML-RT models is used to detect problematic model elements, i.e., elements that cause problems during execution due to the partiality. Then, the models are refined automatically using model transformation techniques, which mostly add decision points where missing information can be supplied. Third, the refined models are executed, and when the execution reaches the decision points, input required to continue the execution is obtained either interactively or from a script that captures how to deal with partial elements. We have evaluated PMExec using several use-cases that show that the static analysis, refinement, and application of user input can be carried out with reasonable performance, and that the overhead of approach is manageable. https://youtu.be/BRKsselcMnc Note: Interested readers can refer to [1] for a thorough discussion and evaluation of this work.","","","10.1109/ASE.2019.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952369","MDD;Partial Models;Execution;Debugging;Model level debugging;Model execution","","","","","","12","","","","","IEEE","IEEE Conferences"
"TestCov: Robust Test-Suite Execution and Coverage Measurement","D. Beyer; T. Lemberger","LMU Munich; LMU Munich","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1074","1077","We present TestCov, a tool for robust test-suite execution and test-coverage measurement on C programs. TestCov executes program tests in isolated containers to ensure system integrity and reliable resource control. The tool provides coverage statistics per test and for the whole test suite. TestCov uses the simple, XML -based exchange format for test-suite specifications that was established as standard by Test-Comp. TestCov has been successfully used in Test-Comp '19 to execute almost 9 million tests on 1720 different programs. The source code of TestCov is released under the open-source license Apache 2.0 and available at https://gitlab.com/sosy-lab/software/test-suite-validator. A full artifact, including a demonstration video, is available at https://doi.org/10.5281/zenodo.3418726.","","","10.1109/ASE.2019.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952265","Test Execution, Coverage, Test-Suite Reduction","","","","","","13","","","","","IEEE","IEEE Conferences"
"Improving Patch Quality by Enhancing Key Components of Automatic Program Repair","M. Soto","Carnegie Mellon University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1230","1233","The error repair process in software systems is, historically, a resource-consuming task that relies heavily in developer manual effort. Automatic program repair approaches enable the repair of software with minimum human interaction, therefore, mitigating the burden from developers. However, a problem automatically generated patches commonly suffer is generating low-quality patches (which overfit to one program specification, thus not generalizing to an independent oracle evaluation). This work proposes a set of mechanisms to increase the quality of plausible patches including an analysis of test suite behavior and their key characteristics for automatic program repair, analyzing developer behavior to inform the mutation operator selection distribution, and a study of patch diversity as a means to create consolidated higher quality fixes.","","","10.1109/ASE.2019.00147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952342","Automatic Program Repair, Patch Quality","","","","","","19","","","","","IEEE","IEEE Conferences"
"PTracer: A Linux Kernel Patch Trace Bot","Y. Wen; J. Cao; S. Cheng","ZTE Corporation; ZTE Corporation; ZTE Corporation","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1210","1211","We present PTracer, a Linux kernel patch trace bot based on an improved PatchNet. PTracer continuously monitors new patches in the git repository of the mainline Linux kernel, filters out unconcerned ones, classifies the rest as bug-fixing or non bug-fixing patches, and reports bug-fixing patches to the kernel experts of commercial operating systems. We use the patches in February 2019 of the mainline Linux kernel to perform the test. As a result, PTracer recommended 151 patches to CGEL kernel experts out of 5,142, and 102 of which were accepted. PTracer has been successfully applied to a commercial operating system and has the advantages of improving software quality and saving labor cost.","","","10.1109/ASE.2019.00140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952485","Linux kernel;patch identification;trace bot","","","","","","7","","","","","IEEE","IEEE Conferences"
"AutoFocus: Interpreting Attention-Based Neural Networks by Code Perturbation","N. D. Q. Bui; Y. Yu; L. Jiang","Singapore Management University; The Open University, UK; Singapore Management University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","38","41","Despite being adopted in software engineering tasks, deep neural networks are treated mostly as a black box due to the difficulty in interpreting how the networks infer the outputs from the inputs. To address this problem, we propose AutoFocus, an automated approach for rating and visualizing the importance of input elements based on their effects on the outputs of the networks. The approach is built on our hypotheses that (1) attention mechanisms incorporated into neural networks can generate discriminative scores for various input elements and (2) the discriminative scores reflect the effects of input elements on the outputs of the networks. This paper verifies the hypotheses by applying AutoFocus on the task of algorithm classification (i.e., given a program source code as input, determine the algorithm implemented by the program). AutoFocus identifies and perturbs code elements in a program systematically, and quantifies the effects of the perturbed elements on the network's classification results. Based on evaluation on more than 1000 programs for 10 different sorting algorithms, we observe that the attention scores are highly correlated to the effects of the perturbed code elements. Such a correlation provides a strong basis for the uses of attention scores to interpret the relations between code elements and the algorithm classification results of a neural network, and we believe that visualizing code elements in an input program ranked according to their attention scores can facilitate faster program comprehension with reduced code.","","","10.1109/ASE.2019.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952269","attention mechanisms, neural networks, algorithm classification, interpretability, explainability, code perturbation, program comprehension","","","","","","17","","","","","IEEE","IEEE Conferences"
"VeriAbs : Verification by Abstraction and Test Generation","M. Afzal; A. Asia; A. Chauhan; B. Chimdyalwar; P. Darke; A. Datar; S. Kumar; R. Venkatesh","Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India; Tata Research Development and Design Center, India","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1138","1141","Verification of programs continues to be a challenge and no single known technique succeeds on all programs. In this paper we present VeriAbs, a reachability verifier for C programs that incorporates a portfolio of techniques implemented as four strategies, where each strategy is a set of techniques applied in a specific sequence. It selects a strategy based on the kind of loops in the program. We analysed the effectiveness of the implemented strategies on the 3831 verification tasks from the ReachSafety category of the 8th International Competition on Software Verification (SV-COMP) 2019 and found that although classic techniques - explicit state model checking and bounded model checking, succeed on a majority of the programs, a wide range of further techniques are required to analyse the rest. A screencast of the tool is available at https://youtu.be/Hzh3PPiODwk.","","","10.1109/ASE.2019.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952452","Software Verification;Strategy Selection;Portfolio Verifier;Loop Abstraction;Array Abstraction;Bounded Model Checking;Fuzz Testing;Loop Invariant Generation;Value Analysis","","","","","","27","","","","","IEEE","IEEE Conferences"
"Trusted Software Supply Chain","K. Singi; J. C. B. R P; S. Podder; A. P. Burden","Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture, Singapore","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1212","1213","Modern software delivery happens in a geographically distributed environment and resembles like a supply chain – consists of various participants, involves various phases, needs adherence to multiple regulations and needs to maintain artifacts' integrity throughout the delivery phases. This shift in software development brings along with it several challenges ranging from communication of information/knowledge, coordination and control of teams, activities adhering to goals and policies and artifacts adhering to quality, visibility, and management. %Software development processes to be transparent, verifiable, compliant, and accountable thereby increasing software's trustworthiness. With the dispersion of centralized control over software delivery to autonomous delivery organizations, the variety of processes and tools used turns transparency into opacity as autonomous teams use different software processes, tools, and metrics, leading to issues like ineffective compliance monitoring, friction prone coordination, and lack of provenance, and thereby trust. In this paper, we present a delivery governance framework based on distributed ledger technology that uses a notion of 'software telemetry' to record data from disparate delivery partners and enables compliance monitoring and adherence, provenance and traceability, transparency, and thereby trust.","","","10.1109/ASE.2019.00141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952169","trust, supply chain, provenance, governance, compliance, integrity, smart advisors","","","","","","4","","","","","IEEE","IEEE Conferences"
"BuRRiTo: A Framework to Extract, Specify, Verify and Analyze Business Rules","P. K. Chittimalli; K. Anand; S. Pradhan; S. Mitra; C. Prakash; R. Shere; R. Naik","Tata Consultancy Services Ltd.; TCS Research; Tata Consultancy Services Ltd.; Tata Consultancy Services Ltd.; Tata Consultancy Services Ltd.; Tata Consultancy Services Ltd.; Tata Consultancy Services Ltd.; Tata Consultancy Services Ltd.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1190","1193","An enterprise system operates business by providing various services that are guided by set of certain business rules (BR) and constraints. These BR are usually written using plain Natural Language in operating procedures, terms and conditions, and other documents or in source code of legacy enterprise systems. For implementing the BR in a software system, expressing them as UML use-case specifications, or preparing for Merger & Acquisition (M&A) activity, analysts manually interpret the documents or try to identify constraints from the source code, leading to potential discrepancies and ambiguities. These issues in the software system can be resolved only after testing, which is a very tedious and expensive activity. To minimize such errors and efforts, we propose BuRRiTo framework consisting of automatic extraction of BR by mining documents and source code, ability to clean them of various anomalies like inconsistency, redundancies, conflicts, etc. and able to analyze the functional gaps present and performing semantic querying and searching.","","","10.1109/ASE.2019.00134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952315","Business Rules Extraction, Rule Document, Rule Components, SBVR, Natural Language Processing, Text Mining, Graphs, Match and Gap, Search and Query, Source Code","","","","","","20","","","","","IEEE","IEEE Conferences"
"Prema: A Tool for Precise Requirements Editing, Modeling and Analysis","Y. Huang; J. Feng; H. Zheng; J. Zhu; S. Wang; S. Jiang; W. Miao; G. Pu","East China Normal University; East China Normal University; East China Normal University; East China Normal University; East China Normal University; Eastern Michigan University; East China Normal University; Tongji University, China; East China Normal University; Shanghai Trusted Industrial Control Platform Co., Ltd, China","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1166","1169","We present Prema, a tool for Precise Requirement Editing, Modeling and Analysis. It can be used in various fields for describing precise requirements using formal notations and performing rigorous analysis. By parsing the requirements written in formal modeling language, Prema is able to get a model which aptly depicts the requirements. It also provides different rigorous verification and validation techniques to check whether the requirements meet users' expectation and find potential errors. We show that our tool can provide a unified environment for writing and verifying requirements without using tools that are not well inter-related. For experimental demonstration, we use the requirements of the automatic train protection (ATP) system of CASCO signal co. LTD., the largest railway signal control system manufacturer of China. The code of the tool cannot be released here because the project is commercially confidential. However, a demonstration video of the tool is available at https://youtu.be/BX0yv8pRMWs.","","","10.1109/ASE.2019.00128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952250","formal methods;requirements modeling;requirements verification;formal engineering methods","","","","","","18","","","","","IEEE","IEEE Conferences"
"Demystifying Application Performance Management Libraries for Android","Y. Tang; X. Zhan; H. Zhou; X. Luo; Z. Xu; Y. Zhou; Q. Yan","The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; Wuhan University; Zhejiang University; Michigan State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","682","685","Since the performance issues of apps can influence users' experience, developers leverage application performance management (APM) tools to locate the potential performance bottleneck of their apps. Unfortunately, most developers do not understand how APMs monitor their apps during the runtime and whether these APMs have any limitations. In this paper, we demystify APMs by inspecting 25 widely-used APMs that target on Android apps. We first report how these APMs implement 8 key functions as well as their limitations. Then, we conduct a large-scale empirical study on 500,000 Android apps from Google Play to explore the usage of APMs. This study has some interesting observations about existing APMs for Android, including 1) some APMs still use deprecated permissions and approaches so that they may not always work properly; 2) some app developers use APMs to collect users' privacy information.","","","10.1109/ASE.2019.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952393","Android;Application Performance Management Library;Empirical Study","","","","","","19","","","","","IEEE","IEEE Conferences"
"Generating Tests to Analyse Dynamically-Typed Programs","S. Lukasczyk","University of Passau","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1226","1229","The increasing popularity of dynamically-typed programming languages, such as JavaScript or Python, requires specific support methods for developers to avoid pitfalls arising from the dynamic nature of these languages. Static analyses are frequently used but the dynamic type systems limit their applicability. Dynamic analyses, in contrast, depend on the execution of the code under analysis, and thus depend on the quality of existing tests. This quality of the test suite can be improved by the use of automated test generation but automated test generation for dynamically-typed programming languages itself is hard due to the lack of type information in the programs. The limitations of each of these approaches will be overcome by iteratively combining test generation with static and dynamic analysis techniques for dynamically-typed programs.","","","10.1109/ASE.2019.00146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952500","Dynamic Analysis;Static Analysis;Python;Type Inference;Test Generation","","","","","","32","","","","","IEEE","IEEE Conferences"
"DeepMutation++: A Mutation Testing Framework for Deep Learning Systems","Q. Hu; L. Ma; X. Xie; B. Yu; Y. Liu; J. Zhao","Kyushu University, Japan; Kyushu University, Japan; Nanyang Technological University, Singapore; Kyushu University, Japan; Nanyang Technological University, Singapore; Kyushu University, Japan","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1158","1161","Deep neural networks (DNNs) are increasingly expanding their real-world applications across domains, e.g., image processing, speech recognition and natural language processing. However, there is still limited tool support for DNN testing in terms of test data quality and model robustness. In this paper, we introduce a mutation testing-based tool for DNNs, DeepMutation++, which facilitates the DNN quality evaluation, supporting both feed-forward neural networks (FNNs) and stateful recurrent neural networks (RNNs). It not only enables to statically analyze the robustness of a DNN model against the input as a whole, but also allows to identify the vulnerable segments of a sequential input (e.g. audio input) by runtime analysis. It is worth noting that DeepMutation++ specially features the support of RNNs mutation testing. The tool demo video can be found on the project website https://sites.google.com/view/deepmutationpp.","","","10.1109/ASE.2019.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952248","deep learning;mutation testing","","","","","","11","","","","","IEEE","IEEE Conferences"
"NeuralVis: Visualizing and Interpreting Deep Learning Models","X. Zhang; Z. Yin; Y. Feng; Q. Shi; J. Liu; Z. Chen","Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1106","1109","Deep Neural Network(DNN) techniques have been prevalent in software engineering. They are employed to facilitate various software engineering tasks and embedded into many software applications. However, because DNNs are built upon a rich data-driven programming paradigm that employs plenty of labeled data to train a set of neurons to construct the internal system logic, analyzing and understanding their behaviors becomes a difficult task for software engineers. In this paper, we present an instance-based visualization tool for DNN, namely NeuralVis, to support software engineers in visualizing and interpreting deep learning models. NeuralVis is designed for: 1). visualizing the structure of DNN models, i.e., neurons, layers, as well as connections; 2). visualizing the data transformation process; 3). integrating existing adversarial attack algorithms for test input generation; 4). comparing intermediate layers' outputs of different inputs. To demonstrate the effectiveness of NeuralVis, we design a task-based user study involving ten participants on two classic DNN models, i.e., LeNet and VGG-12. The result shows NeuralVis can assist engineers in identifying critical features that determine the prediction results. Video: https://youtu.be/solkJri4Z44","","","10.1109/ASE.2019.00113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952427","Visualization;Neural Network Visualization;Program Comprehension","","","","","","14","","","","","IEEE","IEEE Conferences"
"Improving Collaboration Efficiency in Fork-Based Development","S. Zhou","Carnegie Mellon University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1218","1221","Fork-based development is a lightweight mechanism that allows developers to collaborate with or without explicit coordination. Although it is easy to use and popular, when developers each create their own fork and develop independently, their contributions are usually not easily visible to others. When the number of forks grows, it becomes very difficult to maintain an overview of what happens in individual forks, which would lead to additional problems and inefficient practices: lost contributions, redundant development, fragmented communities, and so on. Facing the problems mentioned above, we developed two complementary strategies: (1) Identifying existing best practices and suggesting evidence-based interventions for projects that are inefficient; (2) designing new interventions that could improve the awareness of a community using fork-based development, and help developers to detect redundant development to reduce unnecessary effort.","","","10.1109/ASE.2019.00144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952395","Fork-based Development, Distributed Collaboration, Awareness of Collaboration, Open-Source Community","","","","","","14","","","","","IEEE","IEEE Conferences"
"An Approach for Investigating Emotion Dynamics in Software Development","K. Neupane","Rochester Institute of Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1268","1270","Emotion awareness is critical to interpersonal communication, including that in software development. The SE community has studied emotion in software development using isolated emotion states but it has not considered the dynamic nature of emotion. To investigate the emotion dynamics, SE community needs an effective approach. In this paper, we propose such an approach which can automatically collect project teams' communication records, identify the emotions and their intensities in them, model the emotion dynamics into time series, and provide efficient data management. We demonstrate that this approach can provide end-to-end support for various emotion awareness research and practices through automated data collection, modeling, storage, analysis, and presentation using the IPython's project data on GitHub.","","","10.1109/ASE.2019.00158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952358","Emotion dynamics, emotion awareness, emotion intensity, software development, time-series database","","","","","","13","","","","","IEEE","IEEE Conferences"
"Inference of Properties from Requirements and Automation of Their Formal Verification","M. Reich","Chemnitz University of Technology, Airbus Defence and Space GmbH","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1222","1225","Over the past decades, various techniques for the application of formal program analysis of software for embedded systems have been proposed. However, the application of formal methods for software verification is still limited in practise. It is acknowledged that the task of formally stating requirements by specifying the formal properties is a major hindrance. The verification step itself has its shortcoming in its scalability and its limitation to predefined proof tactics in case of automated theorem proving (ATP). These constraints are reduced today by the interaction of the user with the theorem prover (TP) during the execution of the proof. However, this is difficult for non-experts. The objectives of the presented PhD project are the automated inference of declarative property specifications from example data specified by the engineer for a function under development and their automated verification on abstract model level and on code level. We propose the meta-model for Scenario Modeling Language (SML) that allows to specify example data. For the automated property generation we are motivated by Inductive Logic Programming (ILP) techniques for first-order logic in pure mathematics. We propose modifications to its algorithm that allow to process the information that is incorporated in the meta-model of SML. However, this technique is expected to produce too many uninteresting properties. To turn this weakness into strength, our approach proposes to tailor the algorithm towards selection of the right properties that facilitate the automation of the proof. Automated property generation and less user interaction with the prover will leverage formal verification as it will relieve the engineer in the specification as well as in proofing tasks.","","","10.1109/ASE.2019.00145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952397","embedded systems, formal verification, specification mining, formal properties, declarative requirement specification","","","","","","36","","","","","IEEE","IEEE Conferences"
"Compile-Time Detection of Machine Image Sniping","M. Kellogg","Paul G. Allen University of Washington","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1256","1258","Machine image sniping is a difficult-to-detect security vulnerability in cloud computing code. When programmatically initializing a machine, a developer specifies a machine image (operating system and file system). The developer should restrict the search to only those machine images which their organization controls: otherwise, an attacker can insert a similarly-named malicious image into the public database, where it might be selected instead of the image the developer intended. We present a lightweight type and effect system that detects requests to a cloud provider that are vulnerable to an image sniping attack, or proves that no vulnerable request exists in a codebase. We prototyped our type system for Java programs that initialize Amazon Web Services machines, and evaluated it on more than 500 codebases, detecting 14 vulnerable requests with only 3 false positives.","","","10.1109/ASE.2019.00154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952221","pluggable types, AMI sniping, AWS, EC2, Java, lightweight verification, DescribeImagesRequest","","","","","","8","","","","","IEEE","IEEE Conferences"
"Boosting Neural Commit Message Generation with Code Semantic Analysis","S. Jiang","Fudan University, China","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1280","1282","It has been long suggested that commit messages can greatly facilitate code comprehension. However, developers may not write good commit messages in practice. Neural machine translation (NMT) has been suggested to automatically generate commit messages. Despite the efforts in improving NMT algorithms, the quality of the generated commit messages is not yet satisfactory. This paper, instead of improving NMT algorithms, suggests that proper preprocessing of code changes into concise inputs is quite critical to train NMT. We approach it with semantic analysis of code changes. We collect a real-world dataset with 50k+ commits of popular Java projects, and verify our idea with comprehensive experiments. The results show that preprocessing inputs with code semantic analysis can improve NMT significantly. This work sheds light to how to apply existing DNNs designed by the machine learning community, e.g., NMT models, to complete software engineering tasks.","","","10.1109/ASE.2019.00162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952539","Neural machine translation (NMT);Commit message generation;Deep learning","","","","","","38","","","","","IEEE","IEEE Conferences"
"FPChecker: Detecting Floating-Point Exceptions in GPU Applications","I. Laguna","Lawrence Livermore National Laboratory","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1126","1129","Floating-point arithmetic is widely used in applications from several fields including scientific computing, machine learning, graphics, and finance. Many of these applications are rapidly adopting the use of GPUs to speedup computations. GPUs, however, have limited support to detect floating-point exceptions, which hinders the development of reliable applications in GPU-based systems. We present FPCHECKER, the first tool to automatically detect floating-point exceptions in GPU applications. FPCHECKER uses the clang/LLVM compiler to instrument GPU kernels and to detect exceptions at runtime. Once an exception is detected, it reports to the programmer the code location of the exception as well as other useful information. The programmer can then use this report to avoid the exception, e.g., by modifying the application algorithm or changing the input. We present the design of FPCHECKER, an evaluation of the overhead of the tool, and a real-world case scenario on which the tool is used to identify a hidden exception. The slowdown of FPCHECKER is moderate and the code is publicly available as open source.","","","10.1109/ASE.2019.00118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952258","Floating-point arithmetic;exceptions;GPU;scientific computing","","","","","","6","","","","","IEEE","IEEE Conferences"
"A Journey Towards Providing Intelligence and Actionable Insights to Development Teams in Software Delivery","V. S. Sharma; R. Mehra; S. Podder; A. P. Burden","Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture, Singapore","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1214","1215","For delivering high-quality artifacts within the budget and on schedule, software delivery teams ideally should have a holistic and in-process view of the current health and future trajectory of the project. However, such insights need to be at the right level of granularity and need to be derived typically from a heterogeneous project environment, in a way that helps development team members with their tasks at hand. Due to client mandates, software delivery project environments employ many disparate tools and teams tend to be distributed, thus making the relevant information retrieval, insight generation, and developer intelligence augmentation process fairly complex. In this paper, we discuss our journey in this area spanning across facets like software project modelling and new development metrics, studying developer priorities, adoption of new metrics, and different approaches of developer intelligence augmentation. Finally, we present our exploration of new immersive technologies for human-centered software engineering.","","","10.1109/ASE.2019.00142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952441","Software Delivery, Software Analytics, Project Management, Actionable Insights","","","","","","10","","","","","IEEE","IEEE Conferences"
"Pangolin: An SFL-Based Toolset for Feature Localization","B. Castro; A. Perez; R. Abreu","IST, University of Lisbon; Palo Alto Research Center; IST, University of Lisbon and INESC-ID","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1130","1133","Pinpointing the location where a given unit of functionality-or feature-was implemented is a demanding and time-consuming task, yet prevalent in most software maintenance or evolution efforts. To that extent, we present PANGOLIN, an Eclipse plugin that helps developers identifying features among the source code. It borrows Spectrum-based Fault Localization techniques from the software diagnosis research field by framing feature localization as a diagnostic problem. PANGOLIN prompts users to label system executions based on feature involvement, and subsequently presents its spectrum-based feature localization analysis to users with the aid of a color-coded, hierarchic, and navigable visualization which was shown to be effective at conveying diagnostic information to users. Our evaluation shows that PANGOLIN accurately pinpoints feature implementations and is resilient to misclassifications by users. The tool can be downloaded at https://tqrg.github.io/pangolin/.","","","10.1109/ASE.2019.00119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952297","Spectrum-based Fault Localization;Program Understanding;Maintenance and Evolution","","","","","","10","","","","","IEEE","IEEE Conferences"
"SWAN_ASSIST: Semi-Automated Detection of Code-Specific, Security-Relevant Methods","G. Piskachev; L. Nguyen Quang Do; O. Johnson; E. Bodden","Fraunhofer IEM; Paderborn University; Fraunhofer IEM; Paderborn University and Fraunhofer IEM","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1094","1097","To detect specific types of bugs and vulnerabilities, static analysis tools must be correctly configured with security-relevant methods (SRM), e.g., sources, sinks, sanitizers and authentication methods–usually a very labour-intensive and error-prone process. This work presents the semi-automated tool SWAN_ASSIST, which aids the configuration with an IntelliJ plugin based on active machine learning. It integrates our novel automated machine-learning approach SWAN, which identifies and classifies Java SRM. SWAN_ASSIST further integrates user feedback through iterative learning. SWAN_ASSIST aids developers by asking them to classify at each point in time exactly those methods whose classification best impact the classification result. Our experiments show that SWAN_ASSIST classifies SRM with a high precision, and requires a relatively low effort from the user. A video demo of SWAN_ASSIST can be found at https://youtu.be/fSyD3V6EQOY. The source code is available at https://github.com/secure-software-engineering/swan.","","","10.1109/ASE.2019.00110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952264","Program Analysis;Security;Machine-Learning","","","","","","9","","","","","IEEE","IEEE Conferences"
"Kotless: A Serverless Framework for Kotlin","V. Tankov; Y. Golubev; T. Bryksin","JetBrains; JetBrains Research; JetBrains Research","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1110","1113","Recent trends in Web development demonstrate an increased interest in serverless applications, i.e. applications that utilize computational resources provided by cloud services on demand instead of requiring traditional server management. This approach enables better resource management while being scalable, reliable, and cost-effective. However, it comes with a number of organizational and technical difficulties which stem from the interaction between the application and the cloud infrastructure, for example, having to set up a recurring task of reuploading updated files. In this paper, we present Kotless — a Kotlin Serverless Framework. Kotless is a cloud-agnostic toolkit that solves these problems by interweaving the deployed application into the cloud infrastructure and automatically generating the necessary deployment code. This relieves developers from having to spend their time integrating and managing their applications instead of developing them. Kotless has proven its capabilities and has been used to develop several serverless applications already in production. Its source code is available at https://github.com/JetBrains/kotless, a tool demo can be found at https://www.youtube.com/watch?v=IMSakPNl3TY.","","","10.1109/ASE.2019.00114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952482","Kotlin;Serverless;Web;Framework;Kotless;Cloud","","","","","","8","","","","","IEEE","IEEE Conferences"
"Towards Comprehensible Representation of Controllers using Machine Learning","G. Balasubramaniam","Birla Institute of Technology and Science, Pilani, Goa, India","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1283","1285","From the point of view of a software engineer, having safe and optimal controllers for real life systems like cyber physical systems is a crucial requirement before deployment. Given the mathematical model of these systems along with their specifications, model checkers can be used to synthesize controllers for them. The given work proposes novel approaches for making controller analysis easier by using machine learning to represent the controllers synthesized by model checkers in a succinct manner, while also incorporating the domain knowledge of the system. It also proposes the implementation of a visualization tool which will be integrated into existing model checkers. A lucid controller representation along with a tool to visualize it will help the software engineer debug and monitor the system much more efficiently.","","","10.1109/ASE.2019.00163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952374","Cyber Physical Systems, Controller Synthesis, Model Checking, Machine Learning, Inductive Logic Programming, Domain Knowledge, Strategy Representation","","","","","","17","","","","","IEEE","IEEE Conferences"
"FogWorkflowSim: An Automated Simulation Toolkit for Workflow Performance Evaluation in Fog Computing","X. Liu; L. Fan; J. Xu; X. Li; L. Gong; J. Grundy; Y. Yang","Deakin University; Anhui University; Anhui University; Anhui University; Anhui University; Monash University; Swinburne University of Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1114","1117","Workflow underlies most process automation software, such as those for product lines, business processes, and scientific computing. However, current Cloud Computing based workflow systems cannot support real-time applications due to network latency, which limits their application in many IoT systems such as smart healthcare and smart traffic. Fog Computing extends the Cloud by providing virtualized computing resources close to the End Devices so that the response time of accessing computing resources can be reduced significantly. However, how to most effectively manage heterogeneous resources and different computing tasks in the Fog is a big challenge. In this paper, we introduce ""FogWorkflowSim"" an efficient and extensible toolkit for automatically evaluating resource and task management strategies in Fog Computing with simulated user-defined workflow applications. Specifically, FogWorkflowSim is able to: 1) automatically set up a simulated Fog Computing environment for workflow applications; 2) automatically execute user submitted workflow applications; 3) automatically evaluate and compare the performance of different computation offloading and task scheduling strategies with three basic performance metrics, including time, energy and cost. FogWorkflowSim can serve as an effective experimental platform for researchers in Fog based workflow systems as well as practitioners interested in adopting Fog Computing and workflow systems for their new software projects. (Demo video: https://youtu.be/AsMovcuSkx8)","","","10.1109/ASE.2019.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952516","Fog Computing;Workflow;Performance Evaluation;Task Scheduling;Simulation Toolkit","","","","","","12","","","","","IEEE","IEEE Conferences"
"An Image-Inspired and CNN-Based Android Malware Detection Approach","X. Xiao","Case Western Reserve University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1259","1261","Abstract-Until 2017, Android smartphones occupied approximately 87% of the smartphone market. The vast market also promotes the development of Android malware. Nowadays, the number of malware targeting Android devices found daily is more than 38,000. With the rapid progress of mobile application programming and anti-reverse-engineering techniques, it is harder to detect all kinds of malware. To address challenges in existing detection techniques, such as data obfuscation and limited code coverage, we propose a detection approach that directly learns features of malware from Dalvik bytecode based on deep learning technique (CNN). The average detection time of our model is0.22 seconds, which is much lower than other existing detection approaches. In the meantime, the overall accuracy of our model achieves over 93%.","","","10.1109/ASE.2019.00155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952484","Android Malware Detection;Deep learning;CNN","","","","","","18","","","","","IEEE","IEEE Conferences"
"CONVUL: An Effective Tool for Detecting Concurrency Vulnerabilities","R. Meng; B. Zhu; H. Yun; H. Li; Y. Cai; Z. Yang","State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences; GuardStrike Inc.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1154","1157","Concurrency vulnerabilities are extremely harmful and can be frequently exploited to launch severe attacks. Due to the non-determinism of multithreaded executions, it is very difficult to detect them. Recently, data race detectors and techniques based on maximal casual model have been applied to detect concurrency vulnerabilities. However, the former are ineffective and the latter report many false negatives. In this paper, we present CONVUL, an effective tool for concurrency vulnerability detection. CONVUL is based on exchangeable events, and adopts novel algorithms to detect three major kinds of concurrency vulnerabilities. In our experiments, CONVUL detected 9 of 10 known vulnerabilities, while other tools only detected at most 2 out of these 10 vulnerabilities. The 10 vulnerabilities are available at https://github.com/mryancai/ConVul.","","","10.1109/ASE.2019.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952233","Concurrency;Vulnerabilities","","","","","","15","","","","","IEEE","IEEE Conferences"
"Automatically Repairing Binary Programs Using Adapter Synthesis","V. Sharma","University of Minnesota","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1238","1241","Bugs in commercial software and third-party components are an undesirable and expensive phenomenon. Such software is usually released to users only in binary form. The lack of source code renders users of such software dependent on their software vendors for repairs of bugs. Such dependence is even more harmful if the bugs introduce new vulnerabilities in the software. Automatically repairing security and functionality bugs in binary code increases software robustness without any developer effort. In this research, we propose development of a binary program repair tool that uses existing bug-free fragments of code to repair buggy code.","","","10.1109/ASE.2019.00149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952199","automated program repair;symbolic execution;binary analysis;adapter synthesis","","","","","","24","","","","","IEEE","IEEE Conferences"
"Visual Analytics for Concurrent Java Executions","C. Artho; M. Pande; Q. Tang","KTH Royal Institute of Technology; KTH Royal Institute of Technology; Imperial College London","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1102","1105","Analyzing executions of concurrent software is very difficult. Even if a trace is available, such traces are very hard to read and interpret. A textual trace contains a lot of data, most of which is not relevant to the issue at hand. Past visualization attempts either do not show concurrent behavior, or result in a view that is overwhelming for the user. We provide a visual analytics tool, VA4JVM, for error traces produced by either the Java Virtual Machine, or by Java Pathfinder. Its key features are a layout that spatially associates events with threads, a zoom function, and the ability to filter event data in various ways. We show in examples how filtering and zooming in can highlight a problem without having to read lengthy textual data.","","","10.1109/ASE.2019.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952488","Execution trace visualization;Visual analytics","","","","","","32","","","","","IEEE","IEEE Conferences"
"Tackling Build Failures in Continuous Integration","F. Hassan","University of Texas at San Antonio","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1242","1245","In popular continuous integration(CI) practice, coding is followed by building, integration and system testing, pre-release inspection, and deploying artifacts. This can reduce integration risk and speed up the development process. But large number of CI build failures may interrupt the normal software development process. So, the failures need to be analyzed and fixed quickly. Although various automated program repair techniques have great potential to resolve software failures, the existing techniques mostly focus on repairing source code. So, those techniques cannot directly help resolve software build failures. Apart from that, a special challenge to fix build failures in CI environment is that the failures are often involved with both source code and build scripts. This paper outlines promising preliminary work towards automatic build repair in CI environment that involves both source code and build script. As the first step, we conducted an empirical study on software build failures and build fix patterns. Based on the findings of the empirical study, we developed an approach that can automatically fix build errors involving build scripts. We plan to extend this repair approach considering both source code and build script. Moreover, we plan to quantify our automatic fixes by user study and comparison between fixes generated by our approach and actual fixes.","","","10.1109/ASE.2019.00150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952416","build failures, build repair, continuous integration","","","","","","21","","","","","IEEE","IEEE Conferences"
"API Design Implications of Boilerplate Client Code","D. Nam","Carnegie Mellon University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1253","1255","Designing usable APIs is critical to developers' productivity and software quality but is quite difficult. In this paper, I focus on ""boilerplate"" code, sections of code that have to be included in many places with little or no alteration, which many experts in API design have said can be an indicator of API usability problems. I investigate what properties make code count as boilerplate, and present a novel approach to automatically mine boilerplate code from a large set of client code. The technique combines an existing API usage mining algorithm, with novel filters using AST comparison and graph partitioning. With boilerplate candidates identified by the technique, I discuss how this technique could help API designers in reviewing their design decisions and identifying usability issues.","","","10.1109/ASE.2019.00153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952241","Boilerplate Code;API Usability;Repository Mining","","","","","","20","","","","","IEEE","IEEE Conferences"
"Manticore: A User-Friendly Symbolic Execution Framework for Binaries and Smart Contracts","M. Mossberg; F. Manzano; E. Hennenfent; A. Groce; G. Grieco; J. Feist; T. Brunson; A. Dinaburg","Trail of Bits; Trail of Bits; Trail of Bits; Trail of Bits; Trail of Bits; Trail of Bits; Trail of Bits; Trail of Bits","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1186","1189","An effective way to maximize code coverage in software tests is through dynamic symbolic execution—a technique that uses constraint solving to systematically explore a program's state space. We introduce an open-source dynamic symbolic execution framework called Manticore for analyzing binaries and Ethereum smart contracts. Manticore's flexible architecture allows it to support both traditional and exotic execution environments, and its API allows users to customize their analysis. Here, we discuss Manticore's architecture and demonstrate the capabilities we have used to find bugs and verify the correctness of code for our commercial clients.","","","10.1109/ASE.2019.00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952204","manticore;mcore;symbolic execution;ethereum;smart contract","","","","","","19","","","","","IEEE","IEEE Conferences"
"Lancer: Your Code Tell Me What You Need","S. Zhou; B. Shen; H. Zhong","Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1202","1205","Programming is typically a difficult and repetitive task. Programmers encounter endless problems during programming, and they often need to write similar code over and over again. To prevent programmers from reinventing wheels thus increase their productivity, we propose a context-aware code-to-code recommendation tool named Lancer. With the support of a Library-Sensitive Language Model (LSLM) and the BERT model, Lancer is able to automatically analyze the intention of the incomplete code and recommend relevant and reusable code samples in real-time. A video demonstration of Lancer can be found at https://youtu.be/tO9nhqZY35g. Lancer is open source and the code is available at https://github.com/sfzhou5678/Lancer.","","","10.1109/ASE.2019.00137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952168","Code recommendation;Code reuse;Language model","","","","","","18","","","","","IEEE","IEEE Conferences"
"MutAPK: Source-Codeless Mutant Generation for Android Apps","C. Escobar-Velásquez; M. Osorio-Riaño; M. Linares-Vásquez","Universidad de los Andes; Universidad de los Andes; Universidad de los Andes","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1090","1093","The amount of Android application is having a tremendous increasing trend, exerting pressure over practitioners and researchers around application quality, frequent releases, and quick fixing of bugs. This pressure leads practitioners to make usage of automated approaches based on using source-code as input. Nevertheless, third-party services are not able to use these approaches due to privacy factors. In this paper we present MutAPK, an open source mutation testing tool that enables the usage of APK as input for this task. MutAPK generates mutants without the need of having access to source code, because the mutations are done in an intermediate representation of the code (i.e., SMALI) that does not require compilation. MutAPK is publicly available at GitHub: https://bit.ly/2KYvgP9 VIDEO: https://bit.ly/2WOjiyy","","","10.1109/ASE.2019.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952526","Mutation Testing, Closed Source Apps, Android","","","","","","15","","","","","IEEE","IEEE Conferences"
"Developer Reputation Estimator (DRE)","S. Amreen; A. Karnauch; A. Mockus","The University of Tennessee; The University of Tennessee; The University of Tennessee","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1082","1085","Evidence shows that developer reputation is extremely important when accepting pull requests or resolving reported issues. It is particularly salient in Free/Libre Open Source Software since the developers are distributed around the world, do not work for the same organization and, in most cases, never meet face to face. The existing solutions to expose developer reputation tend to be forge specific (GitHub), focus on activity instead of impact, do not leverage social or technical networks, and do not correct often misspelled developer identities. We aim to remedy this by amalgamating data from all public Git repositories, measuring the impact of developer work, expose developer's collaborators, and correct notoriously problematic developer identity data. We leverage World of Code (WoC), a collection of an almost complete (and continuously updated) set of Git repositories by first allowing developers to select which of the 34 million(M) Git commit author IDs belong to them and then generating their profiles by treating the selected collection of IDs as that single developer. As a side-effect, these selections serve as a training set for a supervised learning algorithm that merges multiple identity strings belonging to a single individual. As we evaluate the tool and the proposed impact measure, we expect to build on these findings to develop reputation badges that could be associated with pull requests and commits so developers could easier trust and prioritize them.","","","10.1109/ASE.2019.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952390","Developer Reputation;Software Ecosystem;Identity Disambiguation","","","","","","7","","","","","IEEE","IEEE Conferences"
"CocoQa: Question Answering for Coding Conventions Over Knowledge Graphs","T. Du; J. Cao; Q. Wu; W. Li; B. Shen; Y. Chen","Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1086","1089","Coding convention plays an important role in guaranteeing software quality. However, coding conventions are usually informally presented and inconvenient for programmers to use. In this paper, we present CocoQa, a system that answers programmer's questions about coding conventions. CocoQa answers questions by querying a knowledge graph for coding conventions. It employs 1) a subgraph matching algorithm that parses the question into a SPARQL query, and 2) a machine comprehension algorithm that uses an end-to-end neural network to detect answers from searched paragraphs. We have implemented CocoQa, and evaluated it on a coding convention QA dataset. The results show that CocoQa can answer questions about coding conventions precisely. In particular, CocoQa can achieve a precision of 82.92% and a recall of 91.10%. Repository: https://github.com/14dtj/CocoQa/ Video: https://youtu.be/VQaXi1WydAU","","","10.1109/ASE.2019.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952314","Coding convention;question answering;knowledge graph","","","","","","15","","","","","IEEE","IEEE Conferences"
"MuSC: A Tool for Mutation Testing of Ethereum Smart Contract","Z. Li; H. Wu; J. Xu; X. Wang; L. Zhang; Z. Chen","Nanjing University; Nanjing University; Nanjing University; Nanjing University; University of Texas at Dallas; Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1198","1201","The smart contract cannot be modified when it has been deployed on a blockchain. Therefore, it must be given thorough test before its being deployed. Mutation testing is considered as a practical test methodology to evaluate the adequacy of software testing. In this paper, we introduce MuSC, a mutation testing tool for Ethereum Smart Contract (ESC). It can generate numerous mutants at a fast speed and supports the automatic operations such as creating test nets, deploying and executing tests. Specially, MuSC implements a set of novel mutation operators w.r.t ESC programming language, Solidity. Therefore, it can expose the defects of smart contracts to a certain degree. The demonstration video of MuSC is available at https: //youtu.be/3KBKXJPVjbQ, and the source code can be downloaded at https://github.com/belikout/MuSC-Tool-Demo-repo.","","","10.1109/ASE.2019.00136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952206","Blockchain;Ethereum-Smart-Contract;Mutation-Test;Mutation-Operator","","","","","","20","","","","","IEEE","IEEE Conferences"
"SiMPOSE - Configurable N-Way Program Merging Strategies for Superimposition-Based Analysis of Variant-Rich Software","D. Reuling; U. Kelter; S. Ruland; M. Lochau","University of Siegen; University of Siegen; Real-Time Systems Lab, TU Darmstadt; Real-Time Systems Lab, TU Darmstadt","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1134","1137","Modern software often exists in many different, yet similar versions and/or variants, usually derived from a common code base (e.g., via clone-and-own). In the context of product-line engineering, family-based analysis has shown very promising potential for improving efficiency in applying quality-assurance techniques to variant-rich software, as compared to a variant-by-variant approach. Unfortunately, these strategies rely on a product-line representation superimposing all program variants in a syntactically well-formed, semantically sound and variant-preserving manner, which is manually hard to obtain in practice. We demonstrate the SiMPOSE methodology for automatically generating superimpositions of N given program versions and/or variants facilitating family-based analysis of variant-rich software. SiMPOSE is based on a novel N-way model-merging technique operating at the level of control-flow automata (CFA) representations of C programs. CFAs constitute a unified program abstraction utilized by many recent software-analysis tools. We illustrate different merging strategies supported by SiMPOSE, namely variant-by-variant, N-way merging, incremental 2-way merging, and partition-based N/2-way merging, and demonstrate how SiMPOSE can be used to systematically compare their impact on efficiency and effectiveness of family-based unit-test generation. The SiMPOSE tool, the demonstration of its usage as well as related artifacts and documentation can be found at http://pi.informatik.uni-siegen.de/projects/variance/simpose.","","","10.1109/ASE.2019.00120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952245","Program Merging;Model Merging;Software Testing;Family-Based Analyses","","","","","","12","","","","","IEEE","IEEE Conferences"
"Towards search-based modelling and analysis of requirements and architecture decisions","S. A. Busari","Software Systems Engineering, Department of Computer Science, University College London, United Kingdom","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1026","1029","Many requirements engineering and software architecture decisions are complicated by uncertainty and multiple conflicting stakeholders objectives. Using quantitative decision models helps clarify these decisions and allows the use of multi-objective simulation optimisation techniques in analysing the impact of decisions on objectives. Existing requirements and architecture decision support methods that use quantitative decision models are limited by the difficulty in elaborating problem-specific decision models and/or lack integrated tool support for automated decision analysis under uncertainty. To address these problems and facilitate requirements and architecture decision analysis, this research proposes a novel modelling language and automated decision analysis technique, implemented in a tool called RADAR. The modelling language is a simplified version of quantitative AND/OR goal models used in requirements engineering and similar to feature models used in software product lines. This research involves developing the RADAR tool and evaluating the tool's applicability, usefulness and scalability on a set of real-world examples.","","","10.1109/ASE.2017.8115725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115725","","Analytical models;Radar;Tools;Decision analysis;Stakeholders;Uncertainty","decision making;decision support systems;production engineering computing;software architecture","requirements engineering;software architecture decisions;multiple conflicting stakeholders objectives;quantitative decision models;multiobjective simulation optimisation techniques;architecture decision support methods;problem-specific decision models;architecture decision analysis;automated decision analysis technique;quantitative goal models;feature models;search-based modelling a;RADAR tool;software product lines","","1","26","","","","","IEEE","IEEE Conferences"
"Tool Support for Analyzing Mobile App Reviews","P. M. Vu; H. V. Pham; T. T. Nguyen; T. T. Nguyen","Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","789","794","Mobile app reviews often contain useful user opinions for app developers. However, manual analysis of those reviews is challenging due to their large volume and noisynature. This paper introduces MARK, a supporting tool for review analysis of mobile apps. With MARK, an analyst can describe her interests of one or more apps via a set of keywords. MARK then lists the reviews most relevant to those keywords for further analyses. It can also draw the trends over time of the selected keywords, which might help the analyst to detect sudden changes in the related user reviews. To help the analyst describe her interests more effectively, MARK can automatically extract and rank the keywords by their associations with negative reviews, divide a large set of keywords into more cohesive subgroups, or expand a small set into a broader one.","","","10.1109/ASE.2015.101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372068","App Review;Opinion Mining;Keyword","Facebook;Market research;Batteries;Energy consumption;Mobile communication;Google;Semantics","data mining;mobile computing;software reviews;text analysis","mobile app reviews;MARK;online reviews;Mining and Analyzing Reviews by Keywords tool","","3","11","","","","","IEEE","IEEE Conferences"
"The challenges of verification and validation of automated planning systems (keynote)","J. Frank","NASA Ames Research Center, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","2","2","Mission planning is central to space mission operations, and has benefited from advances in model-based planning software. A model is a description of the objects, actions, constraints and preferences that the planner reasons over to generate plans. Developing, verifying and validating a planning model is, however, a difficult task. Mission planning constraints and preferences arise from many sources, including simulators and engineering specification documents. As mission constraints evolve, planning domain modelers must add and update model constraints efficiently using the available source data, catching errors quickly, and correcting the model. The consequences of erroneous models are very high, especially in the space operations environment. We first describe the space operations environment, particularly the role of the mission planning system. We then describe model-based planning, and briefly review the current state of the practice in designing model-based mission planning tools and the challenges facing model developers. We then describe an Interactive Model Development Environment (IMDE) approach to developing mission planning systems. This approach integrates modeling and simulation environments to reduce model editing time, generate simulations automatically to evaluate plans, and identify modeling errors automatically by evaluating simulation output. The IMDE approach was tested on a small subset of the Lunar Atmosphere and Dust Environment Explorer (LADEE) flight software to demonstrate how to develop the LADEE mission planning system.","","","10.1109/ASE.2013.6693059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693059","","","","","","","","","","","","IEEE","IEEE Conferences"
"Keynotes","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xxiii","xxv","Provides an abstract for each of the keynote presentations and may include a brief professional biography of each","","","10.1109/ASE.2015.113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371988","","","","","","","","","","","","IEEE","IEEE Conferences"
"LED: Tool for Synthesizing Web Element Locators","K. Bajaj; K. Pattabiraman; A. Mesbah","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","848","851","Web applications are growing fast in popularity and complexity. One of the major problems faced by web developers is writing JavaScript code that can retrieve Document Object Model (DOM) tree elements, and is consistent among multiple DOM states. We attempt to solve this problem by automatically synthesizing JavaScript code that interacts with the DOM. We present an automated tool called LED, to analyze the DOM elements, and synthesize code to select the DOM elements based on the DOM hierarchy as well as the nature of task that the user wants to perform. LED provides an interactive drag and drop support inside the browser for selecting positive and negative examples of DOM elements. We find that LED supports at least 86% of the locators used in the JavaScript code of deployed web applications, and that the locators synthesized by LED have a recall of 98% and a precision of 63%. LED is fast, taking only 0.23 seconds on average to synthesize a locator.","","","10.1109/ASE.2015.110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372078","Program synthesis;Programming by example;Element locators;CSS selectors;Web applications","Light emitting diodes;Cascading style sheets;Automation;Writing;Browsers;Mice;Selenium","Internet;Java;object-oriented methods;program diagnostics;trees (mathematics)","LED;Web element locator;Web application;Web developer;JavaScript code;document object model tree element;DOM tree element;DOM state;automated tool;DOM element","","","14","","","","","IEEE","IEEE Conferences"
"The bounded model checker LLBMC","S. Falke; F. Merz; C. Sinz","Institute for Theoretical Computer Science, Karlsruhe Institute of Technology (KIT), Germany; Institute for Theoretical Computer Science, Karlsruhe Institute of Technology (KIT), Germany; Institute for Theoretical Computer Science, Karlsruhe Institute of Technology (KIT), Germany","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","706","709","This paper presents LLBMC, a tool for finding bugs and runtime errors in sequential C/C++ programs. LLBMC employs bounded model checking using an SMT-solver for the theory of bitvectors and arrays and thus achieves precision down to the level of single bits. The two main features of LLBMC that distinguish it from other bounded model checking tools for C/C++ are (i) its bit-precise memory model, which makes it possible to support arbitrary type conversions via stores and loads; and (ii) that it operates on a compiler intermediate representation and not directly on the source code.","","","10.1109/ASE.2013.6693138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693138","","Model checking;Computer bugs;Runtime;Program processors;Encoding;Decoding","C++ language;formal verification;program compilers;program debugging","bounded model checker LLBMC;finding bugs;runtime errors;sequential C/C++ programs;bounded model checking;SMT solver;source code;program compilers","","14","21","","","","","IEEE","IEEE Conferences"
"Cobra — An interactive static code analyzer","G. Holzmann","Nimble Research, Arcadia, CA 91006, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1","1","Sadly we know that virtually all software of any significance has residual errors. Some of those errors can be traced back to requirements flaws or faulty design assumptions; others are just plain coding mistakes. Static analyzers have become quite good at spotting these types of errors, but they don't scale very well. If, for instance, you need to check a code base of a few million lines you better be prepared to wait for the result; sometimes hours. Eyeballing a large code base to find flaws is clearly not an option, so what is missing is a static analysis capability that can be used to answer common types of queries interactively, even for large code bases. I will describe the design and use of such a tool in this talk.","","","10.1109/ASE.2017.8115610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115610","","","","","","","","","","","","IEEE","IEEE Conferences"
"Measuring Object-Oriented Design Principles","J. Braeuer","Dept. of Bus. Inf. - Software Eng., Johannes Kepler Univ. Linz, Linz, Austria","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","882","885","The idea of automatizing the assessment of object-oriented design is not new. Different approaches define and apply their own quality models, which are composed of single metrics or combinations thereof, to operationalize software design. However, single metrics are too fine-grained to identify core design flaws and they cannot provide hints for making design improvements. In order to deal with these weaknesses of metric-based models, rules-based approaches have proven successful in the realm of source-code quality. Moreover, for developing a well-designed software system, design principles play a key role, as they define fundamental guidelines and help to avoid pitfalls. Therefore, this thesis will enhance and complete a rule-based quality reference model for operationalizing design principles and will provide a measuring tool that implements these rules. The validation of the design quality model and the measurement tool will be based on various industrial projects. Additionally, quantitative and qualitative surveys will be conducted in order to get validated results on the value of object-oriented design principles for software development.","","","10.1109/ASE.2015.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372084","design principles;software-design quality;softwaredesign assessment method;design model","Object oriented modeling;Context;Software design;Software measurement;Software engineering","knowledge based systems;object-oriented methods;object-oriented programming;software quality;source code (software)","object-oriented design;software design;metric-based model;rule-based quality reference model;source-code quality;software development","","1","14","","","","","IEEE","IEEE Conferences"
"Characterizing and taming non-deterministic bugs in Javascript applications","J. Wang","State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China, University of Chinese Academy of Sciences, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1006","1009","JavaScript has become one of the most popular programming languages for both client-side and server-side applications. In JavaScript applications, events may be generated, triggered and consumed non-deterministically. Thus, JavaScript applications may suffer from non-deterministic bugs, when events are triggered and consumed in an unexpected order. In this proposal, we aim to characterize and combat non-deterministic bugs in JavaScript applications. Specifically, we first perform a comprehensive study about real-world non-deterministic bugs in server-side JavaScript applications. In order to facilitate bug diagnosis, we further propose approaches to isolate the necessary events that are responsible for the occurrence of a failure. We also plan to design new techniques in detecting non-deterministic bugs in JavaScript applications.","","","10.1109/ASE.2017.8115720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115720","JavaScript;Node.js;non-deterministic bug;empirical study;record and replay;bug detection","Computer bugs;Debugging;Tools;Proposals;Open source software;Computer languages;Computer architecture","Java;program debugging;program diagnostics;system recovery","nondeterministic bugs;JavaScript applications;server-side applications","","","25","","","","","IEEE","IEEE Conferences"
"Software engineering without borders","A. van Deursen","Department of Software Technolgy, Delft University of Technology, The Netherlands","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","3","3","DevOps approaches software engineering by advocating the removal of borders between development and operations. DevOps emphasizes operational resilience, continuous feedback from operations back to development, and rapid deployment of features developed. In this talk we will look at selected (automation) aspects related to DevOps, based on our collaborations with various industrial partners. For example, we will explore (automated) methods for analyzing log data to support deployments and monitor REST API integrations, (search-based) test input generation for reproducing crashes and testing complex database queries, and zero downtime database schema evolution and deployment. We will close by looking at borders beyond those between development and operations, in order to see whether there are other borders we need to remove in order to strengthen the impact of software engineering research.","","","10.1109/ASE.2017.8115612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115612","","","","","","","","","","","","IEEE","IEEE Conferences"
"MetaMod: A Modeling Formalism with Modularity at Its Core","A. ?utîi","Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Eindhoven, Netherlands","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","890","893","Because modern engineering products require more and more functionality, the models used in the design of these products get larger and more complex. A way to handle this complexity would be a suitable mechanism to modularize models. However, current approaches in the Model Driven Engineering field have limited support for modularity. This is the gap that our research addresses. We want to tackle the gap by designing and creating a modeling formalism with modularity at its core - MetaMod. We are including the modeling formalism into a prototype such that we can experiment with it. Our evaluation plan includes bootstrapping MetaMod (defining MetaMod in MetaMod) and creating an industrial DSL in MetaMod.","","","10.1109/ASE.2015.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372086","modeling;modularity;DSLs","Object oriented modeling;Documentation;Computational modeling;Complexity theory;Prototypes;Software;Calculus","formal specification;statistical analysis","modeling formalism;model driven engineering field;bootstrapping MetaMod;industrial DSL","","1","16","","","","","IEEE","IEEE Conferences"
"TRAM: A tool for transforming textual requirements into analysis models","K. J. Letsholo; L. Zhao; E. Chioasca","School of Computer Science, The University of Manchester, U.K.; School of Computer Science, The University of Manchester, U.K.; School of Computer Science, The University of Manchester, U.K.","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","738","741","Tool support for automatically constructing analysis models from the natural language specification of requirements (NLR) is critical to model driven development (MDD), as it can bring forward the use of precise formal languages from the coding to the specification phase in the MDD lifecycle. TRAM provides such a support through a novel approach. By using a set of conceptual patterns to facilitate the transformation of an NLR to its target software model, TRAM has shown its potential as an automated tool to support the earliest phase of MDD. This paper describes TRAM and evaluates the tool against three benchmark approaches.","","","10.1109/ASE.2013.6693146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693146","Model transformation;natural language processing;conceptual patterns;semantic object models;analysis models","Unified modeling language;Analytical models;Object oriented modeling;Software;Natural languages;Semantics","formal languages;formal specification;natural language processing;program diagnostics;software tools","TRAM;textual requirement transformation;analysis models;tool support;natural language specification of requirements;model driven development;formal languages;software model","","4","15","","","","","IEEE","IEEE Conferences"
"Understanding, Refactoring, and Fixing Concurrency in C#","S. Okur","Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","898","901","Industry leaders provide concurrent libraries because asynchronous & parallel programming are increasingly in demand: responsiveness, scalability, and high-throughput are key elements of all modern applications. However, we know little about how developers use these concurrent libraries in practice and the developer's toolbox for concurrency is very limited. We present the first study that analyzes the usage of concurrent libraries in large codebases, such as 2258 open-source C# apps comprising 54M SLOC and 1378 open-source Windows Phone apps comprising 12M SLOC. Using this data, we find important problems about use and misuse of concurrency. Inspired by our findings, we designed, evaluated, and implemented several static analyses and refactoring tools.","","","10.1109/ASE.2015.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372088","","Libraries;Java;Concurrent computing;Parallel programming;Open source software;Reactive power","concurrency (computers);parallel programming;program diagnostics;public domain software;software maintenance","asynchronous programming;parallel programming;concurrent libraries;open-source C# apps;54M SLOC;open-source Windows Phone apps;12M SLOC;static analyses;refactoring tools;software refactoring","","","25","","","","","IEEE","IEEE Conferences"
"Privacy-aware data-intensive applications","M. Guerriero","Politecnico di Milano, DEIB, Italy","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1030","1033","The rise of Big Data is leading to an increasing demand for data-intensive applications (DIAs), which, in many cases, are expected to process massive amounts of sensitive data. In this context, ensuring data privacy becomes paramount. While the way we design and develop DIAs has radically changed over the last few years in order to deal with Big Data, there has been relatively little effort to make such design privacy-aware. As a result, enforcing privacy policies in large-scale data processing is currently an open research problem. This thesis proposal makes one step towards this investigation: after identifying the dataflow model as the reference computational model for large-scale DIAs, (1) we propose a novel language for specifying privacy policies on dataflow applications along with (2) a dataflow rewriting mechanism to enforce such policies during DIA execution. Although a systematic evaluation still needs to be carried out, preliminary results are promising. We plan to implement our approach within a model-driven solution to ultimately simplify the design and development of privacy-aware DIAs, i.e. DIAs that ensure privacy policies at runtime.","","","10.1109/ASE.2017.8115726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115726","Data Privacy;Data-Intensive Applications;Big Data;Dataflow computing","Data privacy;Privacy;Computational modeling;Access control;Data models;Big Data;Context modeling","Big Data;data flow analysis;data privacy;rewriting systems","reference computational model;large-scale DIAs;dataflow applications;dataflow rewriting mechanism;DIA execution;privacy-aware DIAs;privacy-aware data-intensive applications;Big Data;sensitive data;data privacy;design privacy;large-scale data processing;open research problem;dataflow model;privacy policies","","","11","","","","","IEEE","IEEE Conferences"
"Clone Merge -- An Eclipse Plugin to Abstract Near-Clone C++ Methods","K. Narasimhan","NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","819","823","Software clones are prevalent. In the work of Laguë et al. [2], they observe that 6.4% and 7.5% of the source code in different versions of a large, mature code base are clones. The work of Baxter et al. [1] reports even higher numbers, sometimes exceeding 25%. We consider the prevalence of such near miss clones to be strong indicators that copy-paste-modify is a wide-spread development methodology. Even though clones are prevalent, they are a significant development headache. Specially, if bugs arise in one of the clones, they need to be fixed in all of the clones. This problem is acknowledged in the work of Juergens et al. [4] who say in their work that ""cloning can be a substantial problem during development and maintenance"", since ""inconsistent clones constitute a major source of faults"". A similar concern is raised in practitioner literature [3] suggesting that clones should be removed in some form or the other. We present a tool that can be installed as a plugin to Eclipse CDT, the development environment for C/C++. The research prototype comes with a refactoring option called ""Copy Paste merge"" refactoring, which is available as a menu option in the modified version of the Eclipse CDT.","","","10.1109/ASE.2015.103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372073","Refactoring;Eclipse;CDT;Clone;Evolution;Abstraction","Cloning;Switches;Industries;Software engineering;Maintenance engineering;Prototypes;Syntactics","C++ language;program debugging;software maintenance;source code (software)","clone merge;near-clone C++ methods;source code;near miss software clones;bugs;software development;software maintenance;Eclipse CDT plugin;copy paste merge refactoring","","","7","","","","","IEEE","IEEE Conferences"
"BOOM: Experiences in language and tool design for distributed systems (keynote)","J. M. Hellerstein","University of California at Berkeley, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","1","1","With the rapid expansion of cloud infrastructure and mobile devices, distributed systems have quickly emerged as a dominant computing platform. Distributed systems bring significant complexity to programming, due to platform issues including asynchrony, concurrency, and partial failure. Meanwhile, scalable distributed infrastructure—notably “NoSQL” systems—have put additional burdens on programmers by sacrificing traditional infrastructure contracts like linearizable or transactional I/O in favor of high availability. A growing segment of the developer community needs to deal with these issues today, and for the most part developers are still using languages and tools designed for sequential computation on tightly coupled architectures. This has led to software that is increasingly hard to test and hard to trust. Over the past 5 years, the BOOM project at Berkeley has focused on making it easier to write correct and maintainable code for distributed systems. Our work has taken a number of forms, including the development of the Bloom programming language for distributed systems, tools for testing and checking distributed programs, and the CALM Theorem, which connects programmer level concerns of determinism to system-level concerns about the need for distributed coordination. This talk will reflect on this work, and highlight opportunities for improved collaboration between the software engineering and distributed systems research communities.","","","10.1109/ASE.2013.6693058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693058","","","","","","","","","","","","IEEE","IEEE Conferences"
"Tool support for automatic model transformation specification using concrete visualisations","I. Avazpour; J. Grundy; L. Grunske","Faculty of ICT, Centre for Computing and Engineering Software and Systems (SUCCESS), Swinburne University of Technology, Hawthorn 3122, VIC, Australia; Faculty of ICT, Centre for Computing and Engineering Software and Systems (SUCCESS), Swinburne University of Technology, Hawthorn 3122, VIC, Australia; Institute of Software Technology, Universität Stuttgart, Universitätsstraße 38, D-70569, Germany","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","718","721","Complex model transformation is crucial in several domains, including Model-Driven Engineering (MDE), information visualisation and data mapping. Most current approaches use meta-model-driven transformation specification via coding in textual scripting languages. This paper demonstrates a novel approach and tool support that instead provides for specification of correspondences between models using concrete visualisations of source and target models, and generates transformation scripts from these by-example model correspondence specifications.","","","10.1109/ASE.2013.6693141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693141","","Solid modeling;Visualization;Concrete;Computational modeling;Data visualization;Design automation","data visualisation;formal specification","concrete visualisations;automatic model transformation specification;model-driven engineering;information visualisation;data mapping;meta-model-driven transformation specification;textual scripting languages","","1","9","","","","","IEEE","IEEE Conferences"
"Mining structures from massive text data: Will it help software engineering?","J. Han","Abel Bliss Professor, Department of Computer Science, University of Illinois at Urbana-Champaign, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","2","2","The real-world big data are largely unstructured, interconnected text data. One of the grand challenges is to turn such massive unstructured text data into structured, actionable knowledge. We propose a text mining approach that requires only distant or minimal supervision but relies on massive text data. We show quality phrases can be mined from such massive text data, types can be extracted from massive text data with distant supervision, and entities/attributes/values can be discovered by meta-path directed pattern discovery. We show text-rich and structure-rich networks can be constructed from massive unstructured data. Finally, we speculate whether such a paradigm could be useful for turning massive software repositories into multi-dimensional structures to help searching and mining software repositories.","","","10.1109/ASE.2017.8115611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115611","","","","","","","","","","","","IEEE","IEEE Conferences"
"Crushinator: A framework towards game-independent testing","C. Schaefer; Hyunsook Do; B. M. Slator","North Dakota State University, Computer Science, Fargo, USA; North Dakota State University, Computer Science, Fargo, USA; North Dakota State University, Computer Science, Fargo, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","726","729","Testing game applications relies heavily on beta testing methods. The effectiveness of beta testing depends on how well beta testers represent the common game-application users and if users are willing to participate in the beta test. An automated testing tool framework could reduce the dependence upon beta testing by most companies to analyze their game applications. This paper presents the Crushinator as one such framework. This framework provides a game-independent testing tool that implements multiple testing methods that can assist and possibly replace the use of beta testing.","","","10.1109/ASE.2013.6693143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693143","Crushinator;model-based testing;exploratory testing;event-driven applications","Testing;Games;Servers;Unified modeling language;Engines;Load modeling;Computer architecture","computer games;program testing","Crushinator;game-independent testing;beta testing method;automated testing tool","","5","14","","","","","IEEE","IEEE Conferences"
"Towards API-specific automatic program repair","S. Nielebock","Chair of Software Engineering, Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1010","1013","The domain of Automatic Program Repair (APR) had many research contributions in recent years. So far, most approaches target fixing generic bugs in programs (e.g., off-by-one errors). Nevertheless, recent studies reveal that about 50% of real bugs require API-specific fixes (e.g., adding missing API method calls or correcting method ordering), for which existing APR approaches are not designed. In this paper, we address this problem and introduce the notion of an API-specific program repair mechanism. This mechanism detects erroneous code in a similar way to existing APR approaches. However, to fix such bugs, it uses API-specific information from the erroneous code to search for API usage patterns in other software, with which we could fix the bug. We provide first insights on the applicability of this mechanism and discuss upcoming research challenges.","","","10.1109/ASE.2017.8115721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115721","Automatic Program Repair;API-specific Bugs;Specification Mining","Computer bugs;Maintenance engineering;Software;Data mining;Benchmark testing;Automation;Fasteners","application program interfaces;Java;program debugging;program testing;software maintenance","API-specific automatic program repair;API usage patterns;API-specific information;erroneous code;API-specific fixes;generic bugs","","","38","","","","","IEEE","IEEE Conferences"
"Developing self-verifying service-based systems","R. Calinescu; K. Johnson; Y. Rafiq","Department of Computer Science, University of York, UK; Department of Computer Science, University of York, UK; Department of Computer Science, University of York, UK","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","734","737","We present a tool-supported framework for the engineering of service-based systems (SBSs) capable of self-verifying their compliance with developer-specified reliability requirements. These self-verifying systems select their services dynamically by using a combination of continual quantitative verification and online updating of the verified models. Our framework enables the practical exploitation of recent theoretical advances in the development of self-adaptive SBSs through (a) automating the generation of the software components responsible for model updating, continual verification and service selection; and (b) employing standard SBS development processes.","","","10.1109/ASE.2013.6693145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693145","","Scattering;Unified modeling language;Reliability;Analytical models;Web services;Quality of service;Adaptation models","formal verification;object-oriented programming;software reliability","self-verifying service-based system development;tool-supported framework;developer-specified reliability requirements;continual quantitative verification;online updating;self-adaptive SBSs development;software component generation;model updating;service selection","","13","16","","","","","IEEE","IEEE Conferences"
"A Generic Framework for Concept-Based Exploration of Semi-Structured Software Engineering Data","G. J. Greene","Centre for Artificial Intell. Res. Comput. Sci. Div., Matieland Stellenbosch Univ., Stellenbosch, South Africa","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","894","897","Software engineering meta-data (SE data), such as revision control data, Github project data or test reports, is typically semi-structured, it comprises a mixture of formatted and free-text fields and is often self-describing. Semi-structured SE data cannot be queried in a SQL-like manner because of its lack of structure. Consequently, there are a variety of customized tools built to analyze specific datasets but these do not generalize. We propose to develop a generic framework for exploration and querying of semi-structured SE data. Our approach investigates the use of a formal concept lattice as a universal data structure and a tag cloud as an intuitive interface to support data exploration.","","","10.1109/ASE.2015.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372087","formal concept analysis;tag clouds;browsing software repositories","Lattices;Tag clouds;Data visualization;Navigation;Prototypes;Software engineering;Context","data structures;formal concept analysis;meta data;query processing;software engineering;SQL;user interfaces","semistructured software engineering data;revision control data;Github project data;test reports;formatted fields;free-text fields;SQL-like manner;customized tools;semistructured SE data querying;universal data structure;tag cloud;intuitive interface;data exploration","","5","21","","","","","IEEE","IEEE Conferences"
"Automatic Self-Validation for Code Coverage Profilers","Y. Yang; Y. Jiang; Z. Zuo; Y. Wang; H. Sun; H. Lu; Y. Zhou; B. Xu","Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University; Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","79","90","Code coverage as the primitive dynamic program behavior information, is widely adopted to facilitate a rich spectrum of software engineering tasks, such as testing, fuzzing, debugging, fault detection, reverse engineering, and program understanding. Thanks to the widespread applications, it is crucial to ensure the reliability of the code coverage profilers. Unfortunately, due to the lack of research attention and the existence of testing oracle problem, coverage profilers are far away from being tested sufficiently. Bugs are still regularly seen in the widely deployed profilers, like gcov and llvm-cov, along with gcc and llvm, respectively. This paper proposes Cod, an automated self-validator for effectively uncovering bugs in the coverage profilers. Starting from a test program (either from a compiler's test suite or generated randomly), Cod detects profiler bugs with zero false positive using a metamorphic relation in which the coverage statistics of that program and a mutated variant are bridged. We evaluated Cod over two of the most well-known code coverage profilers, namely gcov and llvm-cov. Within a four-month testing period, a total of 196 potential bugs (123 for gcov, 73 for llvm-cov) are found, among which 23 are confirmed by the developers.","","","10.1109/ASE.2019.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952463","Code coverage, Metamorphic testing, Coverage profilers, Bug detection.","","","","","","51","","","","","IEEE","IEEE Conferences"
"Machine Learning Based Recommendation of Method Names: How Far are We","L. Jiang; H. Liu; H. Jiang","Beijing Institute of Technology; Beijing Institute of Technology; Dalian University of Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","602","614","High quality method names are critical for the readability and maintainability of programs. However, constructing concise and consistent method names is often challenging, especially for inexperienced developers. To this end, advanced machine learning techniques have been recently leveraged to recommend method names automatically for given method bodies/implementation. Recent large-scale evaluations also suggest that such approaches are accurate. However, little is known about where and why such approaches work or don't work. To figure out the state of the art as well as the rationale for the success/failure, in this paper we conduct an empirical study on the state-of-the-art approach code2vec. We assess code2vec on a new dataset with more realistic settings. Our evaluation results suggest that although switching to new dataset does not significantly influence the performance, more realistic settings do significantly reduce the performance of code2vec. Further analysis on the successfully recommended method names also reveals the following findings: 1) around half (48.3%) of the accepted recommendations are made on getter/setter methods; 2) a large portion (19.2%) of the successfully recommended method names could be copied from the given bodies. To further validate its usefulness, we ask developers to manually score the difficulty in naming methods they developed. Code2vec is then applied to such manually scored methods to evaluate how often it works in need. Our evaluation results suggest that code2vec rarely works when it is really needed. Finally, to intuitively reveal the state of the art and to investigate the possibility of designing simple and straightforward alternative approaches, we propose a heuristics based approach to recommending method names. Evaluation results on large-scale dataset suggest that this simple heuristics-based approach significantly outperforms the state-of-the-art machine learning based approach, improving precision and recall by 65.25% and 22.45%, respectively. The comparison suggests that machine learning based recommendation of method names may still have a long way to go.","","","10.1109/ASE.2019.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952208","Code Recommendation;Machine Learning","","","","","","46","","","","","IEEE","IEEE Conferences"
"Learning from Examples to Find Fully Qualified Names of API Elements in Code Snippets","C. M. K. Saifullah; M. Asaduzzaman; C. K. Roy","University of Saskatchewan; Queen's University; University of Saskatchewan","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","243","254","Developers often reuse code snippets from online forums, such as Stack Overflow, to learn API usages of software frameworks or libraries. These code snippets often contain ambiguous undeclared external references. Such external references make it difficult to learn and use those APIs correctly. In particular, reusing code snippets containing such ambiguous undeclared external references requires significant manual efforts and expertise to resolve them. Manually resolving fully qualified names (FQN) of API elements is a non-trivial task. In this paper, we propose a novel context-sensitive technique, called COSTER, to resolve FQNs of API elements in such code snippets. The proposed technique collects locally specific source code elements as well as globally related tokens as the context of FQNs, calculates likelihood scores, and builds an occurrence likelihood dictionary (OLD). Given an API element as a query, COSTER captures the context of the query API element, matches that with the FQNs of API elements stored in the OLD, and rank those matched FQNs leveraging three different scores: likelihood, context similarity, and name similarity scores. Evaluation with more than 600K code examples collected from GitHub and two different Stack Overflow datasets shows that our proposed technique improves precision by 4-6% and recall by 3-22% compared to state-of-the-art techniques. The proposed technique significantly reduces the training time compared to the StatType, a state-of-the-art technique, without sacrificing accuracy. Extensive analyses on results demonstrate the robustness of the proposed technique.","","","10.1109/ASE.2019.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952501","API usages, Context sensitive technique, Recommendation system, Fully Qualified Name","","","","","","41","","","","","IEEE","IEEE Conferences"
"Accurate Modeling of Performance Histories for Evolving Software Systems","S. Mühlbauer; S. Apel; N. Siegmund","Bauhaus-University Weimar; Saarland University; Bauhaus-University Weimar","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","640","652","Learning from the history of a software system's performance behavior does not only help discovering and locating performance bugs, but also identifying evolutionary performance patterns and general trends, such as when technical debt accumulates. Exhaustive regression testing is usually impractical, because rigorous performance benchmarking requires executing a realistic workload per revision, which results in large execution times. In this paper, we propose a novel active revision sampling approach, which aims at tracking and understanding a system's performance history by approximating the performance behavior of a software system across all of its revisions. In a nutshell, we iteratively sample and measure the performance of specific revisions that help us building an exact performance-evolution model, and we use Gaussian Process models to assess in which revision ranges our model is most uncertain with the goal to sample further revisions for measurement. We have conducted an empirical analysis of the evolutionary performance behavior modeled as a time series of the histories of six real-world software systems. Our evaluation demonstrates that Gaussian Process models are able to accurately estimate the performance-evolution history of real-world software systems with only few measurements and to reveal interesting behaviors and trends.","","","10.1109/ASE.2019.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952290","software evolution;software performance;time series analysis","","","","","","39","","","","","IEEE","IEEE Conferences"
"Model Checking Embedded Control Software using OS-in-the-Loop CEGAR","D. Kim; Y. Choi","Kyungpook National University; Kyungpook National University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","565","576","Verification of multitasking embedded software requires taking into account its underlying operating system w.r.t. its scheduling policy and handling of task priorities in order to achieve a higher degree of accuracy. However, such comprehensive verification of multitasking embedded software together with its underlying operating system is very costly and impractical. To reduce the verification cost while achieving the desired accuracy, we propose a variant of CEGAR, named OiL-CEGAR (OS-in-the-Loop Counterexample-Guided Abstraction Refinement), where a composition of a formal OS model and an abstracted application program is used for comprehensive verification and is successively refined using the counterexamples generated from the composition model. The refinement process utilizes the scheduling information in the counterexample, which acts as a mini-OS to check the executability of the counterexample trace on the concrete program. Our experiments using a prototype implementation of OiL-CEGAR show that OiL-CEGAR greatly improves the accuracy and efficiency of property checking in this domain. It automatically removed all false alarms and accomplished property checking within an average of 476 seconds over a set of multitasking programs, whereas model checking using existing approaches over the same set of programs either showed an accuracy of under 11.1% or was unable to finish the verification due to timeout.","","","10.1109/ASE.2019.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952214","CEGAR;embedded OS;multitasking","","","","","","47","","","","","IEEE","IEEE Conferences"
"Improving the Decision-Making Process of Self-Adaptive Systems by Accounting for Tactic Volatility","J. Palmerino; Q. Yu; T. Desell; D. Krutz","RIT; RIT; RIT; RIT","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","949","961","When self-adaptive systems encounter changes withintheir surrounding environments, they enacttacticsto performnecessary adaptations. For example, a self-adaptive cloud-basedsystem may have a tactic that initiates additional computingresources when response time thresholds are surpassed, or theremay be a tactic to activate a specific security measure when anintrusion is detected. In real-world environments, these tacticsfrequently experiencetactic volatilitywhich is variable behaviorduring the execution of the tactic.Unfortunately, current self-adaptive approaches do not accountfor tactic volatility in their decision-making processes, and merelyassume that tactics do not experience volatility. This limitationcreates uncertainty in the decision-making process and mayadversely impact the system's ability to effectively and efficientlyadapt. Additionally, many processes do not properly account forvolatility that may effect the system's Service Level Agreement(SLA). This can limit the system's ability to act proactively, especially when utilizing tactics that contain latency.To address the challenge of sufficiently accounting for tacticvolatility, we propose aTactic Volatility Aware(TVA) solution.Using Multiple Regression Analysis (MRA), TVA enables self-adaptive systems to accurately estimate the cost and timerequired to execute tactics. TVA also utilizesAutoregressiveIntegrated Moving Average(ARIMA) for time series forecasting, allowing the system to proactively maintain specifications.","","","10.1109/ASE.2019.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952178","Artificial Intelligence, Self-Adaptation, Machine Learning","","","","","","45","","","","","IEEE","IEEE Conferences"
"Characterizing Android App Signing Issues","H. Wang; H. Liu; X. Xiao; G. Meng; Y. Guo","Beijing University of Posts and Telecommunications; Peking University; Case Western Reserve University; SKLOIS, Chinese Academy of Sciences; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","280","292","In the app releasing process, Android requires all apps to be digitally signed with a certificate before distribution. Android uses this certificate to identify the author and ensure the integrity of an app. However, a number of signature issues have been reported recently, threatening the security and privacy of Android apps. In this paper, we present the first large-scale systematic measurement study on issues related to Android app signatures. We first create a taxonomy covering four types of app signing issues (21 anti-patterns in total), including vulnerabilities, potential attacks, release bugs and compatibility issues. Then we developed an automated tool to characterize signature-related issues in over 5 million app items (3 million distinct apks) crawled from Google Play and 24 alternative Android app markets. Our empirical findings suggest that although Google has introduced apk-level signing schemes (V2 and V3) to overcome some of the known security issues, more than 93% of the apps still use only the JAR signing scheme (V1), which poses great security threats. Besides, we also revealed that 7% to 45% of the apps in the 25 studied markets have been found containing at least one signing issue, while a large number of apps have been exposed to security vulnerabilities, attacks and compatibility issues. Among them a considerable number of apps we identified are popular apps with millions of downloads. Finally, our evolution analysis suggested that most of the issues were not mitigated after a considerable amount of time across markets. The results shed light on the emergency for detecting and repairing the app signing issues.","","","10.1109/ASE.2019.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952357","Signature;Vulnerability;Mobile App;Certificate","","","","","","64","","","","","IEEE","IEEE Conferences"
"SCMiner: Localizing System-Level Concurrency Faults from Large System Call Traces","T. S. Zaman; X. Han; T. Yu","University of Kentucky; University of Kentucky; University of Kentucky","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","515","526","Localizing concurrency faults that occur in production is hard because, (1) detailed field data, such as user input, file content and interleaving schedule, may not be available to developers to reproduce the failure; (2) it is often impractical to assume the availability of multiple failing executions to localize the faults using existing techniques; (3) it is challenging to search for buggy locations in an application given limited runtime data; and, (4) concurrency failures at the system level often involve multiple processes or event handlers (e.g., software signals), which can not be handled by existing tools for diagnosing intra-process(thread-level) failures. To address these problems, we present SCMiner, a practical online bug diagnosis tool to help developers understand how a system-level concurrency fault happens based on the logs collected by the default system audit tools. SCMiner achieves online bug diagnosis to obviate the need for offline bug reproduction. SCMiner does not require code instrumentation on the production system or rely on the assumption of the availability of multiple failing executions. Specifically, after the system call traces are collected, SCMiner uses data mining and statistical anomaly detection techniques to identify the failure-inducing system call sequences. It then maps each abnormal sequence to specific application functions. We have conducted an empirical study on 19 real-world benchmarks. The results show that SCMiner is both effective and efficient at localizing system-level concurrency faults.","","","10.1109/ASE.2019.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952396","Multi Process Applications, Concurrency Failures, Fault Localization","","","","","","56","","","","","IEEE","IEEE Conferences"
"Discovering, Explaining and Summarizing Controversial Discussions in Community Q&A Sites","X. Ren; Z. Xing; X. Xia; G. Li; J. Sun","Zhejiang University, Ningbo Research Institute, PengCheng Laboratory; Australian National University; Monash University; Shanghai Jiao Tong University; Zhejiang University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","151","162","Developers often look for solutions to programming problems in community Q&A sites like Stack Overflow. Due to the crowdsourcing nature of these Q&A sites, many user-provided answers are wrong, less optimal or out-of-date. Relying on community-curated quality indicators (e.g., accepted answer, answer vote) cannot reliably identify these answer problems. Such problematic answers are often criticized by other users. However, these critiques are not readily discoverable when reading the posts. In this paper, we consider the answers being criticized and their critique posts as controversial discussions in community Q&A sites. To help developers notice such controversial discussions and make more informed choices of appropriate solutions, we design an automatic open information extraction approach for systematically discovering and summarizing the controversies in Stack Overflow and exploiting official API documentation to assist the understanding of the discovered controversies. We apply our approach to millions of java/android-tagged Stack overflow questions and answers and discover a large scale of controversial discussions in Stack Overflow. Our manual evaluation confirms that the extracted controversy information is of high accuracy. A user study with 18 developers demonstrates the usefulness of our generated controversy summaries in helping developers avoid the controversial answers and choose more appropriate solutions to programming questions.","","","10.1109/ASE.2019.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952216","Controversial discussion, Stack Overflow, Open information extraction, Sentence embedding","","","","","","47","","","","","IEEE","IEEE Conferences"
"Cautious Adaptation of Defiant Components","P. H. Maia; L. Vieira; M. Chagas; Y. Yu; A. Zisman; B. Nuseibeh","State University of Ceará, Fortaleza, CE, Brazil; State University of Ceará, Fortaleza, CE, Brazil; State University of Ceará, Fortaleza, CE, Brazil; The Open University, UK; The Open University, UK; The Open University, UK","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","974","985","Systems-of-systems are formed by the composition of independently created software components. These components are designed to satisfy their individual requirements, rather than the global requirements of the systems-of-systems. We refer to components that cannot be adapted to meet both individual and global requirements as ""defiant"" components. In this paper, we propose a ""cautious"" adaptation approach which supports changing the behaviour of such defiant components under exceptional conditions to satisfy global requirements, while continuing to guarantee the satisfaction of the components' individual requirements. The approach represents both normal and exceptional conditions as scenarios; models the behaviour of exceptional conditions as wrappers implemented using an aspect-oriented technique; and deals with both single and multiple instances of defiant components with different precedence order at runtime. We evaluated an implementation of the approach using drones and boats for an organ delivery application conceived by our industrial partners, in which we assess how the proposed approach help achieve the system-of-systems' global requirements while accommodating increased complexity of hybrid aspects such as multiplicity, precedence ordering, openness, and heterogeneity.","","","10.1109/ASE.2019.00094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952359","Defiant Component, Adaptation, Scenarios, Aspects","","","","","","47","","","","","IEEE","IEEE Conferences"
"Goal-Driven Exploration for Android Applications","D. Lai; J. Rubin","University of British Columbia; University of British Columbia","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","115","127","This paper proposes a solution for automated goal-driven exploration of Android applications - a scenario in which a user, e.g., a security auditor, needs to dynamically trigger the functionality of interest in an application, e.g., to check whether user-sensitive info is only sent to recognized third-party servers. As the auditor might need to check hundreds or even thousands of apps, manually exploring each app to trigger the desired behavior is too time-consuming to be feasible. Existing automated application exploration and testing techniques are of limited help in this scenario as well, as their goal is mostly to identify faults by systematically exploring different app paths, rather than swiftly navigating to the target functionality. The goal-driven application exploration approach proposed in this paper, called GoalExplorer, automatically generates an executable test script that directly triggers the functionality of interest. The core idea behind GoalExplorer is to first statically model the application's UI screens and transitions between these screens, producing a Screen Transition Graph (STG). Then, GoalExplorer uses the STG to guide the dynamic exploration of the application to the particular target of interest: an Android activity, API call, or a program statement. The results of our empirical evaluation on 93 benchmark applications and the 95 most popular GooglePlay applications show that the STG is substantially more accurate than other Android UI models and that GoalExplorer is able to trigger a target functionality much faster than existing application exploration techniques.","","","10.1109/ASE.2019.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952363","mobile applications;automated testing;automated GUI exploration","","","","","","60","","","","","IEEE","IEEE Conferences"
"InFix: Automatically Repairing Novice Program Inputs","M. Endres; G. Sakkas; B. Cosman; R. Jhala; W. Weimer","University of Michigan; University of California San Diego; University of California San Diego; University of California San Diego; University of Michigan","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","399","410","This paper presents InFix, a technique for automatically fixing erroneous program inputs for novice programmers. Unlike comparable existing approaches for automatic debugging and maintenance tasks, InFix repairs input data rather than source code, does not require test cases, and does not require special annotations. Instead, we take advantage of patterns commonly used by novice programmers to automatically create helpful, high quality input repairs. InFix iteratively applies error-message based templates and random mutations based on insights about the debugging behavior of novices. This paper presents an implementation of InFix for Python. We evaluate on 29,995 unique scenarios with input-related errors collected from four years of data from Python Tutor, a free online programming tutoring environment. Our results generalize and scale; compared to previous work, we consider an order of magnitude more unique programs. Overall, InFix is able to repair 94.5% of deterministic input errors. We also present the results of a human study with 97 participants. Surprisingly, this simple approach produces high quality repairs; humans judged the output of InFix to be equally helpful and within 4% of the quality of human-generated repairs.","","","10.1109/ASE.2019.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952434","input repair;novice programs;human study","","","","","","51","","","","","IEEE","IEEE Conferences"
"Automatic Generation of Pull Request Descriptions","Z. Liu; X. Xia; C. Treude; D. Lo; S. Li","Zhejiang University; Monash University; University of Adelaide; Singapore Management University; Zhejiang University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","176","188","Enabled by the pull-based development model, developers can easily contribute to a project through pull requests (PRs). When creating a PR, developers can add a free-form description to describe what changes are made in this PR and/or why. Such a description is helpful for reviewers and other developers to gain a quick understanding of the PR without touching the details and may reduce the possibility of the PR being ignored or rejected. However, developers sometimes neglect to write descriptions for PRs. For example, in our collected dataset with over 333K PRs, more than 34% of the PR descriptions are empty. To alleviate this problem, we propose an approach to automatically generate PR descriptions based on the commit messages and the added source code comments in the PRs. We regard this problem as a text summarization problem and solve it using a novel sequence-to-sequence model. To cope with out-of-vocabulary words in software artifacts and bridge the gap between the training loss function of the sequence-to-sequence model and the evaluation metric ROUGE, which has been shown to correspond to human evaluation, we integrate the pointer generator and directly optimize for ROUGE using reinforcement learning and a special loss function. We build a dataset with over 41K PRs and evaluate our approach on this dataset through ROUGE and a human evaluation. Our evaluation results show that our approach outperforms two baselines by significant margins.","","","10.1109/ASE.2019.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952330","Pull Request;Document Generation;Sequence to Sequence Learning","","","","","","63","","","","","IEEE","IEEE Conferences"
"An Empirical Study Towards Characterizing Deep Learning Development and Deployment Across Different Frameworks and Platforms","Q. Guo; S. Chen; X. Xie; L. Ma; Q. Hu; H. Liu; Y. Liu; J. Zhao; X. Li","Tianjin University; Nanyang Technological University; Nanyang Technological University; Kyushu University; Kyushu University; Tianjin University; Nanyang Technological University; Kyushu University; Tianjin University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","810","822","Deep Learning (DL) has recently achieved tremendous success. A variety of DL frameworks and platforms play a key role to catalyze such progress. However, the differences in architecture designs and implementations of existing frameworks and platforms bring new challenges for DL software development and deployment. Till now, there is no study on how various mainstream frameworks and platforms influence both DL software development and deployment in practice. To fill this gap, we take the first step towards understanding how the most widely-used DL frameworks and platforms support the DL software development and deployment. We conduct a systematic study on these frameworks and platforms by using two types of DNN architectures and three popular datasets. (1) For development process, we investigate the prediction accuracy under the same runtime training configuration or same model weights/biases. We also study the adversarial robustness of trained models by leveraging the existing adversarial attack techniques. The experimental results show that the computing differences across frameworks could result in an obvious prediction accuracy decline, which should draw the attention of DL developers. (2) For deployment process, we investigate the prediction accuracy and performance (refers to time cost and memory consumption) when the trained models are migrated/quantized from PC to real mobile devices and web browsers. The DL platform study unveils that the migration and quantization still suffer from compatibility and reliability issues. Meanwhile, we find several DL software bugs by using the results as a benchmark. We further validate the results through bug confirmation from stakeholders and industrial positive feedback to highlight the implications of our study. Through our study, we summarize practical guidelines, identify challenges and pinpoint new research directions, such as understanding the characteristics of DL frameworks and platforms, avoiding compatibility and reliability issues, detecting DL software bugs, and reducing time cost and memory consumption towards developing and deploying high quality DL systems effectively.","","","10.1109/ASE.2019.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952401","Deep learning frameworks;Deep learning platforms;Deep learning deployment;Empirical study","","","","","1","70","","","","","IEEE","IEEE Conferences"
"RENN: Efficient Reverse Execution with Neural-Network-Assisted Alias Analysis","D. Mu; W. Guo; A. Cuevas; Y. Chen; J. Gai; X. Xing; B. Mao; C. Song","Nanjing University; The Pennsylvania State University; The Pennsylvania State University; The Pennsylvania State University; The Pennsylvania State University; The Pennsylvania State University; Nanjing University; UC Riverside","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","924","935","Reverse execution and coredump analysis have long been used to diagnose the root cause of software crashes. Each of these techniques, however, face inherent challenges, such as insufficient capability when handling memory aliases. Recent works have used hypothesis testing to address this drawback, albeit with high computational complexity, making them impractical for real world applications. To address this issue, we propose a new deep neural architecture, which could significantly improve memory alias resolution. At the high level, our approach employs a recurrent neural network (RNN) to learn the binary code pattern pertaining to memory accesses. It then infers the memory region accessed by memory references. Since memory references to different regions naturally indicate a non-alias relationship, our neural architecture can greatly reduce the burden of doing hypothesis testing to track down non-alias relation in binary code. Different from previous researches that have utilized deep learning for other binary analysis tasks, the neural network proposed in this work is fundamentally novel. Instead of simply using off-the-shelf neural networks, we designed a new recurrent neural architecture that could capture the data dependency between machine code segments. To demonstrate the utility of our deep neural architecture, we implement it as RENN, a neural network-assisted reverse execution system. We utilize this tool to analyze software crashes corresponding to 40 memory corruption vulnerabilities from the real world. Our experiments show that RENN can significantly improve the efficiency of locating the root cause for the crashes. Compared to a state-of-the-art technique, RENN has 36.25% faster execution time on average, detects an average of 21.35% more non-alias pairs, and successfully identified the root cause of 12.5% more cases.","","","10.1109/ASE.2019.00090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952186","Reverse Execution, Deep Learning, Memory Alias","","","","","","50","","","","","IEEE","IEEE Conferences"
"Experience Paper: Search-Based Testing in Automated Driving Control Applications","C. Gladisch; T. Heinz; C. Heinzemann; J. Oehlerking; A. von Vietinghoff; T. Pfitzer","Robert Bosch GmbH, Corporate Research; Robert Bosch GmbH, Corporate Research; Robert Bosch GmbH, Corporate Research; Robert Bosch GmbH, Corporate Research; Robert Bosch GmbH, Corporate Research; Robert Bosch Automotive Steering GmbH","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","26","37","Automated test generation and evaluation in simulation environments is a key technology for verification of automated driving (AD) applications. Search-based testing (SBT) is an approach for automated test generation that leverages optimization to efficiently generate interesting concrete tests from abstract test descriptions. In this experience paper, we report on our observations after successfully applying SBT to AD control applications in several use cases with different characteristics. Based on our experiences, we derive a number of lessons learned that we consider important for the adoption of SBT methods and tools in industrial settings. The key lesson is that SBT finds relevant errors and provides valuable feedback to the developers, but requires tool support for writing specifications.","","","10.1109/ASE.2019.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952365","search-based testing;automated driving;automated test generation;experience paper","","","","","","43","","","","","IEEE","IEEE Conferences"
"Assessing the Generalizability of Code2vec Token Embeddings","H. J. Kang; T. F. Bissyandé; D. Lo","Singapore Management University; University of Luxembourg, Luxembourg; Singapore Management University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1","12","Many Natural Language Processing (NLP) tasks, such as sentiment analysis or syntactic parsing, have benefited from the development of word embedding models. In particular, regardless of the training algorithms, the learned embeddings have often been shown to be generalizable to different NLP tasks. In contrast, despite recent momentum on word embeddings for source code, the literature lacks evidence of their generalizability beyond the example task they have been trained for. In this experience paper, we identify 3 potential downstream tasks, namely code comments generation, code authorship identification, and code clones detection, that source code token embedding models can be applied to. We empirically assess a recently proposed code token embedding model, namely code2vec's token embeddings. Code2vec was trained on the task of predicting method names, and while there is potential for using the vectors it learns on other tasks, it has not been explored in literature. Therefore, we fill this gap by focusing on its generalizability for the tasks we have identified. Eventually, we show that source code token embeddings cannot be readily leveraged for the downstream tasks. Our experiments even show that our attempts to use them do not result in any improvements over less sophisticated methods. We call for more research into effective and general use of code embeddings.","","","10.1109/ASE.2019.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952475","Code Embeddings;Distributed Representations;Big Code","","","","","","65","","","","","IEEE","IEEE Conferences"
"MAP-Coverage: A Novel Coverage Criterion for Testing Thread-Safe Classes","Z. Wang; Y. Zhao; S. Liu; J. Sun; X. Chen; H. Lin","Tianjin University; Tianjin University; Tianjin University; Singapore Management University; Nantong University; Tianjin University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","722","734","Concurrent programs must be thoroughly tested, as concurrency bugs are notoriously hard to detect. Code coverage criteria can be used to quantify the richness of a test suite (e.g., whether a program has been tested sufficiently) or provide practical guidelines on test case generation (e.g., as objective functions used in program fuzzing engines). Traditional code coverage criteria are, however, designed for sequential programs and thus ineffective for concurrent programs. In this work, we introduce a novel code coverage criterion for testing thread-safe classes called MAP-coverage (short for memory-access patterns). The motivation is that concurrency bugs are often correlated with certain memory-access patterns, and thus it is desirable to comprehensively cover all memory-access patterns. Furthermore, we propose a testing method for maximizing MAP-coverage. Our method has been implemented as a self-contained toolkit, and the experimental results on 20 benchmark programs show that our toolkit outperforms existing testing methods. Lastly, we show empirically that there exists positive correlation between MAP-coverage and the effectiveness of a set of test executions.","","","10.1109/ASE.2019.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952403","Memory Access Pattern;Coverage Criteria;Thread Safe Classes;Concurrency Bugs","","","","","","48","","","","","IEEE","IEEE Conferences"
"CodeKernel: A Graph Kernel Based Approach to the Selection of API Usage Examples","X. Gu; H. Zhang; S. Kim","The Hong Kong University of Science and Technology; The University of Newcastle; The Hong Kong University of Science and Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","590","601","Developers often want to find out how to use a certain API (e.g., FileReader.read in JDK library). API usage examples are very helpful in this regard. Over the years, many automated methods have been proposed to generate code examples by clustering and summarizing relevant code snippets extracted from a code corpus. These approaches simplify source code as method invocation sequences or feature vectors. Such simplifications only model partial aspects of the code and tend to yield inaccurate examples. We propose CodeKernel, a graph kernel based approach to the selection of API usage examples. Instead of approximating source code as method invocation sequences or feature vectors, CodeKernel represents source code as object usage graphs. Then, it clusters graphs by embedding them into a continuous space using a graph kernel. Finally, it outputs code examples by selecting a representative graph from each cluster using designed ranking metrics. Our empirical evaluation shows that CodeKernel selects more accurate code examples than the related work (MUSE and eXoaDocs). A user study involving 25 developers in a multinational company also confirms the usefulness of CodeKernel in selecting API usage examples.","","","10.1109/ASE.2019.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952546","API usage example, graph kernel, code search, software reuse","","","","","","53","","","","","IEEE","IEEE Conferences"
"Empirical Evaluation of the Impact of Class Overlap on Software Defect Prediction","L. Gong; S. Jiang; R. Wang; L. Jiang","China University of Mining and Technology; China University of Mining and Technology; China University of Mining and Technology; China University of Mining and Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","698","709","Software defect prediction (SDP) utilizes the learning models to detect the defective modules in project, and their performance depends on the quality of training data. The previous researches mainly focus on the quality problems of class imbalance and feature redundancy. However, training data often contains some instances that belong to different class but have similar values on features, and this leads to class overlap to affect the quality of training data. Our goal is to investigate the impact of class overlap on software defect prediction. At the same time, we propose an improved K-Means clustering cleaning approach (IKMCCA) to solve both the class overlap and class imbalance problems. Specifically, we check whether K-Means clustering cleaning approach (KMCCA) or neighborhood cleaning learning (NCL) or IKMCCA is feasible to improve defect detection performance for two cases (i) within-project defect prediction (WPDP) (ii) cross-project defect prediction (CPDP). To have an objective estimate of class overlap, we carry out our investigations on 28 open source projects, and compare the performance of state-of-the-art learning models for the above-mentioned cases by using IKMCCA or KMCCA or NCL VS. without cleaning data. The experimental results make clear that learning models obtain significantly better performance in terms of balance, Recall and AUC for both WPDP and CPDP when the overlapping instances are removed. Moreover, it is better to consider both class overlap and class imbalance.","","","10.1109/ASE.2019.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952192","Class overlap;Software defect prediction;K Means clustering;Machine learning","","","","","","41","","","","","IEEE","IEEE Conferences"
"SEGATE: Unveiling Semantic Inconsistencies between Code and Specification of String Inputs","D. Sondhi; R. Purandare","IIIT Delhi; IIIT Delhi","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","200","212","Automated testing techniques are often assessed on coverage based metrics. However, despite giving good coverage, the test cases may miss the gap between functional specification and the code implementation. This gap may be subtle in nature, arising due to the absence of logical checks, either in the implementation or in the specification, resulting in inconsistencies in the input definition. The inconsistencies may be prevalent especially for structured inputs, commonly specified using string-based data types. Our study on defects reported over popular libraries reveals that such gaps may not be limited to input validation checks. We propose a test generation technique for structured string inputs where we infer inconsistencies in input definition to expose semantic gaps in the method under test and the method specification. We assess this technique using our tool SEGATE, Semantic Gap Tester. SEGATE uses static analysis and automaton modeling to infer the gap and generate test cases. On our benchmark dataset, comprising of defects reported in 15 popular open-source libraries, written in Java, SEGATE was able to generate tests to expose 80% of the defects.","","","10.1109/ASE.2019.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952371","testing;static analysis;string input generation;regular expression;automaton modeling;data flow analysis","","","","","","47","","","","","IEEE","IEEE Conferences"
"DaPanda: Detecting Aggressive Push Notifications in Android Apps","T. Liu; H. Wang; L. Li; G. Bai; Y. Guo; G. Xu","Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Monash University; The University of Queensland; Peking University; Beijing University of Posts and Telecommunications","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","66","78","Mobile push notifications have been widely used in mobile platforms to deliver all sorts of information to app users. Although it offers great convenience for both app developers and mobile users, this feature was frequently reported to serve malicious and aggressive purposes, such as delivering annoying push notification advertisement. However, to the best of our knowledge, this problem has not been studied by our research community so far. To fill the void, this paper presents the first study to detect aggressive push notifications and further characterize them in the global mobile app ecosystem on a large scale. To this end, we first provide a taxonomy of mobile push notifications and identify the aggressive ones using a crowdsourcing-based method. Then we propose sc DaPanda, a novel hybrid approach, aiming at automatically detecting aggressive push notifications in Android apps. sc DaPanda leverages a guided testing approach to systematically trigger and record push notifications. By instrumenting the Android framework, sc DaPanda further collects all notification-relevant runtime information to flag the aggressive ones. Our experimental results show that sc DaPanda is capable of detecting different types of aggressive push notifications effectively in an automated way. By applying sc DaPanda to 20,000 Android apps from different app markets, it yields over 1,000 aggressive notifications, which have been further confirmed as true positives. Our in-depth analysis further reveals that aggressive notifications are prevalent across different markets and could be manifested in all the phases in the lifecycle of push notifications. It is hence urgent for our community to take actions to detect and mitigate apps involving aggressive push notifications.","","","10.1109/ASE.2019.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952509","Push notification;dynamic analysis;advertisement;Android;mobile app","","","","","","75","","","","","IEEE","IEEE Conferences"
"Efficient Test Generation Guided by Field Coverage Criteria","A. Godio; V. Bengolea; P. Ponzio; N. Aguirre; M. F. Frias","ITBA; UNRC; UNRC; UNRC; ITBA","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","91","101","Field-exhaustive testing is a testing criterion suitable for object-oriented code over complex, heap-allocated, data structures. It requires test suites to contain enough test inputs to cover all feasible values for the object's fields within a certain scope (input-size bound). While previous work shows that field-exhaustive suites can be automatically generated, the generation technique required a formal specification of the inputs that can be subject to SAT-based analysis. Moreover, the restriction of producing all feasible values for inputs' fields makes test generation costly. In this paper, we deal with field coverage as testing criteria that measure the quality of a test suite in terms of coverage and mutation score, by examining to what extent the values of inputs' fields are covered. In particular, we consider field coverage in combination with test generation based on symbolic execution to produce underapproximations of field-exhaustive suites, using the Symbolic Pathfinder tool. To underapproximate these suites we use tranScoping, a technique that estimates characteristics of yet to be run analyses for large scopes, based on data obtained from analyses performed in small scopes. This provides us with a suitable condition to prematurely stop the symbolic execution. As we show, tranScoping different metrics regarding field coverage allows us to produce significantly smaller suites using a fraction of the generation time. All this while retaining the effectiveness of field exhaustive suites in terms of test suite quality.","","","10.1109/ASE.2019.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952481","Field-exhaustive testing, field-based testing, symbolic execution, transcoping","","","","","","32","","","","","IEEE","IEEE Conferences"
"Fine-Grain Memory Object Representation in Symbolic Execution","M. Nowack","Imperial College London","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","912","923","Dynamic Symbolic Execution (DSE) has seen rising popularity as it allows to check applications for behaviours such as error patterns automatically. One of its biggest challenges is the state space explosion problem: DSE tries to evaluate all possible execution paths of an application. For every path, it needs to represent the allocated memory and its accesses. Even though different approaches have been proposed to mitigate the state space explosion problem, DSE still needs to represent a multitude of states in parallel to analyse them. If too many states are present, they cannot fit into memory, and DSE needs to terminate them prematurely or store them on disc intermediately. With a more efficient representation of allocated memory, DSE can handle more states simultaneously, improving its performance. In this work, we introduce an enhanced, fine-grain and efficient representation of memory that mimics the allocations of tested applications. We tested Coreutils using three different search strategies with our implementation on top of the symbolic execution engine KLEE. We achieve a significant reduction of the memory consumption of states by up to 99.06% (mean DFS: 2%, BFS: 51%, Cov.: 49%), allowing to represent more states in memory more efficiently. The total execution time is reduced by up to 97.81% (mean DFS: 9%, BFS: 7%, Cov.:4%)—a speedup of 49x in comparison to baseline KLEE.","","","10.1109/ASE.2019.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952548","symbolic execution;memory representation","","","","","","18","","","","","IEEE","IEEE Conferences"
"PeASS: A Tool for Identifying Performance Changes at Code Level","D. G. Reichelt; S. Kühne; W. Hasselbring","Universität Leipzig; Universität Leipzig; Christian-Albrechts-Universität zu Kiel","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1146","1149","We present PeASS (Performance Analysis of Software System versions), a tool for detecting performance changes at source code level that occur between different code versions. By using PeASS, it is possible to identify performance regressions that happened in the past to fix them. PeASS measures the performance of unit tests in different source code versions. To achieve statistic rigor, measurements are repeated and analyzed using an agnostic t-test. To execute a minimal amount of tests, PeASS uses a regression test selection. We evaluate PeASS on a selection of Apache Commons projects and show that 81% of all unit test covered performance changes can be found by PeASS. A video presentation is available at https://www.youtube.com/watch?v=RORFEGSCh6Y and PeASS can be downloaded from https://github.com/DaGeRe/peass.","","","10.1109/ASE.2019.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952552","software performance engineering;empirical software engineering;performance measurement;performance benchmarking","","","","","","22","","","","","IEEE","IEEE Conferences"
"The Impact of Structure on Software Merging: Semistructured Versus Structured Merge","G. Cavalcanti; P. Borba; G. Seibt; S. Apel","Federal University of Pernambuco; Federal University of Pernambuco; University of Passau; Saarland University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1002","1013","Merge conflicts often occur when developers concurrently change the same code artifacts. While state of practice unstructured merge tools (e.g Git merge) try to automatically resolve merge conflicts based on textual similarity, semistructured and structured merge tools try to go further by exploiting the syntactic structure and semantics of the artifacts involved. Although there is evidence that semistructured merge has significant advantages over unstructured merge, and that structured merge reports significantly fewer conflicts than unstructured merge, it is unknown how semistructured merge compares with structured merge. To help developers decide which kind of tool to use, we compare semistructured and structured merge in an empirical study by reproducing more than 40,000 merge scenarios from more than 500 projects. In particular, we assess how often the two merge strategies report different results, we identify conflicts incorrectly reported by one but not by the other (false positives), and conflicts correctly reported by one but missed by the other (false negatives). Our results show that semistructured and structured merge differ in 24% of the scenarios with conflicts. Semistructured merge reports more false positives, whereas structured merge has more false negatives. Finally, we found that adapting a semistructured merge tool to resolve a particular kind of conflict makes semistructured and structured merge even closer.","","","10.1109/ASE.2019.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952301","software merging, collaborative development, code integration, version control systems","","","","","","41","","","","","IEEE","IEEE Conferences"
"ReduKtor: How We Stopped Worrying About Bugs in Kotlin Compiler","D. Stepanov; M. Akhin; M. Belyaev","Saint Petersburg Polytechnic University; Saint Petersburg Polytechnic University; Saint Petersburg Polytechnic University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","317","326","Bug localization is well-known to be a difficult problem in software engineering, and specifically in compiler development, where it is beneficial to reduce the input program to a minimal reproducing example; this technique is more commonly known as delta debugging. What additionally contributes to the problem is that every new programming language has its own unique quirks and foibles, making it near impossible to reuse existing tools and approaches with full efficiency. In this experience paper we tackle the delta debugging problem w.r.t. Kotlin, a relatively new programming language from JetBrains. Our approach is based on a novel combination of program slicing, hierarchical delta debugging and Kotlin-specific transformations, which are synergistic to each other. We implemented it in a prototype called ReduKtor and did extensive evaluation on both synthetic and real Kotlin programs; we also compared its performance with classic delta debugging techniques. The evaluation results support the practical usability of our approach to Kotlin delta debugging and also shows the importance of using both language-agnostic and language-specific techniques to achieve best reduction efficiency and performance.","","","10.1109/ASE.2019.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952444","program fuzzing;delta debugging;program slicing;input reduction;compiler testing","","","","","","27","","","","","IEEE","IEEE Conferences"
"Continuous Incident Triage for Large-Scale Online Service Systems","J. Chen; X. He; Q. Lin; H. Zhang; D. Hao; F. Gao; Z. Xu; Y. Dang; D. Zhang","Tianjin University; Microsoft Research; Microsoft Research; The University of Newcastle; Peking University; Microsoft Azure; Microsoft Azure; Microsoft Azure; Microsoft Research","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","364","375","In recent years, online service systems have become increasingly popular. Incidents of these systems could cause significant economic loss and customer dissatisfaction. Incident triage, which is the process of assigning a new incident to the responsible team, is vitally important for quick recovery of the affected service. Our industry experience shows that in practice, incident triage is not conducted only once in the beginning, but is a continuous process, in which engineers from different teams have to discuss intensively among themselves about an incident, and continuously refine the incident-triage result until the correct assignment is reached. In particular, our empirical study on 8 real online service systems shows that the percentage of incidents that were reassigned ranges from 5.43% to 68.26% and the number of discussion items before achieving the correct assignment is up to 11.32 on average. To improve the existing incident triage process, in this paper, we propose DeepCT, a Deep learning based approach to automated Continuous incident Triage. DeepCT incorporates a novel GRU-based (Gated Recurrent Unit) model with an attention-based mask strategy and a revised loss function, which can incrementally learn knowledge from discussions and update incident-triage results. Using DeepCT, the correct incident assignment can be achieved with fewer discussions. We conducted an extensive evaluation of DeepCT on 14 large-scale online service systems in Microsoft. The results show that DeepCT is able to achieve more accurate and efficient incident triage, e.g., the average accuracy identifying the responsible team precisely is 0.641~0.729 with the number of discussion items increasing from 1 to 5. Also, DeepCT statistically significantly outperforms the state-of-the-art bug triage approach.","","","10.1109/ASE.2019.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952483","Incident Triage;Online Service Systems;Deep Learning","","","","","1","50","","","","","IEEE","IEEE Conferences"
"Test Transfer Across Mobile Apps Through Semantic Mapping","J. Lin; R. Jabbarvand; S. Malek","University of California, Irvine; University of California, Irvine; University of California, Irvine","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","42","53","GUI-based testing has been primarily used to examine the functionality and usability of mobile apps. Despite the numerous GUI-based test input generation techniques proposed in the literature, these techniques are still limited by (1) lack of context-aware text inputs; (2) failing to generate expressive tests; and (3) absence of test oracles. To address these limitations, we propose CraftDroid, a framework that leverages information retrieval, along with static and dynamic analysis techniques, to extract the human knowledge from an existing test suite for one app and transfer the test cases and oracles to be used for testing other apps with the similar functionalities. Evaluation of CraftDroid on real-world commercial Android apps corroborates its effectiveness by achieving 73% precision and 90% recall on average for transferring both the GUI events and oracles. In addition, 75% of the attempted transfers successfully generated valid and feature-based tests for popular features among apps in the same category.","","","10.1109/ASE.2019.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952228","Test transfer, test migration, GUI testing, natural language processing, semantic similarity","","","","","1","43","","","","","IEEE","IEEE Conferences"
"Root Cause Localization for Unreproducible Builds via Causality Analysis Over System Call Tracing","Z. Ren; C. Liu; X. Xiao; H. Jiang; T. Xie","Dalian University of Technology; Case Western Reserve University; Case Western Reserve University; Dalian University of Technology; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","527","538","Localization of the root causes for unreproducible builds during software maintenance is an important yet challenging task, primarily due to limited runtime traces from build processes and high diversity of build environments. To address these challenges, in this paper, we propose RepTrace, a framework that leverages the uniform interfaces of system call tracing for monitoring executed build commands in diverse build environments and identifies the root causes for unreproducible builds by analyzing the system call traces of the executed build commands. Specifically, from the collected system call traces, RepTrace performs causality analysis to build a dependency graph starting from an inconsistent build artifact (across two builds) via two types of dependencies: read/write dependencies among processes and parent/child process dependencies, and searches the graph to find the processes that result in the inconsistencies. To address the challenges of massive noisy dependencies and uncertain parent/child dependencies, RepTrace includes two novel techniques: (1) using differential analysis on multiple builds to reduce the search space of read/write dependencies, and (2) computing similarity of the runtime values to filter out noisy parent/child process dependencies. The evaluation results of RepTrace over a set of real-world software packages show that RepTrace effectively finds not only the root cause commands responsible for the unreproducible builds, but also the files to patch for addressing the unreproducible issues. Among its Top-10 identified commands and files, RepTrace achieves high accuracy rate of 90.00% and 90.56% in identifying the root causes, respectively.","","","10.1109/ASE.2019.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952375","unreproducible builds;localization;system call tracing","","","","","","30","","","","","IEEE","IEEE Conferences"
"Targeted Example Generation for Compilation Errors","U. Z. Ahmed; R. Sindhgatta; N. Srivastava; A. Karkare","IIT Kanpur; Queensland University of Technology; IIT Kanpur; IIT Kanpur","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","327","338","We present TEGCER, an automated feedback tool for novice programmers. TEGCER uses supervised classification to match compilation errors in new code submissions with relevant pre-existing errors, submitted by other students before. The dense neural network used to perform this classification task is trained on 15000+ error-repair code examples. The proposed model yields a test set classification Pred@3 accuracy of 97.7% across 212 error category labels. Using this model as its base, TEGCER presents students with the closest relevant examples of solutions for their specific error on demand. A large scale (N>230) usability study shows that students who use TEGCER are able to resolve errors more than 25% faster on average than students being assisted by human tutors.","","","10.1109/ASE.2019.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952446","Intelligent Tutoring Systems;Introductory Programming;Compilation Error;Example Generation;Neural Networks","","","","","","39","","","","","IEEE","IEEE Conferences"
"Semistructured Merge in JavaScript Systems","A. Trindade Tavares; P. Borba; G. Cavalcanti; S. Soares","Federal University of Pernambuco; Federal University of Pernambuco; Federal University of Pernambuco; Federal University of Pernambuco","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1014","1025","Industry widely uses unstructured merge tools that rely on textual analysis to detect and resolve conflicts between code contributions. Semistructured merge tools go further by partially exploring the syntactic structure of code artifacts, and, as a consequence, obtaining significant merge accuracy gains for Java-like languages. To understand whether semistructured merge and the observed gains generalize to other kinds of languages, we implement two semistructured merge tools for JavaScript, and compare them to an unstructured tool. We find that current semistructured merge algorithms and frameworks are not directly applicable for scripting languages like JavaScript. By adapting the algorithms, and studying 10,345 merge scenarios from 50 JavaScript projects on GitHub, we find evidence that our JavaScript tools report fewer spurious conflicts than unstructured merge, without compromising the correctness of the merging process. The gains, however, are much smaller than the ones observed for Java-like languages, suggesting that semistructured merge advantages might be limited for languages that allow both commutative and non-commutative declarations at the same syntactic level.","","","10.1109/ASE.2019.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952450","Collaborative development, Software merging, Semistructured merge, Version control systems, JavaScript","","","","","","37","","","","","IEEE","IEEE Conferences"
"Detecting Error-Handling Bugs without Error Specification Input","Z. Jia; S. Li; T. Yu; X. Liao; J. Wang; X. Liu; Y. Liu","National University of Defense Technology; National University of Defense Technology; University of Kentucky; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","213","225","Most software systems frequently encounter errors when interacting with their environments. When errors occur, error-handling code must execute flawlessly to facilitate system recovery. Implementing correct error handling is repetitive but non-trivial, and developers often inadvertently introduce bugs into error-handling code. Existing tools require correct error specifications to detect error-handling bugs. Manually generating error specifications is error-prone and tedious, while automatically mining error specifications is hard to achieve a satisfying accuracy. In this paper, we propose EH-Miner, a novel and practical tool that can automatically detect error-handling bugs without the need for error specifications. Given a function, EH-Miner mines its error-handling rules when the function is frequently checked by an equivalent condition, and handled by the same action. We applied EH-Miner to 117 applications across 15 software domains. EH-Miner mined error-handling rules with the precision of 91.1% and the recall of 46.9%. We reported 142 bugs to developers, and 106 bugs had been confirmed and fixed at the time of writing. We further applied EH-Miner to Linux kernel, and reported 68 bugs for kernel-4.17, of which 42 had been confirmed or fixed.","","","10.1109/ASE.2019.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952517","Error handling;Library function;Specification","","","","","","47","","","","","IEEE","IEEE Conferences"
"CoRA: Decomposing and Describing Tangled Code Changes for Reviewer","M. Wang; Z. Lin; Y. Zou; B. Xie","Peking University; Microsoft Research; Peking University; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1050","1061","Code review is an important mechanism for code quality assurance both in open source software and industrial software. Reviewers usually suffer from numerous, tangled and loosely related code changes that are bundled in a single commit, which makes code review very difficult. In this paper, we propose CoRA (Code Review Assistant), an automatic approach to decompose a commit into different parts and generate concise descriptions for reviewers. More specifically, CoRA can decompose a commit into independent parts (e.g., bug fixing, new feature adding, or refactoring) by code dependency analysis and tree-based similar-code detection, then identify the most important code changes in each part based on the PageRank algorithm and heuristic rules. As a result, CoRA can generate a concise description for each part of the commit. We evaluate our approach in seven open source software projects and 50 code commits. The results indicate that CoRA can improve the accuracy of decomposing code changes by 6.3% over the state-ofart practice. At the same time, CoRA can identify the important part from the fine-grained code changes with a mean average precision (MAP) of 87.7%. We also conduct a human study with eight participants to evaluate the performance and usefulness of CoRA, the user feedback indicates that CoRA can effectively help reviewers.","","","10.1109/ASE.2019.00101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952413","Code review;Code changes decomposition;Code changes description;Program comprehension","","","","","","53","","","","","IEEE","IEEE Conferences"
"B2SFinder: Detecting Open-Source Software Reuse in COTS Software","Z. Yuan; M. Feng; F. Li; G. Ban; Y. Xiao; S. Wang; Q. Tang; H. Su; C. Yu; J. Xu; A. Piao; J. Xuey; W. Huo","Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; Chinese Academy of Sciences; University of New South Wales; Chinese Academy of Sciences","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1038","1049","COTS software products are developed extensively on top of OSS projects, resulting in OSS reuse vulnerabilities. To detect such vulnerabilities, finding OSS reuses in COTS software has become imperative. While scalable to tens of thousands of OSS projects, existing binary-to-source matching approaches are severely imprecise in analyzing COTS software products, since they support only a limited number of code features, compute matching scores only approximately in measuring OSS reuses, and neglect the code structures in OSS projects. We introduce a novel binary-to-source matching approach, called B2SFINDER, to address these limitations. First of all, B2SFINDER can reason about seven kinds of code featuresthat are traceable in both binary and source code. In order to compute matching scores precisely, B2SFINDER employs a weighted feature matching algorithm that combines three matching methods (for dealing with different code features) with two importance-weighting methods (for computing the weight of an instance of a code feature in a given COTS software application based on its specificity and occurrence frequency). Finally, B2SFINDER identifies different types of code reusesbased on matching scores and code structures of OSS projects. We have implemented B2SFINDER using an optimized datastructure. We have evaluated B2SFINDERusing 21991 binaries from 1000 popular COTS software products and 2189 candidateOSS projects. Our experimental results show that B2SFINDER is not only precise but also scalable. Compared with the state ofthe art, B2SFINDER has successfully found up to 2.15x as many reuse cases in 53.85 seconds per binary file on average. We also discuss how B2SFINDER can be leveraged in detecting OSS reusevulnerabilities in practice.","","","10.1109/ASE.2019.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952556","COTS Software, OSS, Code Reuse, One Day Vulnerability, Code Feature, Binary-to Source Matching","","","","","","43","","","","","IEEE","IEEE Conferences"
"Property Inference for Deep Neural Networks","D. Gopinath; H. Converse; C. Pasareanu; A. Taly","Carnegie Mellon University; The University of Texas at Austin; Carnegie Mellon University and NASA Ames; Fiddler labs","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","797","809","We present techniques for automatically inferring formal properties of feed-forward neural networks. We observe that a significant part (if not all) of the logic of feed forward networks is captured in the activation status (on or off) of its neurons. We propose to extract patterns based on neuron decisions as preconditions that imply certain desirable output property e.g., the prediction being a certain class. We present techniques to extract input properties, encoding convex predicates on the input space that imply given output properties and layer properties, representing network properties captured in the hidden layers that imply the desired output behavior. We apply our techniques on networks for the MNIST and ACASXU applications. Our experiments highlight the use of the inferred properties in a variety of tasks, such as explaining predictions, providing robustness guarantees, simplifying proofs, and network distillation.","","","10.1109/ASE.2019.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952519","Deep Neural Networks;Explainability;Property Inference;Data Mining","","","","","1","36","","","","","IEEE","IEEE Conferences"
"Combining Spectrum-Based Fault Localization and Statistical Debugging: An Empirical Study","J. Jiang; R. Wang; Y. Xiong; X. Chen; L. Zhang","Peking University; Peking University; Peking University; Sun Yat-sen University; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","502","514","Program debugging is a time-consuming task, and researchers have proposed different kinds of automatic fault localization techniques to mitigate the burden of manual debugging. Among these techniques, two popular families are spectrum-based fault localization (SBFL) and statistical debugging (SD), both localizing faults by collecting statistical information at runtime. Though the ideas are similar, the two families have been developed independently and their combinations have not been systematically explored. In this paper we perform a systematical empirical study on the combination of SBFL and SD. We first build a unified model of the two techniques, and systematically explore four types of variations, different predicates, different risk evaluation formulas, different granularities of data collection, and different methods of combining suspicious scores. Our study leads to several findings. First, most of the effectiveness of the combined approach contributed by a simple type of predicates: branch conditions. Second, the risk evaluation formulas of SBFL significantly outperform that of SD. Third, fine-grained data collection significantly outperforms coarse-grained data collection with a little extra execution overhead. Fourth, a linear combination of SBFL and SD predicates outperforms both individual approaches. According to our empirical study, we propose a new fault localization approach, PREDFL (Predicate-based Fault Localization), with the best configuration for each dimension under the unified model. Then, we explore its complementarity to existing techniques by integrating PREDFL with a state-of-the-art fault localization framework. The experimental results show that PREDFL can further improve the effectiveness of state-of-the-art fault localization techniques. More concretely, integrating PREDFL results in an up to 20.8% improvement w.r.t the faults successfully located at Top-1, which reveals that PREDFL complements existing techniques.","","","10.1109/ASE.2019.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952344","Software engineering, Fault localization, Program debugging","","","","","","79","","","","","IEEE","IEEE Conferences"
"SGUARD: A Feature-Based Clustering Tool for Effective Spreadsheet Defect Detection","D. Li; H. Wang; C. Xu; R. Zhang; S. Cheung; X. Ma","Nanjing University; Nanjing University; Nanjing University; Microsoft, China; The Hong Kong University of Sci. and Tech.; Nanjing University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1142","1145","Spreadsheets are widely used but subject to various defects. In this paper, we present SGUARD to effectively detect spreadsheet defects. SGUARD learns spreadsheet features to cluster cells with similar computational semantics, and then refines these clusters to recognize anomalous cells as defects. SGUARD well balances the trade-off between the precision (87.8%) and recall rate (71.9%) in the defect detection, and achieves an F-measure of 0.79, exceeding existing spreadsheet defect detection techniques. We introduce the SGUARD implementation and its usage by a video presentation (https://youtu.be/gNPmMvQVf5Q), and provide its public download repository (https://github.com/sheetguard/sguard).","","","10.1109/ASE.2019.00122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952240","Cell clustering;Defect detection","","","","","","23","","","","","IEEE","IEEE Conferences"
"RANDR: Record and Replay for Android Applications via Targeted Runtime Instrumentation","O. Sahin; A. Aliyeva; H. Mathavan; A. Coskun; M. Egele","Boston University; Boston University; Boston University; Boston University; Boston University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","128","138","The ability to repeat the execution of a program is a fundamental requirement in many areas of computing from computer system evaluation to software engineering. Reproducing executions of mobile apps, in particular, has proven difficult under real-life scenarios due to multiple sources of external inputs and interactive nature of the apps. Previous works that provide record/replay functionality for mobile apps are restricted to particular input sources (e.g., touchscreen events) and present deployment challenges due to intrusive modifications to the underlying software stack. Moreover, due to their reliance on record and replay of device specific events, the recorded executions cannot be reliably reproduced across different platforms. In this paper, we present a new practical approach, RandR, for record and replay of Android applications. RandR captures and replays multiple sources of input (i.e., UI and network) without requiring source code (OS or app), administrative device privileges, or any special platform support. RandR achieves these qualities by instrumenting a select set of methods at runtime within an application's own sandbox. In addition, to enable portability of recorded executions across different platforms for replay, RandR contextualizes UI events as interactions with particular UI components (e.g., a button) as opposed to relying on platform specific features (e.g., screen coordinates). We demonstrate RandR's accurate cross-platform record and replay capabilities using over 30 real-world Android apps across a variety of platforms including emulators as well as commercial off-the-shelf mobile devices deployed in real life.","","","10.1109/ASE.2019.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952379","Record;Replay;Android;Testing;Tools;Mobile Systems;Automation","","","","","","40","","","","","IEEE","IEEE Conferences"
"Performance-Boosting Sparsification of the IFDS Algorithm with Applications to Taint Analysis","D. He; H. Li; L. Wang; H. Meng; H. Zheng; J. Liu; S. Hu; L. Li; J. Xue","UNSW Sydney; SKL of Computer Architecture, ICT, CAS, China; University of Chinese Academy of Sciences; SKL of Computer Architecture, ICT, CAS, China; University of Chinese Academy of Sciences; SKL of Computer Architecture, ICT, CAS, China; University of Chinese Academy of Sciences; SKL of Computer Architecture, ICT, CAS, China; University of Chinese Academy of Sciences; SKL of Computer Architecture, ICT, CAS, China; University of Chinese Academy of Sciences; UNSW Sydney; Vivo AI Lab, China; SKL of Computer Architecture, ICT, CAS, China; University of Chinese Academy of Sciences; UNSW Sydney","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","267","279","The IFDS algorithm can be compute-and memoryintensive for some large programs, often running for a long time (more than expected) or terminating prematurely after some time and/or memory budgets have been exhausted. In the latter case, the corresponding IFDS data-flow analyses may suffer from false negatives and/or false positives. To improve this, we introduce a sparse alternative to the traditional IFDS algorithm. Instead of propagating the data-flow facts across all the program points along the program’s (interprocedural) control flow graph, we propagate every data-flow fact directly to its next possible use points along its own sparse control flow graph constructed on the fly, thus reducing significantly both the time and memory requirements incurred by the traditional IFDS algorithm. In our evaluation, we compare FLOWDROID, a taint analysis performed by using the traditional IFDS algorithm, with our sparse incarnation, SPARSEDROID, on a set of 40 Android apps selected. For the time budget (5 hours) and memory budget (220GB) allocated per app, SPARSEDROID can run every app to completion but FLOWDROID terminates prematurely for 9 apps, resulting in an average speedup of 22.0x. This implies that when used as a market-level vetting tool, SPARSEDROID can finish analyzing these 40 apps in 2.13 hours (by issuing 228 leak warnings) while FLOWDROID manages to analyze only 30 apps in the same time period (by issuing only 147 leak warnings).","","","10.1109/ASE.2019.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952383","IFDS, data-flow analysis, taint analysis","","","","","","51","","","","","IEEE","IEEE Conferences"
"Empirical Study of Programming to an Interface","B. Verhaeghe; C. Fuhrman; L. Guerrouj; N. Anquetil; S. Ducasse","Berger-Levrault, France; École de Technologie Supérieure, Montreal, Canada; École de Technologie Supérieure, Montreal, Canada; Université de Lille, France; RMoD - Inria Nord Europe, Lille, France","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","847","850","A popular recommendation to programmers in object-oriented software is to ""program to an interface, not an implementation"" (PTI). Expected benefits include increased simplicity from abstraction, decreased dependency on implementations, and higher flexibility. Yet, interfaces must be immutable, excessive class hierarchies can be a form of complexity, and ""speculative generality"" is a known code smell. To advance the empirical knowledge of PTI, we conducted an empirical investigation that involves 126 Java projects on GitHub, aiming to measuring the decreased dependency benefits (in terms of cochange).","","","10.1109/ASE.2019.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952238","Java interfaces, coupling, empirical study, software repositories, cochange, GitHub","","","","","","18","","","","","IEEE","IEEE Conferences"
"Mutation Analysis for Coq","A. Celik; K. Palmskog; M. Parovic; E. Jesús Gallego Arias; M. Gligoric","The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin; MINES ParisTech; The University of Texas at Austin","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","539","551","Mutation analysis, which introduces artificial defects into software systems, is the basis of mutation testing, a technique widely applied to evaluate and enhance the quality of test suites. However, despite the deep analogy between tests and formal proofs, mutation analysis has seldom been considered in the context of deductive verification. We propose mutation proving, a technique for analyzing verification projects that use proof assistants. We implemented our technique for the Coq proof assistant in a tool dubbed mCoq. mCoq applies a set of mutation operators to Coq definitions of functions and datatypes, inspired by operators previously proposed for functional programming languages. mCoq then checks proofs of lemmas affected by operator application. To make our technique feasible in practice, we implemented several optimizations in mCoq such as parallel proof checking. We applied mCoq to several medium and large scale Coq projects, and recorded whether proofs passed or failed when applying different mutation operators. We then qualitatively analyzed the mutants, finding many instances of incomplete specifications. For our evaluation, we made several improvements to serialization of Coq files and even discovered a notable bug in Coq itself, all acknowledged by developers. We believe mCoq can be useful both to proof engineers for improving the quality of their verification projects and to researchers for evaluating proof engineering techniques.","","","10.1109/ASE.2019.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952421","mutation proving;Coq;prof assistants;mutation testing","","","","","","61","","","","","IEEE","IEEE Conferences"
"ACTGAN: Automatic Configuration Tuning for Software Systems with Generative Adversarial Networks","L. Bao; X. Liu; F. Wang; B. Fang","XiDian University; University of California, Davis; XiDian University; XiDian University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","465","476","Complex software systems often provide a large number of parameters so that users can configure them for their specific application scenarios. However, configuration tuning requires a deep understanding of the software system, far beyond the abilities of typical system users. To address this issue, many existing approaches focus on exploring and learning good performance estimation models. The accuracy of such models often suffers when the number of available samples is small, a thorny challenge under a given tuning-time constraint. By contrast, we hypothesize that good configurations often share certain hidden structures. Therefore, instead of trying to improve the performance estimation of a given configuration, we focus on capturing the hidden structures of good configurations and utilizing such learned structure to generate potentially better configurations. We propose ACTGAN to achieve this goal. We have implemented and evaluated ACTGAN using 17 workloads with eight different software systems. Experimental results show that ACTGAN outperforms default configurations by 76.22% on average, and six state-of-the-art configuration tuning algorithms by 6.58%-64.56%. Furthermore, the ACTGAN-generated configurations are often better than those used in training and show certain features consisting with domain knowledge, both of which supports our hypothesis.","","","10.1109/ASE.2019.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952456","software system;automatic configuration tuning;generative adversarial networks","","","","","","57","","","","","IEEE","IEEE Conferences"
"Statistical Log Differencing","L. Bao; N. Busany; D. Lo; S. Maoz","Zhejiang University City College, China; Tel Aviv University; Singapore Management University, Singapore; Tel Aviv University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","851","862","Recent works have considered the problem of log differencing: given two or more system's execution logs, output a model of their differences. Log differencing has potential applications in software evolution, testing, and security. In this paper we present statistical log differencing, which accounts for frequencies of behaviors found in the logs. We present two algorithms, s2KDiff for differencing two logs, and snKDiff, for differencing of many logs at once, both presenting their results over a single inferred model. A unique aspect of our algorithms is their use of statistical hypothesis testing: we let the engineer control the sensitivity of the analysis by setting the target distance between probabilities and the statistical significance value, and report only (and all) the statistically significant differences. Our evaluation shows the effectiveness of our work in terms of soundness, completeness, and performance. It also demonstrates its effectiveness compared to previous work via a user-study and its potential applications via a case study using real-world logs.","","","10.1109/ASE.2019.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952205","Log analysis;Model inference","","","","","","39","","","","","IEEE","IEEE Conferences"
"VeriSmart 2.0: Swarm-Based Bug-Finding for Multi-threaded Programs with Lazy-CSeq","B. Fischer; S. La Torre; G. Parlato","Stellenbosch University; University of Salerno; University of Molise","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1150","1153","Swarm-based verification methods split a verification problem into a large number of independent simpler tasks and so exploit the availability of large numbers of cores to speed up verification. Lazy-CSeq is a BMC-based bug-finding tool for C programs using POSIX threads that is based on sequentialization. Here we present the tool VeriSmart 2.0, which extends Lazy-CSeq with a swarm-based bug-finding method. The key idea of this approach is to constrain the interleaving such that context switches can only happen within selected tiles (more specifically, contiguous code segments within the individual threads). This under-approximates the program's behaviours, with the number and size of tiles as additional parameters, which allows us to vary the complexity of the tasks. Overall, this significantly improves peak memory consumption and (wall-clock) analysis time.","","","10.1109/ASE.2019.00124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952527","program analysis;verification;concurrency;sequentialization;swarm verification","","","","","","19","","","","","IEEE","IEEE Conferences"
"Automated Trainability Evaluation for Smart Software Functions","I. Gerostathopoulos; S. Kugele; C. Segler; T. Bures; A. Knoll","Technical University of Munich; Technical University of Munich; BMW Group Research; Charles University in Prague; Technical University of Munich","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","998","1001","More and more software-intensive systems employ machine learning and runtime optimization to improve their functionality by providing advanced features (e. g. personal driving assistants or recommendation engines). Such systems incorporate a number of smart software functions (SSFs) which gradually learn and adapt to the users' preferences. A key property of SSFs is their ability to learn based on data resulting from the interaction with the user (implicit and explicit feedback)-which we call trainability. Newly developed and enhanced features in a SSF must be evaluated based on their effect on the trainability of the system. Despite recent approaches for continuous deployment of machine learning systems, trainability evaluation is not yet part of continuous integration and deployment (CID) pipelines. In this paper, we describe the different facets of trainability for the development of SSFs. We also present our approach for automated trainability evaluation within an automotive CID framework which proposes to use automated quality gates for the continuous evaluation of machine learning models. The results from our indicative evaluation based on real data from eight BMW cars highlight the importance of continuous and rigorous trainability evaluation in the development of SSFs.","","","10.1109/ASE.2019.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952173","trainability;smart software functions;continuous deployment","","","","","","10","","","","","IEEE","IEEE Conferences"
"VisFuzz: Understanding and Intervening Fuzzing with Interactive Visualization","C. Zhou; M. Wang; J. Liang; Z. Liu; C. Sun; Y. Jiang","Tsinghua University; Tsinghua University; Tsinghua University; Nanjing University of Aeronautics and Astronautics; Waterloo University; Tsinghua University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1078","1081","Fuzzing is widely used for vulnerability detection. One of the challenges for an efficient fuzzing is covering code guarded by constraints such as the magic number and nested conditions. Recently, academia has partially addressed the challenge via whitebox methods. However, high-level constraints such as array sorts, virtual function invocations, and tree set queries are yet to be handled. To meet this end, we present VisFuzz, an interactive tool for better understanding and intervening fuzzing process via real-time visualization. It extracts call graph and control flow graph from source code, maps each function and basic block to the line of source code and tracks real-time execution statistics with detail constraint contexts. With VisFuzz, test engineers first locate blocking constraints and then learn its semantic context, which helps to craft targeted inputs or update test drivers. Preliminary evaluations are conducted on four real-world programs in Google fuzzer-test-suite. Given additional 15 minutes to understand and intervene the state of fuzzing, the intervened fuzzing outperform the original pure AFL fuzzing, and the path coverage improvements range from 10.84% to 150.58%, equally fuzzed by for 12 hours.","","","10.1109/ASE.2019.00106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952352","fuzz testing;software testing;visualization","","","","","","14","","","","","IEEE","IEEE Conferences"
"Systematically Covering Input Structure","N. Havrikov; A. Zeller","CISPA Helmholtz Institute for Information Security; CISPA Helmholtz Institute for Information Security","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","189","199","Grammar-based testing uses a given grammar to produce syntactically valid inputs. To cover program features, it is necessary to also cover input features—say, all URL variants for a URL parser. Our k-path algorithm for grammar production systematically covers syntactic elements as well as their combinations. In our evaluation, we show that this results in a significantly higher code coverage than state of the art.","","","10.1109/ASE.2019.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952419","grammar based;fuzz testing","","","","","","52","","","","","IEEE","IEEE Conferences"
"Test Migration Between Mobile Apps with Similar Functionality","F. Behrang; A. Orso","Georgia Institute of Technology; Georgia Institute of Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","54","65","The use of mobile apps is increasingly widespread, and much effort is put into testing these apps to make sure they behave as intended. To reduce this effort, and thus the overall cost of mobile app testing, we propose APPTESTMIGRATOR, a technique for migrating test cases between apps in the same category (e.g., banking apps). The intuition behind APPTESTMIGRATOR is that many apps share similarities in their functionality, and these similarities often result in conceptually similar user interfaces (through which that functionality is accessed). APPTESTMIGRATOR leverages these commonalities between user interfaces to migrate existing tests written for an app to another similar app. Specifically, given (1) a test case for an app (source app) and (2) a second app (target app), APPTESTMIGRATOR attempts to automatically transform the sequence of events and oracles in the test for the source app to events and oracles for the target app. We implemented APPTESTMIGRATOR for Android mobile apps and evaluated it on a set of randomly selected apps from the Google Play Store in four different categories. Our initial results are promising, support our intuition that test migration is possible, and motivate further research in this direction.","","","10.1109/ASE.2019.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952387","Test migration, GUI testing, mobile apps","","","","","1","34","","","","","IEEE","IEEE Conferences"
"Coverage-Guided Fuzzing for Feedforward Neural Networks","X. Xie; H. Chen; Y. Li; L. Ma; Y. Liu; J. Zhao","Nanyang Technological University; Nanyang Technological University; Nanyang Technological University; Kyushu University; Nanyang Technological University; Kyushu University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1162","1165","Deep neural network (DNN) has been widely applied to safety-critical scenarios such as autonomous vehicle, security surveillance, and cyber-physical control systems. Yet, the incorrect behaviors of DNNs can lead to severe accidents and tremendous losses due to hidden defects. In this paper, we present DeepHunter, a general-purpose fuzzing framework for detecting defects of DNNs. DeepHunter is inspired by traditional grey-box fuzzing and aims to increase the overall test coverage by applying adaptive heuristics according to runtime feedback. Specifically, DeepHunter provides a series of seed selection strategies, metamorphic mutation strategies, and testing criteria customized to DNN testing; all these components support multiple built-in configurations which are easy to extend. We evaluated DeepHunter on two popular datasets and the results demonstrate the effectiveness of DeepHunter in achieving coverage increase and detecting real defects. A video demonstration which showcases the main features of DeepHunter can be found at https://youtu.be/s5DfLErcgrc.","","","10.1109/ASE.2019.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952279","Coverage guided testing;deep learning testing;deep neural network","","","","","","15","","","","","IEEE","IEEE Conferences"
"A Study of Oracle Approximations in Testing Deep Learning Libraries","M. Nejadgholi; J. Yang","Concordia University; Concordia University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","785","796","Due to the increasing popularity of deep learning (DL) applications, testing DL libraries is becoming more and more important. Different from testing general software, for which output is often asserted definitely (e.g., an output is compared with an oracle for equality), testing deep learning libraries often requires to perform oracle approximations, i.e., the output is allowed to be within a restricted range of the oracle. However, oracle approximation practices have not been studied in prior empirical work that focuses on traditional testing practices. The prevalence, common practices, maintenance and evolution challenges of oracle approximations remain unknown in literature. In this work, we study oracle approximation assertions implemented to test four popular DL libraries. Our study shows that there exists a non-negligible portion of assertions that leverage oracle approximation in the test cases of DL libraries. Also, we identify the common sources of oracles on which oracle approximations are being performed through a comprehensive manual study. Moreover, we find that developers frequently modify code related to oracle approximations, i.e., using a different approximation API, modifying the oracle or the output from the code under test, and using a different approximation threshold. Last, we performed an in-depth study to understand the reasons behind the evolution of oracle approximation assertions. Our findings reveal important maintenance challenges that developers may face when maintaining oracle approximation practices as code evolves in DL libraries.","","","10.1109/ASE.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952211","Software Quality;Software Testing;Testing Deep Learning Libraries;Test Oracle","","","","","","28","","","","","IEEE","IEEE Conferences"
"Automating CUDA Synchronization via Program Transformation","M. Wu; L. Zhang; C. Liu; S. H. Tan; Y. Zhang","Southern University of Science and Technology; University of Texas at Dallas; University of Texas at Dallas; Southern University of Science and Technology; Southern University of Science and Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","748","759","While CUDA has been the most popular parallel computing platform and programming model for general purpose GPU computing, CUDA synchronization undergoes significant challenges for GPU programmers due to its intricate parallel computing mechanism and coding practices. In this paper, we propose AuCS, the first general framework to automate synchronization for CUDA kernel functions. AuCS transforms the original LLVM-level CUDA program control flow graph in a semantic-preserving manner for exploring the possible barrier function locations. Accordingly, AuCS develops mechanisms to correctly place barrier functions for automating synchronization in multiple erroneous (challenging-to-be-detected) synchronization scenarios, including data race, barrier divergence, and redundant barrier functions. To evaluate the effectiveness and efficiency of AuCS, we conduct an extensive set of experiments and the results demonstrate that AuCS can automate 20 out of 24 erroneous synchronization scenarios.","","","10.1109/ASE.2019.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952529","CUDA;program repair;synchronization automation;program transformation","","","","","","60","","","","","IEEE","IEEE Conferences"
"History-Guided Configuration Diversification for Compiler Test-Program Generation","J. Chen; G. Wang; D. Hao; Y. Xiong; H. Zhang; L. Zhang","Tianjin University; Peking University; Peking University; Peking University; The University of Newcastle; Peking University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","305","316","Compilers, like other software systems, contain bugs, and compiler testing is the most widely-used way to assure compiler quality. A critical task of compiler testing is to generate test programs that could effectively and efficiently discover bugs. Though we can configure test generators such as Csmith to control the features of the generated programs, it is not clear what test configuration is effective. In particular, an effective test configuration needs to generate test programs that are bug-revealing, i.e., likely to trigger bugs, and diverse, i.e., able to discover different types of bugs. It is not easy to satisfy both properties. In this paper, we propose a novel test-program generation approach, called HiCOND, which utilizes historical data for configuration diversification to solve this challenge. HiCOND first infers the range for each option in a test configuration where bug-revealing test programs are more likely to be generated based on historical data. Then, it identifies a set of test configurations that can lead to diverse test programs through a search method (particle swarm optimization). Finally, based on the set of test configurations for compiler testing, HiCOND generates test programs, which are likely to be bug-revealing and diverse. We have conducted experiments on two popular compilers GCC and LLVM, and the results confirm the effectiveness of our approach. For example, HiCOND detects 75.00%, 133.33%, and 145.00% more bugs than the three existing approaches, respectively. Moreover, HiCOND has been successfully applied to actual compiler testing in a global IT company and detected 11 bugs during the practical evaluation.","","","10.1109/ASE.2019.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952321","Compiler Testing;Configuration;History;Search","","","","","1","58","","","","","IEEE","IEEE Conferences"
"An Industrial Experience Report on Performance-Aware Refactoring on a Database-Centric Web Application","B. Chen; Z. M. Jiang; P. Matos; M. Lacaria","York University; York University; Copywell Inc.; Copywell Inc.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","653","664","Modern web applications rely heavily on databases to query and update information. To ease the development efforts, Object Relational Mapping (ORM) frameworks provide an abstraction for developers to manage databases by writing in the same Object-Oriented programming languages. Prior studies have shown that there are various types of performance issues caused by inefficient accesses to databases via different ORM frameworks (e.g., Hibernate and ActiveRecord). However, it is not clear whether the reported performance anti-patterns (common performance issues) can be generalizable across various frameworks. In particular, there is no study focusing on detecting performance issues for applications written in PHP, which is the choice of programming languages for the majority (79%) of web applications. In this experience paper, we detail our process on conducting performance-aware refactoring of an industrial web application written in Laravel, the most popular web framework in PHP. We have derived a complete catalog of 17 performance anti-patterns based on prior research and our experimentation. We have found that some of the reported anti-patterns and refactoring techniques are framework or programming language specific, whereas others are general. The performance impact of the anti-pattern instances are highly dependent on the actual usage context (workload and database settings). When communicating the performance differences before and after refactoring, the results of the complex statistical analysis may be sometimes confusing. Instead, developers usually prefer more intuitive measures like percentage improvement. Experiments show that our refactoring techniques can reduce the response time up to 93.0% and 93.4% for the industrial and the open source application under various scenarios.","","","10.1109/ASE.2019.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952177","performance anti patterns;ORM framework;database centric applications;refactoring;experience report","","","","","","27","","","","","IEEE","IEEE Conferences"
"Efficient Transaction-Based Deterministic Replay for Multi-threaded Programs","E. Pobee; X. Mei; W. K. Chan","City University of Hong Kong; City University of Hong Kong; City University of Hong Kong","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","760","771","Existing deterministic replay techniques propose strategies which attempt to reduce record log sizes and achieve successful replay. However, these techniques still generate large logs and achieve replay only under certain conditions. We propose a solution based on the division of the sequence of events of each thread into sequential blocks called transactions. Our insight is that there are usually few to no atomicity violations among transactions reported during a program execution. We present TPLAY, a novel deterministic replay technique which records thread access interleavings on shared memory locations at the transactional level. TPLAY also generates an artificial pair of interleavings when an atomicity violation is reported on a transaction. We present an experiment using the Splash2x extension of the PARSEC benchmark suite. Experimental results indicate that TPLAY experiences a 13-fold improvement in record log sizes and achieves a higher replay probability in comparison to existing work.","","","10.1109/ASE.2019.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952181","Concurrency;Deterministic Replay;Transactions;Multi-threading","","","","","","31","","","","","IEEE","IEEE Conferences"
"Debreach: Mitigating Compression Side Channels via Static Analysis and Transformation","B. Paulsen; C. Sung; P. A.H. Peterson; C. Wang","University of Southern California; University of Southern California; University of Minnesota, Duluth; University of Southern California","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","899","911","Compression is an emerging source of exploitable side-channel leakage that threatens data security, particularly in web applications where compression is indispensable for performance reasons. Current approaches to mitigating compression side channels have drawbacks in that they either degrade compression ratio drastically or require too much effort from developers to be widely adopted. To bridge the gap, we develop Debreach, a static analysis and program transformation based approach to mitigating compression side channels. Debreach consists of two steps. First, it uses taint analysis to soundly identify flows of sensitive data in the program and uses code instrumentation to annotate data before feeding them to the compressor. Second, it enhances the compressor to exploit the freedom to not compress of standard compression protocols, thus removing the dependency between sensitive data and the size of the compressor's output. Since Debreach automatically instruments applications and does not change the compression protocols, it has the advantage of being non-disruptive and compatible with existing systems. We have evaluated Debreach on a set of web server applications written in PHP. Our experiments show that, while ensuring leakage-freedom, Debreach can achieve significantly higher compression performance than state-of-the-art approaches.","","","10.1109/ASE.2019.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952360","Program Synthesis and Transformations;Automated Defect Repair;Data Privacy;Side Channel","","","","","","69","","","","","IEEE","IEEE Conferences"
"Regexes are Hard: Decision-Making, Difficulties, and Risks in Programming Regular Expressions","L. G. Michael; J. Donohue; J. C. Davis; D. Lee; F. Servant","Virginia Tech; University of Bradford; Virginia Tech; Stony Brook University & Virginia Tech; Virginia Tech","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","415","426","Regular expressions (regexes) are a powerful mechanism for solving string-matching problems. They are supported by all modern programming languages, and have been estimated to appear in more than a third of Python and JavaScript projects. Yet existing studies have focused mostly on one aspect of regex programming: readability. We know little about how developers perceive and program regexes, nor the difficulties that they face. In this paper, we provide the first study of the regex development cycle, with a focus on (1) how developers make decisions throughout the process, (2) what difficulties they face, and (3) how aware they are about serious risks involved in programming regexes. We took a mixed-methods approach, surveying 279 professional developers from a diversity of backgrounds (including top tech firms) for a high-level perspective, and interviewing 17 developers to learn the details about the difficulties that they face and the solutions that they prefer. In brief, regexes are hard. Not only are they hard to read, our participants said that they are hard to search for, hard to validate, and hard to document. They are also hard to master: the majority of our studied developers were unaware of critical security risks that can occur when using regexes, and those who knew of the risks did not deal with them in effective manners. Our findings provide multiple implications for future work, including semantic regex search engines for regex reuse and improved input generators for regex validation.","","","10.1109/ASE.2019.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952499","regular expressions, developer process, qualitative research","","","","","1","60","","","","","IEEE","IEEE Conferences"
"A Qualitative Analysis of Android Taint-Analysis Results","L. Luo; E. Bodden; J. Späth","Paderborn University; Paderborn University & Fraunhofer IEM; Fraunhofer IEM","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","102","114","In the past, researchers have developed a number of popular taint-analysis approaches, particularly in the context of Android applications. Numerous studies have shown that automated code analyses are adopted by developers only if they yield a good ""signal to noise ratio"", i.e., high precision. Many previous studies have reported analysis precision quantitatively, but this gives little insight into what can and should be done to increase precision further. To guide future research on increasing precision, we present a comprehensive study that evaluates static Android taint-analysis results on a qualitative level. To unravel the exact nature of taint flows, we have designed COVA, an analysis tool to compute partial path constraints that inform about the circumstances under which taint flows may actually occur in practice. We have conducted a qualitative study on the taint flows reported by FlowDroid in 1,022 real-world Android applications. Our results reveal several key findings: Many taint flows occur only under specific conditions, e.g., environment settings, user interaction, I/O. Taint analyses should consider the application context to discern such situations. COVA shows that few taint flows are guarded by multiple different kinds of conditions simultaneously, so tools that seek to confirm true positives dynamically can concentrate on one kind at a time, e.g., only simulating user interactions. Lastly, many false positives arise due to a too liberal source/sink configuration. Taint analyses must be more carefully configured, and their configuration could benefit from better tool assistance.","","","10.1109/ASE.2019.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952502","taint analysis, path conditions, Android","","","","","","59","","","","","IEEE","IEEE Conferences"
"RefBot: Intelligent Software Refactoring Bot","V. Alizadeh; M. A. Ouali; M. Kessentini; M. Chater","University of Michigan-Dearborn; University of Michigan; University of Michigan; University of Michigan","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","823","834","The adoption of refactoring techniques for continuous integration received much less attention from the research community comparing to root-canal refactoring to fix the quality issues in the whole system. Several recent empirical studies show that developers, in practice, are applying refactoring incrementally when they are fixing bugs or adding new features. There is an urgent need for refactoring tools that can support continuous integration and some recent development processes such as DevOps that are based on rapid releases. Furthermore, several studies show that manual refactoring is expensive and existing automated refactoring tools are challenging to configure and integrate into the development pipelines with significant disruption cost. In this paper, we propose, for the first time, an intelligent software refactoring bot, called RefBot. Integrated into the version control system (e.g. GitHub), our bot continuously monitors the software repository, and it is triggered by any ""open"" or ""merge"" action on pull requests. The bot analyzes the files changed during that pull request to identify refactoring opportunities using a set of quality attributes then it will find the best sequence of refactorings to fix the quality issues if any. The bot recommends all these refactorings through an automatically generated pull-request. The developer can review the recommendations and their impacts in a detailed report and select the code changes that he wants to keep or ignore. After this review, the developer can close and approve the merge of the bot's pull request. We quantitatively and qualitatively evaluated the performance and effectiveness of RefBot by a survey conducted with experienced developers who used the bot on both open source and industry projects","","","10.1109/ASE.2019.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952287","Software bot;refactoring;Software quality","","","","","","49","","","","","IEEE","IEEE Conferences"
"Understanding Exception-Related Bugs in Large-Scale Cloud Systems","H. Chen; W. Dou; Y. Jiang; F. Qin","The Ohio State University; Chinese Academy of Sciences; Nanjing University; The Ohio State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","339","351","Exception mechanism is widely used in cloud systems. This is mainly because it separates the error handling code from main business logic. However, the huge space of potential error conditions and the sophisticated logic of cloud systems present a big hurdle to the correct use of exception mechanism. As a result, mistakes in the exception use may lead to severe consequences, such as system downtime and data loss. To address this issue, the communities direly need a better understanding of the exception-related bugs, i.e., eBugs, which are caused by the incorrect use of exception mechanism, in cloud systems. In this paper, we present a comprehensive study on 210 eBugs from six widely-deployed cloud systems, including Cassandra, HBase, HDFS, Hadoop MapReduce, YARN, and ZooKeeper. For all the studied eBugs, we analyze their triggering conditions, root causes, bug impacts, and their relations. To the best of our knowledge, this is the first study on eBugs in cloud systems, and the first one that focuses on triggering conditions. We find that eBugs are severe in cloud systems: 74% of our studied eBugs affect system availability or integrity. Luckily, exposing eBugs through testing is possible: 54% of the eBugs are triggered by non-semantic conditions, such as network errors; 40% of the eBugs can be triggered by simulating the triggering conditions at simple system states. Furthermore, we find that the triggering conditions are useful for detecting eBugs. Based on such relevant findings, we build a static analysis tool, called DIET, and apply it to the latest versions of the studied systems. Our results show that DIET reports 31 bugs and bad practices, and 23 of them are confirmed by the developers as ""previously-unknown"" ones.","","","10.1109/ASE.2019.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952179","exception handling;cloud system;empirical study","","","","","","55","","","","","IEEE","IEEE Conferences"
"Accurate String Constraints Solution Counting with Weighted Automata","E. Sherman; A. Harris","Boise State University; Boise State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","440","452","As an important extension of symbolic execution (SE), probabilistic symbolic execution (PSE) computes execution probabilities of program paths. Using this information, PSE can prioritize path exploration strategies. To calculate the probability of a path PSE relies on solution counting approaches for the path constraint. The correctness of a solution counting approach depends on the methodology used to count solutions and whether a path constraint maintains a one-to-one relation with program input values. This work focuses on the latter aspect of the solution counting correctness for string constraints. In general, maintaining a one-to-one relation is not always possible, especially in the presence of non-linear constraints. To deal with this issue, researchers that work on PSE for numerical domains either analyze programs with linear constraints, or develop novel techniques to handle solution counting of non-linear constraints. For the string domain, however, previous work on PSE mainly focuses on efficient and accurate solution counting for automata-based string models and has not investigated whether a one-to-one relationship between the strings encoded by automata and input string values is preserved. In this work we demonstrate that traditional automata-based string models fail to maintain one-to-one relations and propose to use the weighted automata model, which preserves the one-to-one relation between the path constraint it encodes and the input string values. We use this model to implement a string constraint solver and show its correctness on a set of non-trivial synthetic benchmarks. We also present an empirical evaluation of traditional and proposed automata solvers on real-world string constraints. The evaluations show that while being less efficient than traditional automata models, the weighted automata model maintains correct solution counts.","","","10.1109/ASE.2019.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952608","probabilistic symbolic execution, string constraints, quantitative program analysis","","","","","","43","","","","","IEEE","IEEE Conferences"
"Wuji: Automatic Online Combat Game Testing Using Evolutionary Deep Reinforcement Learning","Y. Zheng; X. Xie; T. Su; L. Ma; J. Hao; Z. Meng; Y. Liu; R. Shen; Y. Chen; C. Fan","Tianjin University; Nanyang Technological University; Nanyang Technological University; Kyushu University; Tianjin University; Tianjin University; Nanyang Technological University; Fuxi AI Lab, Neteast, Inc.; Fuxi AI Lab, Netease, Inc.; AI Lab, Netease, Inc.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","772","784","Game testing has been long recognized as a notoriously challenging task, which mainly relies on manual playing and scripting based testing in game industry. Even until recently, automated game testing still remains to be largely untouched niche. A key challenge is that game testing often requires to play the game as a sequential decision process. A bug may only be triggered until completing certain difficult intermediate tasks, which requires a certain level of intelligence. The recent success of deep reinforcement learning (DRL) sheds light on advancing automated game testing, without human competitive intelligent support. However, the existing DRLs mostly focus on winning the game rather than game testing. To bridge the gap, in this paper, we first perform an in-depth analysis of 1349 real bugs from four real-world commercial game products. Based on this, we propose four oracles to support automated game testing, and further propose Wuji, an on-the-fly game testing framework, which leverages evolutionary algorithms, DRL and multi-objective optimization to perform automatic game testing. Wuji balances between winning the game and exploring the space of the game. Winning the game allows the agent to make progress in the game, while space exploration increases the possibility of discovering bugs. We conduct a large-scale evaluation on a simple game and two popular commercial games. The results demonstrate the effectiveness of Wuji in exploring space and detecting bugs. Moreover, Wuji found 3 previously unknown bugs, which have been confirmed by the developers, in the commercial games.","","","10.1109/ASE.2019.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952543","Game Testing;Artificial Intelligence;Deep Reinforcement Learning;Evolutionary Multi-Objective Optimization","","","","","","47","","","","","IEEE","IEEE Conferences"
"Verifying Arithmetic in Cryptographic C Programs","J. Liu; X. Shi; M. Tsai; B. Wang; B. Yang","Shenzhen University; Shenzhen University; Institute of Information Science, Academia Sinica; Institute of Information Science, Academia Sinica; Institute of Information Science, Academia Sinica","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","552","564","Cryptographic primitives are ubiquitous for modern security. The correctness of their implementations is crucial to resist malicious attacks. Typical arithmetic computation of these C programs contains large numbers of non-linear operations, hence is challenging existing automatic C verification tools. We present an automated approach to verify cryptographic C programs. Our approach successfully verifies C implementations of various arithmetic operations used in NIST P-224, P-256, P-521 and Curve25519 in OpenSSL. During verification, we expose a bug and a few anomalies that have been existing for a long time. They have been reported to and confirmed by the OpenSSL community. Our results establish the functional correctness of these C implementations for the first time.","","","10.1109/ASE.2019.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952256","program verification;cryptographic programs;functional correctness;OpenSSL","","","","","","40","","","","","IEEE","IEEE Conferences"
"Understanding Automatically-Generated Patches Through Symbolic Invariant Differences","P. Cashin; C. Martinez; W. Weimer; S. Forrest","Arizona State University; University of New Mexico; University of Michigan; Arizona State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","411","414","Developer trust is a major barrier to the deployment of automatically-generated patches. Understanding the effect of a patch is a key element of that trust. We find that differences in sets of formal invariants characterize patch differences and that implication-based distances in invariant space characterize patch similarities. When one patch is similar to another it often contains the same changes as well as additional behavior; this pattern is well-captured by logical implication. We can measure differences using a theorem prover to verify implications between invariants implied by separate programs. Although effective, theorem provers are computationally intensive; we find that string distance is an efficient heuristic for implication-based distance measurements. We propose to use distances between patches to construct a hierarchy highlighting patch similarities. We evaluated this approach on over 300 patches and found that it correctly categorizes programs into semantically similar clusters. Clustering programs reduces human effort by reducing the number of semantically distinct patches that must be considered by over 50%, thus reducing the time required to establish trust in automatically generated repairs.","","","10.1109/ASE.2019.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952219","Automated Program Repair;Program Measurement;Dynamic Invariants","","","","","","20","","","","","IEEE","IEEE Conferences"
"Get Rid of Inline Assembly through Verification-Oriented Lifting","F. Recoules; S. Bardin; R. Bonichon; L. Mounier; M. Potet","CEA LIST; CEA LIST; CEA LIST; Univ. Grenoble Alpes; Univ. Grenoble Alpes","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","577","589","Formal methods for software development have made great strides in the last two decades, to the point that their application in safety-critical embedded software is an undeniable success. Their extension to non-critical software is one of the notable forthcoming challenges. For example, C programmers regularly use inline assembly for low-level optimizations and system primitives. This usually results in rendering state-of-the-art formal analyzers developed for C ineffective. We thus propose TINA, the first automated, generic, verification-friendly and trustworthy lifting technique turning inline assembly into semantically equivalent C code amenable to verification, in order to take advantage of existing C analyzers. Extensive experiments on real-world code (including GMP and ffmpeg) show the feasibility and benefits of TINA.","","","10.1109/ASE.2019.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952223","inline assembly;software verification;lifting;formal methods","","","","","","59","","","","","IEEE","IEEE Conferences"
"Emotions Extracted from Text vs. True Emotions–An Empirical Evaluation in SE Context","Y. Wang","Rochester Institute of Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","230","242","Emotion awareness research in SE context has been growing in recent years. Currently, researchers often rely on textual communication records to extract emotion states using natural language processing techniques. However, how well these extracted emotion states reflect people's real emotions has not been thoroughly investigated. In this paper, we report a multi-level, longitudinal empirical study with 82 individual members in 27 project teams. We collected their self-reported retrospective emotion states on a weekly basis during their year-long projects and also extracted corresponding emotions from the textual communication records. We then model and compare the dynamics of these two types of emotions using multiple statistical and time series analysis methods. Our analyses yield a rich set of findings. The most important one is that the dynamics of emotions extracted using text-based algorithms often do not well reflect the dynamics of self-reported retrospective emotions. Besides, the extracted emotions match self-reported retrospective emotions better at the team-level. Our results also suggest that individual personalities and the team's emotion display norms significantly impact the match/mismatch. Our results should warn the research community about the limitations and challenges of applying text-based emotion recognition tools in SE research.","","","10.1109/ASE.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952437","emotion recognition;emotion dynamics;text based NLP techniques;time series analysis;personality;organizational norms","","","","","","89","","","","","IEEE","IEEE Conferences"
"V2: Fast Detection of Configuration Drift in Python","E. Horton; C. Parnin","North Carolina State University; North Carolina State University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","477","488","Code snippets are prevalent, but are hard to reuse because they often lack an accompanying environment configuration. Most are not actively maintained, allowing for drift between the most recent possible configuration and the code snippet as the snippet becomes out-of-date over time. Recent work has identified the problem of validating and detecting out-of-date code snippets as the most important consideration for code reuse. However, determining if a snippet is correct, but simply out-of-date, is a non-trivial task. In the best case, breaking changes are well documented, allowing developers to manually determine when a code snippet contains an out-of-date API usage. In the worst case, determining if and when a breaking change was made requires an exhaustive search through previous dependency versions. We present V2, a strategy for determining if a code snippet is out-of-date by detecting discrete instances of configuration drift, where the snippet uses an API which has since undergone a breaking change. Each instance of configuration drift is classified by a failure encountered during validation and a configuration patch, consisting of dependency version changes, which fixes the underlying fault. V2 uses feedback-directed search to explore the possible configuration space for a code snippet, reducing the number of potential environment configurations that need to be validated. When run on a corpus of public Python snippets from prior research, V2 identifies 248 instances of configuration drift.","","","10.1109/ASE.2019.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952262","Configuration Management;Configuration Repair;Configuration Drift;Environment Inference;Dependencies","","","","","","33","","","","","IEEE","IEEE Conferences"
"Automated Refactoring to Reactive Programming","M. Köhler; G. Salvaneschi","Technische Universität Darmstadt; Technische Universität Darmstadt","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","835","846","Reactive programming languages and libraries, such as ReactiveX, have been shown to significantly improve software design and have seen important industrial adoption over the last years. Asynchronous applications - which are notoriously error-prone to implement and to maintain - greatly benefit from reactive programming because they can be defined in a declarative style, which improves code clarity and extensibility. In this paper, we tackle the problem of refactoring existing software that has been designed with traditional abstractions for asynchronous programming. We propose 2Rx, a refactoring approach to automatically convert asynchronous code to reactive programming. Our evaluation on top-starred GitHub projects shows that 2Rx is effective with the most common asynchronous constructs, covering 12.7% of projects with asynchronous computations, and it can provide a refactoring for 91.7% of their occurrences.","","","10.1109/ASE.2019.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952329","refactoring;asynchronous programming;reactive programming;Java","","","","","","59","","","","","IEEE","IEEE Conferences"
"Active Hotspot: An Issue-Oriented Model to Monitor Software Evolution and Degradation","Q. Feng; Y. Cai; R. Kazman; D. Cui; T. Liu; H. Fang","Drexel University; Drexel University; University of Hawaii & SEI/CMU; Xi'an Jiaotong University; Xi'an Jiaotong University; Drexel University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","986","997","Architecture degradation has a strong negative impact on software quality and can result in significant losses. Severe software degradation does not happen overnight. Software evolves continuously, through numerous issues, fixing bugs and adding new features, and architecture flaws emerge quietly and largely unnoticed until they grow in scope and significance when the system becomes difficult to maintain. Developers are largely unaware of these flaws or the accumulating debt as they are focused on their immediate tasks of address individual issues. As a consequence, the cumulative impacts of their activities, as they affect the architecture, go unnoticed. To detect these problems early and prevent them from accumulating into severe ones we propose to monitor software evolution by tracking the interactions among files revised to address issues. In particular, we propose and show how we can automatically detect active hotspots, to reveal architecture problems. We have studied hundreds of hotspots along the evolution timelines of 21 open source projects and showed that there exist just a few dominating active hotspots per project at any given time. Moreover, these dominating active hotspots persist over long time periods, and thus deserve special attention. Compared with state-of-the-art design and code smell detection tools we report that, using active hotspots, it is possible to detect signs of software degradation both earlier and more precisely.","","","10.1109/ASE.2019.00095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952512","software evolution;architecture debt","","","","","","55","","","","","IEEE","IEEE Conferences"
"Automating App Review Response Generation","C. Gao; J. Zeng; X. Xia; D. Lo; M. R. Lyu; I. King","The Chinese University of Hong Kong; The Chinese University of Hong Kong; Monash University; Singapore Management University; The Chinese University of Hong Kong; The Chinese University of Hong Kong","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","163","175","Previous studies showed that replying to a user review usually has a positive effect on the rating that is given by the user to the app. For example, Hassan et al. found that responding to a review increases the chances of a user updating their given rating by up to six times compared to not responding. To alleviate the labor burden in replying to the bulk of user reviews, developers usually adopt a template-based strategy where the templates can express appreciation for using the app or mention the company email address for users to follow up. However, reading a large number of user reviews every day is not an easy task for developers. Thus, there is a need for more automation to help developers respond to user reviews. Addressing the aforementioned need, in this work we propose a novel approach RRGen that automatically generates review responses by learning knowledge relations between reviews and their responses. RRGen explicitly incorporates review attributes, such as user rating and review length, and learns the relations between reviews and corresponding responses in a supervised way from the available training data. Experiments on 58 apps and 309,246 review-response pairs highlight that RRGen outperforms the baselines by at least 67.4% in terms of BLEU-4 (an accuracy measure that is widely used to evaluate dialogue response generation systems). Qualitative analysis also confirms the effectiveness of RRGen in generating relevant and accurate responses.","","","10.1109/ASE.2019.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952476","App reviews;response generation;neural machine translation","","","","","","76","","","","","IEEE","IEEE Conferences"
"DIRE: A Neural Approach to Decompiled Identifier Naming","J. Lacomis; P. Yin; E. Schwartz; M. Allamanis; C. Le Goues; G. Neubig; B. Vasilescu","Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University Software Engineering Institute; Microsoft Research; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","628","639","The decompiler is one of the most common tools for examining binaries without corresponding source code. It transforms binaries into high-level code, reversing the compilation process. Decompilers can reconstruct much of the information that is lost during the compilation process (e.g., structure and type information). Unfortunately, they do not reconstruct semantically meaningful variable names, which are known to increase code understandability. We propose the Decompiled Identifier Renaming Engine (DIRE), a novel probabilistic technique for variable name recovery that uses both lexical and structural information recovered by the decompiler. We also present a technique for generating corpora suitable for training and evaluating models of decompiled code renaming, which we use to create a corpus of 164,632 unique x86-64 binaries generated from C projects mined from GitHub. Our results show that on this corpus DIRE can predict variable names identical to the names in the original source code up to 74.3% of the time.","","","10.1109/ASE.2019.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952404","Decompilation;Deep learning","","","","","","43","","","","","IEEE","IEEE Conferences"
"CLCDSA: Cross Language Code Clone Detection using Syntactical Features and API Documentation","K. W. Nafi; T. S. Kar; B. Roy; C. K. Roy; K. A. Schneider","University of Saskatchewan; University of Saskatchewan; University of Saskatchewan; University of Saskatchewan; University of Saskatchewan","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1026","1037","Software clones are detrimental to software maintenance and evolution and as a result many clone detectors have been proposed. These tools target clone detection in software applications written in a single programming language. However, a software application may be written in different languages for different platforms to improve the application's platform compatibility and adoption by users of different platforms. Cross language clones (CLCs) introduce additional challenges when maintaining multi-platform applications and would likely go undetected using existing tools. In this paper, we propose CLCDSA, a cross language clone detector which can detect CLCs without extensive processing of the source code and without the need to generate an intermediate representation. The proposed CLCDSA model analyzes different syntactic features of source code across different programming languages to detect CLCs. To support large scale clone detection, the CLCDSA model uses an action filter based on cross language API call similarity to discard non-potential clones. The design methodology of CLCDSA is two-fold: (a) it detects CLCs on the fly by comparing the similarity of features, and (b) it uses a deep neural network based feature vector learning model to learn the features and detect CLCs. Early evaluation of the model observed an average precision, recall and F-measure score of 0.55, 0.86, and 0.64 respectively for the first phase and 0.61, 0.93, and 0.71 respectively for the second phase which indicates that CLCDSA outperforms all available models in detecting cross language clones.","","","10.1109/ASE.2019.00099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952189","Code Clone;API documentation;Word2Vector;Source Code Syntax","","","","","","63","","","","","IEEE","IEEE Conferences"
"Learning-Guided Network Fuzzing for Testing Cyber-Physical System Defences","Y. Chen; C. M. Poskitt; J. Sun; S. Adepu; F. Zhang","Singapore University of Technology and Design; Singapore University of Technology and Design; Singapore Management University; Singapore University of Technology and Design; Zhejiang University and Alibaba-Zhejiang University Joint Institute of Frontier Technologies","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","962","973","The threat of attack faced by cyber-physical systems (CPSs), especially when they play a critical role in automating public infrastructure, has motivated research into a wide variety of attack defence mechanisms. Assessing their effectiveness is challenging, however, as realistic sets of attacks to test them against are not always available. In this paper, we propose smart fuzzing, an automated, machine learning guided technique for systematically finding 'test suites' of CPS network attacks, without requiring any knowledge of the system's control programs or physical processes. Our approach uses predictive machine learning models and metaheuristic search algorithms to guide the fuzzing of actuators so as to drive the CPS into different unsafe physical states. We demonstrate the efficacy of smart fuzzing by implementing it for two real-world CPS testbeds—a water purification plant and a water distribution system—finding attacks that drive them into 27 different unsafe states involving water flow, pressure, and tank levels, including six that were not covered by an established attack benchmark. Finally, we use our approach to test the effectiveness of an invariant-based defence system for the water treatment plant, finding two attacks that were not detected by its physical invariant checks, highlighting a potential weakness that could be exploited in certain conditions.","","","10.1109/ASE.2019.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952193","cyber-physical systems;fuzzing;testing;benchmark generation;machine learning;metaheuristic optimisation","","","","","","67","","","","","IEEE","IEEE Conferences"
"Subformula Caching for Model Counting and Quantitative Program Analysis","W. Eiers; S. Saha; T. Brennan; T. Bultan","University of California Santa Barbara; University of California Santa Barbara; University of California Santa Barbara; University of California Santa Barbara","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","453","464","Quantitative program analysis is an emerging area with applications to software reliability, quantitative information flow, side-channel detection and attack synthesis. Most quantitative program analysis techniques rely on model counting constraint solvers, which are typically the bottleneck for scalability. Although the effectiveness of formula caching in expediting expensive model-counting queries has been demonstrated in prior work, our key insight is that many subformulas are shared across non-identical constraints generated during program analyses. This has not been utilized by prior formula caching approaches. In this paper we present a subformula caching framework and integrate it into a model counting constraint solver. We experimentally evaluate its effectiveness under three quantitative program analysis scenarios: 1) model counting constraints generated by symbolic execution, 2) reliability analysis using probabilistic symbolic execution, 3) adaptive attack synthesis for side-channels. Our experimental results demonstrate that our subformula caching approach significantly improves the performance of quantitative program analysis.","","","10.1109/ASE.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952551","formula caching, model counting, quantitative program analysis","","","","","","36","","","","","IEEE","IEEE Conferences"
"Testing Regex Generalizability And Its Implications: A Large-Scale Many-Language Measurement Study","J. C. Davis; D. Moyer; A. M. Kazerouni; D. Lee","Virginia Tech; Virginia Tech; Virginia Tech; Stony Brook University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","427","439","The regular expression (regex) practices of software engineers affect the maintainability, correctness, and security of their software applications. Empirical research has described characteristics like the distribution of regex feature usage, the structural complexity of regexes, and worst-case regex match behaviors. But researchers have not critically examined the methodology they follow to extract regexes, and findings to date are typically generalized from regexes written in only 1-2 programming languages. This is an incomplete foundation. Generalizing existing research depends on validating two hypotheses: (1) Various regex extraction methodologies yield similar results, and (2) Regex characteristics are similar across programming languages. To test these hypotheses, we defined eight regex metrics to capture the dimensions of regex representation, string language diversity, and worst-case match complexity. We report that the two competing regex extraction methodologies yield comparable corpuses, suggesting that simpler regex extraction techniques will still yield sound corpuses. But in comparing regexes across programming languages, we found significant differences in some characteristics by programming language. Our findings have bearing on future empirical methodology, as the programming language should be considered, and generalizability will not be assured. Our measurements on a corpus of 537,806 regexes can guide data-driven designs of a new generation of regex tools and regex engines.","","","10.1109/ASE.2019.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952443","Regular expressions;Empirical software engineering;Data driven design;Methods","","","","","1","75","","","","","IEEE","IEEE Conferences"
"Size and Accuracy in Model Inference","N. Busany; S. Maoz; Y. Yulazari","Tel Aviv University; Tel Aviv University; Tel Aviv University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","887","898","Many works infer finite-state models from execution logs. Large models are more accurate but also more difficult to present and understand. Small models are easier to present and understand but are less accurate. In this work we investigate the tradeoff between model size and accuracy in the context of the classic k-Tails model inference algorithm. First, we define mk-Tails, a generalization of k-Tails from one to many parameters, which enables fine-grained control over the tradeoff. Second, we extend mk-Tails with a reduction based on past-equivalence, which effectively reduces the size of the model without decreasing its accuracy. We implemented our work and evaluated its performance and effectiveness on real-world logs as well as on models and generated logs from the literature.","","","10.1109/ASE.2019.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952335","Log analysis;Model inference","","","","","","31","","","","","IEEE","IEEE Conferences"
"Logzip: Extracting Hidden Structures via Iterative Clustering for Log Compression","J. Liu; J. Zhu; S. He; P. He; Z. Zheng; M. R. Lyu","Sun Yat-Sen University & The Chinese University of Hong Kong; Huawei Noah’s Ark Lab, China; The Chinese University of Hong Kong; ETH Zurich; Sun Yat-Sen University; The Chinese University of Hong Kong","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","863","873","System logs record detailed runtime information of software systems and are used as the main data source for many tasks around software engineering. As modern software systems are evolving into large scale and complex structures, logs have become one type of fast-growing big data in industry. In particular, such logs often need to be stored for a long time in practice (e.g., a year), in order to analyze recurrent problems or track security issues. However, archiving logs consumes a large amount of storage space and computing resources, which in turn incurs high operational cost. Data compression is essential to reduce the cost of log storage. Traditional compression tools (e.g., gzip) work well for general texts, but are not tailed for system logs. In this paper, we propose a novel and effective log compression method, namely logzip. Logzip is capable of extracting hidden structures from raw logs via fast iterative clustering and further generating coherent intermediate representations that allow for more effective compression. We evaluate logzip on five large log datasets of different system types, with a total of 63.6 GB in size. The results show that logzip can save about half of the storage space on average over traditional compression tools. Meanwhile, the design of logzip is highly parallel and only incurs negligible overhead. In addition, we share our industrial experience of applying logzip to Huawei's real products.","","","10.1109/ASE.2019.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952406","logs;structure extraction;log compression;log management;iterative clustering","","","","","","49","","","","","IEEE","IEEE Conferences"
"An Experience Report of Generating Load Tests Using Log-Recovered Workloads at Varying Granularities of User Behaviour","J. Chen; W. Shang; A. E. Hassan; Y. Wang; J. Lin","Concordia University; Concordia University; Queen's University; Alibaba Group; Alibaba Group","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","669","681","Designing field-representative load tests is an essential step for the quality assurance of large-scale systems. Practitioners may capture user behaviour at different levels of granularity. A coarse-grained load test may miss detailed user behaviour, leading to a non-representative load test; while an extremely fine-grained load test would simply replay user actions step by step, leading to load tests that are costly to develop, execute and maintain. Workload recovery is at core of these load tests. Prior research often captures the workload as the frequency of user actions. However, there exists much valuable information in the context and sequences of user actions. Such richer information would ensure that the load tests that leverage such workloads are more field-representative. In this experience paper, we study the use of different granularities of user behaviour, i.e., basic user actions, basic user actions with contextual information and user action sequences with contextual information, when recovering workloads for use in the load testing of large-scale systems. We propose three approaches that are based on the three granularities of user behaviour and evaluate our approaches on four subject systems, namely Apache James, OpenMRS, Google Borg, and an ultra-large-scale industrial system (SA) from Alibaba. Our results show that our approach that is based on user action sequences with contextual information outperforms the other two approaches and can generate more representative load tests with similar throughput and CPU usage to the original field workload (i.e., mostly statistically insignificant or with small/trivial effect sizes). Such representative load tests are generated only based on a small number of clusters of users, leading to a low cost of conducting/maintaining such tests. Finally, we demonstrate that our approaches can detect injected users in the original field workloads with high precision and recall. Our paper demonstrates the importance of user action sequences with contextual information in the workload recovery of large-scale systems.","","","10.1109/ASE.2019.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952553","Workload recovery, Load tests, Software log analysis, Software performance","","","","","","60","","","","","IEEE","IEEE Conferences"
"Automating Non-Blocking Synchronization In Concurrent Data Abstractions","J. Zhang; Q. Yi; D. Dechev","University of Colorado at Colorado Springs; University of Colorado at Colorado Springs; University of Central Florida","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","735","747","This paper investigates using compiler technology to automatically convert sequential C++ data abstractions, e.g., queues, stacks, maps, and trees, to concurrent lock-free implementations. By automatically tailoring a number of state-of-the-practice synchronization methods to the underlying sequential implementations of different data structures, our automatically synchronized code can attain performance competitive to that of manually-written concurrent data structures by experts and much better performance than heavier-weight support by software transactional memory (STM).","","","10.1109/ASE.2019.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952270","Concurrency;Parallel Programming;Automation Compilers;Data Structures","","","","","","63","","","","","IEEE","IEEE Conferences"
"Multi-modal Attention Network Learning for Semantic Source Code Retrieval","Y. Wan; J. Shu; Y. Sui; G. Xu; Z. Zhao; J. Wu; P. Yu","Zhejiang University; Zhejiang University; University of Technology Sydney; University of Technology Sydney; Zhejiang University; Zhejiang University; University of Illinois at Chicago","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","13","25","Code retrieval techniques and tools have been playing a key role in facilitating software developers to retrieve existing code fragments from available open-source repositories given a user query (e.g., a short natural language text describing the functionality for retrieving a particular code snippet). Despite the existing efforts in improving the effectiveness of code retrieval, there are still two main issues hindering them from being used to accurately retrieve satisfiable code fragments from large-scale repositories when answering complicated queries. First, the existing approaches only consider shallow features of source code such as method names and code tokens, but ignoring structured features such as abstract syntax trees (ASTs) and control-flow graphs (CFGs) of source code, which contains rich and well-defined semantics of source code. Second, although the deep learning-based approach performs well on the representation of source code, it lacks the explainability, making it hard to interpret the retrieval results and almost impossible to understand which features of source code contribute more to the final results. To tackle the two aforementioned issues, this paper proposes MMAN, a novel Multi-Modal Attention Network for semantic source code retrieval. A comprehensive multi-modal representation is developed for representing unstructured and structured features of source code, with one LSTM for the sequential tokens of code, a Tree-LSTM for the AST of code and a GGNN (Gated Graph Neural Network) for the CFG of code. Furthermore, a multi-modal attention fusion layer is applied to assign weights to different parts of each modality of source code and then integrate them into a single hybrid representation. Comprehensive experiments and analysis on a large-scale real-world dataset show that our proposed model can accurately retrieve code snippets and outperforms the state-of-the-art methods.","","","10.1109/ASE.2019.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952337","Code retrieval;multi-modal network;attention mechanism;deep learning","","","","","","57","","","","","IEEE","IEEE Conferences"
"iFeedback: Exploiting User Feedback for Real-Time Issue Detection in Large-Scale Online Service Systems","W. Zheng; H. Lu; Y. Zhou; J. Liang; H. Zheng; Y. Deng","Tencent Inc.; Fudan University; Fudan University; Tencent Inc.; Tencent Inc.; Tencent Inc.","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","352","363","Large-scale online systems are complex, fast-evolving, and hardly bug-free despite the testing efforts. Backend system monitoring cannot detect many types of issues, such as UI related bugs, bugs with small impact on backend system indicators, or errors from third-party co-operating systems, etc. However, users are good informers of such issues: They will provide their feedback for any types of issues. This experience paper discusses our design of iFeedback, a tool to perform real-time issue detection based on user feedback texts. Unlike traditional approaches that analyze user feedback with computation-intensive natural language processing algorithms, iFeedback is focusing on fast issue detection, which can serve as a system life-condition monitor. In particular, iFeedback extracts word combination-based indicators from feedback texts. This allows iFeedback to perform fast system anomaly detection with sophisticated machine learning algorithms. iFeedback then further summarizes the texts with an aim to effectively present the anomaly to the developers for root cause analysis. We present our representative experiences in successfully applying iFeedback in tens of large-scale production online service systems in ten months.","","","10.1109/ASE.2019.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952229","Bug and vulnerability detection","","","","","","42","","","","","IEEE","IEEE Conferences"
"Apricot: A Weight-Adaptation Approach to Fixing Deep Learning Models","H. Zhang; W. K. Chan","City University of Hong Kong; City University of Hong Kong","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","376","387","A deep learning (DL) model is inherently imprecise. To address this problem, existing techniques retrain a DL model over a larger training dataset or with the help of fault injected models or using the insight of failing test cases in a DL model. In this paper, we present Apricot, a novel weight-adaptation approach to fixing DL models iteratively. Our key observation is that if the deep learning architecture of a DL model is trained over many different subsets of the original training dataset, the weights in the resultant reduced DL model (rDLM) can provide insights on the adjustment direction and magnitude of the weights in the original DL model to handle the test cases that the original DL model misclassifies. Apricot generates a set of such reduced DL models from the original DL model. In each iteration, for each failing test case experienced by the input DL model (iDLM), Apricot adjusts each weight of this iDLM toward the average weight of these rDLMs correctly classifying the test case and/or away from that of these rDLMs misclassifying the same test case, followed by training the weight-adjusted iDLM over the original training dataset to generate a new iDLM for the next iteration. The experiment using five state-of-the-art DL models shows that Apricot can increase the test accuracy of these models by 0.87%-1.55% with an average of 1.08%. The experiment also reveals the complementary nature of these rDLMs in Apricot.","","","10.1109/ASE.2019.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952197","Deep Neural Networks;Optimization;Model Evolution;Debugging;Model Fixing;Model Repair","","","","","","60","","","","","IEEE","IEEE Conferences"
"OAUTHLINT: An Empirical Study on OAuth Bugs in Android Applications","T. A. Rahat; Y. Feng; Y. Tian","University of Virginia; University of California at Santa Barbara; University of Virginia","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","293","304","Mobile developers use OAuth APIs to implement Single-Sign-On services. However, the OAuth protocol was originally designed for the authorization for third-party websites not to authenticate users in third-party mobile apps. As a result, it is challenging for developers to correctly implement mobile OAuth securely. These vulnerabilities due to the misunderstanding of OAuth and inexperience of developers could lead to data leakage and account breach. In this paper, we perform an empirical study on the usage of OAuth APIs in Android applications and their security implications. In particular, we develop OAUTHLINT, that incorporates a query-driven static analysis to automatically check programs on the Google Play marketplace. OAUTHLINT takes as input an anti-protocol that encodes a vulnerable pattern extracted from the OAuth specifications and a program P. Our tool then generates a counter-example if the anti-protocol can match a trace of Ps possible executions. To evaluate the effectiveness of our approach, we perform a systematic study on 600+ popular apps which have more than 10 millions of downloads. The evaluation shows that 101 (32%) out of 316 applications that use OAuth APIs make at least one security mistake.","","","10.1109/ASE.2019.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952200","Security, OAuth, Android, Static Analysis, Bug Finding","","","","","","40","","","","","IEEE","IEEE Conferences"
"Predicting Licenses for Changed Source Code","X. Liu; L. Huang; J. Ge; V. Ng","Southern Methodist University; Southern Methodist University; Nanjing University; University of Texas at Dallas","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","686","697","Open source software licenses regulate the circumstances under which software can be redistributed, reused and modified. Ensuring license compatibility and preventing license restriction conflicts among source code during software changes are the key to protect their commercial use. However, selecting the appropriate licenses for software changes requires lots of experience and manual effort that involve examining, assimilating and comparing various licenses as well as understanding their relationships with software changes. Worse still, there is no state-of-the-art methodology to provide this capability. Motivated by this observation, we propose in this paper Automatic License Prediction (ALP), a novel learning-based method and tool for predicting licenses as software changes. An extensive evaluation of ALP on predicting licenses in 700 open source projects demonstrate its effectiveness: ALP can achieve not only a high overall prediction accuracy (92.5% in micro F1 score) but also high accuracies across all license types.","","","10.1109/ASE.2019.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952518","Mining Software Repository;Software License Prediction","","","","","","28","","","","","IEEE","IEEE Conferences"
"Re-Factoring Based Program Repair Applied to Programming Assignments","Y. Hu; U. Z. Ahmed; S. Mechtaev; B. Leong; A. Roychoudhury","The University of Texas at Austin; National University of Singapore; University College London; National University of Singapore; National University of Singapore","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","388","398","Automated program repair has been used to provide feedback for incorrect student programming assignments, since program repair captures the code modification needed to make a given buggy program pass a given test-suite. Existing student feedback generation techniques are limited because they either require manual effort in the form of providing an error model, or require a large number of correct student submissions to learn from, or suffer from lack of scalability and accuracy. In this work, we propose a fully automated approach for generating student program repairs in real-time. This is achieved by first re-factoring all available correct solutions to semantically equivalent solutions. Given an incorrect program, we match the program with the closest matching refactored program based on its control flow structure. Subsequently, we infer the input-output specifications of the incorrect program's basic blocks from the executions of the correct program's aligned basic blocks. Finally, these specifications are used to modify the blocks of the incorrect program via search-based synthesis. Our dataset consists of almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. Our experimental results suggest that our method is more effective and efficient than recently proposed feedback generation approaches. About 30% of the patches produced by our tool Refactory are smaller than those produced by the state-of-art tool Clara, and can be produced given fewer correct solutions (often a single correct solution) and in a shorter time. We opine that our method is applicable not only to programming assignments, and could be seen as a general-purpose program repair method that can achieve good results with just a single correct reference solution.","","","10.1109/ASE.2019.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952522","Program Repair;Programming Education;Software Refactoring","","","","","","20","","","","","IEEE","IEEE Conferences"
"PraPR: Practical Program Repair via Bytecode Mutation","A. Ghanbari; L. Zhang","University of Texas at Dallas; University of Texas at Dallas","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1118","1121","Automated program repair (APR) is one of the recent advances in automated software engineering aiming for reducing the burden of debugging by suggesting high-quality patches that either directly fix the bugs, or help the programmers in the course of manual debugging. We believe scalability, applicability, and accurate patch validation are the main design objectives for a practical APR technique. In this paper, we present PraPR, our implementation of a practical APR technique that operates at the level of JVM bytecode. We discuss design decisions made in the development of PraPR, and argue that the technique is a viable baseline toward attaining aforementioned objectives. Our experimental results show that: (1) PraPR can fix more bugs than state-of-the-art APR techniques and can be over 10X faster, (2) state-of-the-art APR techniques suffer from dataset overfitting, while the simplistic template-based PraPR performs more consistently on different datasets, and (3) PraPR can fix bugs for other JVM languages, such as Kotlin. PraPR is publicly available at https://github.com/prapr/prapr.","","","10.1109/ASE.2019.00116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952486","Program Repair;JVM Bytecode;Mutation Testing","","","","","","44","","","","","IEEE","IEEE Conferences"
"Combining Program Analysis and Statistical Language Model for Code Statement Completion","S. Nguyen; T. Nguyen; Y. Li; S. Wang","The University of Texas at Dallas; The University of Texas at Dallas; New Jersey Institute of Technology; New Jersey Institute of Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","710","721","Automatic code completion helps improve developers' productivity in their programming tasks. A program contains instructions expressed via code statements, which are considered as the basic units of program execution. In this paper, we introduce AutoSC, which combines program analysis and the principle of software naturalness to fill in a partially completed statement. AutoSC benefits from the strengths of both directions, in which the completed code statement is both frequent and valid. AutoSC is first trained on a large code corpus to derive the templates of candidate statements. Then, it uses program analysis to validate and concretize the templates into syntactically and type-valid candidate statements. Finally, these candidates are ranked by using a language model trained on the lexical form of the source code in the code corpus. Our empirical evaluation on the large datasets of real-world projects shows that AutoSC achieves 38.9-41.3% top-1 accuracy and 48.2-50.1% top-5 accuracy in statement completion. It also outperforms a state-of-the-art approach from 9X-69X in top-1 accuracy.","","","10.1109/ASE.2019.00072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952235","Code Completion;Statement Completion;Statistical Language Model;Program Analysis","","","","","","29","","","","","IEEE","IEEE Conferences"
"MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network Centrality Analysis","Y. Wu; X. Li; D. Zou; W. Yang; X. Zhang; H. Jin","Huazhong University of Science and Technology; University of Texas at Dallas; Huazhong University of Science and Technology; University of Texas at Dallas; Huazhong University of Science and Technology; Huazhong University of Science and Technology","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","139","150","Malware scanning of an app market is expected to be scalable and effective. However, existing approaches use either syntax-based features which can be evaded by transformation attacks or semantic-based features which are usually extracted by performing expensive program analysis. Therefor, in this paper, we propose a lightweight graph-based approach to perform Android malware detection. Instead of traditional heavyweight static analysis, we treat function call graphs of apps as social networks and perform social-network-based centrality analysis to represent the semantic features of the graphs. Our key insight is that centrality provides a succinct and fault-tolerant representation of graph semantics, especially for graphs with certain amount of inaccurate information (e.g., inaccurate call graphs). We implement a prototype system, MalScan, and evaluate it on datasets of 15,285 benign samples and 15,430 malicious samples. Experimental results show that MalScan is capable of detecting Android malware with up to 98% accuracy under one second which is more than 100 times faster than two state-of-the-art approaches, namely MaMaDroid and Drebin. We also demonstrate the feasibility of MalScan on market-wide malware scanning by performing a statistical study on over 3 million apps. Finally, in a corpus of dataset collected from Google-Play app market, MalScan is able to identify 18 zero-day malware including malware samples that can evade detection of existing tools.","","","10.1109/ASE.2019.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952382","Lightweight feature, Android Malware, API Centrality, Market-wide","","","","","","43","","","","","IEEE","IEEE Conferences"
"Sip4J: Statically Inferring Access Permission Contracts for Parallelising Sequential Java Programs","A. Sadiq; L. Li; Y. Li; I. Ahmed; S. Ling","Monash University, Australia; Monash University, Australia; Monash University, Australia; University of Lahore, Pakistan; Monash University, Australia","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1098","1101","This paper presents Sip4J, a fully automated, scalable and effective tool to automatically generate access permission contracts for a sequential Java program. The access permission contracts, which represent the dependency of code blocks, have been frequently used to enable concurrent execution of sequential programs. Those permission contracts, unfortunately, need to be manually created by programmers, which is known to be time-consuming, laborious and error-prone. To mitigate those manual efforts, Sip4J performs inter-procedural static analysis of Java source code to automatically extract the implicit dependencies in the program and subsequently leverages them to automatically generate access permission contracts, following the Design by Contract principle. The inferred specifications are then used to identify the concurrent (immutable) methods in the program. Experimental results further show that Sip4J is useful and effective towards generating access permission contracts for sequential Java programs. The implementation of Sip4J has been published as an open-sourced project at https://github.com/Sip4J/Sip4J and a demo video of Sip4J can be found at https://youtu.be/RjMTIxlhHTg.","","","10.1109/ASE.2019.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952453","access permissions, static analysis, concurrency, permission inference","","","","","","17","","","","","IEEE","IEEE Conferences"
"XRaSE: Towards Virtually Tangible Software using Augmented Reality","R. Mehra; V. S. Sharma; V. Kaulgud; S. Podder","Accenture Labs, India; Accenture Labs, India; Accenture Labs, India; Accenture Labs, India","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1194","1197","Software engineering has seen much progress in recent past including introduction of new methodologies, new paradigms for software teams, and from smaller monolithic applications to complex, intricate, and distributed software applications. However, the way we represent, discuss, and collaborate on software applications throughout the software development life cycle is still primarily using the source code, textual representations, or charts on 2D computer screens - the confines of which have long limited how we visualize and comprehend software systems. In this paper, we present XRaSE, a novel prototype implementation that leverages augmented reality to visualize a software application as a virtually tangible entity. This immersive approach is aimed at making activities like application comprehension, architecture analysis, knowledge communication, and analysis of a software's dynamic aspects, more intuitive, richer and collaborative.","","","10.1109/ASE.2019.00135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952170","Augmented Reality, Immersive Experience, Software Visualization, Software Comprehension","","","","","","16","","","","","IEEE","IEEE Conferences"
"Code-First Model-Driven Engineering: On the Agile Adoption of MDE Tooling","A. Boronat","University of Leicester","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","874","886","Domain models are the most important asset in widely accepted software development approaches, like Domain-Driven Design (DDD), yet those models are still implicitly represented in programs. Model-Driven Engineering (MDE) regards those models as representable entities that are amenable to automated analysis and processing, facilitating quality assurance while increasing productivity in software development processes. Although this connection is not new, very few approaches facilitate adoption of MDE tooling without compromising existing value, their data. Moreover, switching to MDE tooling usually involves re-engineering core parts of an application, hindering backward compatibility and, thereby, continuous integration, while requiring an up-front investment in training in specialized modeling frameworks. In those approaches that overcome the previous problem, there is no clear indication - from a quantitative point of view - of the extent to which adopting state-of-the-art MDE practices and tooling is feasible or advantageous. In this work, we advocate a code-first approach to modeling through an approach for applying MDE techniques and tools to existing object-oriented software applications that fully preserves the semantics of the original application, which need not be modified. Our approach consists both of a semi-automated method for specifying explicit view models out of existing object-oriented applications and of a conservative extension mechanism that enables the use of such view models at run time, where view model queries are resolved on demand and view model updates are propagated incrementally to the original application. This mechanism enables an iterative, flexible application of MDE tooling to software applications, where metamodels and models do not exist explicitly. An evaluation of this extension mechanism, implemented for Java applications and for view models atop the Eclipse Modeling Framework (EMF), has been conducted with an industry-targeted benchmark for decision support systems, analyzing performance and scalability of the synchronization mechanism. Backward propagation of large updates over very large views is instant.","","","10.1109/ASE.2019.00086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952237","domain model, MDE, EMF, roundtrip synchronization, algebraic specification, performance analysis","","","","","","41","","","","","IEEE","IEEE Conferences"
"MARBLE: Mining for Boilerplate Code to Identify API Usability Problems","D. Nam; A. Horvath; A. Macvean; B. Myers; B. Vasilescu","Carnegie Mellon University; Carnegie Mellon University; Google; Carnegie Mellon University; Carnegie Mellon University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","615","627","Designing usable APIs is critical to developers' productivity and software quality, but is quite difficult. One of the challenges is that anticipating API usability barriers and real-world usage is difficult, due to a lack of automated approaches to mine usability data at scale. In this paper, we focus on one particular grievance that developers repeatedly express in online discussions about APIs: ""boilerplate code."" We investigate what properties make code count as boilerplate, the reasons for boilerplate, and how programmers can reduce the need for it. We then present MARBLE, a novel approach to automatically mine boilerplate code candidates from API client code repositories. MARBLE adapts existing techniques, including an API usage mining algorithm, an AST comparison algorithm, and a graph partitioning algorithm. We evaluate MARBLE with 13 Java APIs, and show that our approach successfully identifies both already-known and new API-related boilerplate code instances.","","","10.1109/ASE.2019.00063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952239","Boilerplate Code;API Usability;Repository Mining","","","","","1","65","","","","","IEEE","IEEE Conferences"
"Feature-Interaction Aware Configuration Prioritization for Configurable Code","S. Nguyen; H. Nguyen; N. Tran; H. Tran; T. Nguyen","The University of Texas at Dallas, USA; Amazon Corporation; The University of Texas at Dallas; The University of Texas at Dallas, USA; The University of Texas at Dallas, USA","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","489","501","Unexpected interactions among features induce most bugs in a configurable software system. Exhaustively analyzing all the exponential number of possible configurations is prohibitively costly. Thus, various sampling techniques have been proposed to systematically narrow down the exponential number of legal configurations to be analyzed. Since analyzing all selected configurations can require a huge amount of effort, fault-based configuration prioritization, that helps detect faults earlier, can yield practical benefits in quality assurance. In this paper, we propose CoPro, a novel formulation of feature-interaction bugs via common program entities enabled/disabled by the features. Leveraging from that, we develop an efficient feature-interaction-aware configuration prioritization technique for a configurable system by ranking the configurations according to their total number of potential bugs. We conducted several experiments to evaluate CoPro on the ability to detect configuration-related bugs in a public benchmark. We found that CoPro outperforms the state-of-the-art configuration prioritization techniques when we add them on advanced sampling algorithms. In 78% of the cases, CoPro ranks the buggy configurations at the top 3 positions in the resulting list. Interestingly, CoPro is able to detect 17 not-yet-discovered feature-interaction bugs.","","","10.1109/ASE.2019.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952386","Configurable Code;Feature Interaction;Configuration Prioritization;Software Product Lines","","","","","","59","","","","","IEEE","IEEE Conferences"
"A Quantitative Analysis Framework for Recurrent Neural Network","X. Du; X. Xie; Y. Li; L. Ma; Y. Liu; J. Zhao","Nanyang Technological University; Nanyang Technological University; Nanyang Technological University; Kyushu University; Nanyang Technological University; Kyushu University","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1062","1065","Recurrent neural network (RNN) has achieved great success in processing sequential inputs for applications such as automatic speech recognition, natural language processing and machine translation. However, quality and reliability issues of RNNs make them vulnerable to adversarial attacks and hinder their deployment in real-world applications. In this paper, we propose a quantitative analysis framework - DeepStellar - to pave the way for effective quality and security analysis of software systems powered by RNNs. DeepStellar is generic to handle various RNN architectures, including LSTM and GRU, scalable to work on industrial-grade RNN models, and extensible to develop customized analyzers and tools. We demonstrated that, with DeepStellar, users are able to design efficient test generation tools, and develop effective adversarial sample detectors. We tested the developed applications on three real RNN models, including speech recognition and image classification. DeepStellar outperforms existing approaches three hundred times in generating defect-triggering tests and achieves 97% accuracy in detecting adversarial attacks. A video demonstration which shows the main features of DeepStellar is available at: https://sites.google.com/view/deepstellar/tool-demo.","","","10.1109/ASE.2019.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952565","recurrent neural netwrod;model abstraction;quantitative analysis;similarity metrics;coverage criteria","","","","","","18","","","","","IEEE","IEEE Conferences"
"Batch Alias Analysis","J. Vedurada; V. K. Nandivada","Indian Institute of Technology Madras; Indian Institute of Technology Madras","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","936","948","Many program-analysis based tools require precise points-to/alias information only for some program variables. To meet this requirement efficiently, there have been many works on demand-driven analyses that perform only the work necessary to compute the points-to or alias information on the requested variables (queries). However, these demand-driven analyses can be very expensive when applied on large systems where the number of queries can be significant. Such a blow-up in analysis time is unacceptable in cases where scalability with real-time constraints is crucial; for example, when program analysis tools are plugged into an IDE (Integrated Development Environment). In this paper, we propose schemes to improve the scalability of demand-driven analyses without compromising on precision. Our work is based on novel ideas for eliminating irrelevant and redundant data-flow paths for the given queries. We introduce the idea of batch analysis, which can answer multiple given queries in batch mode. Batch analysis suits the environments with strict time constraints, where the queries come in batch. We present a batch alias analysis framework that can be used to speed up given demand-driven alias analysis. To show the effectiveness of this framework, we use two demand-driven alias analyses (1) the existing best performing demand-driven alias analysis tool for race-detection clients and (2) an optimized version thereof that avoids irrelevant computation. Our evaluations on a simulated data-race client, and on a recent program-understanding tool, show that batch analysis leads to significant performance gains, along with minor gains in precision.","","","10.1109/ASE.2019.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952457","Batch analysis;Alias analysis;Points to Analysis","","","","","","36","","","","","IEEE","IEEE Conferences"
"Inferring Program Transformations From Singular Examples via Big Code","J. Jiang; L. Ren; Y. Xiong; L. Zhang","Peking University; Peking University; Peking University; University of Texas at Dallas","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","255","266","Inferring program transformations from concrete program changes has many potential uses, such as applying systematic program edits, refactoring, and automated program repair. Existing work for inferring program transformations usually rely on statistical information over a potentially large set of program-change examples. However, in many practical scenarios we do not have such a large set of program-change examples. In this paper, we address the challenge of inferring a program transformation from one single example. Our core insight is that ""big code"" can provide effective guide for the generalization of a concrete change into a program transformation, i.e., code elements appearing in many files are general and should not be abstracted away. We first propose a framework for transformation inference, where programs are represented as hypergraphs to enable fine-grained generalization of transformations. We then design a transformation inference approach, GENPAT, that infers a program transformation based on code context and statistics from a big code corpus. We have evaluated GENPAT under two distinct application scenarios, systematic editing and program repair. The evaluation on systematic editing shows that GENPAT significantly outperforms a state-of-the-art approach, SYDIT, with up to 5.5x correctly transformed cases. The evaluation on program repair suggests that GENPAT has the potential to be integrated in advanced program repair tools-GENPAT successfully repaired 19 real-world bugs in the Defects4J benchmark by simply applying transformations inferred from existing patches, where 4 bugs have never been repaired by any existing technique. Overall, the evaluation results suggest that GENPAT is effective for transformation inference and can potentially be adopted for many different applications.","","","10.1109/ASE.2019.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952210","Pattern generation, Program adaptation, Code abstraction","","","","","1","63","","","","","IEEE","IEEE Conferences"
"SpyREST: Automated RESTful API Documentation Using an HTTP Proxy Server (N)","S. M. Sohan; C. Anslow; F. Maurer","Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada; Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada; Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","271","276","RESTful API documentation is expensive to produce and maintain due to the lack of reusable tools and automated solutions. Most RESTful APIs are documented manually and the API developers are responsible for keeping the documentation up to date as the API evolves making the process both costly and error-prone. In this paper we introduce a novel technique using an HTTP proxy server that can be used to automatically generate RESTful API documentation and demonstrate SpyREST, an example implementation of the proposed technique. SpyREST uses a proxy to intercept example API calls and intelligently produces API documentation for RESTful Web APIs by processing the request and response data. Using the proposed HTTP proxy server based technique, RESTful API developers can significantly reduce the cost of producing and maintaining API documentation by replacing a large manual process with an automated process.","","","10.1109/ASE.2015.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372015","RESTful API;Web API;Documentation;Automation;Example based documentation","Documentation;Servers;Manuals;Databases;Uniform resource locators;Software as a service;Libraries","application program interfaces;hypermedia;Internet;software reusability;software tools;system documentation","automated RESTful API documentation;reusable tools;HTTP proxy server;SpyREST;RESTful Web API","","10","19","","","","","IEEE","IEEE Conferences"
"Testing intermediate representations for binary analysis","S. Kim; M. Faerevaag; M. Jung; S. Jung; D. Oh; J. Lee; S. K. Cha","KAIST, Republic of Korea; KAIST, Republic of Korea; KAIST, Republic of Korea; KAIST, Republic of Korea; KAIST, Republic of Korea; Gachon University, Republic of Korea; KAIST, Republic of Korea","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","353","364","Binary lifting, which is to translate a binary executable to a high-level intermediate representation, is a primary step in binary analysis. Despite its importance, there are only few existing approaches to testing the correctness of binary lifters. Furthermore, the existing approaches suffer from low test coverage, because they largely depend on random test case generation. In this paper, we present the design and implementation of the first systematic approach to testing binary lifters. We have evaluated the proposed system on 3 state-of-the-art binary lifters, and found 24 previously unknown semantic bugs. Our result demonstrates that writing a precise binary lifter is extremely difficult even for those heavily tested projects.","","","10.1109/ASE.2017.8115648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115648","","Semantics;Computer bugs;Binary codes;Testing;Tools;Software;C++ languages","program debugging;program testing","binary analysis;binary lifting;binary executable;high-level intermediate representation;random test case generation;systematic approach;precise binary lifter","","3","60","","","","","IEEE","IEEE Conferences"
"Have We Seen Enough Traces? (T)","H. Cohen; S. Maoz","Sch. of Comput. Sci., Tel Aviv Univ., Tel Aviv, Israel; Sch. of Comput. Sci., Tel Aviv Univ., Tel Aviv, Israel","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","93","103","Dynamic specification mining extracts candidate specifications from logs of execution traces. Existing algorithms differ in the kinds of traces they take as input and in the kinds of candidate specification they present as output. One challenge common to all approaches relates to the faithfulness of the mining results: how can we be confident that the extracted specifications faithfully characterize the program we investigate? Since producing and analyzing traces is costly, how would we know we have seen enough traces? And, how would we know we have not wasted resources and seen too many of them?In this paper we address these important questions by presenting a novel, black box, probabilistic framework based on a notion of log completeness, and by applying it to three different well-known specification mining algorithms from the literature: k-Tails, Synoptic, and mining of scenario-based triggers and effects. Extensive evaluation over 24 models taken from 9 different sources shows the soundness, generalizability, and usefulness of the framework and its contribution to the state-of-the-art in dynamic specification mining.","","","10.1109/ASE.2015.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371999","Specification Mining","Heuristic algorithms;Computational modeling;Data mining;Estimation;Probabilistic logic;Adaptation models;Servers","data mining;formal specification;probability;program verification","dynamic specification mining algorithm;program specification;black box;probabilistic framework;k-Tails;Synoptic","","7","42","","","","","IEEE","IEEE Conferences"
"Mining implicit design templates for actionable code reuse","Y. Lin; G. Meng; Y. Xue; Z. Xing; J. Sun; X. Peng; Y. Liu; W. Zhao; J. Dong","National University of Singapore, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Australia National University, Australia; Singapore University of Technology and Design, Singapore; Fudan University, China; Nanyang Technological University, Singapore; Fudan University, China; National University of Singapore, Singapore","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","394","404","In this paper, we propose an approach to detecting project-specific recurring designs in code base and abstracting them into design templates as reuse opportunities. The mined templates allow programmers to make further customization for generating new code. The generated code involves the code skeleton of recurring design as well as the semi-implemented code bodies annotated with comments to remind programmers of necessary modification. We implemented our approach as an Eclipse plugin called MICoDe. We evaluated our approach with a reuse simulation experiment and a user study involving 16 participants. The results of our simulation experiment on 10 open source Java projects show that, to create a new similar feature with a design template, (1) on average 69% of the elements in the template can be reused and (2) on average 60% code of the new feature can be adopted from the template. Our user study further shows that, compared to the participants adopting the copy-paste-modify strategy, the ones using MICoDe are more effective to understand a big design picture and more efficient to accomplish the code reuse task.","","","10.1109/ASE.2017.8115652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115652","","Unified modeling language;Object oriented modeling;Cloning;Skeleton;Java;Feature extraction","data mining;Java;public domain software;software reusability","open source Java projects;implicit design template mining;project-specific recurring design detection;code reuse task;reuse simulation experiment;semiimplemented code bodies;code skeleton;generated code;code base;actionable code reuse","","3","41","","","","","IEEE","IEEE Conferences"
"The potential of polyhedral optimization: An empirical study","A. Simbürger; S. Apel; A. Größlinger; C. Lengauer","University of Passau, Germany; University of Passau, Germany; University of Passau, Germany; University of Passau, Germany","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","508","518","Present-day automatic optimization relies on powerful static (i.e., compile-time) analysis and transformation methods. One popular platform for automatic optimization is the polyhedron model. Yet, after several decades of development, there remains a lack of empirical evidence of the model's benefits for real-world software systems. We report on an empirical study in which we analyzed a set of popular software systems, distributed across various application domains. We found that polyhedral analysis at compile time often lacks the information necessary to exploit the potential for optimization of a program's execution. However, when conducted also at run time, polyhedral analysis shows greater relevance for real-world applications. On average, the share of the execution time amenable to polyhedral optimization is increased by a factor of nearly 3. Based on our experimental results, we discuss the merits and potential of polyhedral optimization at compile time and run time.","","","10.1109/ASE.2013.6693108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693108","","Optimization;Benchmark testing;Arrays;Analytical models;Program processors;Multimedia communication;Time measurement","optimisation;optimising compilers;program diagnostics","polyhedral optimization;present-day automatic optimization;static analysis;transformation methods;polyhedron model;real-world software systems;polyhedral analysis;program execution","","2","37","","","","","IEEE","IEEE Conferences"
"Automated verification of interactive rule-based configuration systems","D. Dhungana; C. H. Tang; C. Weidenbach; P. Wischnewski","Siemens AG Österreich, Vienna, Austria; Max Planck Institute for Informatics, Saarbrücken, Germany; Max Planck Institute for Informatics, Saarbrücken, Germany; Logic4Business GmbH, Saarbrücken, Germany","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","551","561","Rule-based specifications of systems have again become common in the context of product line variability modeling and configuration systems. In this paper, we define a logical foundation for rule-based specifications that has enough expressivity and operational behavior to be practically useful and at the same time enables decidability of important overall properties such as consistency or cycle-freeness. Our logic supports rule-based interactive user transitions as well as the definition of a domain theory via rule transitions. As a running example, we model DOPLER, a rule-based configuration system currently in use at Siemens.","","","10.1109/ASE.2013.6693112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693112","","Semantics;Slabs;Calculus;Silicon;Redundancy;Context;Computer languages","formal logic;formal specification;formal verification;interactive systems;knowledge based systems","automated verification;interactive rule-based configuration system;rule-based specification;product line variability modeling;rule-based interactive user transition;domain theory;rule transition;DOPLER","","1","19","","","","","IEEE","IEEE Conferences"
"Static Analysis of Implicit Control Flow: Resolving Java Reflection and Android Intents (T)","P. Barros; R. Just; S. Millstein; P. Vines; W. Dietl; M. dAmorim; M. D. Ernst","Fed. Univ. of Pernambuco, Recife, Brazil; Univ. of Washington, Seattle, WA, USA; Univ. of Washington, Seattle, WA, USA; Univ. of Washington, Seattle, WA, USA; Univ. of Waterloo, Waterloo, ON, Canada; NA; Univ. of Washington, Seattle, WA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","669","679","Implicit or indirect control flow is a transfer of control between procedures using some mechanism other than an explicit procedure call. Implicit control flow is a staple design pattern that adds flexibility to system design. However, it is challenging for a static analysis to compute or verify properties about a system that uses implicit control flow. This paper presents static analyses for two types of implicit control flow that frequently appear in Android apps: Java reflection and Android intents. Our analyses help to resolve where control flows and what data is passed. This information improves the precision of downstream analyses, which no longer need to make conservative assumptions about implicit control flow. We have implemented our techniques for Java. We enhanced an existing security analysis with a more precise treatment of reflection and intents. In a case study involving ten real-world Android apps that use both intents and reflection, the precision of the security analysis was increased on average by two orders of magnitude. The precision of two other downstream analyses was also improved.","","","10.1109/ASE.2015.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372054","Android;Static Analysis;Implicit Control Flow;Type systems","Androids;Humanoid robots;Java;Security;Dictionaries;Context","Android (operating system);Java;program diagnostics;security of data","static analysis;implicit control flow;Java reflection;Android intents;indirect control flow;security analysis","","26","35","","","","","IEEE","IEEE Conferences"
"Learning effective changes for software projects","R. Krishna","Comptuer Science, North Carolina State University, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1002","1005","The primary motivation of much of software analytics is decision making. How to make these decisions? Should one make decisions based on lessons that arise from within a particular project? Or should one generate these decisions from across multiple projects? This work is an attempt to answer these questions. Our work was motivated by a realization that much of the current generation software analytics tools focus primarily on prediction. Indeed prediction is a useful task, but it is usually followed by ""planning"" about what actions need to be taken. This research seeks to address the planning task by seeking methods that support actionable analytics by offering clear guidance on what to do. Specifically, we propose XTREE and BELLTREE algorithms for generating a set of actionable plans within and across projects. Each of these plans, if followed will improve the quality of the software project.","","","10.1109/ASE.2017.8115719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115719","Planning;bellwethers;defect prediction","Planning;Software;Tools;Software engineering;Decision trees;Software algorithms","decision making;project management;software engineering","actionable plans;software project;primary motivation;decision making;planning task;actionable analytics;generation software analytics tools focus;XTREE algorithms;BELLTREE algorithms","","","29","","","","","IEEE","IEEE Conferences"
"Towards the automatic classification of traceability links","C. Mills","Department of Computer Science, Florida State University, Tallahassee, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1018","1021","A wide range of text-based artifacts contribute to software projects (e.g., source code, test cases, use cases, project requirements, interaction diagrams, etc.). Traceability Link Recovery (TLR) is the software task in which relevant documents in these various sets are linked to one another, uncovering information about the project that is not available when considering only the documents themselves. This information is helpful for enabling other tasks such as improving test coverage, impact analysis, and ensuring that system or regulatory requirements are met. However, while traceability links are useful, performing TLR manually is time consuming and fraught with error. Previous work has applied Information Retrieval (IR) and other techniques to reduce the human effort involved; however, that effort remains significant. In this research we seek to take the next step in reducing it by using machine learning (ML) classification models to predict whether a candidate link is valid or invalid without human oversight. Preliminary results show that this approach has promise for accurately recommending valid links; however, there are several challenges that still must be addressed in order to achieve a technique with high enough performance to consider it a viable, completely automated solution.","","","10.1109/ASE.2017.8115723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115723","software traceability;traceability link recovery;machine learning","Software;Classification algorithms;Semantics;Predictive models;Measurement;Tuning","information retrieval;learning (artificial intelligence);software maintenance;text analysis","automatic classification;traceability links;software projects;source code;project requirements;interaction diagrams;TLR;software task;relevant documents;test coverage;human effort;machine learning classification models;information retrieval;traceability link recovery","","","33","","","","","IEEE","IEEE Conferences"
"Automated verification of pattern-based interaction invariants in Ajax applications","Y. Maezawa; H. Washizaki; Y. Tanabe; S. Honiden","The University of Tokyo, Japan; Waseda University, Tokyo, Japan; National Institute of Informatics, Tokyo, Japan; The University of Tokyo, National Institute of Informatics, Japan","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","158","168","When developing asynchronous JavaScript and XML (Ajax) applications, developers implement Ajax design patterns for increasing the usability of the applications. However, unpredictable contexts of running applications might conceal faults that will break the design patterns, which decreases usability. We propose a support tool called JSVerifier that auto-matically verifies interaction invariants; the applications handle their interactions in invariant occurrence and order. We also present a selective set of interaction invariants derived from Ajax design patterns, as input. If the application behavior breaks the design patterns, JSVerifier automatically outputs faulty execution paths for debugging. The results of our case studies show that JSVerifier can verify the interaction invariants in a feasible amount of time, and we conclude that it can help developers increase the usability of Ajax applications.","","","10.1109/ASE.2013.6693076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693076","Ajax;Reverse Engineering;Model Checking;Design Pattern","Usability;Servers;Context;Testing;Debugging;Web pages;Educational institutions","Java;object-oriented programming;program debugging;program verification;software tools;XML","automated verification;pattern-based interaction invariants;Ajax applications;asynchronous JavaScript applications;XML applications;JSVerifier;Ajax design patterns;faulty execution paths;debugging","","1","26","","","","","IEEE","IEEE Conferences"
"JFlow: Practical refactorings for flow-based parallelism","N. Chen; R. E. Johnson","Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","202","212","Emerging applications in the domains of recognition, mining and synthesis (RMS); image and video processing; data warehousing; and automatic financial trading admit a particular style of parallelism termed flow-based parallelism. To help developers exploit flow-based parallelism, popular parallel libraries such as Groovy's GPars, Intel's TBB Flow Graph and Microsoft's TPL Dataflow have begun introducing many new and useful constructs. However, to reap the benefits of such constructs, developers must first use them. This involves refactoring their existing sequential code to incorporate these constructs - a manual process that overwhelms even experts. To alleviate this burden, we introduce a set of novel analyses and transformations targeting flow-based parallelism. We implemented these ideas in JFlow, an interactive refactoring tool integrated into the Eclipse IDE. We used JFlow to parallelize seven applications: four from a previously known benchmark and three from a suite of large open source projects. JFlow, with minimal interaction from the developer, can successfully parallelize applications from the aforementioned domains with good performance (offering up to 3.45x speedup on a 4-core machine) and is fast enough to be used interactively as part of a developer's workflow.","","","10.1109/ASE.2013.6693080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693080","","Parallel processing;Feature extraction;Libraries;Pipelines;Sensitivity;Java;Databases","interactive systems;parallel programming;public domain software;software maintenance","JFlow;flow-based parallelism;RMS domain;recognition, mining and synthesis domain;video processing;image processing;data warehousing;automatic financial trading;parallel libraries;Groovy GPars;Intel TBB flow graph;Microsoft TPL dataflow;sequential code refactoring;interactive refactoring tool;Eclipse IDE;large open source projects","","2","56","","","","","IEEE","IEEE Conferences"
"Understanding and overcoming parallelism bottlenecks in ForkJoin applications","G. Pinto; A. Canino; F. Castor; G. Xu; Y. D. Liu","UFPA, Brazil; SUNY Binghamton, USA; UFPE, Brazil; UC Irvine, USA; SUNY Binghamton, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","765","775","ForkJoin framework is a widely used parallel programming framework upon which both core concurrency libraries and real-world applications are built. Beneath its simple and user-friendly APIs, ForkJoin is a sophisticated managed parallel runtime unfamiliar to many application programmers: the framework core is a work-stealing scheduler, handles fine-grained tasks, and sustains the pressure from automatic memory management. ForkJoin poses a unique gap in the compute stack between high-level software engineering and low-level system optimization. Understanding and bridging this gap is crucial for the future of parallelism support in JVM-supported applications. This paper describes a comprehensive study on parallelism bottlenecks in ForkJoin applications, with a unique focus on how they interact with underlying system-level features, such as work stealing and memory management. We identify 6 bottlenecks, and found that refactoring them can significantly improve performance and energy efficiency. Our field study includes an in-depth analysis of Akka - a real-world actor framework - and 30 additional open-source ForkJoin projects. We sent our patches to the developers of 15 projects, and 7 out of the 9 projects that replied to our patches have accepted them.","","","10.1109/ASE.2017.8115687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115687","","Java;Parallel processing;Programming;Runtime;Optimization;Synchronization","application program interfaces;Java;parallel programming;processor scheduling;software engineering","real-world actor framework;parallelism bottlenecks;core concurrency libraries;real-world applications;application programmers;work-stealing scheduler;automatic memory management;compute stack;high-level software engineering;low-level system optimization;parallelism support;energy efficiency;JVM-supported applications;user-friendly API;parallel programming framework;ForkJoin applications;open-source ForkJoin;system-level features","","2","39","","","","","IEEE","IEEE Conferences"
"Symlnfer: Inferring program invariants using symbolic states","T. Nguyen; M. B. Dwyer; W. Visser","University of Nebraska-Lincoln, USA; University of Nebraska-Lincoln, USA; Stellenbosch University, South Africa","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","804","814","We introduce a new technique for inferring program invariants that uses symbolic states generated by symbolic execution. Symbolic states, which consist of path conditions and constraints on local variables, are a compact description of sets of concrete program states and they can be used for both invariant inference and invariant verification. Our technique uses a counterexample-based algorithm that creates concrete states from symbolic states, infers candidate invariants from concrete states, and then verifies or refutes candidate invariants using symbolic states. The refutation case produces concrete counterexamples that prevent spurious results and allow the technique to obtain more precise invariants. This process stops when the algorithm reaches a stable set of invariants. We present Symlnfer, a tool that implements these ideas to automatically generate invariants at arbitrary locations in a Java program. The tool obtains symbolic states from Symbolic PathFinder and uses existing algorithms to infer complex (potentially nonlinear) numerical invariants. Our preliminary results show that Symlnfer is effective in using symbolic states to generate precise and useful invariants for proving program safety and analyzing program runtime complexity. We also show that Symlnfer outperforms existing invariant generation systems.","","","10.1109/ASE.2017.8115691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115691","","Concrete;Inference algorithms;Complexity theory;Encoding;Benchmark testing;Tools;Runtime","formal verification;Java;program diagnostics;program testing;program verification","concrete states;symbolic states;concrete program states;Symlnfer;program invariant inference;symbolic execution;path conditions;local variable constraints;invariant verification;Java program;Symbolic PathFinder;program safety;program runtime complexity analysis","","1","37","","","","","IEEE","IEEE Conferences"
"EHBDroid: Beyond GUI testing for Android applications","W. Song; X. Qian; J. Huang","School of Computer Sci. & Eng., Nanjing University of Sci. & Tech., Nanjing, China; School of Computer Sci. & Eng., Nanjing University of Sci. & Tech., Nanjing, China; Parasol Laboratory, Texas A&M University, College Station, TX, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","27","37","With the prevalence of Android-based mobile devices, automated testing for Android apps has received increasing attention. However, owing to the large variety of events that Android supports, test input generation is a challenging task. In this paper, we present a novel approach and an open source tool called EHBDroid for testing Android apps. In contrast to conventional GUI testing approaches, a key novelty of EHBDroid is that it does not generate events from the GUI, but directly invokes callbacks of event handlers. By doing so, EHBDroid can efficiently simulate a large number of events that are difficult to generate by traditional UI-based approaches. We have evaluated EHBDroid on a collection of 35 real-world large-scale Android apps and compared its performance with two state-of-the-art UI-based approaches, Monkey and Dynodroid. Our experimental results show that EHBDroid is significantly more effective and efficient than Monkey and Dynodroid: in a much shorter time, EHBDroid achieves as much as 22.3% higher statement coverage (11.1% on average) than the other two approaches, and found 12 bugs in these benchmarks, including 5 new bugs that the other two failed to find.","","","10.1109/ASE.2017.8115615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115615","Android;automated testing;event generation;event handlers","Androids;Humanoid robots;Testing;Tools;Instruments;Graphical user interfaces;XML","Android (operating system);graphical user interfaces;mobile computing;program testing","EHBDroid;Android applications;test input generation;conventional GUI testing approaches;event handlers;UI-based approaches;large-scale Android apps;open source tool;Android based mobile devices","","5","39","","","","","IEEE","IEEE Conferences"
"iProbe: A lightweight user-level dynamic instrumentation tool","N. Arora; Hui Zhang; Junghwan Rhee; K. Yoshihira; Guofei Jiang","NEC Laboratories America, USA; NEC Laboratories America, USA; NEC Laboratories America, USA; NEC Laboratories America, USA; NEC Laboratories America, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","742","745","We introduce a new hybrid instrumentation tool for dynamic application instrumentation called iProbe, which is flexible and has low overhead. iProbe takes a novel 2-stage design, and offloads much of the dynamic instrumentation complexity to an offline compilation stage. It leverages standard compiler flags to introduce “place-holders” for hooks in the program executable. Then it utilizes an efficient user-space “HotPatching” mechanism which modifies the functions to be traced and enables execution of instrumented code in a safe and secure manner. In its evaluation on a micro-benchmark and SPEC CPU2006 benchmark applications, the iProbe prototype achieved the instrumentation overhead an order of magnitude lower than existing state-of-the-art dynamic instrumentation tools like SystemTap and DynInst.","","","10.1109/ASE.2013.6693147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693147","Monitoring;Tracing;Hotpatching;Production Systems;Low-Overhead","Complexity theory;Scalability;Probes;Kernel;Linux;Benchmark testing","program compilers;program debugging","iProbe;lightweight user-level dynamic instrumentation tool;hybrid instrumentation tool;dynamic application instrumentation;HotPatching mechanism;SystemTap;DynInst","","1","19","","","","","IEEE","IEEE Conferences"
"Context-aware task allocation for distributed agile team","J. Lin","School of Computer Engineering, Nanyang Technological University, Singapore","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","758","761","The philosophy of Agile software development advocates the spirit of open discussion and coordination among team members to adapt to incremental changes encountered during the process. Based on our observations from 20 agile student development teams over an 8-week study in Beihang University, China, we found that the task allocation strategy as a result of following the Agile process heavily depends on the experience of the users, and cannot be guaranteed to result in efficient utilization of team resources. In this research, we propose a context-aware task allocation decision support system that balances the considerations for quality and timeliness to improve the overall utility derived from an agile software development project.We formulate the agile process as a distributed constraint optimization problem, and propose a technology framework that assesses individual developers' situations based on data collected from a Scrum-based agile process, and helps individual developers make situation-aware decisions on which tasks from the backlog to select in real-time. Preliminary analysis and simulation results show that it can achieve close to optimally efficient utilization of the developers' collective capacity. We plan to build the framework into a computer-supported collaborative development platform and refine the method through more realistic projects.","","","10.1109/ASE.2013.6693151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693151","distributed agile;task allocation;project management","Resource management;Software;Variable speed drives;Planning;Educational institutions;Indexes;Delays","groupware;optimisation;software development management;software prototyping;team working","context-aware task allocation;distributed agile team;agile software development;team member discussion;team member coordination;Beihang University;China;task allocation strategy;context-aware task allocation decision support system;agile software development project;distributed constraint optimization problem;technology framework;Scrum-based agile process;developer collective capacity;computer-supported collaborative development platform","","4","11","","","","","IEEE","IEEE Conferences"
"A Message-Passing Architecture without Public Ids Using Send-to-Behavior","E. S. Wang; Z. Dang","Sch. of Electr. Eng. & Comput. Sci., Washington State Univ., Pullman, WA, USA; Sch. of Electr. Eng. & Comput. Sci., Washington State Univ., Pullman, WA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","902","905","We explore a novel model of computation based on nodes that have no public addresses (ids). We define nodes as concurrent, message-passing computational entities in an abstract communication medium, similar to the Actor model, but with all public node ids elided. Instead, drawing inspiration from biological systems, we postulate a send-to-behavior language construct to enable anonymous one-way communication. A behavior, defined as a function of input to actions, is also an intensional definition of the subset of nodes that express it. Sending to a behavior is defined to deliver the message to one or more nodes that implement that behavior.","","","10.1109/ASE.2015.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372089","behavior composition;message passing;multi node","Computer architecture;Programming;Computational modeling;Topology;Computers;Hardware;Protocols","application program interfaces;message passing;parallel programming","message-passing architecture;message-passing computational entity;communication medium;actor model;public node;send-to-behavior language","","","8","","","","","IEEE","IEEE Conferences"
"An Automated Framework for Recommending Program Elements to Novices (N)","K. Zimmerman; C. R. Rupakheti","Dept. of Comput. Sci. & Software Eng., Rose-Hulman Inst. of Technol., Terre Haute, IN, USA; Dept. of Comput. Sci. & Software Eng., Rose-Hulman Inst. of Technol., Terre Haute, IN, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","283","288","Novice programmers often learn programming by implementing well-known algorithms. There are several challenges in the process. Recommendation systems in software currently focus on programmer productivity and ease of development. Teaching aides for such novice programmers based on recommendation systems still remain an under-explored area. In this paper, we present a general framework for recognizing the desired target for partially-written code and recommending a reliable series of edits to transform the input program into the target solution. Our code analysis is based on graph matching and tree edit algorithms. Our experimental results show that efficient graph comparison techniques can accurately match two portions of source code and produce an accurate set of source code edits. We provide details on implementation of our framework, which is developed as a plugin for Java in Eclipse IDE.","","","10.1109/ASE.2015.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372017","Recommendation Framework;pq-Gram Algorithm","Programming;Software engineering;Target recognition;Knowledge based systems;Transforms;Algorithm design and analysis;Java","graph theory;Java;pattern matching;programming;recommender systems;source code (software)","automated framework;recommending program element;novice programmer;programming;recommendation system;programmer productivity;teaching aide;partially-written code;code analysis;graph matching;tree edit algorithm;graph comparison technique;source code edit;Java;Eclipse IDE","","2","30","","","","","IEEE","IEEE Conferences"
"Search-Based Synthesis of Probabilistic Models for Quality-of-Service Software Engineering (T)","S. Gerasimou; G. Tamburrelli; R. Calinescu","Dept. of Comput. Sci., Univ. of York, York, UK; Dept. of Comput. Sci., Vrije Univ., Amsterdam, Netherlands; Dept. of Comput. Sci., Univ. of York, York, UK","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","319","330","The formal verification of finite-state probabilistic models supports the engineering of software with strict quality-of-service (QoS) requirements. However, its use in software design is currently a tedious process of manual multiobjective optimisation. Software designers must build and verify probabilistic models for numerous alternative architectures and instantiations of the system parameters. When successful, they end up with feasible but often suboptimal models. The EvoChecker search-based software engineering approach and tool introduced in our paper employ multiobjective optimisation genetic algorithms to automate this process and considerably improve its outcome. We evaluate EvoChecker for six variants of two software systems from the domains of dynamic power management and foreign exchange trading. These systems are characterised by different types of design parameters and QoS requirements, and their design spaces comprise between 2E+14 and 7.22E+86 relevant alternative designs. Our results provide strong evidence that EvoChecker significantly outperforms the current practice and yields actionable insights for software designers.","","","10.1109/ASE.2015.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372021","Probabilistic Model Checking;Model Synthesis;Genetic Algorithms;Search-Based Software Engineering;Model Repair","Probabilistic logic;Quality of service;Software systems;Markov processes;Optimization;Software engineering","genetic algorithms;probability;program testing;program verification;quality of service","search-based synthesis;probabilistic models;quality-of-service software engineering;formal verification;finite-state probabilistic models;quality-of-service requirements;software design;suboptimal models;EvoChecker search-based software engineering approach;multiobjective optimisation genetic algorithms;dynamic power management;foreign exchange trading;design parameters;QoS requirements;design space","","15","68","","","","","IEEE","IEEE Conferences"
"Automatically assessing code understandability: How far are we?","S. Scalabrino; G. Bavota; C. Vendome; M. Linares-Vásquez; D. Poshyvanyk; R. Oliveto","University of Molise, Italy; Università della Svizzera italiana (USI), Switzerland; The College of William and Mary, USA; Universidad de los Andes, Colombia; The College of William and Mary, USA; University of Molise, Italy","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","417","427","Program understanding plays a pivotal role in software maintenance and evolution: a deep understanding of code is the stepping stone for most software-related activities, such as bug fixing or testing. Being able to measure the understandability of a piece of code might help in estimating the effort required for a maintenance activity, in comparing the quality of alternative implementations, or even in predicting bugs. Unfortunately, there are no existing metrics specifically designed to assess the understandability of a given code snippet. In this paper, we perform a first step in this direction, by studying the extent to which several types of metrics computed on code, documentation, and developers correlate with code understandability. To perform such an investigation we ran a study with 46 participants who were asked to understand eight code snippets each. We collected a total of 324 evaluations aiming at assessing the perceived understandability, the actual level of understanding, and the time needed to understand a code snippet. Our results demonstrate that none of the (existing and new) metrics we considered is able to capture code understandability, not even the ones assumed to assess quality attributes strongly related with it, such as code readability and complexity.","","","10.1109/ASE.2017.8115654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115654","Software metrics;Code understandability;Empirical study;Negative result","Measurement;Complexity theory;Software;Computer bugs;Correlation;Maintenance engineering;Documentation","program debugging;public domain software;software maintenance;software metrics;software quality","program understanding;software maintenance;software-related activities;perceived understandability;code readability;code snippet;code complexity;automatic code understandability assessibility;quality attributes","","7","37","","","","","IEEE","IEEE Conferences"
"Detecting system use cases and validations from documents","S. Ghaisas; M. Motwani; P. R. Anish","Tata Research, Development and Design Center, 54 Hadapsar Industrial Estates, Pune, 411013, India; Tata Research, Development and Design Center, 54 Hadapsar Industrial Estates, Pune, 411013, India; Tata Research, Development and Design Center, 54 Hadapsar Industrial Estates, Pune, 411013, India","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","568","573","Identifying system use cases and corresponding validations involves analyzing large requirement documents to understand the descriptions of business processes, rules and policies. This consumes a significant amount of effort and time. We discuss an approach to automate the detection of system use cases and corresponding validations from documents. We have devised a representation that allows for capturing the essence of rule statements as a composition of atomic `Rule intents' and key phrases associated with the intents. Rule intents that co-occur frequently constitute `Rule acts' analogous to the Speech acts in Linguistics. Our approach is based on NLP techniques designed around this Rule Model. We employ syntactic and semantic NL analyses around the model to identify and classify rules and annotate them with Rule acts. We map the Rule acts to business process steps and highlight the combinations as potential system use cases and validations for human supervision.","","","10.1109/ASE.2013.6693114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693114","Requirement documents;System use cases;validations;NL analyses;Rules;Rule types;Rule acts;Rule intents","Business;Switches;Insurance;Access control;Manuals;User interfaces;Databases","business data processing;document handling;knowledge based systems;natural language processing;program verification","human supervision;rule acts;rules annotation;rule identification;rule classification;semantic NL analysis;syntactic NL analysis;rule model;NLP techniques;linguistics;speech acts;atomic rule intents;rule statements;business policies;business rules;business processes;requirement document analysis;validation detection;automatic system use case detection","","5","26","","","","","IEEE","IEEE Conferences"
"Semantic Slicing of Software Version Histories (T)","Y. Li; J. Rubin; M. Chechik","Univ. of Toronto, Toronto, ON, Canada; Massachusetts Inst. of Technol., Cambridge, MA, USA; Univ. of Toronto, Toronto, ON, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","686","696","Software developers often need to transfer func-tionality, e.g., a set of commits implementing a new feature or a bug fix, from one branch of a configuration management system to another. That can be a challenging task as the existing configuration management tools lack support for matching high-level semantic functionality with low-level version histories. The developer thus has to either manually identify the exact set of semantically-related commits implementing the functionality of interest or sequentially port a specific subset of the change history, ""inheriting"" additional, unwanted functionality. In this paper, we tackle this problem by providing automated support for identifying the set of semantically-related commits implementing a particular functionality, which is defined by a set of tests. We refer to our approach, CSLICER, as semantic slicing of version histories. We formally define the semantic slicing problem, provide an algorithm for identifying a set of commits that constitute a slice, and instantiate it in a specific implementation for Java projects managed in Git. We evaluate the correctness and effectiveness of our approach on a set of open-source software repositories. We show that it allows to identify subsets of change histories that maintain the functionality of interest but are substantially smaller than the original ones.","","","10.1109/ASE.2015.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372056","Software changes;version history;dependency","History;Semantics;Java;Software;Context;Syntactics;Software algorithms","configuration management;Java;program debugging;program slicing;public domain software","software version history;software developer;bug fix;configuration management system;high-level semantic functionality;low-level version history;change history;unwanted functionality;automated support;CSLICER;semantic slicing problem;Java project;open-source software repository","","9","38","","","","","IEEE","IEEE Conferences"
"Developing a DSL-Based Approach for Event-Based Monitoring of Systems of Systems: Experiences and Lessons Learned (E)","M. Vierhauser; R. Rabiser; P. Grünbacher; A. Egyed","Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria; Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria; Inst. for Software Syst. Eng., Johannes Kepler Univ., Linz, Austria; Inst. for Software Syst. Eng., Johannes Kepler Univ., Linz, Austria","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","715","725","Complex software-intensive systems are often described as systems of systems (SoS) comprising heterogeneous architectural elements. As SoS behavior fully emerges during operation only, runtime monitoring is needed to detect deviations from requirements. Today, diverse approaches exist to define and check runtime behavior and performance characteristics. However, existing approaches often focus on specific types of systems and address certain kinds of checks, thus impeding their use in industrial SoS. Furthermore, as many SoS need to run continuously for long periods, the dynamic definition and deployment of constraints needs to be supported. In this paper we describe experiences of developing and applying a DSL-based approach for monitoring an SoS in the domain of industrial automation software. We evaluate both the expressiveness of our DSL as well as the scalability of the constraint checker. We also describe lessons learned.","","","10.1109/ASE.2015.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372060","Systems of systems;requirements monitoring;constraint checking;domain-specific languages","Monitoring;Runtime;Steel;Automation;Iron;Casting;Software","computerised monitoring;constraint handling;factory automation;system monitoring;visual programming","DSL-based approach;event-based monitoring;complex software-intensive system;systems of systems;heterogeneous architectural elements;SoS;runtime monitoring;runtime behavior checking;performance characteristics;constraint deployment;industrial automation software;constraint checker scalability;domain-specific languages","","10","45","","","","","IEEE","IEEE Conferences"
"A study of repetitiveness of code changes in software evolution","H. A. Nguyen; A. T. Nguyen; T. T. Nguyen; T. N. Nguyen; H. Rajan","Iowa State University, USA; Iowa State University, USA; Iowa State University, USA; Iowa State University, USA; Iowa State University, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","180","190","In this paper, we present a large-scale study of repetitiveness of code changes in software evolution. We collected a large data set of 2,841 Java projects, with 1.7 billion source lines of code (SLOC) at the latest revisions, 1.8 million code change revisions (0.4 million fixes), 6.2 million changed files, and 2.5 billion changed SLOCs. A change is considered repeated within or cross-project if it matches another change having occurred in the history of the project or another project, respectively. We report the following important findings. First, repetitiveness of changes could be as high as 70-100% at small sizes and decreases exponentially as size increases. Second, repetitiveness is higher and more stable in the cross-project setting than in the within-project one. Third, fixing changes repeat similarly to general changes. Importantly, learning code changes and recommending them in software evolution is beneficial with accuracy for top-1 recommendation of over 30% and top-3 of nearly 35%. Repeated fixing changes could also be useful for automatic program repair.","","","10.1109/ASE.2013.6693078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693078","Repetitive Code Changes;Software Evolution","Software;Vegetation;Databases;History;Maintenance engineering;Libraries;Programming","automatic programming;Java;software maintenance;source code (software)","software evolution;Java projects;source lines of code;SLOC;code change revisions;automatic program repair;code change learning;code change repetitiveness","","34","39","","","","","IEEE","IEEE Conferences"
"Automatically synthesizing SQL queries from input-output examples","S. Zhang; Y. Sun","Computer Science & Engineering, University of Washington, USA; Computer Science & Engineering, University of Washington, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","224","234","Many computer end-users, such as research scientists and business analysts, need to frequently query a database, yet lack enough programming knowledge to write a correct SQL query. To alleviate this problem, we present a programming by example technique (and its tool implementation, called SQLSynthesizer) to help end-users automate such query tasks. SQLSynthesizer takes from users an example input and output of how the database should be queried, and then synthesizes a SQL query that reproduces the example output from the example input. If the synthesized SQL query is applied to another, potentially larger, database with a similar schema, the synthesized SQL query produces a corresponding result that is similar to the example output. We evaluated SQLSynthesizer on 23 exercises from a classic database textbook and 5 forum questions about writing SQL queries. SQLSynthesizer synthesized correct answers for 15 textbook exercises and all 5 forum questions, and it did so from relatively small examples.","","","10.1109/ASE.2013.6693082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693082","","Databases;Skeleton;Aggregates;Writing;Standards;Syntactics;Graphical user interfaces","query processing;SQL","automatic SQL query synthesis;input-output examples;computer end-users;database query;programming-by-example technique;SQLSynthesizer tool;forum questions;SQL query writing;database textbook exercises","","12","35","","","","","IEEE","IEEE Conferences"
"Automatic loop-invariant generation anc refinement through selective sampling","J. Li; J. Sun; L. Li; Q. L. Le; S. Lin","Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; School of Computing, Teesside University, United Kingdom; School of Computer Science and Engineering, Nanyang Technological University, Singapore","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","782","792","Automatic loop-invariant generation is important in program analysis and verification. In this paper, we propose to generate loop-invariants automatically through learning and verification. Given a Hoare triple of a program containing a loop, we start with randomly testing the program, collect program states at run-time and categorize them based on whether they satisfy the invariant to be discovered. Next, classification techniques are employed to generate a candidate loop-invariant automatically. Afterwards, we refine the candidate through selective sampling so as to overcome the lack of sufficient test cases. Only after a candidate invariant cannot be improved further through selective sampling, we verify whether it can be used to prove the Hoare triple. If it cannot, the generated counterexamples are added as new tests and we repeat the above process. Furthermore, we show that by introducing a path-sensitive learning, i.e., partitioning the program states according to program locations they visit and classifying each partition separately, we are able to learn disjunctive loop-invariants. In order to evaluate our idea, a prototype tool has been developed and the experiment results show that our approach complements existing approaches.","","","10.1109/ASE.2017.8115689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115689","Loop-invariant;program verification;classification;active learning;selective sampling","Cost accounting;Tools;Software;Computer science;Testing;Prototypes;Indexes","learning (artificial intelligence);program control structures;program diagnostics;program verification","automatic loop-invariant generation;selective sampling;program analysis;Hoare triple;program states;candidate loop-invariant;program locations;disjunctive loop-invariants;program verification;program state partitioning;path-sensitive learning","","","50","","","","","IEEE","IEEE Conferences"
"Mining constraints for event-based monitoring in systems of systems","T. Krismayer; R. Rabiser; P. GrUnbacher","Christian Doppler Laboratory MEVSS, Institute for Software Systems Engineering, Johannes Kepler University Linz, Austria; Christian Doppler Laboratory MEVSS, Institute for Software Systems Engineering, Johannes Kepler University Linz, Austria; Christian Doppler Laboratory MEVSS, Institute for Software Systems Engineering, Johannes Kepler University Linz, Austria","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","826","831","The full behavior of software-intensive systems of systems (SoS) emerges during operation only. Runtime monitoring approaches have thus been proposed to detect deviations from the expected behavior. They commonly rely on temporal logic or domain-specific languages to formally define requirements, which are then checked by analyzing the stream of monitored events and event data. Some approaches also allow developers to generate constraints from declarative specifications of the expected behavior. However, independent of the approach, deep domain knowledge is required to specify the desired behavior. This knowledge is often not accessible in SoS environments with multiple development teams independently working on different, heterogeneous systems. In this New Ideas Paper we thus describe an approach that automatically mines constraints for runtime monitoring from event logs recorded in SoS. Our approach builds on ideas from specification mining, process mining, and machine learning to mine different types of constraints on event occurrence, event timing, and event data. The approach further presents the mined constraints to users in an existing constraint language and it ranks the constraints using different criteria. We demonstrate the feasibility of our approach by applying it to event logs from a real-world industrial SoS.","","","10.1109/ASE.2017.8115693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115693","Constraint mining;event-based monitoring;systems of systems","Monitoring;Data mining;Runtime;Feature extraction;Automation;Heuristic algorithms;System of systems","data mining;formal specification;learning (artificial intelligence);system monitoring","mined constraints;event logs;real-world industrial SoS;deviation detection;constraint language;software-intensive systems of systems;event timing;event occurrence;process mining;specification mining;heterogeneous systems;multiple development teams;SoS environments;deep domain knowledge;declarative specifications;event data;monitored events;temporal logic;expected behavior;runtime monitoring approaches","","","29","","","","","IEEE","IEEE Conferences"
"Saying ‘Hi!’ is not enough: Mining inputs for effective test generation","L. D. Toffola; C. Staicu; M. Pradel","Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, TU Darmstadt, Germany; Department of Computer Science, TU Darmstadt, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","44","49","Automatically generating unit tests is a powerful approach to exercise complex software. Unfortunately, current techniques often fail to provide relevant input values, such as strings that bypass domain-specific sanity checks. As a result, state-of-the-art techniques are effective for generic classes, such as collections, but less successful for domain-specific software. This paper presents TestMiner, the first technique for mining a corpus of existing tests for input values to be used by test generators for effectively testing software not in the corpus. The main idea is to extract literals from thousands of tests and to adapt information retrieval techniques to find values suitable for a particular domain. Evaluating the approach with 40 Java classes from 18 different projects shows that TestMiner improves test coverage by 21% over an existing test generator. The approach can be integrated into various test generators in a straightforward way, increasing their effectiveness on previously difficult-to-test classes.","","","10.1109/ASE.2017.8115617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115617","","Generators;Software;Testing;Indexes;Data mining;Computer science","data mining;information retrieval;Java;program testing","TestMiner;test coverage;test generators;difficult-to-test classes;mining inputs;effective test generation;complex software;relevant input values;state-of-the-art techniques;generic classes;domain-specific software;information retrieval techniques;unit tests automatic generation;domain-specific sanity checks;Java classes","","","57","","","","","IEEE","IEEE Conferences"
"Synthesizing fault-tolerant programs from deontic logic specifications","R. Demasi","Department of Computing and Software, McMaster University, Hamilton, Ontario, Canada, L8S 4K1","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","750","753","We study the problem of synthesizing fault-tolerant components from specifications, i.e., the problem of automatically constructing a fault-tolerant component implementation from a logical specification of the component, and the system's required level of fault-tolerance. In our approach, the logical specification of the component is given in dCTL, a branching time temporal logic with deontic operators, especially designed for fault-tolerant component specification. The synthesis algorithm takes the component specification, and a user-defined level of fault-tolerance (masking, nonmasking, failsafe), and automatically determines whether a component with the required fault-tolerance is realizable. Moreover, if the answer is positive, then the algorithm produces such a fault-tolerant implementation. Our technique for synthesis is based on the use of (bi)simulation algorithms for capturing different fault-tolerance classes, and the extension of a synthesis algorithm for CTL to cope with dCTL specifications.","","","10.1109/ASE.2013.6693149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693149","Formal specification;Fault-tolerance;Program Synthesis;Temporal Logics;Deontic logics;Correctness by construction","Fault tolerant systems;Fault tolerance;Model checking;Algorithm design and analysis;Cognition;Safety;Writing","formal specification;software fault tolerance;temporal logic","deontic logic specifications;fault-tolerant program synthesis;logical specification;fault-tolerance required level;branching time temporal logic;deontic operators;fault-tolerant component specification;synthesis algorithm;bisimulation algorithm;dCTL specifications","","","16","","","","","IEEE","IEEE Conferences"
"Can automated pull requests encourage software developers to upgrade out-of-date dependencies?","S. Mirhosseini; C. Parnin","North Carolina State University, Raleigh, NC, USA; North Carolina State University, Raleigh, NC, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","84","94","Developers neglect to update legacy software dependencies, resulting in buggy and insecure software. One explanation for this neglect is the difficulty of constantly checking for the availability of new software updates, verifying their safety, and addressing any migration efforts needed when upgrading a dependency. Emerging tools attempt to address this problem by introducing automated pull requests and project badges to inform the developer of stale dependencies. To understand whether these tools actually help developers, we analyzed 7,470 GitHub projects that used these notification mechanisms to identify any change in upgrade behavior. Our results find that, on average, projects that use pull request notifications upgraded 1.6× as often as projects that did not use any tools. Badge notifications were slightly less effective: users upgraded 1.4× more frequently. Unfortunately, although pull request notifications are useful, developers are often overwhelmed by notifications: only a third of pull requests were actually merged. Through a survey, 62 developers indicated that their most significant concerns are breaking changes, understanding the implications of changes, and migration effort. The implications of our work suggests ways in which notifications can be improved to better align with developers' expectations and the need for new mechanisms to reduce notification fatigue and improve confidence in automated pull requests.","","","10.1109/ASE.2017.8115621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115621","","Tools;Software;Libraries;Security;Google;Safety","project management;software engineering;software maintenance","automated pull requests;software developers;out-of-date dependencies;developers neglect;legacy software dependencies;insecure software;software updates;migration effort;project badges;stale dependencies;notification mechanisms;upgrade behavior;notification fatigue","","8","33","","","","","IEEE","IEEE Conferences"
"Repairing Programs with Semantic Code Search (T)","Y. Ke; K. T. Stolee; C. L. Goues; Y. Brun","NA; NA; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","295","306","Automated program repair can potentially reduce debugging costs and improve software quality but recent studies have drawn attention to shortcomings in the quality of automatically generated repairs. We propose a new kind of repair that uses the large body of existing open-source code to find potential fixes. The key challenges lie in efficiently finding code semantically similar (but not identical) to defective code and then appropriately integrating that code into a buggy program. We present SearchRepair, a repair technique that addresses these challenges by(1) encoding a large database of human-written code fragments as SMT constraints on input-output behavior, (2) localizing a given defect to likely buggy program fragments and deriving the desired input-output behavior for code to replace those fragments, (3) using state-of-the-art constraint solvers to search the database for fragments that satisfy that desired behavior and replacing the likely buggy code with these potential patches, and (4) validating that the patches repair the bug against program testsuites. We find that SearchRepair repairs 150 (19%) of 778 benchmark C defects written by novice students, 20 of which are not repaired by GenProg, TrpAutoRepair, and AE. We compare the quality of the patches generated by the four techniques by measuring how many independent, not-used-during-repairtests they pass, and find that SearchRepair-repaired programs pass 97.3% ofthe tests, on average, whereas GenProg-, TrpAutoRepair-, and AE-repaired programs pass 68.7%, 72.1%, and 64.2% of the tests, respectively. We concludethat SearchRepair produces higher-quality repairs than GenProg, TrpAutoRepair, and AE, and repairs some defects those tools cannot.","","","10.1109/ASE.2015.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372019","automated repair;SearchRepair;semantic code search;repair quality;debugging;fault localization","Maintenance engineering;Semantics;Software;Benchmark testing;Computer bugs;Indexing","program debugging;program diagnostics;software quality","program repair;semantic code search;software quality;SearchRepair technique;human-written code fragments;SMT constraints;buggy code;C defects;GenProg-repaired program;TrpAutoRepair-repaired program;AE-repaired programs","","52","77","","","","","IEEE","IEEE Conferences"
"Cost-Efficient Sampling for Performance Prediction of Configurable Systems (T)","A. Sarkar; J. Guo; N. Siegmund; S. Apel; K. Czarnecki","Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Waterloo, Waterloo, ON, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","342","352","A key challenge of the development and maintenanceof configurable systems is to predict the performance ofindividual system variants based on the features selected. It isusually infeasible to measure the performance of all possible variants, due to feature combinatorics. Previous approaches predictperformance based on small samples of measured variants, butit is still open how to dynamically determine an ideal samplethat balances prediction accuracy and measurement effort. Inthis paper, we adapt two widely-used sampling strategies forperformance prediction to the domain of configurable systemsand evaluate them in terms of sampling cost, which considersprediction accuracy and measurement effort simultaneously. Togenerate an initial sample, we introduce a new heuristic based onfeature frequencies and compare it to a traditional method basedon t-way feature coverage. We conduct experiments on six realworldsystems and provide guidelines for stakeholders to predictperformance by sampling.","","","10.1109/ASE.2015.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372023","performance prediction;sampling;configurable systems","Predictive models;Training;Testing;Measurement;Buildings;Mathematical model;Electronic mail","sampling methods;software maintenance;software performance evaluation","feature combinatorics;performance prediction accuracy;sampling strategies;configurable system development;configurable system maintenance;sampling cost;measurement effort;feature frequencies","","35","21","","","","","IEEE","IEEE Conferences"
"Understanding feature requests by leveraging fuzzy method and linguistic analysis","L. Shi; C. Chen; Q. Wang; S. Li; B. Boehm","Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Center for Systems and Software Engineering, University of Southern California, Los Angeles, USA; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Center for Systems and Software Engineering, University of Southern California, Los Angeles, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","440","450","In open software development environment, a large number of feature requests with mixed quality are often posted by stakeholders and usually managed in issue tracking systems. Thoroughly understanding and analyzing the real intents that feature requests imply is a labor-intensive and challenging task. In this paper, we introduce an approach to understand feature requests automatically. We generate a set of fuzzy rules based on natural language processing techniques that classify each sentence in feature requests into a set of categories: Intent, Explanation, Benefit, Drawback, Example and Trivia. Consequently, the feature requests can be automatically structured based on the classification results. We conduct experiments on 2,112 sentences taken from 602 feature requests of nine popular open source projects. The results show that our method can reach a high performance on classifying sentences from feature requests. Moreover, when applying fuzzy rules on machine learning methods, the performance can be improved significantly.","","","10.1109/ASE.2017.8115656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115656","","Pragmatics;Software;Terminology;Semantics;Syntactics;Natural language processing;Learning systems","classification;fuzzy set theory;knowledge based systems;learning (artificial intelligence);natural language processing;public domain software;software quality","understanding feature requests;machine learning methods;open source projects;trivia category;example category;drawback category;benefit category;explanation category;intent category;sentence classification;natural language processing techniques;fuzzy rules;open software development environment;linguistic analysis;fuzzy method","","2","45","","","","","IEEE","IEEE Conferences"
"Software performance self-adaptation through efficient model predictive control","E. Incerto; M. Tribastone; C. Trubiani","Gran Sasso Science Institute, Viale Francesco Crispi, 7, L'Aquila, Italy; IMT School for Advanced Studies, Piazza San Francesco, 19 Lucca, Italy; Gran Sasso Science Institute, Viale Francesco Crispi, 7, L'Aquila, Italy","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","485","496","A key challenge in software systems that are exposed to runtime variabilities, such as workload fluctuations and service degradation, is to continuously meet performance requirements. In this paper we present an approach that allows performance self-adaptation using a system model based on queuing networks (QNs), a well-assessed formalism for software performance engineering. Software engineers can select the adaptation knobs of a QN (routing probabilities, service rates, and concurrency level) and we automatically derive a Model Predictive Control (MPC) formulation suitable to continuously configure the selected knobs and track the desired performance requirements. Previous MPC approaches have two main limitations: i) high computational cost of the optimization, due to nonlinearity of the models; ii) focus on long-run performance metrics only, due to the lack of tractable representations of the QN's time-course evolution. As a consequence, these limitations allow adaptations with coarse time granularities, neglecting the system's transient behavior. Our MPC adaptation strategy is efficient since it is based on mixed integer programming, which uses a compact representation of a QN with ordinary differential equations. An extensive evaluation on an implementation of a load balancer demonstrates the effectiveness of the adaptation and compares it with traditional methods based on probabilistic model checking.","","","10.1109/ASE.2017.8115660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115660","Adaptive software;Control-theory;Model predictive control;Performance requirements","Adaptation models;Optimization;Runtime;Quality of service;Concurrent computing;Computational modeling;Throughput","differential equations;integer programming;predictive control;probability;queueing theory;resource allocation;software performance evaluation","model predictive control;mixed integer programming;ordinary differential equations;probabilistic model checking;MPC adaptation strategy;concurrency level;service rates;routing probabilities;adaptation knobs;software performance engineering;queuing networks;system model;service degradation;workload fluctuations;runtime variabilities;software systems;software performance self-adaptation","","1","66","","","","","IEEE","IEEE Conferences"
"From comparison matrix to Variability Model: The Wikipedia case study","N. Sannier; M. Acher; B. Baudry","University of Rennes 1, Irisa/Inria, Campus Universitaire de Beaulieu, 35042 cedex, France; University of Rennes 1, Irisa/Inria, Campus Universitaire de Beaulieu, 35042 cedex, France; University of Rennes 1, Irisa/Inria, Campus Universitaire de Beaulieu, 35042 cedex, France","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","580","585","Product comparison matrices (PCMs) provide a convenient way to document the discriminant features of a family of related products and now abound on the internet. Despite their apparent simplicity, the information present in existing PCMs can be very heterogeneous, partial, ambiguous, hard to exploit by users who desire to choose an appropriate product. Variability Models (VMs) can be employed to formulate in a more precise way the semantics of PCMs and enable automated reasoning such as assisted configuration. Yet, the gap between PCMs and VMs should be precisely understood and automated techniques should support the transition between the two. In this paper, we propose variability patterns that describe PCMs content and conduct an empirical analysis of 300+ PCMs mined from Wikipedia. Our findings are a first step toward better engineering techniques for maintaining and configuring PCMs.","","","10.1109/ASE.2013.6693116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693116","","Phase change materials;Internet;Encyclopedias;Electronic publishing;Electronic mail;Color","Internet;matrix algebra;Web sites","variability model;Wikipedia;product comparison matrices;discriminant feature documentation;Internet;automated reasoning;assisted configuration;variability patterns;PCM mining","","6","21","","","","","IEEE","IEEE Conferences"
"SBFR: A search based approach for reproducing failures of programs with grammar based input","F. M. Kifetew; W. Jin; R. Tiella; A. Orso; P. Tonella","Fondazione Bruno Kessler, Trento, Italy; Georgia Institute of Technology, USA; Fondazione Bruno Kessler, Trento, Italy; Georgia Institute of Technology, USA; Fondazione Bruno Kessler, Trento, Italy","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","604","609","Reproducing field failures in-house, a step developers must perform when assigned a bug report, is an arduous task. In most cases, developers must be able to reproduce a reported failure using only a stack trace and/or some informal description of the failure. The problem becomes even harder for the large class of programs whose input is highly structured and strictly specified by a grammar. To address this problem, we present SBFR, a search-based failure-reproduction technique for programs with structured input. SBFR formulates failure reproduction as a search problem. Starting from a reported failure and a limited amount of dynamic information about the failure, SBFR exploits the potential of genetic programming to iteratively find legal inputs that can trigger the failure.","","","10.1109/ASE.2013.6693120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693120","","Production;Grammar;Sociology;Statistics;Trajectory;Genetic algorithms;Search problems","dynamic programming;genetic algorithms;grammars;search problems;system recovery","SBFR;search based approach;program failures;grammar based input;field failures;bug report;informal description;search based failure reproduction technique;search problem;dynamic information;genetic programming","","4","32","","","","","IEEE","IEEE Conferences"
"Quantification of Software Changes through Probabilistic Symbolic Execution (N)","A. Filieri; C. S. Pasareanu; G. Yang","Univ. of Stuttgart, Stuttgart, Germany; Carnegie Mellon Silicon Valley, NASA Ames, Moffet Field, CA, USA; Texas State Univ., San Marcos, TX, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","703","708","Characterizing software changes is fundamental for software maintenance. However existing techniques are imprecise leading to unnecessary maintenance efforts. We introduce a novel approach that computes a precise numeric characterization of program changes, which quantifies the likelihood of reaching target program events (e.g., assert violations or successful termination) and how that evolves with each program update, together with the percentage of inputs impacted by the change. This precise characterization leads to a natural ranking of different program changes based on their probability of execution and their impact on target events. The approach is based on model counting over the constraints collected with a symbolic execution of the program, and exploits the similarity between program versions to reduce cost and improve the quality of analysis results. We implemented our approach in the Symbolic PathFinder tool and illustrate it on several Java case studies, including the evaluation of different program repairs, mutants used in testing, or incremental analysis after a change.","","","10.1109/ASE.2015.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372058","","Probabilistic logic;Maintenance engineering;Software;Java;IP networks;Probability;Computational modeling","Java;probability;program testing;software maintenance","software change quantification;probabilistic symbolic execution;software maintenance;program update;Symbolic PathFinder tool;Java;program repairs;program testing","","6","23","","","","","IEEE","IEEE Conferences"
"How Verified is My Code? Falsification-Driven Verification (T)","A. Groce; I. Ahmed; C. Jensen; P. E. McKenney","Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR, USA; Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR, USA; Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR, USA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","737","748","Formal verification has advanced to the point that developers can verify the correctness of small, critical modules. Unfortunately, despite considerable efforts, determining if a ""verification"" verifies what the author intends is still difficult. Previous approaches are difficult to understand and often limited in applicability. Developers need verification coverage in terms of the software they are verifying, not model checking diagnostics. We propose a methodology to allow developers to determine (and correct) what it is that they have verified, and tools to support that methodology. Our basic approach is based on a novel variation of mutation analysis and the idea of verification driven by falsification. We use the CBMC model checker to show that this approach is applicable not only to simple data structures and sorting routines, and verification of a routine in Mozilla's JavaScript engine, but to understanding an ongoing effort to verify the Linux kernel Read-Copy-Update (RCU) mechanism.","","","10.1109/ASE.2015.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372062","model checking;verification;mutation;oracles;falsification;test harnesses","Arrays;Model checking;Software;Sorting;Computer bugs;Software engineering","formal verification;Java;Linux","falsification-driven verification;formal verification;mutation analysis;CBMC model checker;JavaScript engine;Linux kernel read-copy-update mechanism","","7","56","","","","","IEEE","IEEE Conferences"
"Characteristic studies of loop problems for structural test generation via symbolic execution","X. Xiao; S. Li; T. Xie; N. Tillmann","North Carolina State University, Raleigh, USA; University of Illinois at Urbana-Champaign, USA; University of Illinois at Urbana-Champaign, USA; Microsoft Research, Redmond, WA, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","246","256","Dynamic Symbolic Execution (DSE) is a state-of-the-art test-generation approach that systematically explores program paths to generate high-covering tests. In DSE, the presence of loops (especially unbound loops) can cause an enormous or even infinite number of paths to be explored. There exist techniques (such as bounded iteration, heuristics, and summarization) that assist DSE in addressing loop problems. However, there exists no literature-survey or empirical work that shows the pervasiveness of loop problems or identifies challenges faced by these techniques on real-world open-source applications. To fill this gap, we provide characteristic studies to guide future research on addressing loop problems for DSE. Our proposed study methodology starts with conducting a literature-survey study to investigate how technical problems such as loop problems compromise automated software-engineering tasks such as test generation, and which existing techniques are proposed to deal with such technical problems. Then the study methodology continues with conducting an empirical study of applying the existing techniques on real-world software applications sampled based on the literature-survey results and major open-source project hostings. This empirical study investigates the pervasiveness of the technical problems and how well existing techniques can address such problems among real-world software applications. Based on such study methodology, our two-phase characteristic studies identify that bounded iteration and heuristics are effective in addressing loop problems when used properly. Our studies further identify challenges faced by these techniques and provide guidelines for effectively addressing these challenges.","","","10.1109/ASE.2013.6693084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693084","","Security;Open source software;Software testing;Search problems;Debugging","program testing","characteristic studies;loop problems;structural test generation;dynamic symbolic execution;DSE;unbound loops;infinite number;real world open source applications;software applications;open source project hostings;real-world software applications;software testing","","21","54","","","","","IEEE","IEEE Conferences"
"Test suite parallelization in open-source projects: A study on its usage and impact","J. Candido; L. Melo; M. d'Amorim","Federal University of Pernambuco, Pernambuco, Brazil; Federal University of Pernambuco, Pernambuco, Brazil; Federal University of Pernambuco, Pernambuco, Brazil","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","838","848","Dealing with high testing costs remains an important problem in Software Engineering. Test suite parallelization is an important approach to address this problem. This paper reports our findings on the usage and impact of test suite parallelization in open-source projects. It provides recommendations to practitioners and tool developers to speed up test execution. Considering a set of 468 popular Java projects we analyzed, we found that 24% of the projects contain costly test suites but parallelization features still seem underutilized in practice - only 19.1% of costly projects use parallelization. The main reported reason for adoption resistance was the concern to deal with concurrency issues. Results suggest that, on average, developers prefer high predictability than high performance in running tests.","","","10.1109/ASE.2017.8115695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115695","","Testing;Parallel processing;Java;Open source software;Resistance;Electrical resistance measurement;Instruction sets","concurrency (computers);Java;parallel processing;program testing;software engineering","test suite parallelization;open-source projects;test execution;parallelization features;Java projects;testing costs;adoption resistance","","1","42","","","","","IEEE","IEEE Conferences"
"The impact of continuous integration on other software development practices: A large-scale empirical study","Y. Zhao; A. Serebrenik; Y. Zhou; V. Filkov; B. Vasilescu","Nanjing University, China; Eindhoven U of Technology, The Netherlands; Nanjing Universit, China; UC Davis, USA; Carnegie Mellon University, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","60","71","Continuous Integration (CI) has become a disruptive innovation in software development: with proper tool support and adoption, positive effects have been demonstrated for pull request throughput and scaling up of project sizes. As any other innovation, adopting CI implies adapting existing practices in order to take full advantage of its potential, and ""best practices"" to that end have been proposed. Here we study the adaptation and evolution of code writing and submission, issue and pull request closing, and testing practices as TRAVIS CI is adopted by hundreds of established projects on GITHUB. To help essentialize the quantitative results, we also survey a sample of GITHUB developers about their experiences with adopting TRAVIS CI. Our findings suggest a more nuanced picture of how GITHUB teams are adapting to, and benefiting from, continuous integration technology than suggested by prior work.","","","10.1109/ASE.2017.8115619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115619","","Testing;Tools;Open source software;Best practices;Automation","program testing;project management;public domain software;software engineering","project sizes;GITHUB;pull request throughput;software development;continuous integration technology;TRAVIS CI","","14","56","","","","","IEEE","IEEE Conferences"
"SentiCR: A customized sentiment analysis tool for code review interactions","T. Ahmed; A. Bosu; A. Iqbal; S. Rahimi","Department of Computer Science & Engineering, Bangladesh University of Engineering and Technology, Dhaka, Bangladeshi; Department of Computer Science, Southern Illinois University Carbondale, IL, USA; Department of Computer Science & Engineering, Bangladesh University of Engineering and Technology, Dhaka, Bangladeshi; Department of Computer Science, Southern Illinois University Carbondale, IL, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","106","111","Sentiment Analysis tools, developed for analyzing social media text or product reviews, work poorly on a Software Engineering (SE) dataset. Since prior studies have found developers expressing sentiments during various SE activities, there is a need for a customized sentiment analysis tool for the SE domain. On this goal, we manually labeled 2000 review comments to build a training dataset and used our dataset to evaluate seven popular sentiment analysis tools. The poor performances of the existing sentiment analysis tools motivated us to build SentiCR, a sentiment analysis tool especially designed for code review comments. We evaluated SentiCR using one hundred 10-fold cross-validations of eight supervised learning algorithms. We found a model, trained using the Gradient Boosting Tree (GBT) algorithm, providing the highest mean accuracy (83%), the highest mean precision (67.8%), and the highest mean recall (58.4%) in identifying negative review comments.","","","10.1109/ASE.2017.8115623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115623","","Tools;Sentiment analysis;Supervised learning;Training;Algorithm design and analysis;Dictionaries;Social network services","learning (artificial intelligence);natural language processing;pattern classification;social networking (online);text analysis;trees (mathematics)","software engineering dataset;gradient boosting tree algorithm;GBT algorithm;SentiCR;negative review comments;code review comments;SE domain;SE activities;social media text;code review interactions;customized sentiment analysis tool","","8","48","","","","","IEEE","IEEE Conferences"
"Performance Prediction of Configurable Software Systems by Fourier Learning (T)","Y. Zhang; J. Guo; E. Blais; K. Czarnecki","Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Waterloo, Waterloo, ON, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","365","373","Understanding how performance varies across a large number of variants of a configurable software system is important for helping stakeholders to choose a desirable variant. Given a software system with n optional features, measuring all its 2n possible configurations to determine their performances is usually infeasible. Thus, various techniques have been proposed to predict software performances based on a small sample of measured configurations. We propose a novel algorithm based on Fourier transform that is able to make predictions of any configurable software system with theoretical guarantees of accuracy and confidence level specified by the user, while using minimum number of samples up to a constant factor. Empirical results on the case studies constructed from real-world configurable systems demonstrate the effectiveness of our algorithm.","","","10.1109/ASE.2015.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372025","","Software systems;Prediction algorithms;Boolean functions;Software algorithms;Fourier transforms;Estimation;Algorithm design and analysis","configuration management;Fourier transforms;learning (artificial intelligence);software performance evaluation","performance prediction;configurable software system;Fourier learning;optional feature;possible configuration;software performance;Fourier transform;confidence level","","18","20","","","","","IEEE","IEEE Conferences"
"Gremlin-ATL: A scalable model transformation framework","G. Daniel; F. Jouault; G. Sunyé; J. Cabot","AtlanMod Team, Inria, IMT Atlantique, LS2N, Nantes, France; TRAME Team, Groupe ESEO, Angers, France; AtlanMod Team, Inria, IMT Atlantique, LS2N, Nantes, France; ICREA, UOC, Barcelona, Spain","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","462","472","Industrial use of Model Driven Engineering techniques has emphasized the need for efficiently store, access, and transform very large models. While scalable persistence frameworks, typically based on some kind of NoSQL database, have been proposed to solve the model storage issue, the same level of performance improvement has not been achieved for the model transformation problem. Existing model transformation tools (such as the well-known ATL) often require the input models to be loaded in memory prior to the start of the transformation and are not optimized to benefit from lazy-loading mechanisms, mainly due to their dependency on current low-level APIs offered by the most popular modeling frameworks nowadays. In this paper we present Gremlin-ATL, a scalable and efficient model-to-model transformation framework that translates ATL transformations into Gremlin, a query language supported by several NoSQL databases. With Gremlin-ATL, the transformation is computed within the database itself, bypassing the modeling framework limitations and improving its performance both in terms of execution time and memory consumption. Tool support is available online.","","","10.1109/ASE.2017.8115658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115658","ATL;Gremlin;OCL Scalability;Persistence Framework;model transformation;NoSQL","Unified modeling language;Databases;Load modeling;Computational modeling;Transforms;Tools;Database languages","application program interfaces;NoSQL databases;object-oriented programming;query languages;query processing;software engineering;storage management","low-level API;execution time;memory consumption;query language;ATL transformations;model-to-model transformation framework;input models;model transformation tools;model storage issue;NoSQL database;scalable persistence frameworks;Model Driven Engineering techniques;scalable model transformation framework;Gremlin-ATL","","","33","","","","","IEEE","IEEE Conferences"
"A comprehensive study of real-world numerical bug characteristics","A. Di Franco; H. Guo; C. Rubio-González","Department of Computer Science, University of California, Davis, USA; Department of Computer Science, University of California, Davis, USA; Department of Computer Science, University of California, Davis, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","509","519","Numerical software is used in a wide variety of applications including safety-critical systems, which have stringent correctness requirements, and whose failures have catastrophic consequences that endanger human life. Numerical bugs are known to be particularly difficult to diagnose and fix, largely due to the use of approximate representations of numbers such as floating point. Understanding the characteristics of numerical bugs is the first step to combat them more effectively. In this paper, we present the first comprehensive study of real-world numerical bugs. Specifically, we identify and carefully examine 269 numerical bugs from five widely-used numerical software libraries: NumPy, SciPy, LAPACK, GNU Scientific Library, and Elemental. We propose a categorization of numerical bugs, and discuss their frequency, symptoms and fixes. Our study opens new directions in the areas of program analysis, testing, and automated program repair of numerical software, and provides a collection of real-world numerical bugs.","","","10.1109/ASE.2017.8115662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115662","","Computer bugs;Libraries;Software;Tools;Semantics;Roundoff errors;Maintenance engineering","program debugging;program diagnostics;program testing;public domain software;safety-critical software;software libraries;software maintenance","numerical software libraries;safety-critical systems;numerical bug characteristics;NumPy;SciPy;LAPACK;GNU Scientific Library;Elemental;program analysis;program testing;automated program repair","","3","45","","","","","IEEE","IEEE Conferences"
"Environment rematching: Toward dependability improvement for self-adaptive applications","C. Xu; Wenhua Yang; X. Ma; C. Cao; J. Lü","State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, China","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","592","597","Self-adaptive applications can easily contain faults. Existing approaches detect faults, but can still leave some undetected and manifesting into failures at runtime. In this paper, we study the correlation between occurrences of application failure and those of consistency failure. We propose fixing consistency failure to reduce application failure at runtime. We name this environment rematching, which can systematically reconnect a self-adaptive application to its environment in a consistent way. We also propose enforcing atomicity for application semantics during the rematching to avoid its side effect. We evaluated our approach using 12 self-adaptive robot-car applications by both simulated and real experiments. The experimental results confirmed our approach's effectiveness in improving dependability for all applications by 12.5-52.5%.","","","10.1109/ASE.2013.6693118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693118","Consistency failure;environment rematching","Noise measurement;Semantics;Correlation;Legged locomotion;Robot sensing systems","automobiles;mobile robots;self-adjusting systems","environment rematching;dependability improvement;consistency failure;application failure;application semantics;self-adaptive robot-car applications","","1","25","","","","","IEEE","IEEE Conferences"
"Randomizing regression tests using game theory","N. Kukreja; W. G. J. Halfond; M. Tambe","University of Southern California, Los Angeles, USA; University of Southern California, Los Angeles, USA; University of Southern California, Los Angeles, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","616","621","As software evolves, the number of test-cases in the regression test suites continues to increase, requiring testers to prioritize their execution. Usually only a subset of the test cases is executed due to limited testing resources. This subset is often known to the developers who may try to “game” the system by committing insufficiently tested code for parts of the software that will not be tested. In this new ideas paper, we propose a novel approach for randomizing regression test scheduling, based on Stackelberg games for deployment of scarce resources. We apply this approach to randomizing test cases in such a way as to maximize the testers' expected payoff when executing the test cases. Our approach accounts for resource limitations (e.g., number of testers) and provides a probabilistic distribution for scheduling test cases. We provide an example application of our approach showcasing the idea of using Stackelberg games for randomized regression test scheduling.","","","10.1109/ASE.2013.6693122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693122","","Games;Testing;Security;Equations;Vectors;Game theory;Schedules","game theory;processor scheduling;program testing;regression analysis;statistical distributions","randomizing regression tests;game theory;software evolution;regression test suites;randomizing regression test scheduling;Stackelberg games;probabilistic distribution;scheduling test cases;randomized regression test scheduling","","5","20","","","","","IEEE","IEEE Conferences"
"""What Parts of Your Apps are Loved by Users?"" (T)","X. Gu; S. Kim","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","760","770","Recently, Begel et al. found that one of the most important questions software developers ask is ""what parts of software are used/loved by users."" User reviews provide an effective channel to address this question. However, most existing review summarization tools treat reviews as bags-of-words (i.e., mixed review categories) and are limited to extract software aspects and user preferences. We present a novel review summarization framework, SUR-Miner. Instead of a bags-of-words assumption, it classifies reviews into five categories and extracts aspects for sentences which include aspect evaluation using a pattern-based parser. Then, SUR-Miner visualizes the summaries using two interactive diagrams. Our evaluation on seventeen popular apps shows that SUR-Miner summarizes more accurate and clearer aspects than state-of-the-art techniques, with an F1-score of 0.81, significantly greater than that of ReviewSpotlight (0.56) and Guzmans' method (0.55). Feedback from developers shows that 88% developers agreed with the usefulness of the summaries from SUR-Miner.","","","10.1109/ASE.2015.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372064","Review Summarization;User Feedback;Sentiment Analysis;Data Mining","Feature extraction;Software;Semantics;Market research;Data mining;Visualization;Software engineering","data mining;diagrams;feature extraction;grammars;pattern classification;software engineering;software reviews","software development;review summarization tool;bags-of-words;software aspect extraction;user preference;SUR-Miner;review classification;pattern-based parser;interactive diagram","","35","38","","","","","IEEE","IEEE Conferences"
"Detecting bad smells in source code using change history information","F. Palomba; G. Bavota; M. Di Penta; R. Oliveto; A. De Lucia; D. Poshyvanyk","University of Salerno, Fisciano, Italy; University of Sannio, Benevento, Italy; University of Sannio, Benevento, Italy; University of Molise, Pesche (IS), Italy; University of Salerno, Fisciano, Italy; The College of William and Mary, Williamsburg, VA, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","268","278","Code smells represent symptoms of poor implementation choices. Previous studies found that these smells make source code more difficult to maintain, possibly also increasing its fault-proneness. There are several approaches that identify smells based on code analysis techniques. However, we observe that many code smells are intrinsically characterized by how code elements change over time. Thus, relying solely on structural information may not be sufficient to detect all the smells accurately. We propose an approach to detect five different code smells, namely Divergent Change, Shotgun Surgery, Parallel Inheritance, Blob, and Feature Envy, by exploiting change history information mined from versioning systems. We applied approach, coined as HIST (Historical Information for Smell deTection), to eight software projects written in Java, and wherever possible compared with existing state-of-the-art smell detectors based on source code analysis. The results indicate that HIST's precision ranges between 61% and 80%, and its recall ranges between 61% and 100%. More importantly, the results confirm that HIST is able to identify code smells that cannot be identified through approaches solely based on code analysis.","","","10.1109/ASE.2013.6693086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693086","Code Smells;Change History Information","History;Feature extraction;Surgery;Association rules;Detectors;Measurement","fault tolerant computing;software maintenance;software management;source code (software)","bad smells detection;change history information;code smells;fault proneness;code elements;structural information;divergent change;shotgun surgery;parallel inheritance;blob;feature envy;versioning systems;HIST;Historical Information for Smell deTection;software projects;Java;smell detectors;source code analysis","","83","31","","","","","IEEE","IEEE Conferences"
"A scalable approach for malware detection through bounded feature space behavior modeling","M. Chandramohan; H. B. K. Tan; L. C. Briand; L. K. Shar; B. M. Padmanabhuni","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","312","322","In recent years, malware (malicious software) has greatly evolved and has become very sophisticated. The evolution of malware makes it difficult to detect using traditional signature-based malware detectors. Thus, researchers have proposed various behavior-based malware detection techniques to mitigate this problem. However, there are still serious shortcomings, related to scalability and computational complexity, in existing malware behavior modeling techniques. This raises questions about the practical applicability of these techniques. This paper proposes and evaluates a bounded feature space behavior modeling (BOFM) framework for scalable malware detection. BOFM models the interactions between software (which can be malware or benign) and security-critical OS resources in a scalable manner. Information collected at run-time according to this model is then used by machine learning algorithms to learn how to accurately classify software as malware or benign. One of the key problems with simple malware behavior modeling (e.g., n-gram model) is that the number of malware features (i.e., signatures) grows proportional to the size of execution traces, with a resulting malware feature space that is so large that it makes the detection process very challenging. On the other hand, in BOFM, the malware feature space is bounded by an upper limit N, a constant, and the results of our experiments show that its computation time and memory usage are vastly lower than in currently reported, malware detection techniques, while preserving or even improving their high detection accuracy.","","","10.1109/ASE.2013.6693090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693090","Malware detection;Malware behavior modeling","Malware;Feature extraction;Computational modeling;File systems;Scalability;Instruction sets","computational complexity;invasive software;learning (artificial intelligence);operating systems (computers);pattern classification","scalable malware detection techniques;bounded feature space behavior modeling;malicious software;signature-based malware detectors;behavior-based malware detection techniques;computational complexity;malware behavior modeling techniques;BOFM framework;security-critical OS resources;machine learning algorithms;software classification;execution trace size;malware feature space","","9","32","","","","","IEEE","IEEE Conferences"
"Automatically reducing tree-structured test inputs","S. Herfert; J. Patra; M. Pradel","Department of Computer Science, TU Darmstadt, Germany; Department of Computer Science, TU Darmstadt, Germany; Department of Computer Science, TU Darmstadt, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","861","871","Reducing the test input given to a program while preserving some property of interest is important, e.g., to localize faults or to reduce test suites. The well-known delta debugging algorithm and its derivatives automate this task by repeatedly reducing a given input. Unfortunately, these approaches are limited to blindly removing parts of the input and cannot reduce the input by restructuring it. This paper presents the Generalized Tree Reduction (GTR) algorithm, an effective and efficient technique to reduce arbitrary test inputs that can be represented as a tree, such as program code, PDF files, and XML documents. The algorithm combines tree transformations with delta debugging and a greedy backtracking algorithm. To reduce the size of the considered search space, the approach automatically specializes the tree transformations applied by the algorithm based on examples of input trees. We evaluate GTR by reducing Python files that cause interpreter crashes, JavaScript files that cause browser inconsistencies, PDF documents with malicious content, and XML files used to tests an XML validator. The GTR algorithm reduces the trees of these files to 45.3%, 3.6%, 44.2%, and 1.3% of the original size, respectively, outperforming both delta debugging and another state-of-the-art algorithm.","","","10.1109/ASE.2017.8115697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115697","","Debugging;Computer bugs;XML;Portable document format;Syntactics","greedy algorithms;Internet;online front-ends;program debugging;program testing;tree data structures;XML","delta debugging algorithm;generalized tree reduction algorithm;XML validator;tree-structured test inputs;GTR algorithm;XML files;JavaScript files;Python files;greedy backtracking algorithm;tree transformations;XML documents;PDF files;program code;arbitrary test inputs","","4","46","","","","","IEEE","IEEE Conferences"
"Improving software text retrieval using conceptual knowledge in source code","Z. Lin; Y. Zou; J. Zhao; B. Xie","Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China, 100871; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China, 100871; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China, 100871; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China, 100871","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","123","134","A large software project usually has lots of various textual learning resources about its API, such as tutorials, mailing lists, user forums, etc. Text retrieval technology allows developers to search these API learning resources for related documents using free-text queries, but it suffers from the lexical gap between search queries and documents. In this paper, we propose a novel approach for improving the retrieval of API learning resources through leveraging software-specific conceptual knowledge in software source code. The basic idea behind this approach is that the semantic relatedness between queries and documents could be measured according to software-specific concepts involved in them, and software source code contains a large amount of software-specific conceptual knowledge. In detail, firstly we extract an API graph from software source code and use it as software-specific conceptual knowledge. Then we discover API entities involved in queries and documents, and infer semantic document relatedness through analyzing structural relationships between these API entities. We evaluate our approach in three popular open source software projects. Comparing to the state-of-the-art text retrieval approaches, our approach lead to at least 13.77% improvement with respect to mean average precision (MAP).","","","10.1109/ASE.2017.8115625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115625","Software text retrieval;conceptual knowledge;API graph;semantic relatedness","Semantics;Knowledge based systems;Software engineering;Internet;Tutorials;Open source software","application program interfaces;information retrieval;learning (artificial intelligence);public domain software;text analysis","MAP;mean average precision;semantic document relatedness;software-specific conceptual knowledge;software text retrieval;popular open source software projects;API entities;API graph;software-specific concepts;software source code;search queries;free-text queries;related documents;API learning resources;text retrieval technology;textual learning resources;software project","","3","53","","","","","IEEE","IEEE Conferences"
"Configuration-Aware Change Impact Analysis (T)","F. Angerer; A. Grimmer; H. Prähofer; P. Grünbacher","Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria; Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria; Inst. for Syst. Software, Johannes Kepler Univ. Linz, Linz, Austria; Inst. for Syst. Software, Johannes Kepler Univ. Linz, Linz, Austria","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","385","395","Understanding variability is essential to allow the configuration of software systems to diverse requirements. Variability-aware program analysis techniques have been proposed for analyzing the space of program variants. Such techniques are highly beneficial, e.g., to determine the potential impact of changes during maintenance. This paper presents an interprocedural and configuration-aware change impact analysis (CIA) approach for determining possibly impacted products when changing source code of a product family. The approach further supports engineers, who are adapting specific product variants after an initial pre-configuration. The approach can be adapted to work with different variability mechanism, it provides more precise results than existing CIA approaches, and it can be implemented using standard control flow and data flow analysis. Using an industrial product line we report evaluation results on the benefit and performance of the approach.","","","10.1109/ASE.2015.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372027","change impact analysis;program analysis;maintenance;configuration","Software systems;Testing;Mechanical factors;Maintenance engineering;Runtime;Standards","data flow analysis;source code (software)","configuration-aware change impact analysis;product family source code;product variants;variability mechanism;CIA;data flow analysis;control flow analysis;industrial product line","","15","33","","","","","IEEE","IEEE Conferences"
"Automated Test Input Generation for Android: Are We There Yet? (E)","S. R. Choudhary; A. Gorla; A. Orso","Georgia Inst. of Technol., Atlanta, GA, USA; IMDEA Software Inst., Spain; Georgia Inst. of Technol., Atlanta, GA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","429","440","Like all software, mobile applications (""apps"") must be adequately tested to gain confidence that they behave correctly. Therefore, in recent years, researchers and practitioners alike have begun to investigate ways to automate apps testing. In particular, because of Android's open source nature and its large share of the market, a great deal of research has been performed on input generation techniques for apps that run on the Android operating systems. At this point in time, there are in fact a number of such techniques in the literature, which differ in the way they generate inputs, the strategy they use to explore the behavior of the app under test, and the specific heuristics they use. To better understand the strengths and weaknesses of these existing approaches, and get general insight on ways they could be made more effective, in this paper we perform a thorough comparison of the main existing test input generation tools for Android. In our comparison, we evaluate the effectiveness of these tools, and their corresponding techniques, according to four metrics: ease of use, ability to work on multiple platforms, code coverage, and ability to detect faults. Our results provide a clear picture of the state of the art in input generation for Android apps and identify future research directions that, if suitably investigated, could lead to more effective and efficient testing tools for Android.","","","10.1109/ASE.2015.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372031","Test input generation;automated testing;Android apps","Androids;Humanoid robots;Testing;Java;Software;Systematics;Receivers","Android (operating system);graphical user interfaces;mobile computing;program testing","automated test input generation;mobile applications;automatic application testing;open source Android operating systems;ease-of-use metric;work ability metric;code coverage metric;fault detection ability metric","","119","35","","","","","IEEE","IEEE Conferences"
"Visualization support for requirements monitoring in systems of systems","L. M. Kritzinger; T. Krismayer; M. Vierhauser; R. Rabiser; P. Grünbacher","Christian Doppler Lab MEVSS, ISSE, Johannes Kepler University Linz, Austria; Christian Doppler Lab MEVSS, ISSE, Johannes Kepler University Linz, Austria; Computer Science and Engineering, University of Notre Dame, IN, USA; Christian Doppler Lab MEVSS, ISSE, Johannes Kepler University Linz, Austria; Christian Doppler Lab MEVSS, ISSE, Johannes Kepler University Linz, Austria","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","889","894","Industrial software systems are often systems of systems (SoS) whose full behavior only emerges at runtime. The systems and their interactions thus need to be continuously monitored and checked during operation to determine compliance with requirements. Many requirements monitoring approaches have been proposed. However, only few of these come with tools that present and visualize monitoring results and details on requirements violations to end users such as industrial engineers. In this tool demo paper we present visualization capabilities we have been developing motivated by industrial scenarios. Our tool complements ReMinds, an existing requirements monitoring framework, which supports collecting, aggregating, and analyzing events and event data in architecturally heterogeneous SoS. Our visualizations support a `drill-down' scenario for monitoring and diagnosis: starting from a graphical status overview of the monitored systems and their relations, engineers can view trends and statistics about performed analyses and diagnose the root cause of problems by inspecting the events and event data that led to a specific violation. Initial industry feedback we received confirms the usefulness of our tool support. Demo video: https://youtu.be/iv7kWzeNkdk..","","","10.1109/ASE.2017.8115700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115700","Requirements monitoring;visualization;systems of systems","Monitoring;Tools;Data visualization;System of systems;Runtime;Automation;Probes","data visualisation;formal specification;Internet;system monitoring","visualization support;industrial software systems;visualize monitoring results;industrial engineers;tool demo paper;visualization capabilities;industrial scenarios;tool complements ReMinds;event data;architecturally heterogeneous SoS;drill-down scenario;monitored systems;initial industry feedback","","4","19","","","","","IEEE","IEEE Conferences"
"Generating simpler AST edit scripts by considering copy-and-paste","Y. Higo; A. Ohtani; S. Kusumoto","Graduate School of Information Science and Technology, Osaka University, 1-5, Yamadaoka, Suita, Osaka, 565-0871, Japan; Graduate School of Information Science and Technology, Osaka University, 1-5, Yamadaoka, Suita, Osaka, 565-0871, Japan; Graduate School of Information Science and Technology, Osaka University, 1-5, Yamadaoka, Suita, Osaka, 565-0871, Japan","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","532","542","In software development, there are many situations in which developers need to understand given source code changes in detail. Until now, a variety of techniques have been proposed to support understanding source code changes. Tree-based differencing techniques are expected to have better understandability than text-based ones, which are widely used nowadays (e.g., diff in Unix). In this paper, we propose to consider copy-and-paste as a kind of editing action forming tree-based edit script, which is an editing sequence that transforms a tree to another one. Software developers often perform copy- and-paste when they are writing source code. Introducing copy- and-paste action into edit script contributes to not only making simpler (more easily understandable) edit scripts but also making edit scripts closer to developers' actual editing sequences. We conducted experiments on an open dataset. As a result, we confirmed that our technique made edit scripts shorter for 18% of the code changes with a little more computational time. For the other 82% code changes, our technique generated the same edit scripts as an existing technique. We also confirmed that our technique provided more helpful visualizations.","","","10.1109/ASE.2017.8115664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115664","","Cloning;Visualization;Software;Transforms;Writing;Syntactics;Computer bugs","configuration management;Java;software engineering;source code (software);text editing;tree data structures;XML","software development;editing sequence;AST edit scripts;copy-and-paste action;source code change;tree-based differencing techniques;tree-based edit script;computational time","","5","24","","","","","IEEE","IEEE Conferences"
"Adding context to fault localization with integration coverage","H. A. de Souza; M. L. Chaim","Institute of Mathematics and Statistics, University of Sao Paulo, Brazil; School of Arts, Sciences and Humanities, University of Sao Paulo, Brazil","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","628","633","Fault localization is a costly task in the debugging process. Several techniques to automate fault localization have been proposed aiming at reducing effort and time spent. Some techniques use heuristics based on code coverage data. The goal is to indicate program code excerpts more likely to contain faults. The coverage data mostly used in automated debugging is based on white-box unit testing (e.g., statements, basic blocks, predicates). This paper presents a technique which uses integration coverage data to guide the fault localization process. By ranking most suspicious pairs of method invocations, roadmaps-sorted lists of methods to be investigated-are created. At each method, unit coverage (e.g., basic blocks) is used to locate the fault site. Fifty-five bugs of four programs containing 2K to 80K lines of code (LOC) were analyzed. The results indicate that, by using the roadmaps, the effectiveness of the fault localization process is improved: 78% of all the faults are reached within a fixed amount of basic blocks; 40% more than an approach based on the Tarantula technique. Furthermore, fewer blocks have to be investigated until reaching the fault.","","","10.1109/ASE.2013.6693124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693124","Coverage-based debugging;Fault localization;Integration coverage","Debugging;Computer bugs;Libraries;Educational institutions;Statistical analysis;Context;Testing","program debugging;program testing","integration coverage;debugging process;fault localization automation;program code excerpts;white-box unit testing;fault localization process;Tarantula technique","","1","20","","","","","IEEE","IEEE Conferences"
"The ReMinds Tool Suite for Runtime Monitoring of Systems of Systems","M. Vierhauser; R. Rabiser; P. Grünbacher; J. Thanhofer-Pilisch","Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria; Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria; Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria; Christian Doppler Lab. MEVSS, Johannes Kepler Univ. Linz, Linz, Austria","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","777","782","The behavior of systems of systems (SoS) emerges only fully during operation and is hard to predict. SoS thus need to be monitored at runtime to detect deviations from important requirements. However, existing approaches for checking runtime behavior and performance characteristics are limited with respect to the kinds of checks and the types of technologies supported, which impedes their use in industrial SoS. In this tool demonstration paper we describe the ReMinds tool suite for runtime monitoring of SoS developed in response to industrial monitoring scenarios. ReMinds provides comprehensive tool support for instrumenting systems, extracting events and data at runtime, defining constraints to check expected behavior and properties, and visualizing constraint violations to facilitate diagnosis.","","","10.1109/ASE.2015.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372066","System of systems;runtime monitoring;tool support","Monitoring;Runtime;Probes;Data visualization;Java;Aggregates","program verification;software tools;system monitoring","ReMinds tool suite;systems of systems runtime monitoring;runtime behavior checking;industrial SoS;industrial monitoring scenarios","","1","33","","","","","IEEE","IEEE Conferences"
"FLYAQ: Enabling Non-expert Users to Specify and Generate Missions of Autonomous Multicopters","D. Bozhinoski; D. D. Ruscio; I. Malavolta; P. Pelliccione; M. Tivoli","Gran Sasso Sci. Inst., L'Aquila, Italy; NA; Gran Sasso Sci. Inst., L'Aquila, Italy; Dept. of Inf. Eng., Univ. of L'Aquila, L'Aquila, Italy; Dept. of Inf. Eng., Univ. of L'Aquila, L'Aquila, Italy","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","801","806","Multicopters are increasingly popular since they promise to simplify a myriad of everyday tasks. Currently, vendors provide low-level APIs and basic primitives to program multicopters, making mission development a task-specific and error-prone activity. As a consequence, current approaches are affordable only for users that have a strong technical expertise. Then, software engineering techniques are needed to support the definition, development, and realization of missions at the right level of abstraction and involving teams of autonomous multicopters that guarantee the safety today's users expect. In this paper we describe a tool that enables end-users with no technical expertise, e.g., firefighters and rescue workers, to specify missions for a team of multicopters. The detailed flight plan that each multicopter must perform to accomplish the specified mission is automatically generated by preventing collisions between multicopters and obstacles, and ensuring the preservation of no-fly zones.","","","10.1109/ASE.2015.104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372070","Multicopter;Model-Driven Engineering;Domain-specific Languages","Drones;Monitoring;Software engineering;Solar panels;Software;Safety;Earthquakes","aerospace computing;application program interfaces;control engineering computing;helicopters;software engineering","FLYAQ;nonexpert users;autonomous multicopters;low-level API;program multicopters;error-prone activity;task-specific activity;software engineering techniques;no-fly zones","","10","14","","","","","IEEE","IEEE Conferences"
"Automatic recommendation of API methods from feature requests","F. Thung; S. Wang; D. Lo; J. Lawall","Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore; Inria/Lip6 Regal, France","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","290","300","Developers often receive many feature requests. To implement these features, developers can leverage various methods from third party libraries. In this work, we propose an automated approach that takes as input a textual description of a feature request. It then recommends methods in library APIs that developers can use to implement the feature. Our recommendation approach learns from records of other changes made to software systems, and compares the textual description of the requested feature with the textual descriptions of various API methods. We have evaluated our approach on more than 500 feature requests of Axis2/Java, CXF, Hadoop Common, HBase, and Struts 2. Our experiments show that our approach is able to recommend the right methods from 10 libraries with an average recall-rate@5 of 0.690 and recall-rate@10 of 0.779 respectively. We also show that the state-of-the-art approach by Chan et al., that recommends API methods based on precise text phrases, is unable to handle feature requests.","","","10.1109/ASE.2013.6693088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693088","","Libraries;Vectors;Databases;Control systems;Documentation;Software systems;Java","application program interfaces;Java;software libraries","automatic recommendation;API methods;feature requests;textual description;library APIs;software systems;Axis2/Java;CXF;Hadoop Common;HBase;Struts 2","","28","37","","","","","IEEE","IEEE Conferences"
"Finding architectural flaws using constraints","R. Vanciu; M. Abi-Antoun","Department of Computer Science, Wayne State University, Detroit, Michigan, USA; Department of Computer Science, Wayne State University, Detroit, Michigan, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","334","344","During Architectural Risk Analysis (ARA), security architects use a runtime architecture to look for security vulnerabilities that are architectural flaws rather than coding defects. The current ARA process, however, is mostly informal and manual. In this paper, we propose Scoria, a semi-automated approach for finding architectural flaws. Scoria uses a sound, hierarchical object graph with abstract objects and dataflow edges, where edges can refer to nodes in the graph. The architects can augment the object graph with security properties, which can express security information unavailable in code. Scoria allows architects to write queries on the graph in terms of the hierarchy, reachability, and provenance of a dataflow object. Based on the query results, the architects enhance their knowledge of the system security and write expressive constraints. The expressiveness is richer than previous approaches that check only for the presence or absence of communication or do not track a dataflow as an object. To evaluate Scoria, we apply these constraints to several extended examples adapted from the CERT standard for Java to confirm that Scoria can detect injected architectural flaws. Next, we write constraints to enforce an Android security policy and find one architectural flaw in one Android application.","","","10.1109/ASE.2013.6693092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693092","","Runtime;Abstracts;Connectors;Standards;Encryption;Encoding","Android (operating system);data flow analysis;Java;reachability analysis;security of data;software architecture","architectural flaws;architectural risk analysis;security architects;runtime architecture;security vulnerability;coding defects;ARA process;Scoria;semiautomated approach;object graph;dataflow edges;security property;security information;reachability;dataflow object;system security;CERT standard;Java;Android security policy","","3","47","","","","","IEEE","IEEE Conferences"
"SEALANT: A detection and visualization tool for inter-app security vulnerabilities in androic","Y. K. Lee; P. Yoodee; A. Shahbazian; D. Nam; N. Medvidovic","Computer Science Department, University of Southern California, 941 Bloom Walk, Los Angeles, California, USA 90089; Computer Science Department, University of Southern California, 941 Bloom Walk, Los Angeles, California, USA 90089; Computer Science Department, University of Southern California, 941 Bloom Walk, Los Angeles, California, USA 90089; Computer Science Department, University of Southern California, 941 Bloom Walk, Los Angeles, California, USA 90089; Computer Science Department, University of Southern California, 941 Bloom Walk, Los Angeles, California, USA 90089","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","883","888","Android's flexible communication model allows interactions among third-party apps, but it also leads to inter-app security vulnerabilities. Specifically, malicious apps can eavesdrop on interactions between other apps or exploit the functionality of those apps, which can expose a user's sensitive information to attackers. While the state-of-the-art tools have focused on detecting inter-app vulnerabilities in Android, they neither accurately analyze realistically large numbers of apps nor effectively deliver the identified issues to users. This paper presents SEALANT, a novel tool that combines static analysis and visualization techniques that, together, enable accurate identification of inter-app vulnerabilities as well as their systematic visualization. SEALANT statically analyzes architectural information of a given set of apps, infers vulnerable communication channels where inter-app attacks can be launched, and visualizes the identified information in a compositional representation. SEALANT has been demonstrated to accurately identify inter-app vulnerabilities from hundreds of real-world Android apps and to effectively deliver the identified information to users. (Demo Video: https://youtu.be/E4lLQonOdUw)","","","10.1109/ASE.2017.8115699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115699","","Sealing materials;Androids;Humanoid robots;Visualization;Tools;Analytical models;Data mining","Android (operating system);mobile computing;program diagnostics;security of data","inter-app security vulnerabilities;third-party apps;detecting inter-app vulnerabilities;static analysis;SEALANT statically analyzes architectural information;infers vulnerable communication channels;real-world Android apps;visualization tool;Android flexible communication model","","1","25","","","","","IEEE","IEEE Conferences"
"Improving missing issue-commit link recovery using positive and unlabeled data","Y. Sun; C. Chen; Q. Wang; B. Boehm","University of Chinese Academy of Sciences, Beijing, 100049, P.R. China; Department of Computer Science, Occidental College, Los Angeles, CA; University of Chinese Academy of Sciences, Beijing, 100049, P.R. China; Department of Computer Science, Occidental College, Los Angeles, CA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","147","152","Links between issue reports and corresponding fix commits are widely used in software maintenance. The quality of links directly affects maintenance costs. Currently, such links are mainly maintained by error-prone manual efforts, which may result in missing links. To tackle this problem, automatic link recovery approaches have been proposed by building traditional classifiers with positive and negative links. However, these traditional classifiers may not perform well due to the inherent characteristics of missing links. Positive links, which can be used to build link recovery model, are quite limited as the result of missing links. Since the construction of negative links depends on the number of positive links in many existing approaches, the available negative links also become restricted. In this paper, we point out that it is better to consider the missing link problem as a model learning problem by using positive and unlabeled data, rather than the construction of traditional classifier. We propose PULink, an approach that constructs the link recovery model with positive and unlabeled links. Our experiment results show that compared to existing state-of-the-art technologies built on traditional classifier, PULink can achieve competitive performance by utilizing only 70% positive links that are used in those approaches.","","","10.1109/ASE.2017.8115627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115627","","Feature extraction;Indexes;Metadata;Training;Software maintenance","learning (artificial intelligence);pattern classification;software maintenance","improving missing issue-commit link recovery;positive data;missing links;automatic link recovery approaches;traditional classifier;link recovery model;unlabeled link data","","1","11","","","","","IEEE","IEEE Conferences"
"More effective interpolations in software model checking","C. Tian; Z. Duan; Z. Duan; C. -. L. Ong","ICTT and ISN Lab, Xidian University, Xi'an 710071, P.R. China; ICTT and ISN Lab, Xidian University, Xi'an 710071, P.R. China; ICTT and ISN Lab, Xidian University, Xi'an 710071, P.R. China; Department of Computer Science, University of Oxford, UK","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","183","193","An approach to CEGAR-based model checking which has proved to be successful on large models employs Craig interpolation to efficiently construct parsimonious abstractions. Following this design, we introduce new applications, universal safety interpolant and existential error interpolant, of Craig interpolation that can systematically reduce the program state space to be explored for safety verification. Whenever the universal safety interpolant is implied by the current path, all paths emanating from that location are guaranteed to be safe. Dually whenever the existential error interpolant is implied by the current path, there is guaranteed to be an unsafe path from the location. We show how these interpolants are computed and applied in safety verification. We have implemented our approach in a tool named InterpChecker by building on an open source software model checker. Experiments on a large number of benchmark programs show that both the interpolations and the auxiliary optimization strategies are effective in improving scalability of software model checking.","","","10.1109/ASE.2017.8115631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115631","","Interpolation;Safety;Model checking;Space exploration;Subspace constraints;Software;Tools","formal verification;interpolation;program diagnostics;program verification;public domain software;theorem proving","universal safety interpolant;existential error interpolant;Craig interpolation;program state space;safety verification;unsafe path;open source software model checking;CEGAR-based model checking;InterpChecker","","","39","","","","","IEEE","IEEE Conferences"
"Scaling Size and Parameter Spaces in Variability-Aware Software Performance Models (T)","M. Kowal; M. Tschaikowski; M. Tribastone; I. Schaefer","Tech. Univ. Braunschweig, Braunschweig, Germany; IMT Inst. for Adv. Studies Lucca, Lucca, Italy; IMT Inst. for Adv. Studies Lucca, Lucca, Italy; Tech. Univ. Braunschweig, Braunschweig, Germany","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","407","417","In software performance engineering, what-if scenarios, architecture optimization, capacity planning, run-time adaptation, and uncertainty management of realistic models typically require the evaluation of many instances. Effective analysis is however hindered by two orthogonal sources of complexity. The first is the infamous problem of state space explosion -- the analysis of a single model becomes intractable with its size. The second is due to massive parameter spaces to be explored, but such that computations cannot be reused across model instances. In this paper, we efficiently analyze many queuing models with the distinctive feature of more accurately capturing variability and uncertainty of execution rates by incorporating general (i.e., non-exponential) distributions. Applying product-line engineering methods, we consider a family of models generated by a core that evolves into concrete instances by applying simple delta operations affecting both the topology and the model's parameters. State explosion is tackled by turning to a scalable approximation based on ordinary differential equations. The entire model space is analyzed in a family-based fashion, i.e., at once using an efficient symbolic solution of a super-model that subsumes every concrete instance. Extensive numerical tests show that this is orders of magnitude faster than a naive instance-by-instance analysis.","","","10.1109/ASE.2015.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372029","","Unified modeling language;Mathematical model;Analytical models;Computational modeling;Software performance;Numerical models;Uncertainty","differential equations;queueing theory;software performance evaluation;software product lines","variability-aware software performance models;software performance engineering;what-if scenarios;architecture optimization;capacity planning;run-time adaptation;uncertainty management;state space explosion;queuing models;product-line engineering methods;ordinary differential equations","","13","41","","","","","IEEE","IEEE Conferences"
"CLAMI: Defect Prediction on Unlabeled Datasets (T)","J. Nam; S. Kim","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","452","463","Defect prediction on new projects or projects with limited historical data is an interesting problem in software engineering. This is largely because it is difficult to collect defect information to label a dataset for training a prediction model. Cross-project defect prediction (CPDP) has tried to address this problem by reusing prediction models built by other projects that have enough historical data. However, CPDP does not always build a strong prediction model because of the different distributions among datasets. Approaches for defect prediction on unlabeled datasets have also tried to address the problem by adopting unsupervised learning but it has one major limitation, the necessity for manual effort. In this study, we propose novel approaches, CLA and CLAMI, that show the potential for defect prediction on unlabeled datasets in an automated manner without need for manual effort. The key idea of the CLA and CLAMI approaches is to label an unlabeled dataset by using the magnitude of metric values. In our empirical study on seven open-source projects, the CLAMI approach led to the promising prediction performances, 0.636 and 0.723 in average f-measure and AUC, that are comparable to those of defect prediction based on supervised learning.","","","10.1109/ASE.2015.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372033","","Predictive models;Measurement;Software;Training;Supervised learning;Data models;Manuals","software fault tolerance;software quality;unsupervised learning","CLAMI approach;cross-project defect prediction;software engineering;defect information collection;unsupervised learning;CLA approach;supervised learning","","39","63","","","","","IEEE","IEEE Conferences"
"TREM: A tool for mining timed regular specifications from system traces","L. Schmidt; A. Narayan; S. Fischmeister","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","901","906","Software specifications are useful for software validation, model checking, runtime verification, debugging, monitoring, etc. In context of safety-critical real-time systems, temporal properties play an important role. However, temporal properties are rarely present due to the complexity and evolutionary nature of software systems. We propose Timed Regular Expression Mining (TREM) a hosted tool for specification mining using timed regular expressions (TREs). It is designed for easy and robust mining of dominant temporal properties. TREM uses an abstract structure of the property; the framework constructs a finite state machine to serve as an acceptor. TREM is scalable, easy to access/use, and platform independent specification mining framework. The tool is tested on industrial strength software system traces such as the QNX real-time operating system using traces with more than 1.5 Million entries. The tool demonstration video can be accessed here: youtu.be/cSd_aj3_LH8.","","","10.1109/ASE.2017.8115702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115702","Specification Mining;Timed Regular Expressions;Real-time systems","Data mining;Automata;Tools;Software;Debugging;Real-time systems;Monitoring","data mining;finite state machines;formal specification;operating systems (computers);program verification;safety-critical software","model checking;runtime verification;safety-critical real-time systems;software systems;TREM;regular expressions;robust mining;dominant temporal properties;platform independent specification mining framework;industrial strength software system traces;QNX real-time operating system;tool demonstration video;software specifications;software validation;finite state machine;Timed Regular Expression Mining","","1","27","","","","","IEEE","IEEE Conferences"
"Semantics-assisted code review: An efficient tool chain and a user study","M. Menarini; Y. Yan; W. G. Griswold","Department of Computer Science and Engineering, University of California at San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of California at San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of California at San Diego, La Jolla, CA, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","554","565","Code changes are often reviewed before they are deployed. Popular source control systems aid code review by presenting textual differences between old and new versions of the code, leaving developers with the difficult task of determining whether the differences actually produced the desired behavior. Fortunately, we can mine such information from code repositories. We propose aiding code review with inter-version semantic differential analysis. During review of a new commit, a developer is presented with summaries of both code differences and behavioral differences, which are expressed as diffs of likely invariants extracted by running the system's test cases. As a result, developers can more easily determine that the code changes produced the desired effect. We created an invariant-mining tool chain, Getty, to support our concept of semantically-assisted code review. To validate our approach, 1) we applied Getty to the commits of 6 popular open source projects, 2) we assessed the performance and cost of running Getty in different configurations, and 3) we performed a comparative user study with 18 developers. Our results demonstrate that semantically-assisted code review is feasible, effective, and that real programmers can leverage it to improve the quality of their reviews.","","","10.1109/ASE.2017.8115666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115666","Software behavior;mining software repository;code review;likely invariants;dynamic impact analysis;scalability;software testing","Tools;Testing;Computer bugs;Semantics;Software;Navigation","data mining;Internet;project management;software maintenance","semantic-assisted code review;invariant-mining tool chain;code differences;inter-version semantic differential analysis;code repositories;code changes","","","38","","","","","IEEE","IEEE Conferences"
"Floating-point symbolic execution: A case study in N-version programming","D. Liew; D. Schemmel; C. Cadar; A. F. Donaldson; R. Zahl; K. Wehrle","Imperial College London, United Kingdom; RWTH Aachen University, Germany; Imperial College London, United Kingdom; Imperial College London, United Kingdom; RWTH Aachen University, Germany; RWTH Aachen University, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","601","612","Symbolic execution is a well-known program analysis technique for testing software, which makes intensive use of constraint solvers. Recent support for floating-point constraint solving has made it feasible to support floating-point reasoning in symbolic execution tools. In this paper, we present the experience of two research teams that independently added floating-point support to KLEE, a popular symbolic execution engine. Since the two teams independently developed their extensions, this created the rare opportunity to conduct a rigorous comparison between the two implementations, essentially a modern case study on N-version programming. As part of our comparison, we report on the different design and implementation decisions taken by each team, and show their impact on a rigorously assembled and tested set of benchmarks, itself a contribution of the paper.","","","10.1109/ASE.2017.8115670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115670","","Benchmark testing;Tools;Programming;Cognition;Encoding;Concrete","constraint handling;floating point arithmetic;program diagnostics;program testing;public domain software","implementation decisions;N-version programming symbolic execution;testing software;constraint solvers;floating-point constraint solving;floating-point reasoning;symbolic execution tools;program analysis technique;symbolic execution engine;floating-point symbolic execution;floating-point support;research teams","","2","82","","","","","IEEE","IEEE Conferences"
"Class level fault prediction using software clustering","G. Scanniello; C. Gravino; A. Marcus; T. Menzies","University of Basilicata, Italy; University of Salerno, Italy; Wayne State University, USA; West Virginia University, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","640","645","Defect prediction approaches use software metrics and fault data to learn which software properties associate with faults in classes. Existing techniques predict fault-prone classes in the same release (intra) or in a subsequent releases (inter) of a subject software system. We propose an intra-release fault prediction technique, which learns from clusters of related classes, rather than from the entire system. Classes are clustered using structural information and fault prediction models are built using the properties of the classes in each cluster. We present an empirical investigation on data from 29 releases of eight open source software systems from the PROMISE repository, with predictors built using multivariate linear regression. The results indicate that the prediction models built on clusters outperform those built on all the classes of the system.","","","10.1109/ASE.2013.6693126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693126","Empirical Study;Fault Prediction;Software Clustering","Predictive models;Clustering algorithms;Measurement;Accuracy;Open source software;Linear regression","pattern clustering;program debugging;public domain software;regression analysis;software fault tolerance;software metrics","class level fault prediction;software clustering;defect prediction;software properties;software metrics;fault-prone class prediction;intrarelease fault prediction technique;subject software system;open source software systems;PROMISE repository;multivariate linear regression","","21","35","","","","","IEEE","IEEE Conferences"
"Semi-automatic generation of metamodels from model sketches","D. Wüest; N. Seyff; M. Glinz","Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","664","669","Traditionally, metamodeling is an upfront activity performed by experts for defining modeling languages. Modeling tools then typically restrict modelers to using only constructs defined in the metamodel. This is inappropriate when users want to sketch graphical models without any restrictions and only later assign meanings to the sketched elements. Upfront metamodeling also complicates the creation of domain-specific languages, as it requires experts with both domain and metamodeling expertise. In this paper we present a new approach that supports modelers in creating metamodels for diagrams they have sketched or are currently sketching. Metamodels are defined in a semi-automatic, interactive way by annotating diagram elements and automated model analysis. Our approach requires no metamodeling expertise and supports the co-evolution of models and meta-models.","","","10.1109/ASE.2013.6693130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693130","Sketch;model;metamodel;inference;semiautomated;end-user","Unified modeling language;Metamodeling;DSL;Adaptation models;Libraries;Computational modeling;Context","computer graphics;SysML","model sketches;metamodels semiautomatic generation;graphical models;domain-specific languages;automated model analysis;diagram elements annotation","","8","31","","","","","IEEE","IEEE Conferences"
"SpyREST in Action: An Automated RESTful API Documentation Tool","S. M. Sohan; C. Anslow; F. Maurer","Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada; Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada; Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","813","818","RESTful APIs are often manually documented. As a result, the process of maintaining the documentation of RESTful APIs is both expensive and error-prone. In this demonstration paper, we present SpyREST as an automated software as a service tool that can be used to document RESTful APIs. SpyREST leverages an HTTP Proxy server to intercept real API calls to automatically collect and generate RESTful API documentation by processing HTTP traffic involved in API calls. SpyREST provides an automated yet customizable example based documentation solution for RESTful APIs. RESTful API developers can use SpyREST to automatically generate and maintain updated API documentation.","","","10.1109/ASE.2015.92","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372072","RESTful API;Web API;Documentation;Automation;Example based documentation","Documentation;Servers;Uniform resource locators;Payloads;Collaboration;Software as a service;Context","application program interfaces;cloud computing","SpyREST;automated RESTful API documentation tool;software as a service tool;HTTP proxy server;HTTP traffic","","3","16","","","","","IEEE","IEEE Conferences"
"Leveraging program equivalence for adaptive program repair: Models and first results","W. Weimer; Z. P. Fry; S. Forrest","Computer Science Department, University of Virginia, Charlottesville, USA; Computer Science Department, University of Virginia, Charlottesville, USA; Computer Science Department, University of New Mexico, Albuquerque, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","356","366","Software bugs remain a compelling problem. Automated program repair is a promising approach for reducing cost, and many methods have recently demonstrated positive results. However, success on any particular bug is variable, as is the cost to find a repair. This paper focuses on generate-and-validate repair methods that enumerate candidate repairs and use test cases to define correct behavior. We formalize repair cost in terms of test executions, which dominate most test-based repair algorithms. Insights from this model lead to a novel deterministic repair algorithm that computes a patch quotient space with respect to an approximate semantic equivalence relation. This allows syntactic and dataflow analysis techniques to dramatically reduce the repair search space. Generate-and-validate program repair is shown to be a dual of mutation testing, suggesting several possible cross-fertilizations. Evaluating on 105 real-world bugs in programs totaling 5MLOC and involving 10,000 tests, our new algorithm requires an order-of-magnitude fewer test evaluations than the previous state-of-the-art and is over three times more efficient monetarily.","","","10.1109/ASE.2013.6693094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693094","Automated program repair;mutation testing;program equivalence;search-based software engineering","Maintenance engineering;Approximation algorithms;Testing;Algorithm design and analysis;Adaptation models;Optimization;Search problems","cost reduction;data flow analysis;deterministic algorithms;program debugging;program testing;software maintenance","program equivalence;adaptive program repair;software bugs;automated program repair;cost reduction;generate-and-validate program repair methods;test cases;repair cost;test-based repair algorithms;deterministic repair algorithm;approximate semantic equivalence relation;patch quotient space;dataflow analysis techniques;syntactic analysis techniques;repair search space reduction;mutation testing;cross-fertilizations","","84","55","","","","","IEEE","IEEE Conferences"
"Extracting Visual Contracts from Java Programs (T)","A. Alshanqiti; R. Heckel","NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","104","114","Visual contracts model the operations of components or services by pre-and post-conditions formalised as graph transformation rules. They provide a precise intuitive notation to support testing, understanding and analysis of software. However, due to their detailed specification of data states and transformations, modelling real applications is an error-prone process. In this paper we propose a dynamic approach to reverse engineering visual contracts from Java based on tracing the execution of Java operations. The resulting contracts give an accurate description of the observed object transformations, their effects and preconditions in terms of object structures, parameter and attribute values, and their generalised specification by universally quantified (multi) objects. While this paper focusses on the fundamental technique rather than a particular application, we explore potential uses in our evaluation, including in program understanding, review of test reports and debugging.","","","10.1109/ASE.2015.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372000","graph transformation;rule learning;multi objects;extraction of visual contracts","Contracts;Unified modeling language;Visualization;Java;Context;Testing;Cities and towns","Java","Java programs;visual contracts model;graph transformation rules;software;error-prone process;reverse engineering visual contracts;Java operations;object transformations;generalised specification;universally quantified objects","","6","31","","","","","IEEE","IEEE Conferences"
"Automatic summarization of API reviews","G. Uddin; F. Khomh","School of Computer Science, McGill University, Montréal, QC, Canada; SWAT Lab Polytechnique, Montréal, QC, Canada","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","159","170","With the proliferation of online developer forums as informal documentation, developers often share their opinions about the APIs they use. However, given the plethora of opinions available for an API in various online developer forums, it can be challenging for a developer to make informed decisions about the APIs. While automatic summarization of opinions have been explored for other domains (e.g., cameras, cars), we found little research that investigates the benefits of summaries of public API reviews. In this paper, we present two algorithms (statistical and aspect-based) to summarize opinions about APIs. To investigate the usefulness of the techniques, we developed, Opiner, an online opinion summarization engine that presents summaries of opinions using both our proposed techniques and existing six off-the-shelf techniques. We investigated the usefulness of Opiner using two case studies, both involving professional software engineers. We found that developers were interested to use our proposed summaries much more frequently than other summaries (daily vs once a year) and that while combined with Stack Overflow, Opiner helped developers to make the right decision with more accuracy and confidence and in less time.","","","10.1109/ASE.2017.8115629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115629","Opinion mining;API informal documentation;opinion summaries;study;summary quality","Java;Message systems;Software;Heuristic algorithms;Cameras;Engines","application program interfaces;Internet;software engineering;text analysis","public API reviews;Opiner;online opinion summarization engine;automatic summarization;online developer forums;informal documentation;informed decisions;time 11.0 year","","6","64","","","","","IEEE","IEEE Conferences"
"Model checker execution reports","R. Castaño; V. Braberman; D. Garbervetsky; S. Uchitel","Departamento de Computación, FCEyN, UBA, CONICET, Buenos Aires, Argentina; Departamento de Computación, FCEyN, UBA, CONICET, Buenos Aires, Argentina; Departamento de Computación, FCEyN, UBA, CONICET, Buenos Aires, Argentina; Departamento de Computación, FCEyN, UBA, CONICET, Buenos Aires, Argentina","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","200","205","Software model checking constitutes an undecidable problem and, as such, even an ideal tool will in some cases fail to give a conclusive answer. In practice, software model checkers fail often and usually do not provide any information on what was effectively checked. The purpose of this work is to provide a conceptual framing to extend software model checkers in a way that allows users to access information about incomplete checks. We characterize the information that model checkers themselves can provide, in terms of analyzed traces, i.e. sequences of statements, and safe canes, and present the notion of execution reports (ERs), which we also formalize. We instantiate these concepts for a family of techniques based on Abstract Reachability Trees and implement the approach using the software model checker CPAchecker. We evaluate our approach empirically and provide examples to illustrate the ERs produced and the information that can be extracted.","","","10.1109/ASE.2017.8115633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115633","","Software;Safety;Model checking;Tools;Erbium;Computational modeling;Atmospheric modeling","formal specification;program verification;reachability analysis;trees (mathematics)","incomplete checks;model checker execution reports;software model checking;CPAchecker software model checker;abstract reachability trees","","","23","","","","","IEEE","IEEE Conferences"
"Combining Deep Learning with Information Retrieval to Localize Buggy Files for Bug Reports (N)","A. N. Lam; A. T. Nguyen; H. A. Nguyen; T. N. Nguyen","Iowa State Univ., Ames, IA, USA; Iowa State Univ., Ames, IA, USA; Iowa State Univ., Ames, IA, USA; Iowa State Univ., Ames, IA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","476","481","Bug localization refers to the automated process of locating the potential buggy files for a given bug report. To help developers focus their attention to those files is crucial. Several existing automated approaches for bug localization from a bug report face a key challenge, called lexical mismatch, in which the terms used in bug reports to describe a bug are different from the terms and code tokens used in source files. This paper presents a novel approach that uses deep neural network (DNN) in combination with rVSM, an information retrieval (IR) technique. rVSM collects the feature on the textual similarity between bug reports and source files. DNN is used to learn to relate the terms in bug reports to potentially different code tokens and terms in source files and documentation if they appear frequently enough in the pairs of reports and buggy files. Our empirical evaluation on real-world projects shows that DNN and IR complement well to each other to achieve higher bug localization accuracy than individual models. Importantly, our new model, HyLoc, with a combination of the features built from DNN, rVSM, and project's bug-fixing history, achieves higher accuracy than the state-of-the-art IR and machine learning techniques. In half of the cases, it is correct with just a single suggested file. Two out of three cases, a correct buggy file is in the list of three suggested files.","","","10.1109/ASE.2015.73","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372035","Deep Neural Network;Deep Learning;Bug Localization;Information Retrieval;Bug Reports","Feature extraction;History;Metadata;Computer bugs;Software;Bridges;Information retrieval","information retrieval;learning (artificial intelligence);program debugging;support vector machines","deep learning;buggy file localization;bug reports;lexical mismatch;source files;deep neural network;DNN;rVSM;information retrieval technique;IR technique;code tokens;HyLoc;projec bug-fixing history;machine learning techniques","","32","10","","","","","IEEE","IEEE Conferences"
"Incrementally slicing editable submodels","C. Pietsch; M. Ohrndorf; U. Kelter; T. Kehrer","Software Engineering Group, University of Siegen, Germany; Software Engineering Group, University of Siegen, Germany; Software Engineering Group, University of Siegen, Germany; Department of Computer Science, Humboldt-University of Berlin, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","913","918","Model slicers are tools which provide two services: (a) finding parts of interest in a model and (b) displaying these parts somehow or extract these parts as a new, autonomous model, which is referred to as slice or sub-model. This paper focuses on the creation of editable slices, which can be processed by model editors, analysis tools, model management tools etc. Slices are useful if, e.g., only a part of a large model shall be analyzed, compared or processed by time-consuming algorithms, or if sub-models shall be modified independently. We present a new generic incremental slicer which can slice models of arbitrary type and which creates slices which are consistent in the sense that they are editable by standard editors. It is built on top of a model differencing framework and does not require additional configuration data beyond those available in the differencing framework. The slicer can incrementally extend or reduce an existing slice if model elements shall be added or removed, even if the slice has been edited meanwhile. We demonstrate the usefulness of our slicer in several scenarios using a large UML model. A screencast of the demonstrated scenarios is provided at http://pi.informatik.uni-siegen.de/projects/SiLift/ase2017.","","","10.1109/ASE.2017.8115704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115704","","Unified modeling language;Adaptation models;Tools;Servers;Load modeling;Computational modeling;Data models","formal specification;object-oriented programming;program slicing;program visualisation;Unified Modeling Language","UML model;autonomous model;editable slices;model editors;analysis tools;model management tools;generic incremental slicer;model differencing framework;model elements;incrementally sliced editable submodels","","2","21","","","","","IEEE","IEEE Conferences"
"Round-up: Runtime checking quasi linearizability of concurrent data structures","Lu Zhang; A. Chattopadhyay; C. Wang","Department of ECE, Virginia Tech, Blacksburg, 24061, USA; Department of ECE, Virginia Tech, Blacksburg, 24061, USA; Department of ECE, Virginia Tech, Blacksburg, 24061, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","4","14","We propose a new method for runtime checking of a relaxed consistency property called quasi linearizability for concurrent data structures. Quasi linearizability generalizes the standard notion of linearizability by intentionally introducing nondeterminism into the parallel computations and exploiting such nondeterminism to improve the performance. However, ensuring the quantitative aspects of this correctness condition in the low level code is a difficult task. Our method is the first fully automated method for checking quasi linearizability in the unmodified C/C++ code of concurrent data structures. It guarantees that all the reported quasi linearizability violations are real violations. We have implemented our method in a software tool based on LLVM and a concurrency testing tool called Inspect. Our experimental evaluation shows that the new method is effective in detecting quasi linearizability violations in the source code of concurrent data structures.","","","10.1109/ASE.2013.6693061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693061","","History;Data structures;Standards;Law;Instruction sets;Runtime","concurrency control;data structures;formal verification;parallel processing;program testing","runtime checking;concurrent data structures;quasilinearizability property;linearizability notion;nondeterminism notion;parallel computations;correctness condition;C-C++ code;software tool;concurrency testing tool;Inspect tool","","5","43","","","","","IEEE","IEEE Conferences"
"Why and how JavaScript developers use linters","K. F. Tómasdóttir; M. Aniche; A. van Deursen","Delft University of Technology - The Netherlands; Delft University of Technology - The Netherlands; Delft University of Technology - The Netherlands","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","578","589","Automatic static analysis tools help developers to automatically spot code issues in their software. They can be of extreme value in languages with dynamic characteristics, such as JavaScript, where developers can easily introduce mistakes which can go unnoticed for a long time, e.g. a simple syntactic or spelling mistake. Although research has already shown how developers perceive such tools for strongly-typed languages such as Java, little is known about their perceptions when it comes to dynamic languages. In this paper, we investigate what motivates and how developers make use of such tools in JavaScript projects. To that goal, we apply a qualitative research method to conduct and analyze a series of 15 interviews with developers responsible for the linter configuration in reputable OSS JavaScript projects that apply the most commonly used linter, ESLint. The results describe the benefits that developers obtain when using ESLint, the different ways one can configure the tool and prioritize its rules, and the existing challenges in applying linters in the real world. These results have direct implications for developers, tool makers, and researchers, such as tool improvements, and a research agenda that aims to increase our knowledge about the usefulness of such analyzers.","","","10.1109/ASE.2017.8115668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115668","","Interviews;Tools;Software;Face;Standards;Encoding","Java;program diagnostics;type theory","ESLint;strongly-typed languages;automatic static analysis tools;JavaScript developers;linters;reputable OSS JavaScript projects;dynamic languages","","5","59","","","","","IEEE","IEEE Conferences"
"Leveraging abstract interpretation for efficient dynamic symbolic execution","E. Alatawi; H. S⊘ndergaard; T. Miller","School of Computing and Information Systems, The University of Melbourne, Victoria 3010, Australia; School of Computing and Information Systems, The University of Melbourne, Victoria 3010, Australia; School of Computing and Information Systems, The University of Melbourne, Victoria 3010, Australia","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","619","624","Dynamic Symbolic Execution (DSE) is a technique to automatically generate test inputs by executing a program with concrete and symbolic values simultaneously. A key challenge in DSE is scalability; executing all feasible program paths is not possible, owing to the potentially exponential or infinite number of paths. Loops are a main source of path explosion, in particular where the number of iterations depends on a program's input. Problems arise because DSE maintains symbolic values that capture only the dependencies on symbolic inputs. This ignores control dependencies, including loop dependencies that depend indirectly on the inputs. We propose a method to increase the coverage achieved by DSE in the presence of input-data dependent loops and loop dependent branches. We combine DSE with abstract interpretation to find indirect control dependencies, including loop and branch indirect dependencies. Preliminary results show that this results in better coverage, within considerably less time compared to standard DSE.","","","10.1109/ASE.2017.8115672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115672","Dynamic symbolic execution;DSE;abstract interpretation;path explosion;test generation","Tools;Explosions;Concrete;Testing;Scalability","program control structures;program diagnostics;program testing;program verification","symbolic inputs;loop dependencies;input-data dependent loops;dependent branches;indirect control dependencies;branch indirect dependencies;standard DSE;efficient dynamic symbolic execution;test inputs;symbolic values;feasible program paths;path explosion","","2","21","","","","","IEEE","IEEE Conferences"
"Flow Permissions for Android","S. Holavanalli; D. Manuel; V. Nanjundaswamy; B. Rosenberg; F. Shen; S. Y. Ko; L. Ziarek","University at Buffalo, The State University of New York, USA; University at Buffalo, The State University of New York, USA; University at Buffalo, The State University of New York, USA; University at Buffalo, The State University of New York, USA; University at Buffalo, The State University of New York, USA; University at Buffalo, The State University of New York, USA; University at Buffalo, The State University of New York, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","652","657","This paper proposes Flow Permissions, an extension to the Android permission mechanism. Unlike the existing permission mechanism our permission mechanism contains semantic information based on information flows. Flow Permissions allow users to examine and grant explicit information flows within an application (e.g., a permission for reading the phone number and sending it over the network) as well as implicit information flows across multiple applications (e.g., a permission for reading the phone number and sending it to another application already installed on the user's phone). Our goal with Flow Permissions is to provide visibility into the holistic behavior of the applications installed on a user's phone. Our evaluation compares our approach to dynamic flow tracking techniques; our results with 600 popular applications and 1,200 malicious applications show that our approach is practical and effective in deriving Flow Permissions statically.","","","10.1109/ASE.2013.6693128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693128","","Smart phones;Seals;Androids;Humanoid robots;MySpace;Browsers;Java","Android (operating system)","flow permissions;Android permission mechanism;semantic information;information flows","","17","20","","","","","IEEE","IEEE Conferences"
"Natural language requirements quality analysis based on business domain models","K. M. Annervaz; V. Kaulgud; S. Sengupta; M. Savagaonkar","Accenture Technology Labs, Bangalore, India; Accenture Technology Labs, Bangalore, India; Accenture Technology Labs, Bangalore, India; Accenture Technology Labs, Bangalore, India","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","676","681","Quality of requirements written in natural language has always been a critical concern in software engineering. Poorly written requirements lead to ambiguity and false interpretation in different phases of a software delivery project. Further, incomplete requirements lead to partial implementation of the desired system behavior. In this paper, we present a model for harvesting domain (functional or business) knowledge. Subsequently we present natural language processing and ontology based techniques for leveraging the model to analyze requirements quality and for requirements comprehension. The prototype also provides an advisory to business analysts so that the requirements can be aligned to the expected domain standard. The prototype developed is currently being used in practice, and the initial results are very encouraging.","","","10.1109/ASE.2013.6693132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693132","Requirements Engineering;Ontology;Natural Language Processing;Business Domain Modeling","Business;Ontologies;Natural languages;Analytical models;Portals;OWL;Standards","business data processing;natural language processing;ontologies (artificial intelligence);software engineering;systems analysis","natural language requirements quality analysis;business domain models;software engineering;software delivery project;domain knowledge;natural language processing;ontology based techniques;requirements comprehension;business analysts;domain standard","","3","21","","","","","IEEE","IEEE Conferences"
"Pseudogen: A Tool to Automatically Generate Pseudo-Code from Source Code","H. Fudaba; Y. Oda; K. Akabe; G. Neubig; H. Hata; S. Sakti; T. Toda; S. Nakamura","Nara Inst. of Sci. & Technol., Nara, Japan; Nara Inst. of Sci. & Technol., Nara, Japan; Nara Inst. of Sci. & Technol., Nara, Japan; Nara Inst. of Sci. & Technol., Nara, Japan; Nara Inst. of Sci. & Technol., Nara, Japan; Nara Inst. of Sci. & Technol., Nara, Japan; Nara Inst. of Sci. & Technol., Nara, Japan; Nara Inst. of Sci. & Technol., Nara, Japan","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","824","829","Understanding the behavior of source code written in an unfamiliar programming language is difficult. One way to aid understanding of difficult code is to add corresponding pseudo-code, which describes in detail the workings of the code in a natural language such as English. In spite of its usefulness, most source code does not have corresponding pseudo-code because it is tedious to create. This paper demonstrates a tool Pseudogen that makes it possible to automatically generate pseudo-code from source code using statistical machine translation (SMT). Pseudogen currently supports generation of English or Japanese pseudo-code from Python source code, and the SMT framework makes it easy for users to create new generators for their preferred source code/pseudo-code pairs.","","","10.1109/ASE.2015.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372074","machine translation;programming language;natural language","Computer languages;Natural languages;Generators;Syntactics;Training;Programming;Arrays","language translation;program compilers;source code (software)","Pseudogen tool;automatic pseudocode generation;programming language;English language;statistical machine translation;English pseudocode generation;Japanese pseudocode generation;Python source code;SMT framework","","2","24","","","","","IEEE","IEEE Conferences"
"Lightweight control-flow instrumentation and postmortem analysis in support of debugging","P. Ohmann; B. Liblit","University of Wisconsin-Madison, USA; University of Wisconsin-Madison, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","378","388","Debugging is difficult and costly. As a human programmer looks for a bug, it would be helpful to see a complete trace of events leading to the point of failure. Unfortunately, full tracing is simply too slow to use in deployment, and may even be impractical during testing. We aid post-deployment debugging by giving programmers additional information about program activity shortly before failure. We use latent information in post-failure memory dumps, augmented by low-overhead, tunable run-time tracing. Our results with a realistically-tuned tracing scheme show low enough overhead (0-5%) to be used in production runs. We demonstrate several potential uses of this enhanced information, including a novel postmortem static slice restriction technique and a reduced view of potentially-executed code. Experimental evaluation shows our approach to be very effective, such as shrinking stack-sensitive interprocedural static slices by 49-78% in larger applications.","","","10.1109/ASE.2013.6693096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693096","","Instruments;Core dumps;Debugging;Arrays;Computer crashes;Algorithm design and analysis;Production","program debugging;program slicing","lightweight control-flow instrumentation;postmortem analysis;post-deployment debugging;program activity;latent information;post-failure memory dumps;run-time tracing;realistically-tuned tracing scheme;postmortem static slice restriction technique;potentially-executed code;shrinking stack-sensitive interprocedural static slices","","8","45","","","","","IEEE","IEEE Conferences"
"Evolutionary Robustness Testing of Data Processing Systems Using Models and Data Mutation (T)","D. D. Nardo; F. Pastore; A. Arcuri; L. Briand","NA; Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg City, Luxembourg; Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg City, Luxembourg; Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg City, Luxembourg","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","126","137","System level testing of industrial data processing software poses several challenges. Input data can be very large, even in the order of gigabytes, and with complex constraints that define when an input is valid. Generating the right input data to stress the system for robustness properties (e.g. to test how faulty data is handled) is hence very complex, tedious and error prone when done manually. Unfortunately, this is the current practice in industry. In previous work, we defined a methodology to model the structure and the constraints of input data by using UML class diagrams and OCL constraints. Tests were automatically derived to cover predefined fault types in a fault model. In this paper, to obtain more effective system level test cases, we developed a novel search-based test generation tool. Experiments on a real-world, large industrial data processing system show that our automated approach can not only achieve better code coverage, but also accomplishes this using significantly smaller test suites.","","","10.1109/ASE.2015.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372002","","Unified modeling language;Data models;Robustness;Testing;Data processing;Software;Search problems","data handling;program testing;search problems","evolutionary robustness testing;data mutation;search-based test generation tool;industrial data processing system;automated approach","","1","42","","","","","IEEE","IEEE Conferences"
"BProVe: A formal verification framework for business process models","F. Corradini; F. Fornari; A. Polini; B. Re; F. Tiezzi; A. Vandin","School of Science and Technology, University of Camerino, Camerino, Italy; School of Science and Technology, University of Camerino, Camerino, Italy; School of Science and Technology, University of Camerino, Camerino, Italy; School of Science and Technology, University of Camerino, Camerino, Italy; School of Science and Technology, University of Camerino, Camerino, Italy; DTU Compute, Technical University of Denmark, Lyngby, Denmark","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","217","228","Business Process Modelling has acquired increasing relevance in software development. Available notations, such as BPMN, permit to describe activities of complex organisations. On the one hand, this shortens the communication gap between domain experts and IT specialists. On the other hand, this permits to clarify the characteristics of software systems introduced to provide automatic support for such activities. Nevertheless, the lack of formal semantics hinders the automatic verification of relevant properties. This paper presents a novel verification framework for BPMN 2.0, called BProVe. It is based on an operational semantics, implemented using MAUDE, devised to make the verification general and effective. A complete tool chain, based on the Eclipse modelling environment, allows for rigorous modelling and analysis of Business Processes. The approach has been validated using more than one thousand models available on a publicly accessible repository. Besides showing the performance of BProVe, this validation demonstrates its practical benefits in identifying correctness issues in real models.","","","10.1109/ASE.2017.8115635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115635","Business Processes;BPMN;Structural Operational Semantics;MAUDE;Software Verification","Semantics;Analytical models;Logic gates;Business;Software systems;Tools;Collaboration","business data processing;formal specification;program verification","automatic verification;relevant properties;novel verification framework;BPMN 2;operational semantics;Eclipse modelling environment;rigorous modelling analysis;Business Processes;formal verification framework;business process models;Business Process Modelling;software development;available notations;domain experts;software systems;automatic support;formal semantics","","2","58","","","","","IEEE","IEEE Conferences"
"Learning to Rank for Question-Oriented Software Text Retrieval (T)","Y. Zou; T. Ye; Y. Lu; J. Mylopoulos; L. Zhang","Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China; Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China; Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China; Dept. of Comput. Sci., Univ. of Toronto, Toronto, ON, Canada; Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","1","11","Question-oriented text retrieval, aka natural language-based text retrieval, has been widely used in software engineering. Earlier work has concluded that questions with the same keywords but different interrogatives (such as how, what) should result in different answers. But what is the difference? How to identify the right answers to a question? In this paper, we propose to investigate the ""answer style"" of software questions with different interrogatives. Towards this end, we build classifiers in a software text repository and propose a re-ranking approach to refine search results. The classifiers are trained by over 16,000 answers from the StackOverflow forum. Each answer is labeled accurately by its question's explicit or implicit interrogatives. We have evaluated the performance of our classifiers and the refinement of our re-ranking approach in software text retrieval. Our approach results in 13.1% and 12.6% respectively improvement with respect to text retrieval criteria nDCG@1 and nDCG@10 compared to the baseline. We also apply our approach to FAQs of 7 open source projects and show 13.2% improvement with respect to nDCG@1. The results of our experiments suggest that our approach could find answers to FAQs more precisely.","","","10.1109/ASE.2015.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371990","text retrieval;interrogative;classifier;rank","Software;Feature extraction;Indexes;Software engineering;Buildings;Training;Search engines","information retrieval;learning (artificial intelligence);text analysis","learning-to-rank;question-oriented software text retrieval;natural language-based text retrieval;software engineering;software text repository;re-ranking approach;StackOverflow forum","","10","40","","","","","IEEE","IEEE Conferences"
"TCA: An Efficient Two-Mode Meta-Heuristic Algorithm for Combinatorial Test Generation (T)","J. Lin; C. Luo; S. Cai; K. Su; D. Hao; L. Zhang","Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China; Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China; State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China; Dept. of Comput. Sci., Jinan Univ., Guangzhou, China; Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China; Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","494","505","Covering arrays (CAs) are often used as test suites for combinatorial interaction testing to discover interaction faults of real-world systems. Most real-world systems involve constraints, so improving algorithms for covering array generation (CAG) with constraints is beneficial. Two popular methods for constrained CAG are greedy construction and meta-heuristic search. Recently, a meta-heuristic framework called two-mode local search has shown great success in solving classic NPhard problems. We are interested whether this method is also powerful in solving the constrained CAG problem. This work proposes a two-mode meta-heuristic framework for constrained CAG efficiently and presents a new meta-heuristic algorithm called TCA. Experiments show that TCA significantly outperforms state-of-the-art solvers on 3-way constrained CAG. Further experiments demonstrate that TCA also performs much better than its competitors on 2-way constrained CAG.","","","10.1109/ASE.2015.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372037","","Software;Heuristic algorithms;Search problems;Testing;Algorithm design and analysis;Software algorithms;Computer science","program testing;search problems","TCA algorithm;two-mode metaheuristic algorithm;combinatorial test generation;covering array generation;CA;combinatorial interaction testing;CAG;greedy construction method;metaheuristic search method;NP-hard problems;two-mode local search","","13","57","","","","","IEEE","IEEE Conferences"
"Model Checking Task Parallel Programs Using Gradual Permissions (N)","E. G. Mercer; P. Anderson; N. Vrvilo; V. Sarkar","Brigham Young Univ., Provo, UT, USA; Brigham Young Univ., Provo, UT, USA; Rice Univ., Houston, TX, USA; Rice Univ., Houston, TX, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","535","540","Habanero is a task parallel programming model that provides correctness guarantees to the programmer. Even so, programs may contain data races that lead to non-determinism, which complicates debugging and verification. This paper presents a sound algorithm based on permission regions to prove data race and deadlock freedom in Habanero programs. Permission regions are user annotations to indicate the use of shared variables over spans of code. The verification algorithm restricts scheduling to permission region boundaries and isolation to reduce verification cost. The effectiveness of the algorithm is shown in benchmarks with an implementation in the Java Pathfinder (JPF) model checker. The implementation uses a verification specific library for Habanero that is tested using JPF for correctness. The results show significant reductions in cost, where cost is controlled with the size of the permission regions, at the risk of rejecting programs that are actually free of any data race or deadlock.","","","10.1109/ASE.2015.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372041","Data race;deadlock;model checking;task parallel languages;Habanero;Java Pathfinder","System recovery;Schedules;Java;Synchronization;Model checking;Data models;Writing","formal verification;parallel programming","model checking;Habanero task parallel programming model;gradual permission;program debugging;program verification;permission region;verification algorithm;Java Pathfinder model checker;JPF model checker","","2","14","","","","","IEEE","IEEE Conferences"
"A static analysis tool with optimizations for reachability determination","Y. Wang; M. Zhou; Y. Jiang; X. Song; M. Gu; J. Sun","Key Laboratory for Information System Security, Ministry of Education, China; Key Laboratory for Information System Security, Ministry of Education, China; Key Laboratory for Information System Security, Ministry of Education, China; Electrical and Computer Engineering, Portland State University, USA; Key Laboratory for Information System Security, Ministry of Education, China; Key Laboratory for Information System Security, Ministry of Education, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","925","930","To reduce the false positives of static analysis, many tools collect path constraints and integrate SMT solvers to filter unreachable execution paths. However, the accumulated calling and computing of SMT solvers are time and resource consuming. This paper presents TsmartLW, an alternate static analysis tool in which we implement a path constraint solving engine to speed up reachability determination. Within the engine, typical types of constraint-patterns are firstly defined based on an empirical study of a large number of code repositories. For each pattern, a constraint solving algorithm is designed and implemented. For each program, the engine predicts the most suitable strategy and then applies the strategy to solve path constraints. The experimental results on some well-known benchmarks and real-world applications show that TsmartLW is faster than some state-of-the-art static analysis tools. For example, it is 1.32× faster than CPAchecker and our engine is 369× faster than SMT solvers in solving path constraints. The demo video is available at https://www.youtube.com/watch?v=5c3ARhFclHA&t=2s.","","","10.1109/ASE.2017.8115706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115706","Reachability determination;constraint pattern;path constraint solving","Tools;Algorithm design and analysis;Engines;Benchmark testing;Visualization;Optimization","formal verification;program diagnostics;program testing;program verification","reachability determination;path constraint;SMT solvers;unreachable execution paths;alternate static analysis tool;constraint-patterns;constraint solving algorithm;TsmartLW","","2","15","","","","","IEEE","IEEE Conferences"
"STARTS: STAtic regression test selection","O. Legunsen; A. Shi; D. Marinov","Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","949","954","Regression testing is an important part of software development, but it can be very time consuming. Regression test selection (RTS) aims to speed up regression testing by running only impacted tests-the subset of tests that can change behavior due to code changes. We present STARTS, a tool for STAtic Regression Test Selection. Unlike dynamic RTS, STARTS requires no code instrumentation or runtime information to find impacted tests; instead, STARTS uses only compile-time information. Specifically, STARTS builds a dependency graph of program types and finds, as impacted, tests that can reach some changed type in the transitive closure of the dependency graph. STARTS is a Maven plugin that can be easily integrated into any Maven-based Java project. We find that STARTS selects on average 35.2% of tests, leading to an end-to-end runtime that is on average 81.0% of running all the tests. A video demo of STARTS can be found at https://youtu.be/PCNtk8jphrM.","","","10.1109/ASE.2017.8115710","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115710","","Tools;Testing;Prototypes;Software;Runtime;Java;Libraries","Java;program compilers;program diagnostics;program testing;regression analysis","program type dependency graph;dynamic RTS;static regression test selection;STARTS selects;code instrumentation","","5","22","","","","","IEEE","IEEE Conferences"
"Proving MCAPI executions are correct using SMT","Y. Huang; E. Mercer; J. McCarthy","Department of Computer Science, Brigham Young University, Provo, UT, 84602, USA; Department of Computer Science, Brigham Young University, Provo, UT, 84602, USA; Department of Computer Science, Brigham Young University, Provo, UT, 84602, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","26","36","Asynchronous message passing is an important paradigm in writing applications for embedded heterogeneous multicore systems. The Multicore Association (MCA), an industry consortium promoting multicore technology, is working to standardize message passing into a single API, MCAPI, for bare metal implementation and portability across platforms. Correctness in such an API is difficult to reason about manually, and testing against reference solutions is equally difficult as reference solutions implement an unknown set of allowed behaviors, and programmers have no way to directly control API internals to expose or reproduce errors. This paper provides a way to encode an MCAPI execution as a Satisfiability Modulo Theories (SMT) problem, which if satisfiable, yields a feasible execution schedule on the same trace, such that it resolves non-determinism in the MCAPI runtime in a way that it now fails user provided assertions. The paper proves the problem is NP-complete. The encoding is useful for test, debug, and verification of MCAPI program execution. The novelty in the encoding is the direct use of match pairs (potential send and receive couplings). Match-pair encoding for MCAPI executions, when compared to other encoding strategies, is simpler to reason about, results in significantly fewer terms in the SMT problem, and captures feasible behaviors that are ignored in previously published techniques. Further, to our knowledge, this is the first SMT encoding that is able to run in infinite-buffer semantics, meaning the runtime has unlimited internal buffering as opposed to no internal buffering. Results demonstrate that the SMT encoding, restricted to zero-buffer semantics, uses fewer clauses when compared to another zero-buffer technique, and it runs faster and uses less memory. As a result the encoding scales well for programs with high levels of non-determinism in how sends and receives may potentially match.","","","10.1109/ASE.2013.6693063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693063","Abstraction;Refinement;SMT;Message Passing","Encoding;Semantics;Schedules;Runtime;Message passing;Multicore processing;Complexity theory","application program interfaces;computability;embedded systems;message passing;multiprocessing systems;program verification","MCAPI executions;asynchronous message passing;embedded heterogeneous multicore systems;Multicore Association;industry consortium;multicore technology;single API;bare metal implementation;portability;reference solutions;API internals;satisfiability modulo theories problem;execution schedule;MCAPI runtime;NP-complete problem;MCAPI program execution testing;MCAPI program execution verification;match-pair encoding;encoding strategies;infinite-buffer semantics;unlimited internal buffering;SMT encoding;zero-buffer semantics;zero-buffer technique;MCAPI program execution debugging","","4","29","","","","","IEEE","IEEE Conferences"
"Contract-based program repair without the contracts","L. Chen; Y. Pei; C. A. Furia","Department of Computing, The Hong Kong Polytechnic University, China; Department of Computing, The Hong Kong Polytechnic University, China; Department of Computer Science and Engineering, Chalmers University of Technology, Sweden","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","637","647","Automated program repair (APR) is a promising approach to automatically fixing software bugs. Most APR techniques use tests to drive the repair process; this makes them readily applicable to realistic code bases, but also brings the risk of generating spurious repairs that overfit the available tests. Some techniques addressed the overfitting problem by targeting code using contracts (such as pre- and postconditions), which provide additional information helpful to characterize the states of correct and faulty computations; unfortunately, mainstream programming languages do not normally include contract annotations, which severely limits the applicability of such contract-based techniques. This paper presents JAID, a novel APR technique for Java programs, which is capable of constructing detailed state abstractions-similar to those employed by contract-based techniques-that are derived from regular Java code without any special annotations. Grounding the repair generation and validation processes on rich state abstractions mitigates the overfitting problem, and helps extend APR's applicability: in experiments with the DEFECTS4J benchmark, a prototype implementation of JAID produced genuinely correct repairs, equivalent to those written by programmers, for 25 bugs-improving over the state of the art of comparable Java APR techniques in the number and kinds of correct fixes.","","","10.1109/ASE.2017.8115674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115674","","Maintenance engineering;Contracts;Java;Computer bugs;Monitoring;Tools;Indexes","contracts;formal specification;Java;program debugging;program diagnostics;software maintenance","overfitting problem;mainstream programming languages;contract annotations;Java programs;detailed state abstractions;regular Java code;repair generation;validation processes;comparable Java APR techniques;automated program repair;realistic code bases;spurious repairs;APR technique","","13","37","","","","","IEEE","IEEE Conferences"
"Recovering model transformation traces using multi-objective optimization","H. Saada; M. Huchard; C. Nebut; H. Sahraoui","LIRMM, Université Montpellier 2 et CNRS, France; LIRMM, Université Montpellier 2 et CNRS, France; LIRMM, Université Montpellier 2 et CNRS, France; DIRO, Université de Montréal, Canada","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","688","693","Model Driven Engineering (MDE) is based on a large set of models that are used and manipulated throughout the development cycle. These models are manually or automatically produced and/or exploited using model transformations. To allow engineers to maintain the models and track their changes, recovering transformation traces is essential. In this paper, we propose an automated approach, based on multi-objective optimization, to recover transformation traces between models. Our approach takes as input a source model in the form of a set of fragments (fragments are defined using the source meta-model cardinalities and OCL constraints), and a target model. The recovered transformation traces take the form of many-to-many mappings between the constructs of the two models.","","","10.1109/ASE.2013.6693134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693134","","Unified modeling language;Sociology;Statistics;Optimization;Vectors;Context;Genetics","optimisation;program diagnostics;software engineering","model transformation trace recovery;multiobjective optimization;model driven engineering;MDE;development cycle;source meta-model cardinalities;OCL constraints;target model;many-to-many mappings","","7","19","","","","","IEEE","IEEE Conferences"
"Refactorings for Android Asynchronous Programming","Y. Lin; D. Dig","Comput. Sci. Dept., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","836","841","Running compute-intensive or blocking I/O operationsin the UI event thread of smartphone apps can severelydegrade responsiveness. Despite the fact that Android provides several async constructs that developers can use, developers can still miss opportunities to encapsulate long-running operations in async constructs. On the other hand, they can use the inappropriate async constructs, which result in memory leaks, lost results, and wasted energy. Fortunately, refactoring tools can eliminate these problems by retrofitting asynchrony to sequential code and transforming async code to use the appropriate constructs. This demo presents two refactoring tools for Android apps: (i) ASYNCHRONIZER, a refactoring tool that enables developers to extract long-running operations into Android AsyncTask. (ii) ASYNCDROID, a refactoring tool which enables developers to transform existing improperly-used AsyncTask into Android IntentService.","","","10.1109/ASE.2015.100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372076","Refactoring;Android;Asynchronous","Androids;Humanoid robots;Graphical user interfaces;Instruction sets;Message systems;Programming;Safety","Android (operating system);smart phones;software maintenance;software tools;user interfaces","Android asynchronous programming;compute-intensive operations;I/O operations;UI event thread;smartphone apps;long-running operation encapsulation;memory leaks;refactoring tools;sequential code;async code;asynchronizer;Android AsyncTask;ASYNCDROID;improperly-used AsyncTask;Android IntentService","","3","37","","","","","IEEE","IEEE Conferences"
"Model-Based Testing of Stateful APIs with Modbat","C. Artho; M. Seidl; Q. Gros; E. Choi; T. Kitamura; A. Mori; R. Ramler; Y. Yamagata","Nat. Inst. of Adv. Ind. Sci. & Technol., Amagasaki, Japan; Johannes Kepler Univ., Linz, Austria; Univ. of Nantes, Nantes, France; Nat. Inst. of Adv. Ind. Sci. & Technol., Amagasaki, Japan; Nat. Inst. of Adv. Ind. Sci. & Technol., Amagasaki, Japan; Nat. Inst. of Adv. Ind. Sci. & Technol., Amagasaki, Japan; Software Competence Center Hagenberg, Hagenberg, Austria; Software Competence Center Hagenberg, Hagenberg, Austria","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","858","863","Modbat makes testing easier by providing a user-friendly modeling language to describe the behavior of systems, from such a model, test cases are generated and executed. Modbat's domain-specific language is based on Scala, its features include probabilistic and non-deterministic transitions, component models with inheritance, and exceptions. We demonstrate the versatility of Modbat by finding a confirmed defect in the currently latest version of Java, and by testing SAT solvers.","","","10.1109/ASE.2015.95","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372080","model-based testing;software test tools;domain-specific language;extended finite-state machines;component-based systems;exception testing","Java;Data models;Arrays;DSL;Testing;Libraries","application program interfaces;computability;Java;program testing;simulation languages","model-based testing;stateful API;Modbat;user-friendly modeling language;domain-specific language;Scala;nondeterministic transitions;probabilistic transitions;Java;SAT solvers","","2","31","","","","","IEEE","IEEE Conferences"
"Dangling references in multi-configuration and dynamic PHP-based Web applications","H. V. Nguyen; H. A. Nguyen; T. T. Nguyen; A. T. Nguyen; T. N. Nguyen","Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","399","409","PHP is a dynamic language popularly used in Web development for writing server-side code to dynamically create multiple versions of client-side pages at run time for different configurations. A PHP program contains code to be executed or produced for multiple configurations/versions. That dynamism and multi-configuration nature leads to dangling references. Specifically, in the execution for a configuration, a reference to a variable or a call to a function is dangling if its corresponding declaration cannot be found. We conducted an exploratory study to confirm the existence of such dangling reference errors including dangling cross-language and embedded references in the client-side HTML/JavaScript code and in data-accessing SQL code that are embedded in scattered PHP code. Dangling references have caused run-time fatal failures and security vulnerabilities. We developed DRC, a static analysis method to detect such dangling references. DRC uses symbolic execution to collect PHP declarations/references and to approximate all versions of the generated output, and then extracts embedded declarations/references. It associates each detected declaration/reference with a conditional constraint that represents the execution paths (i.e. configurations/versions) containing that declaration/reference. It then validates references against declarations via a novel dangling reference detection algorithm. Our empirical evaluation shows that DRC detects dangling references with high accuracy. It revealed 83 yet undiscovered defects caused by dangling references.","","","10.1109/ASE.2013.6693098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693098","Dangling References;Web Code Analysis","HTML;Thumb;Databases;Reactive power;Security;Servers;Detection algorithms","Internet;program diagnostics;SQL","dynamic PHP-based Web applications;dynamic language;Web development;writing server-side code;client-side pages;PHP program;multiple configurations;multiple versions;multiconfiguration nature;dangling cross-language;embedded references;HTML code;JavaScript code;data-accessing SQL code;scattered PHP code;run-time fatal failures;static analysis method;dangling references","","5","34","","","","","IEEE","IEEE Conferences"
"Test Analysis: Searching for Faults in Tests (N)","M. Waterloo; S. Person; S. Elbaum","Comput. Sci. & Eng. Dept., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Comput. Sci. & Eng. Dept., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Comput. Sci. & Eng. Dept., Univ. of Nebraska-Lincoln, Lincoln, NE, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","149","154","Tests are increasingly specified as programs. Expressing tests as code is advantageous in that developers are comfortable writing and running code, and tests can be automated and reused as the software evolves. Tests expressed as code, however, can also contain faults. Some test faults are similar to those found in application code, while others are more subtle, caused by incorrect implementation of testing concepts and processes. These faults may cause a test to fail when it should not, or allow program faults to go undetected. In this work we explore whether lightweight static analyses can be cost-effective in pinpointing patterns associated with faults tests. Our exploration includes a categorization and explanation of test patterns, and their application to 12 open source projects that include over 40K tests. We found that several patterns, detectable through simple and efficient static analyses of just the test code, can detect faults with a low false positive rate, while other patterns would require a more sophisticated and extensive code analysis to be useful.","","","10.1109/ASE.2015.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372004","coding patterns;lightweight static analysis;test faults","Software;Testing;Encoding;Syntactics;Dynamic scheduling;Fault diagnosis;Detectors","program diagnostics;program testing;software fault tolerance;source code (software)","test analysis;test faults;application code;program faults;static analyses","","1","21","","","","","IEEE","IEEE Conferences"
"PAD: Programming third-party web advertisement censorship","W. Wang; Y. Kwon; Y. Zheng; Y. Aafer; I. Kim; W. Lee; Y. Liu; W. Meng; X. Zhang; P. Eugster","Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; IBM T.J. Watson Research Center, Yorktown Height, New York, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","240","251","In the current online advertisement delivery, an ad slot on a publisher's website may go through multiple layers of bidding and reselling until the final ad content is delivered. The publishers have little control on the ads being displayed on their web pages. As a result, website visitors may suffer from unwanted ads such as malvertising, intrusive ads, and information disclosure ads. Unfortunately, the visitors often blame the publisher for their unpleasant experience and switch to competitor websites. In this paper, we propose a novel programming support system for ad delivery, called PAD, for publisher programmers, who specify their policies on regulating third-party ads shown on their websites. PAD features an expressive specification language and a novel persistent policy enforcement runtime that can self-install and self-protect throughout the entire ad delegation chain. It also provides an ad-specific memory protection scheme that prevents malvertising by corrupting malicious payloads. Our experiments show that PAD has negligible runtime overhead. It effectively suppresses a set of malvertising cases and unwanted ad behaviors reported in the real world, without affecting normal functionalities and regular ads.","","","10.1109/ASE.2017.8115637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115637","","Internet;Runtime;Browsers;Advertising;Trojan horses","advertising data processing;Internet;security of data;Web sites","current online advertisement delivery;bidding;unwanted ads;intrusive ads;information disclosure ads;unpleasant experience;programming support system;publisher programmers;third-party ads;expressive specification language;ad-specific memory protection scheme;negligible runtime overhead;malvertising cases;unwanted ad behaviors;Web pages;programming third-party Web advertisement censorship;Website visitors;competitor Websites;PAD;persistent policy enforcement runtime","","","64","","","","","IEEE","IEEE Conferences"
"Learning to share: Engineering adaptive decision-support for online social networks","Y. Rafiq; L. Dickens; A. Russo; A. K. Bandara; M. Yang; A. Stuart; M. Levine; G. Calikli; B. A. Price; B. Nuseibeh","Imperial College London UK; University College London, UK; Imperial College London UK; The Open University, UK; University of Southampton, UK; University of Exeter, UK; University of Exeter, UK; Chalmers & University of Gothenburg, Sweden; The Open University, UK; The Open University, UK","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","280","285","Some online social networks (OSNs) allow users to define friendship-groups as reusable shortcuts for sharing information with multiple contacts. Posting exclusively to a friendship-group gives some privacy control, while supporting communication with (and within) this group. However, recipients of such posts may want to reuse content for their own social advantage, and can bypass existing controls by copy-pasting into a new post; this cross-posting poses privacy risks. This paper presents a learning to share approach that enables the incorporation of more nuanced privacy controls into OSNs. Specifically, we propose a reusable, adaptive software architecture that uses rigorous runtime analysis to help OSN users to make informed decisions about suitable audiences for their posts. This is achieved by supporting dynamic formation of recipient-groups that benefit social interactions while reducing privacy risks. We exemplify the use of our approach in the context of Facebook.","","","10.1109/ASE.2017.8115641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115641","","Privacy;Facebook;Monitoring;Sensitivity;Computational modeling;Adaptation models","data privacy;social networking (online)","engineering adaptive decision-support;online social networks;friendship-group;reusable shortcuts;privacy control;social advantage;nuanced privacy controls;reusable software architecture;adaptive software architecture;OSN users;informed decisions;recipient-groups;social interactions;cross-posting pose privacy risks;Facebook","","","42","","","","","IEEE","IEEE Conferences"
"CodeExchange: Supporting Reformulation of Internet-Scale Code Queries in Context (T)","L. Martie; T. D. LaToza; A. v. d. Hoek","Dept. of Inf. Irvine, Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf. Irvine, Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf. Irvine, Univ. of California, Irvine, Irvine, CA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","24","35","Programming today regularly involves searching for source code online, whether through a general search engine such as Google or a specialized code search engine such as SearchCode, Ohloh, or GitHub. Searching typically is an iterative process, with develop-ers adjusting the keywords they use based on the results of the previous query. However, searching in this manner is not ideal, because just using keywords places limits on what developers can express as well as the overall interaction that is required. Based on the observation that the results from one query create a con-text in which a next is formulated, we present CodeExchange, a new code search engine that we developed to explicitly leverage this context to support fluid, expressive reformulation of queries. We motivate the need for CodeExchange, highlight its key design decisions and overall architecture, and evaluate its use in both a field deployment and a laboratory study.","","","10.1109/ASE.2015.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371992","Code search;query reformulation;context;interface;internet-scale","Search engines;Context;Google;Manuals;Java;Programming;Face","Internet;iterative methods;query processing;search engines;source code (software)","CodeExchange;Internet-scale code queries;source code;Google;specialized code search engine;SearchCode;Ohloh;GitHub;iterative process;code search engine;field deployment","","10","60","","","","","IEEE","IEEE Conferences"
"TzuYu: Learning stateful typestates","H. Xiao; J. Sun; Y. Liu; S. Lin; C. Sun","School of Computer Engineering, Nanyang Technological University, Singapore; Singapore University of Technology and Design, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; Temasek Laboratories, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","432","442","Behavioral models are useful for various software engineering tasks. They are, however, often missing in practice. Thus, specification mining was proposed to tackle this problem. Existing work either focuses on learning simple behavioral models such as finite-state automata, or relies on techniques (e.g., symbolic execution) to infer finite-state machines equipped with data states, referred to as stateful typestates. The former is often inadequate as finite-state automata lack expressiveness in capturing behaviors of data-rich programs, whereas the latter is often not scalable. In this work, we propose a fully automated approach to learn stateful typestates by extending the classic active learning process to generate transition guards (i.e., propositions on data states). The proposed approach has been implemented in a tool called TzuYu and evaluated against a number of Java classes. The evaluation results show that TzuYu is capable of learning correct stateful typestates more efficiently.","","","10.1109/ASE.2013.6693101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693101","","Testing;Support vector machines;Concrete;Java;Educational institutions;Learning automata;Automata","data mining;formal specification;Java;learning (artificial intelligence)","TzuYu;software engineering tasks;specification mining;behavioral model learning;data-rich programs;fully automated approach;stateful typestate learning;classic active learning process;transition guards;data state propositions;Java classes","","14","37","","","","","IEEE","IEEE Conferences"
"Region and Effect Inference for Safe Parallelism (T)","A. Tzannes; S. T. Heumann; L. Eloussi; M. Vakilian; V. S. Adve; M. Han","NA; NA; NA; NA; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","512","523","In this paper, we present the first full regions-and-effects inference algorithm for explicitly parallel fork-join programs. We infer annotations inspired by Deterministic Parallel Java (DPJ) for a type-safe subset of C++. We chose the DPJ annotations because they give the strongest safety guarantees of any existing concurrency-checking approach we know of, static or dynamic, and it is also the most expressive static checking system we know of that gives strong safety guarantees. This expressiveness, however, makes manual annotation difficult and tedious, which motivates the need for automatic inference, but it also makes the inference problem very challenging: the code may use region polymorphism, imperative updates with complex aliasing, arbitrary recursion, hierarchical region specifications, and wildcard elements to describe potentially infinite sets of regions. We express the inference as a constraint satisfaction problem and develop, implement, and evaluate an algorithm for solving it. The region and effect annotations inferred by the algorithm constitute a checkable proof of safe parallelism, and it can be recorded both for documentation and for fast and modular safety checking.","","","10.1109/ASE.2015.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372039","Annotation Inference;Safe Parallelism;Static Analysis;Checkable Proof","Inference algorithms;Parallel processing;Heuristic algorithms;Manuals;Yttrium;Safety;Java","C++ language;Java;parallel programming;program diagnostics","safe parallelism;region-and-effect inference algorithm;parallel fork-join program;deterministic parallel Java;type-safe subset;C++;concurrency-checking approach;static checking system;region polymorphism;complex aliasing;arbitrary recursion;hierarchical region specification;constraint satisfaction problem;modular safety checking","","1","49","","","","","IEEE","IEEE Conferences"
"Static Analysis of JavaScript Web Applications in the Wild via Practical DOM Modeling (T)","C. Park; S. Won; J. Jin; S. Ryu","NA; NA; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","552","562","We present SAFEWapp, an open-source static analysis framework for JavaScript web applications. It provides a faithful (partial) model of web application execution environments of various browsers, based on empirical data from the main web pages of the 9,465 most popular websites. A main feature of SAFEWapp is the configurability of DOM tree abstraction levels to allow users to adjust a trade-off between analysis performance and precision depending on their applications. We evaluate SAFEWapp on the 5 most popular JavaScript libraries and the main web pages of the 10 most popular websites in terms of analysis performance, precision, and modeling coverage. Additionally, as an application of SAFEWapp, we build a bug detector for JavaScript web applications that uses static analysis results from SAFEWapp. Our bug detector found previously undiscovered bugs including ones from wikipedia.org and amazon.com.","","","10.1109/ASE.2015.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372043","","Browsers;HTML;Analytical models;Web pages;Internet;Encyclopedias","Java;program debugging;program diagnostics;Web sites","javascript Web application;SAFEWapp;open-source static analysis;Web sites;DOM tree abstraction level;bug detector","","14","29","","","","","IEEE","IEEE Conferences"
"BProVe: Tool support for business process verification","F. Corradini; F. Fornari; A. Polini; B. Re; F. Tiezzi; A. Vandin","University of Camerino, Italy; University of Camerino, Italy; University of Camerino, Italy; University of Camerino, Italy; University of Camerino, Italy; DTU Compute, Denmark","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","937","942","This demo introduces BProVe, a tool supporting automated verification of Business Process models. BProVe analysis is based on a formal operational semantics defined for the BPMN 2.0 modelling language, and is provided as a freely accessible service that uses open standard formats as input data. Furthermore a plug-in for the Eclipse platform has been developed making available a tool chain supporting users in modelling and visualising, in a friendly manner, the results of the verification. Finally we have conducted a validation through more than one thousand models, showing the effectiveness of our verification tool in practice. (Demo video: https://youtu.be/iF5OM7vKtDA).","","","10.1109/ASE.2017.8115708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115708","Business Processes;BPMN;Structural Operational Semantics;MAUDE;Software Verification","Tools;Business;Atmospheric modeling;Load modeling;Semantics;Analytical models;Collaboration","business data processing;formal specification;program verification","business process verification;automated verification;formal operational semantics;BPMN 2;freely accessible service;open standard formats;Eclipse platform;BProVe tool support;business process models","","1","26","","","","","IEEE","IEEE Conferences"
"ANDROFLEET: Testing WiFi peer-to-peer mobile apps in the large","L. Meftah; M. Gomez; R. Rouvoy; I. Chrisment","Inria / University of Lille, France; Saarland University, Germany; University of Lille / Inria / Institut Universitaire de France, France; Telecom Nancy / Inria, France","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","961","966","WiFi P2P allows mobile apps to connect to each other via WiFi without an intermediate access point. This communication mode is widely used by mobile apps to support interactions with one or more devices simultaneously. However, testing such P2P apps remains a challenge for app developers as i) existing testing frameworks lack support for WiFi P2P, and ii) WiFi P2P testing fails to scale when considering a deployment on more than two devices. In this paper, we therefore propose an acceptance testing framework, named Androfleet, to automate testing of WiFi P2P mobile apps at scale. Beyond the capability of testing point-to-point interactions under various conditions, An-drofleet supports the deployment and the emulation of a fleet of mobile devices as part of an alpha testing phase in order to assess the robustness of a WiFi P2P app once deployed in the field. To validate Androfleet, we demonstrate the detection of failing black-box acceptance tests for WiFi P2P apps and we capture the conditions under which such a mobile app can correctly work in the field. The demo video of Androfleet is made available from https://youtu.be/gJ5_Ed7XL04.","","","10.1109/ASE.2017.8115712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115712","","Wireless fidelity;Peer-to-peer computing;Testing;Mobile communication;Androids;Humanoid robots;Mobile handsets","mobile computing;peer-to-peer computing;program testing;wireless LAN","P2P testing;acceptance testing framework;An-drofleet;point-to-point interaction testing;WiFi peer-to-peer mobile application testing;black-box acceptance tests;Androfleet;alpha testing phase;mobile devices","","2","38","","","","","IEEE","IEEE Conferences"
"PIEtrace: Platform independent executable trace","Y. Kwon; X. Zhang; D. Xu","Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","48","58","To improve software dependability, a large number of software engineering tools have been developed over years. Many of them are difficult to apply in practice because their system and library requirements are incompatible with those of the subject software. We propose a technique called platform independent executable trace. Our technique traces and virtualizes a regular program execution that is platform dependent, and generates a stand-alone program called the trace program. Running the trace program re-generates the original execution. More importantly, trace program execution is completely independent of the underlying operating system and libraries such that it can be compiled and executed on arbitrary platforms. As such, it can be analyzed by a third party tool on a platform preferred by the tool. We have implemented the technique on x86 and sensor platforms. We show that buggy executions of 10 real-world Windows and sensor applications can be traced and virtualized, and later analyzed by existing Linux tools. We also demonstrate how the technique can be used in cross-platform malware analysis.","","","10.1109/ASE.2013.6693065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693065","","Registers;Libraries;Malware;Linux;Virtualization;Operating systems","invasive software;Linux;software engineering","PIEtrace;platform independent executable trace;software dependability;software engineering tools;library requirements;subject software;program execution;sensor platforms;Linux tools;malware analysis","","2","47","","","","","IEEE","IEEE Conferences"
"Leveraging syntax-related code for automated program repair","Q. Xin; S. P. Reiss","Department of Computer Science, Brown University, Providence, RI, USA; Department of Computer Science, Brown University, Providence, RI, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","660","670","We present our automated program repair technique ssFix which leverages existing code (from a code database) that is syntax-related to the context of a bug to produce patches for its repair. Given a faulty program and a fault-exposing test suite, ssFix does fault localization to identify suspicious statements that are likely to be faulty. For each such statement, ssFix identifies a code chunk (or target chunk) including the statement and its local context. ssFix works on the target chunk to produce patches. To do so, it first performs syntactic code search to find candidate code chunks that are syntax-related, i.e., structurally similar and conceptually related, to the target chunk from a code database (or codebase) consisting of the local faulty program and an external code repository. ssFix assumes the correct fix to be contained in the candidate chunks, and it leverages each candidate chunk to produce patches for the target chunk. To do so, ssFix translates the candidate chunk by unifying the names used in the candidate chunk with those in the target chunk; matches the chunk components (expressions and statements) between the translated candidate chunk and the target chunk; and produces patches for the target chunk based on the syntactic differences that exist between the matched components and in the unmatched components. ssFix finally validates the patched programs generated against the test suite and reports the first one that passes the test suite. We evaluated ssFix on 357 bugs in the Defects4J bug dataset. Our results show that ssFix successfully repaired 20 bugs with valid patches generated and that it outperformed five other repair techniques for Java.","","","10.1109/ASE.2017.8115676","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115676","Automated program repair;code search;code transfer","Maintenance engineering;Computer bugs;Syntactics;Semantics;Databases;Java;Fault diagnosis","computational linguistics;Java;program debugging;program diagnostics;program testing;software maintenance","automated program repair technique ssFix;code database;code chunk;syntactic code search;candidate code chunks;local faulty program;chunk components;translated candidate chunk;syntax-related code;target chunk;external code repository;unmatched components;matched components;Defects4J bug dataset","","14","54","","","","","IEEE","IEEE Conferences"
"Predicting relevance of change recommendations","T. Rolfsnes; L. Moonen; D. Binkley","Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Loyola University Maryland, Baltimore, Maryland, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","694","705","Software change recommendation seeks to suggest artifacts (e.g., files or methods) that are related to changes made by a developer, and thus identifies possible omissions or next steps. While one obvious challenge for recommender systems is to produce accurate recommendations, a complimentary challenge is to rank recommendations based on their relevance. In this paper, we address this challenge for recommendation systems that are based on evolutionary coupling. Such systems use targeted association-rule mining to identify relevant patterns in a software system's change history. Traditionally, this process involves ranking artifacts using interestingness measures such as confidence and support. However, these measures often fall short when used to assess recommendation relevance. We propose the use of random forest classification models to assess recommendation relevance. This approach improves on past use of various interestingness measures by learning from previous change recommendations. We empirically evaluate our approach on fourteen open source systems and two systems from our industry partners. Furthermore, we consider complimenting two mining algorithms: Co-Change and Tarmaq. The results find that random forest classification significantly outperforms previous approaches, receives lower Brier scores, and has superior trade-off between precision and recall. The results are consistent across software system and mining algorithm.","","","10.1109/ASE.2017.8115680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115680","recommendation confidence;evolutionary coupling;targeted association rule mining;random forests","Data mining;History;Couplings;Software algorithms;Software measurement;Software systems","data mining;learning (artificial intelligence);pattern classification;recommender systems;relevance feedback;software engineering","software system;association-rule mining;relevance prediction;open source systems;Co-Change mining algorithm;Tarmaq mining algorithm;Brier scores;precision value;recall value;random forest classification models;recommendation relevance;interestingness measures;recommender systems;artifacts;software change recommendation","","2","44","","","","","IEEE","IEEE Conferences"
"Smart Cloud Broker: Finding your home in the clouds","M. Baruwal Chhetri; S. Chichin; Q. Bao Vo; R. Kowalczyk","Faculty of Information and Communication Technologies, Swinburrne University of Technology, Melbourne, Victoria 3122, Australia; Faculty of Information and Communication Technologies, Swinburrne University of Technology, Melbourne, Victoria 3122, Australia; Faculty of Information and Communication Technologies, Swinburrne University of Technology, Melbourne, Victoria 3122, Australia; Faculty of Information and Communication Technologies, Swinburrne University of Technology, Melbourne, Victoria 3122, Australia","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","698","701","As the rate of cloud computing adoption grows, so does the need for consumption assistance. Enterprises looking to migrate their IT systems to the cloud require assistance in identifying providers that offer resources with the most appropriate pricing and performance levels to match their specific business needs. In this paper, we present Smart Cloud Broker - a suite of software tools that allows cloud infrastructure consumers to evaluate and compare the performance of different Infrastructure as a Service (IaaS) offerings from competing cloud service providers, and consequently supports selection of the cloud configuration and provider with the specifications that best meet the user's requirements. Using Smart Cloud Broker, prospective cloud users can estimate the performance of the different cloud platforms by running live tests against representative benchmark applications under representative load conditions.","","","10.1109/ASE.2013.6693136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693136","","Benchmark testing;Cloud computing;Servers;Pricing;Databases;Catalogs","cloud computing;program testing;software performance evaluation","Smart Cloud Broker;cloud computing;software tools;cloud infrastructure consumers;Infrastructure as a Service;IaaS;cloud service providers;cloud configuration;cloud platform performance","","5","14","","","","","IEEE","IEEE Conferences"
"Automated testing of cloud-based elastic systems with AUToCLES","A. Gambi; W. Hummer; S. Dustdar","University of Lugano, Switzerland; Vienna University of Technology, Austria; Vienna University of Technology, Austria","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","714","717","Cloud-based elastic computing systems dynamically change their resources allocation to provide consistent quality of service and minimal usage of resources in the face of workload fluctuations. As elastic systems are increasingly adopted to implement business critical functions in a cost-efficient way, their reliability is becoming a key concern for developers. Without proper testing, cloud-based systems might fail to provide the required functionalities with the expected service level and costs. Using system testing techniques, developers can expose problems that escaped the previous quality assurance activities and have a last chance to fix bugs before releasing the system in production. System testing of cloud-based systems accounts for a series of complex and time demanding activities, from the deployment and configuration of the elastic system, to the execution of synthetic clients, and the collection and persistence of execution data. Furthermore, clouds enable parallel executions of the same elastic system that can reduce the overall test execution time. However, manually managing the concurrent testing of multiple system instances might quickly overwhelm developers' capabilities, and automatic support for test generation, system test execution, and management of execution data is needed. In this demo we showcase AUToCLES, our tool for automatic testing of cloud-based elastic systems. Given specifications of the test suite and the system under test, AUToCLES implements testing as a service (TaaS): It automatically instantiates the SUT, configures the testing scaffoldings, and automatically executes test suites. If required, AUToCLES can generate new test inputs. Designers can inspect executions both during and after the tests.","","","10.1109/ASE.2013.6693140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693140","","Elasticity;Monitoring;Standards;System testing;Cloud computing","cloud computing;program testing","automated testing;AUToCLES;cloud-based elastic computing system;resources allocation;quality of service;business critical function;system testing technique;quality assurance;concurrent testing;test generation;system test execution;testing as a service;TaaS;SUT","","10","18","","","","","IEEE","IEEE Conferences"
"Investigating Program Behavior Using the Texada LTL Specifications Miner","C. Lemieux; I. Beschastnikh","Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada; Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","870","875","Temporal specifications, relating program events through time, are useful for tasks ranging from bug detection to program comprehension. Unfortunately, such specifications are often lacking from system descriptions, leading researchers to investigate methods for inferring these specifications from code, execution traces, code comments, and other artifacts. This paper describes Texada, a tool to dynamically mine temporal specifications in LTL from traces of program activity. We review Texada's key features and demonstrate how it can be used to investigate program behavior through two scenarios: validating an implementation that solves the dining philosophers problem and supporting comprehension of a stack implementation. We also detail Texada's other, more advanced, usage options. Texada is an open source tool: https://bitbucket.org/bestchai/texada.","","","10.1109/ASE.2015.94","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372082","texada;specification mining;linear temporal logic;program comprehension","Runtime;Concurrent computing;Data structures;Java;Distance measurement","data mining;formal specification;program debugging;public domain software","program behavior;Texada LTL specification miner;program events;bug detection;program comprehension;execution traces;code comments;dynamic temporal specification mining;program activity;open source tool","","1","19","","","","","IEEE","IEEE Conferences"
"Fast and Precise Symbolic Analysis of Concurrency Bugs in Device Drivers (T)","P. Deligiannis; A. F. Donaldson; Z. Rakamaric","Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK; Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","166","177","Concurrency errors, such as data races, make device drivers notoriously hard to develop and debug without automated tool support. We present Whoop, a new automated approach that statically analyzes drivers for data races. Whoop is empowered by symbolic pairwise lockset analysis, a novel analysis that can soundly detect all potential races in a driver. Our analysis avoids reasoning about thread interleavings and thus scales well. Exploiting the race-freedom guarantees provided by Whoop, we achieve a sound partial-order reduction that significantly accelerates Corral, an industrial-strength bug-finder for concurrent programs. Using the combination of Whoop and Corral, we analyzed 16 drivers from the Linux 4.0 kernel, achieving 1.5 -- 20× speedups over standalone Corral.","","","10.1109/ASE.2015.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372006","","Concurrent computing;Programming;Linux;Computer bugs;Kernel;Instruction sets;Context","concurrency (computers);device drivers;Linux;program debugging;symbol manipulation","data races;device drivers;WHOOP;automated approach;symbolic pairwise lockset analysis;statical analysis;data races all;thread interleavings;race-freedom guarantees;partial-order reduction;CORRAL;industrial-strength bug-finder;concurrent programs;concurrent errors;debugging;Linux 4.0 kernel;concurrency bugs","","9","57","","","","","IEEE","IEEE Conferences"
"GRT: Program-Analysis-Guided Random Testing (T)","L. Ma; C. Artho; C. Zhang; H. Sato; J. Gmeiner; R. Ramler","Univ. of Tokyo, Tokyo, Japan; AIST / ITRI, Japan; Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Tokyo, Tokyo, Japan; Software Competence Center Hagenberg, Hagenberg, Austria; Software Competence Center Hagenberg, Hagenberg, Austria","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","212","223","We propose Guided Random Testing (GRT), which uses static and dynamic analysis to include information on program types, data, and dependencies in various stages of automated test generation. Static analysis extracts knowledge from the system under test. Test coverage is further improved through state fuzzing and continuous coverage analysis. We evaluated GRT on 32 real-world projects and found that GRT outperforms major peer techniques in terms of code coverage (by 13 %) and mutation score (by 9 %). On the four studied benchmarks of Defects4J, which contain 224 real faults, GRT also shows better fault detection capability than peer techniques, finding 147 faults (66 %). Furthermore, in an in-depth evaluation on the latest versions of ten popular real-world projects, GRT successfully detects over 20 unknown defects that were confirmed by developers.","","","10.1109/ASE.2015.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372010","Automatic test generation;random testing;static analysis;dynamic analysis","Testing;Software;Tin;Data mining;Computer bugs;Impurities;Frequency measurement","object-oriented programming;program testing","GRT;program analysis guided random testing;program types;automated test generation;static analysis;continuous coverage analysis;fault detection capability;peer techniques","","19","66","","","","","IEEE","IEEE Conferences"
"Detecting information flow by mutating input data","B. Mathis; V. Avdiienko; E. O. Soremekun; M. Böhme; A. Zeller","Saarland University, Saarbrücken, Germany; Saarland University, Saarbrücken, Germany; Saarland University, Saarbrücken, Germany; National University of Singapore, Singapore; Saarland University, Saarbrücken, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","263","273","Analyzing information flow is central in assessing the security of applications. However, static and dynamic analyses of information flow are easily challenged by non-available or obscure code. We present a lightweight mutation-based analysis that systematically mutates dynamic values returned by sensitive sources to assess whether the mutation changes the values passed to sensitive sinks. If so, we found a flow between source and sink. In contrast to existing techniques, mutation-based flow analysis does not attempt to identify the specific path of the flow and is thus resilient to obfuscation. In its evaluation, our MUTAFLOW prototype for Android programs showed that mutation-based flow analysis is a lightweight yet effective complement to existing tools. Compared to the popular FlowDroid static analysis tool, MutaFlow requires less than 10% of source code lines but has similar accuracy; on 20 tested real-world apps, it is able to detect 75 flows that FlowDroid misses.","","","10.1109/ASE.2017.8115639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115639","","Tools;Java;Instruments;Concrete;Prototypes;Smart phones","Android (operating system);data flow analysis;program diagnostics;security of data;source coding","static analyses;dynamic analyses;obscure code;lightweight mutation;sensitive sources;sensitive sinks;flow analysis;lightweight yet effective complement;source code lines;information flow analysis;FlowDroid static analysis tool;MUTAFLOW prototype;systematically mutate dynamic values","","2","24","","","","","IEEE","IEEE Conferences"
"SimplyDroid: Efficient event sequence simplification for android application","B. Jiang; Y. Wu; T. Li; W. K. Chan","School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; Department of Computer Science, City University of Hong Kong, Hong Kong","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","297","307","To ensure the quality of Android applications, many automatic test case generation techniques have been proposed. Among them, the Monkey fuzz testing tool and its variants are simple, effective and widely applicable. However, one major drawback of those Monkey tools is that they often generate many events in a failure-inducing input trace, which makes the follow-up debugging activities hard to apply. It is desirable to simplify or reduce the input event sequence while triggering the same failure. In this paper, we propose an efficient event trace representation and the SimplyDroid tool with three hierarchical delta-debugging algorithms each operating on this trace representation to simplify crash traces. We have evaluated SimplyDroid on a suite of real-life Android applications with 92 crash traces. The empirical result shows that our new algorithms in SimplyDroid are both efficient and effective in reducing these event traces.","","","10.1109/ASE.2017.8115643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115643","Test case reduction;delta debugging;event sequence reduction;Android","Graphical user interfaces;Computer crashes;Tools;Debugging;Smart phones;Algorithm design and analysis;Androids","Android (operating system);program debugging;program testing;software tools","android application;automatic test case generation techniques;Monkey fuzz testing tool;Monkey tools;failure-inducing input trace;debugging activities;input event sequence;SimplyDroid tool;hierarchical delta-debugging algorithms;real-life Android applications;event sequence simplification;event trace representation;crash traces","","2","41","","","","","IEEE","IEEE Conferences"
"Efficient Data Model Verification with Many-Sorted Logic (T)","I. Bocic; T. Bultan","Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA; Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","42","52","Misuse or loss of web application data can have catastrophic consequences in today's Internet oriented world. Hence, verification of web application data models is of paramount importance. We have developed a framework for verification of web application data models via translation to First Order Logic (FOL), followed by automated theorem proving. Due to the undecidability of FOL, this automated approach does not always produce a conclusive answer. In this paper, we investigate the use of many-sorted logic in data model verification in order to improve the effectiveness of this approach. Many-sorted logic allows us to specify type information explicitly, thus lightening the burden of reasoning about type information during theorem proving. Our experiments demonstrate that using many-sorted logic improves the verification performance significantly, and completely eliminates inconclusive results in all cases over 7 real world web applications, down from an 17% inconclusive rate.","","","10.1109/ASE.2015.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371994","Data Models;Verification;Logic;Many-Sorted Logic","Data models;Semantics;Complexity theory;Rails;Java;Libraries;Encoding","formal verification;Internet;theorem proving","many-sorted logic;Internet;Web application data model verification;first order logic;FOL;automated theorem proving","","4","41","","","","","IEEE","IEEE Conferences"
"Measuring the structural complexity of feature models","R. Pohl; V. Stricker; K. Pohl","paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Gerlingstr. 16, 45127, Germany; paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Gerlingstr. 16, 45127, Germany; paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Gerlingstr. 16, 45127, Germany","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","454","464","The automated analysis of feature models (FM) is based on SAT, BDD, and CSP - known NP-complete problems. Therefore, the analysis could have an exponential worst-case execution time. However, for many practical relevant analysis cases, state-of-the-art (SOTA) analysis tools quite successfully master the problem of exponential worst-case execution time based on heuristics. So far, however, very little is known about the structure of FMs that cause the cases in which the execution time (hardness) for analyzing a given FM increases unpredictably for SOTA analysis tools. In this paper, we propose to use width measures from graph theory to characterize the structural complexity of FMs as a basis for an estimation of the hardness of analysis operations on FMs with SOTA analysis tools. We present an experiment that we use to analyze the reasonability of graph width measures as metric for the structural complexity of FMs and the hardness of FM analysis. Such a complexity metric can be used as a basis for a unified method to systematically improve SOTA analysis tools.","","","10.1109/ASE.2013.6693103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693103","software product line;feature model;automated analysis;performance measurement","Complexity theory;Frequency modulation;Encoding;Analytical models;Measurement;Data structures;Boolean functions","computational complexity;optimisation;software product lines","structural complexity metric;feature models;automated analysis;NP complete problems;exponential worst case execution time;practical relevant analysis;state-of-the-art analysis tools;SOTA analysis tools;heuristics;graph theory","","10","37","","","","","IEEE","IEEE Conferences"
"Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation (T)","Y. Oda; H. Fudaba; G. Neubig; H. Hata; S. Sakti; T. Toda; S. Nakamura","Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","574","584","Pseudo-code written in natural language can aid the comprehension of source code in unfamiliar programming languages. However, the great majority of source code has no corresponding pseudo-code, because pseudo-code is redundant and laborious to create. If pseudo-code could be generated automatically and instantly from given source code, we could allow for on-demand production of pseudo-code without human effort. In this paper, we propose a method to automatically generate pseudo-code from source code, specifically adopting the statistical machine translation (SMT) framework. SMT, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudo-code pairs, making it possible to create a pseudo-code generator with less human effort. In experiments, we generated English or Japanese pseudo-code from Python statements using SMT, and find that the generated pseudo-code is largely accurate, and aids code understanding.","","","10.1109/ASE.2015.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372045","Algorithms;Education;Statistical Approach","Natural languages;Computer languages;Software engineering;Programming profession;Generators;Software","language translation;natural language processing;statistical analysis","source code;statistical machine translation;natural language;programming language;SMT framework;English pseudocode;Japanese pseudocode;Python statement","","31","36","","","","","IEEE","IEEE Conferences"
"TiQi: A natural language interface for querying software project data","J. Lin; Y. Liu; J. Guo; J. Cleland-Huang; W. Goss; W. Liu; S. Lohar; N. Monaikul; A. Rasin","University of Notre Dame, South Bend, IN, USA; University of Notre Dame, South Bend, IN, USA; University of Notre Dame, South Bend, IN, USA; University of Notre Dame, South Bend, IN, USA; School of Computing, DePaul University, Chicago, USA; School of Computing, DePaul University, Chicago, USA; School of Computing, DePaul University, Chicago, USA; School of Computing, DePaul University, Chicago, USA; School of Computing, DePaul University, Chicago, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","973","977","Software projects produce large quantities of data such as feature requests, requirements, design artifacts, source code, tests, safety cases, release plans, and bug reports. If leveraged effectively, this data can be used to provide project intelligence that supports diverse software engineering activities such as release planning, impact analysis, and software analytics. However, project stakeholders often lack skills to formulate complex queries needed to retrieve, manipulate, and display the data in meaningful ways. To address these challenges we introduce TiQi, a natural language interface, which allows users to express software-related queries verbally or written in natural language. TiQi is a web-based tool. It visualizes available project data as a prompt to the user, accepts Natural Language (NL) queries, transforms those queries into SQL, and then executes the queries against a centralized or distributed database. Raw data is stored either directly in the database or retrieved dynamically at runtime from case tools and repositories such as Github and Jira. The transformed query is visualized back to the user as SQL and augmented UML, and raw data results are returned. Our tool demo can be found on YouTube at the following link:http://tinyurl.com/TIQIDemo.","","","10.1109/ASE.2017.8115714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115714","Natural Language Interface;Project Data;Query","Structured Query Language;Natural languages;Hazards;Software;Tools;Distributed databases;Unified modeling language","distributed databases;natural language interfaces;program debugging;public domain software;query processing;software engineering;SQL;Unified Modeling Language","TiQi;natural language interface;software projects;design artifacts;source code;safety cases;release plans;bug reports;project intelligence;release planning;software analytics;project stakeholders;complex queries;software project data querying","","1","20","","","","","IEEE","IEEE Conferences"
"Efficient parametric runtime verification with deterministic string rewriting","P. Meredith; G. Roşu","University of Illinois at Urbana-Champaign, United States of America; University of Illinois at Urbana-Champaign, United States of America","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","70","80","Early efforts in runtime verification show that parametric regular and temporal logic specifications can be monitored efficiently. These approaches, however, have limited expressiveness: their specifications always reduce to monitors with finite state. More recent developments showed that parametric context-free properties can be efficiently monitored with overheads generally lower than 12-15%. While context-free grammars are more expressive than finite-state languages, they still do not allow every computable safety property. This paper presents a monitor synthesis algorithm for string rewriting systems (SRS). SRSs are well known to be Turing complete, allowing for the formal specification of any computable safety property. Earlier attempts at Turing complete monitoring have been relatively inefficient. This paper demonstrates that monitoring parametric SRSs is practical. The presented algorithm uses a modified version of Aho-Corasick string searching for quick pattern matching with an incremental rewriting approach that avoids reexamining parts of the string known to contain no redexes.","","","10.1109/ASE.2013.6693067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693067","Runtime Verification;Monitoring;String Rewriting","Monitoring;Runtime;Pattern matching;Automata;Safety;Algorithm design and analysis;Java","context-free grammars;finite state machines;formal specification;formal verification;rewriting systems;temporal logic;Turing machines","parametric runtime verification;deterministic string rewriting;temporal logic specifications;parametric regular specifications;context-free grammars;finite-state languages;string rewriting systems;SRS;formal specification;Turing complete monitoring;Aho-Corasick string searching;quick pattern matching;incremental rewriting approach","","6","30","","","","","IEEE","IEEE Conferences"
"Testing properties of dataflow program operators","Z. Xu; M. Hirzel; G. Rothermel; K. Wu","University of Nebraska, Lincoln, USA; IBM Watson Research, Yorktown Heights, NY, USA; University of Nebraska, Lincoln, USA; IBM Watson Research, Yorktown Heights, NY, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","103","113","Dataflow programming languages, which represent programs as graphs of data streams and operators, are becoming increasingly popular and being used to create a wide array of commercial software applications. The dependability of programs written in these languages, as well as the systems used to compile and run these programs, hinges on the correctness of the semantic properties associated with operators. Unfortunately, these properties are often poorly defined, and frequently are not checked, and this can lead to a wide range of problems in the programs that use the operators. In this paper we present an approach for improving the dependability of dataflow programs by checking operators for necessary properties. Our approach is dynamic, and involves generating tests whose results are checked to determine whether specific properties hold or not. We present empirical data that shows that our approach is both effective and efficient at assessing the status of properties.","","","10.1109/ASE.2013.6693071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693071","","Testing;Aggregates;Optimization;Semantics;Ports (Computers);System recovery;Program processors","data flow analysis;program testing","testing properties;dataflow program operators;dataflow programming languages;data streams;commercial software applications;semantic properties","","7","26","","","","","IEEE","IEEE Conferences"
"A language model for statements of software code","Y. Yang; Y. Jiang; M. Gu; J. Sun; J. Gao; H. Liu","School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","682","687","Building language models for source code enables a large set of improvements on traditional software engineering tasks. One promising application is automatic code completion. State-of-the-art techniques capture code regularities at token level with lexical information. Such language models are more suitable for predicting short token sequences, but become less effective with respect to long statement level predictions. In this paper, we have proposed PCC to optimize the token-level based language modeling. Specifically, PCC introduced an intermediate representation (IR) for source code, which puts tokens into groups using lexeme and variable relative order. In this way, PCC is able to handle long token sequences, i.e., group sequences, to suggest a complete statement with the precise synthesizer. Further more, PCC employed a fuzzy matching technique which combined genetic and longest common subsequence algorithms to make the prediction more accurate. We have implemented a code completion plugin for Eclipse and evaluated it on open-source Java projects. The results have demonstrated the potential of PCC in generating precise long statement level predictions. In 30%-60% of the cases, it can correctly suggest the complete statement with only six candidates, and 40%-90% of the cases with ten candidates.","","","10.1109/ASE.2017.8115678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115678","Code Completion;Language Model;IR","Predictive models;Synthesizers;Java;Training data;Training;Software;Context modeling","fuzzy set theory;genetic algorithms;Java;pattern matching;public domain software;software engineering;source code (software)","PCC;precise long statement level predictions;complete statement;software code;source code;automatic code completion;lexical information;short token sequences;token-level based language modeling;variable relative order;long token sequences;group sequences;fuzzy matching technique;genetic subsequence algorithms;longest common subsequence algorithms;code completion plugin;open-source Java projects","","2","15","","","","","IEEE","IEEE Conferences"
"Recommending crowdsourced software developers in consideration of skill improvement","Z. Wang; H. Sun; Y. Fu; L. Ye","State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","717","722","Finding suitable developers for a given task is critical and challenging for successful crowdsourcing software development. In practice, the development skills will be improved as developers accomplish more development tasks. Prior studies on crowdsourcing developer recommendation do not consider the changing of skills, which can underestimate developers' skills to fulfill a task. In this work, we first conducted an empirical study of the performance of 74 developers on Topcoder. With a difficulty-weighted algorithm, we re-compute the scores of each developer by eliminating the effect of task difficulty from the performance. We find out that the skill improvement of Topcoder developers can be fitted well with the negative exponential learning curve model. Second, we design a skill prediction method based on the learning curve. Then we propose a skill improvement aware framework for recommending developers for software development with crowdsourcing.","","","10.1109/ASE.2017.8115682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115682","Crowdsourcing;recommender systems;software development;Topcoder","Software;Correlation;Reliability;Crowdsourcing;Algorithm design and analysis;Prediction algorithms","crowdsourcing;professional aspects;software engineering","development skills;development tasks;crowdsourcing developer recommendation;Topcoder developers;skill prediction method;skill improvement aware framework;crowdsourcing software development;negative exponential learning curve model","","3","13","","","","","IEEE","IEEE Conferences"
"CCmutator: A mutation generator for concurrency constructs in multithreaded C/C++ applications","M. Kusano; Chao Wang","Virginia Tech, Blacksburg, 24061, USA; Virginia Tech, Blacksburg, 24061, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","722","725","We introduce CCmutator, a mutation generation tool for multithreaded C/C++ programs written using POSIX threads and the recently standardized C++11 concurrency constructs. CCmutator is capable of performing partial mutations and generating higher order mutants, which allow for more focused and complex combinations of elementary mutation operators leading to higher quality mutants. We have implemented CCmutator based on the popular Clang/LLVM compiler framework, which allows CCmutator to be extremely scalable and robust in handling real-world C/C++ applications. CCmutator is also designed in such a way that all mutants of the same order can be generated in parallel, which allows the tool to be easily parallelized on commodity multicore hardware to improve performance.","","","10.1109/ASE.2013.6693142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693142","","Concurrent computing;Computer bugs;Instruction sets;Synchronization;Java;Software testing","C++ language;multiprocessing programs;multi-threading;program compilers;program testing;software performance evaluation","multithreaded C++ applications;multithreaded C applications;CCmutator;mutation generation tool;POSIX threads;standardized C++11 concurrency constructs;partial mutations;higher order mutant generation;elementary mutation operators;Clang-LLVM compiler framework;commodity multicore hardware;performance improvement;software testing;software development process","","13","21","","","","","IEEE","IEEE Conferences"
"Generating Fixtures for JavaScript Unit Testing (T)","A. M. Fard; A. Mesbah; E. Wohlstadter","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","190","200","In today's web applications, JavaScript code interacts with the Document Object Model (DOM) at runtime. This runtime interaction between JavaScript and the DOM is error-prone and challenging to test. In order to unit test a JavaScript function that has read/write DOM operations, a DOM instance has to be provided as a test fixture. This DOM fixture needs to be in the exact structure expected by the function under test. Otherwise, the test case can terminate prematurely due to a null exception. Generating these fixtures is challenging due to the dynamic nature of JavaScript and the hierarchical structure of the DOM. We present an automated technique, based on dynamic symbolic execution, which generates test fixtures for unit testing JavaScript functions. Our approach is implemented in a tool called ConFix. Our empirical evaluation shows that ConFix can effectively generate tests that cover DOM-dependent paths. We also find that ConFix yields considerably higher coverage compared to an existing JavaScript input generation technique.","","","10.1109/ASE.2015.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372008","Test fixture;test generation;dynamic symbolic execution;concolic execution;DOM;JavaScript;web applications","Testing;Runtime;HTML;Fixtures;Computer bugs;Concrete;Generators","data flow analysis;Internet;object-oriented programming","fixtures generation;JavaScript Unit Testing;Web applications;JavaScript code;document object model;runtime interaction;DOM fixture;null exception;dynamic symbolic execution;JavaScript functions;ConFix","","7","41","","","","","IEEE","IEEE Conferences"
"Tracking the Software Quality of Android Applications Along Their Evolution (T)","G. Hecht; O. Benomar; R. Rouvoy; N. Moha; L. Duchien","Univ. of Lille / Inria, Lille, France; Univ. du Quebec a Montreal, Montreal, QC, Canada; Univ. of Lille / Inria, Lille, France; Univ. du Quebec a Montreal, Montreal, QC, Canada; Univ. of Lille / Inria, Lille, France","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","236","247","Mobile apps are becoming complex software systems that must be developed quickly and evolve continuously to fit new user requirements and execution contexts. However, addressing these requirements may result in poor design choices, also known as antipatterns, which may incidentally degrade software quality and performance. Thus, the automatic detection and tracking of antipatterns in this apps are important activities in order to ease both maintenance and evolution. Moreover, they guide developers to refactor their applications and thus, to improve their quality. While antipatterns are well-known in object-oriented applications, their study in mobile applications is still in its infancy. In this paper, we analyze the evolution of mobile apps quality on 3, 568 versions of 106 popular Android applications downloaded from the Google Play Store. For this purpose, we use a tooled approach, called PAPRIKA, to identify 3 object-oriented and 4 Android-specific antipatterns from binaries of mobile apps, and to analyze their quality along evolutions.","","","10.1109/ASE.2015.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372012","Android;antipattern;mobile app;software quality","Androids;Humanoid robots;Mobile communication;Software quality;Java;Measurement","mobile computing;object-oriented methods;software maintenance;software quality","software quality;Android applications;mobile apps quality;Google Play Store;PAPRIKA;Android-specific antipatterns;object-oriented antipatterns;software evolution","","29","56","","","","","IEEE","IEEE Conferences"
"In-memory fuzzing for binary code similarity analysis","S. Wang; D. Wu","The Pennsylvania State University, University Park, PA 16802, USA; The Pennsylvania State University, University Park, PA 16802, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","319","330","Detecting similar functions in binary executables serves as a foundation for many binary code analysis and reuse tasks. By far, recognizing similar components in binary code remains a challenge. Existing research employs either static or dynamic approaches to capture program syntax or semantics-level features for comparison. However, there exist multiple design limitations in previous work, which result in relatively high cost, low accuracy and scalability, and thus severely impede their practical use. In this paper, we present a novel method that leverages in-memory fuzzing for binary code similarity analysis. Our prototype tool IMF-SIM applies in-memory fuzzing to launch analysis towards every function and collect traces of different kinds of program behaviors. The similarity score of two behavior traces is computed according to their longest common subsequence. To compare two functions, a feature vector is generated, whose elements are the similarity scores of the behavior trace-level comparisons. We train a machine learning model through labeled feature vectors; later, for a given feature vector by comparing two functions, the trained model gives a final score, representing the similarity score of the two functions. We evaluate IMF-SIM against binaries compiled by different compilers, optimizations, and commonly-used obfuscation methods, in total over one thousand binary executables. Our evaluation shows that IMF-SIM notably outperforms existing tools with higher accuracy and broader application scopes.","","","10.1109/ASE.2017.8115645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115645","In-memory fuzzing;code similarity;reverse engineering;taint analysis","Binary codes;Tools;Runtime;Indexes;Syntactics","feature extraction;fuzzy set theory;learning (artificial intelligence);program compilers","similar components;program syntax;binary code similarity analysis;in-memory fuzzing;similarity score;behavior trace-level comparisons;IMF-SIM;binary code analysis;similar functions","","4","65","","","","","IEEE","IEEE Conferences"
"Interpolation Guided Compositional Verification (T)","S. Lin; J. Sun; T. K. Nguyen; Y. Liu; J. S. Dong","NA; NA; NA; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","65","74","Model checking suffers from the state space explosion problem. Compositional verification techniques such as assume-guarantee reasoning (AGR) have been proposed to alleviate the problem. However, there are at least three challenges in applying AGR. Firstly, given a system M1 ? M2, how do we automatically construct and refine (in the presence of spurious counterexamples) an assumption A2, which must be an abstraction of M2? Previous approaches suggest to incrementally learn and modify the assumption through multiple invocations of a model checker, which could be often time consuming. Secondly, how do we keep the state space small when checking M1 ? A2 = f if multiple refinements of A2 are necessary? Lastly, in the presence of multiple parallel components, how do we partition the components? In this work, we propose interpolation-guided compositional verification. The idea is to tackle three challenges by using interpolations to generate and refine the abstraction of M2, to abstract M1 at the same time (so that the state space is reduced even if A2 is refined all the way to M2), and to find good partitions. Experimental results show that the proposed approach outperforms existing approaches consistently.","","","10.1109/ASE.2015.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371996","model checking;automatic compositional verification;satisfiability;interpolation","Model checking;Interpolation;Reactive power;Radiation detectors;Cognition;Explosions;Computer security","formal verification;interpolation;parallel processing","interpolation guided compositional verification;model checking;state space explosion problem;compositional verification techniques;assume-guarantee reasoning;AGR;parallel components","","3","39","","","","","IEEE","IEEE Conferences"
"Software analytics for incident management of online services: An experience report","J. Lou; Q. Lin; R. Ding; Q. Fu; D. Zhang; T. Xie","Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; University of Illinois at Urbana-Champaign, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","475","485","As online services become more and more popular, incident management has become a critical task that aims to minimize the service downtime and to ensure high quality of the provided services. In practice, incident management is conducted through analyzing a huge amount of monitoring data collected at runtime of a service. Such data-driven incident management faces several significant challenges such as the large data scale, complex problem space, and incomplete knowledge. To address these challenges, we carried out two-year software-analytics research where we designed a set of novel data-driven techniques and developed an industrial system called the Service Analysis Studio (SAS) targeting real scenarios in a large-scale online service of Microsoft. SAS has been deployed to worldwide product datacenters and widely used by on-call engineers for incident management. This paper shares our experience about using software analytics to solve engineers' pain points in incident management, the developed data-analysis techniques, and the lessons learned from the process of research development and technology transfer.","","","10.1109/ASE.2013.6693105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693105","Online service;service incident diagnosis;incident management","Monitoring;Measurement;Software;Synthetic aperture sonar;Servers;Runtime;Radiation detectors","computer centres;data handling;Internet;program diagnostics;technology transfer","software analytics;online services;monitoring data;data-driven incident management;large data scale;software-analytics research;data-driven techniques;Service Analysis Studio;large-scale online service;Microsoft;worldwide product datacenters;data-analysis techniques;research development;technology transfer","","18","27","","","","","IEEE","IEEE Conferences"
"Experiences from Designing and Validating a Software Modernization Transformation (E)","A. F. Iosif-Lazar; A. S. Al-Sibahi; A. S. Dimovski; J. E. Savolainen; K. Sierszecki; A. Wasowski","IT Univ. of Copenhagen, Copenhagen, Denmark; IT Univ. of Copenhagen, Copenhagen, Denmark; IT Univ. of Copenhagen, Copenhagen, Denmark; NA; NA; IT Univ. of Copenhagen, Copenhagen, Denmark","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","597","607","Software modernization often involves complex code transformations that convert legacy code to new architectures or platforms, while preserving the semantics of the original programs. We present the lessons learnt from an industrial software modernization project of considerable size. This includes collecting requirements for a code-to-model transformation, designing and implementing the transformation algorithm, and then validating correctness of this transformation for the code-base at hand. Our transformation is implemented in the TXL rewriting language and assumes specifically structured C++ code as input, which it translates to a declarative configuration model. The correctness criterion for the transformation is that the produced model admits the same configurations as the input code. The transformation converts C++ functions specifying around a thousand configuration parameters. We verify the correctness for each run individually, using translation validation and symbolic execution. The technique is formally specified and is applicable automatically for most of the code-base.","","","10.1109/ASE.2015.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372047","Experience Report;Functional Equivalence;Program Transformation;Symbolic Execution","Software;Semantics;Switches;Object oriented modeling;Complexity theory;Industries;Power electronics","C++ language;formal specification;rewriting systems;software maintenance","software modernization transformation;complex code transformation;legacy code;industrial software modernization project;code-to-model transformation;transformation algorithm;code-base;TXL rewriting language;C++ code;declarative configuration model;correctness criterion;input code;C++ function;configuration parameter;translation validation;symbolic execution;formal specification","","7","30","","","","","IEEE","IEEE Conferences"
"Detecting Broken Pointcuts Using Structural Commonality and Degree of Interest (N)","R. Khatchadourian; A. Rashid; H. Masuhara; T. Watanabe","City Univ. of New York, New York, NY, USA; Lancaster Univ., Lancaster, UK; Tokyo Inst. of Technol., Tokyo, Japan; Edirium K.K., Japan","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","641","646","Pointcut fragility is a well-documented problem in Aspect-Oriented Programming, changes to the base-code can lead to join points incorrectly falling in or out of the scope of pointcuts. Deciding which pointcuts have broken due to base-code changes is a daunting venture, especially in large and complex systems. We present an automated approach that recommends pointcuts that are likely to require modification due to a particular base-code change, as well as ones that do not. Our hypothesis is that join points selected by a pointcut exhibit common structural characteristics. Patterns describing such commonality are used to recommend pointcuts that have potentially broken to the developer. The approach is implemented as an extension to the popular Mylyn Eclipse IDE plug-in, which maintains focused contexts of entities relevant to the task at hand using a Degree of Interest (DOI) model.","","","10.1109/ASE.2015.80","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372051","Aspect-Oriented programming;software evolution","Context;Software;Programming;Complex systems;Java;Software engineering;Cities and towns","aspect-oriented programming;program debugging","broken pointcut detection;structural commonality;pointcut fragility;aspect-oriented programming;complex systems;Mylyn Eclipse IDE plug-in;degree of interest model;DOI model;structural characteristics","","1","25","","","","","IEEE","IEEE Conferences"
"Defaultification refactoring: A tool for automatically converting Java methods to default","R. Khatchadourian; H. Masuhara","City University of New York, USA; Tokyo Institute of Technology, Japan","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","984","989","Enabling interfaces to declare (instance) method implementations, Java 8 default methods can be used as a substitute for the ubiquitous skeletal implementation software design pattern. Performing this transformation on legacy software manually, though, may be non-trivial. The refactoring requires analyzing complex type hierarchies, resolving multiple implementation inheritance issues, reconciling differences between class and interface methods, and analyzing tie-breakers (dispatch precedence) with overriding class methods. All of this is necessary to preserve type-correctness and confirm semantics preservation. We demonstrate an automated refactoring tool called MIGRATE Skeletal Implementation to Interface for transforming legacy Java code to use the new default construct. The tool, implemented as an Eclipse plug-in, is driven by an efficient, fully-automated, type constraint-based refactoring approach. It features an extensive rule set covering various corner-cases where default methods cannot be used. The resulting code is semantically equivalent to the original, more succinct, easier to comprehend, less complex, and exhibits increased modularity. A demonstration can be found at http://youtu.be/YZHIy0yePh8.","","","10.1109/ASE.2017.8115716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115716","refactoring;java;interfaces;default methods;type constraints;eclipse","Tools;Java;Semantics;Software;Computer architecture;Software engineering","Java;object-oriented programming;software maintenance","legacy Java code;type constraint;refactoring approach;defaultification refactoring;Java methods;method implementations;Java 8 default methods;ubiquitous skeletal implementation software design pattern;legacy software;complex type hierarchies;multiple implementation inheritance issues;dispatch precedence;semantics preservation;automated refactoring tool;MIGRATE Skeletal Implementation","","3","19","","","","","IEEE","IEEE Conferences"
"Identifying execution points for dynamic analyses","W. N. Sumner; X. Zhang","School of Computing Science, Simon Fraser University, Canada; Department of Computer Science, Purdue University, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","81","91","Dynamic analyses rely on the ability to identify points within or across executions. In spite of this being a core task for dynamic analyses, new solutions are frequently developed without an awareness of existing solutions, their strengths, their weaknesses, or their caveats. This paper surveys the existing approaches for identifying execution points and examines their analytical and empirical properties that researchers and developers should be aware of when using them within an analysis. In addition, based on limitations in precision, correctness, and efficiency for techniques that identify corresponding execution points across multiple executions, we designed and implemented a new technique, Precise Execution Point IDs. This technique avoids correctness and precision issues in prior solutions, enabling analyses that use our approach to also produce more correct results. Empirical comparison with the surveyed techniques shows that our approach has 25% overhead on average, several times less than existing solutions.","","","10.1109/ASE.2013.6693069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693069","","Context;Radiation detectors;Instruments;Runtime;Silicon carbide;Core dumps;Indexing","system monitoring","execution points identification;dynamic analysis;precision;precise execution point ID","","3","39","","","","","IEEE","IEEE Conferences"
"SABRINE: State-based robustness testing of operating systems","D. Cotroneo; D. Di Leo; F. Fucci; R. Natella","DIETI department, Università degli Studi di Napoli Federico II, Via Claudio 21, 80125, Italy; DIETI department, Università degli Studi di Napoli Federico II, Via Claudio 21, 80125, Italy; DIETI department, Università degli Studi di Napoli Federico II, Via Claudio 21, 80125, Italy; DIETI department, Università degli Studi di Napoli Federico II, Via Claudio 21, 80125, Italy","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","125","135","The assessment of operating systems robustness with respect to unexpected or anomalous events is a fundamental requirement for mission-critical systems. Robustness can be tested by deliberately exposing the system to erroneous events during its execution, and then analyzing the OS behavior to evaluate its ability to gracefully handle these events. Since OSs are complex and stateful systems, robustness testing needs to account for the timing of erroneous events, in order to evaluate the robust behavior of the OS under different states. This paper presents SABRINE (StAte-Based Robustness testIng of operatiNg systEms), an approach for state-aware robustness testing of OSs. SABRINE automatically extracts state models from execution traces, and generates a set of test cases that cover different OS states. We evaluate the approach on a Linux-based Real-Time Operating System adopted in the avionic domain. Experimental results show that SABRINE can automatically identify relevant OS states, and find robustness vulnerabilities while keeping low the number of test cases.","","","10.1109/ASE.2013.6693073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693073","Robustness Testing;Fault Injection;Operating Systems;Linux kernel;Fault Tolerance;Dependability Benchmarking","Robustness;Testing;Kernel;Probes;Hardware;Monitoring","Linux;operating system kernels;program diagnostics;program testing","SABRINE;operating systems robustness assessment;mission-critical systems;erroneous event timing;OS;state-based robustness testing of operating systems;execution traces;Linux-based real-time operating system;avionic domain;Linux kernel","","11","47","","","","","IEEE","IEEE Conferences"
"UNDEAD: Detecting and preventing deadlocks in production software","J. Zhou; S. Silvestro; H. Liu; Y. Cai; T. Liu","Department of Computer Science, University of Texas at San Antonio, USA; Department of Computer Science, University of Texas at San Antonio, USA; Department of Computer Science, University of Texas at San Antonio, USA; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Computer Science, University of Texas at San Antonio, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","729","740","Deadlocks are critical problems afflicting parallel applications, causing software to hang with no further progress. Existing detection tools suffer not only from significant recording performance overhead, but also from excessive memory and/or storage overhead. In addition, they may generate numerous false alarms. Subsequently, after problems have been reported, tremendous manual effort is required to confirm and fix these deadlocks. This paper designs a novel system, UnDead, that helps defeat deadlocks in production software. Different from existing detection tools, UnDead imposes negligible runtime performance overhead (less than 3 % on average) and small memory overhead (around 6%), without any storage consumption. After detection, UnDead automatically strengthens erroneous programs to prevent future occurrences of both existing and potential deadlocks, which is similar to the existing work-Dimmunix. However, UnDead exceeds Dimmunix with several orders of magnitude lower performance overhead, while eliminating numerous false positives. Extremely low runtime and memory overhead, convenience, and automatic prevention make UnDead an always-on detection tool, and a ""band-aid"" prevention system for production software.","","","10.1109/ASE.2017.8115684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115684","","System recovery;Software;Production;Tools;Runtime;Concurrent computing;Computer bugs","concurrency control;production engineering computing;program debugging;program diagnostics","Dimmunix;performance overhead;false positives;runtime performance overhead;band-aid prevention system;automatic prevention;memory overhead;storage consumption;UnDead;storage overhead;production software;UNDEAD","","4","42","","","","","IEEE","IEEE Conferences"
"Pex4Fun: A web-based environment for educational gaming via automated test generation","N. Tillmann; J. de Halleux; T. Xie; J. Bishop","Microsoft Research, One Microsoft Way, Redmond, WA, USA; Microsoft Research, One Microsoft Way, Redmond, WA, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Microsoft Research, One Microsoft Way, Redmond, WA, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","730","733","Pex4Fun (http://www.pex4fun.com/) is a web-based educational gaming environment for teaching and learning programming and software engineering. Pex4Fun can be used to teach and learn programming and software engineering at many levels, from high school all the way through graduate courses. With Pex4Fun, a student edits code in any browser - with Intellisense - and Pex4Fun executes it and analyzes it in the cloud. Pex4Fun connects teachers, curriculum authors, and students in a unique social experience, tracking and streaming progress updates in real time. In particular, Pex4Fun finds interesting and unexpected input values (with Pex, an advanced test-generation tool) that help students understand what their code is actually doing. The real fun starts with coding duels where a student writes code to implement a teacher's secret specification (in the form of sample-solution code not visible to the student). Pex4Fun finds any discrepancies in behavior between the student's code and the secret specification. Such discrepancies are given as feedback to the student to guide how to fix the student's code to match the behavior of the secret specification. This tool demonstration shows how Pex4Fun can be used in teaching and learning, such as solving coding duels, exploring course materials in feature courses, creating and teaching a course, creating and publishing coding duels, and learning advanced topics behind Pex4Fun.","","","10.1109/ASE.2013.6693144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693144","","Encoding;Software engineering;Games;Programming profession;Education;Testing","cloud computing;computer aided instruction;computer games;computer science education;educational courses;programming;software engineering;teaching","Pex4Fun;automated test generation;Web-based educational gaming environment;programming teaching;software engineering teaching;high school;graduate courses;Intellisense;cloud;advanced test-generation tool;secret specification;coding duels;course materials","","6","25","","","","","IEEE","IEEE Conferences"
"CodeHow: Effective Code Search Based on API Understanding and Extended Boolean Model (E)","F. Lv; H. Zhang; J. Lou; S. Wang; D. Zhang; J. Zhao","Sch. of Software, Shanghai Jiao Tong Univ., Shanghai, China; Microsoft Res., Beijing, China; Microsoft Res., Beijing, China; Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore; Microsoft Res., Beijing, China; Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","260","270","Over the years of software development, a vast amount of source code has been accumulated. Many code search tools were proposed to help programmers reuse previously-written code by performing free-text queries over a large-scale codebase. Our experience shows that the accuracy of these code search tools are often unsatisfactory. One major reason is that existing tools lack of query understanding ability. In this paper, we propose CodeHow, a code search technique that can recognize potential APIs a user query refers to. Having understood the potentially relevant APIs, CodeHow expands the query with the APIs and performs code retrieval by applying the Extended Boolean model, which considers the impact of both text similarity and potential APIs on code search. We deploy the backend of CodeHow as a Microsoft Azure service and implement the front-end as a Visual Studio extension. We evaluate CodeHow on a large-scale codebase consisting of 26K C# projects downloaded from GitHub. The experimental results show that when the top 1 results are inspected, CodeHow achieves a precision score of 0.794 (i.e., 79.4% of the first returned results are relevant code snippets). The results also show that CodeHow outperforms conventional code search tools. Furthermore, we perform a controlled experiment and a survey of Microsoft developers. The results confirm the usefulness and effectiveness of CodeHow in programming practices.","","","10.1109/ASE.2015.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372014","code search;API understanding;Extended Boolean model;software reuse","Programming;Standards;Documentation;Software;Visualization;Indexes;Libraries","application program interfaces;Boolean algebra;query processing;text analysis","software development;free-text queries;large-scale codebase;CodeHow;code search technique;user query;code retrieval;extended Boolean model;text similarity;Microsoft Azure service;Visual Studio extension;C# projects;GitHub;precision score;Microsoft developers;programming practices;API","","29","43","","","","","IEEE","IEEE Conferences"
"Towards robust instruction-level trace alignment of binary code","U. Kargén; N. Shahmehri","Department of Computer and Information Science, Linköping University, Linköping, Sweden; Department of Computer and Information Science, Linköping University, Linköping, Sweden","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","342","352","Program trace alignment is the process of establishing a correspondence between dynamic instruction instances in executions of two semantically similar but syntactically different programs. In this paper we present what is, to the best of our knowledge, the first method capable of aligning realistically long execution traces of real programs. To maximize generality, our method works entirely on the machine code level, i.e. it does not require access to source code. Moreover, the method is based entirely on dynamic analysis, which avoids the many challenges associated with static analysis of binary code, and which additionally makes our approach inherently resilient to e.g. static code obfuscation. Therefore, we believe that our trace alignment method could prove to be a useful aid in many program analysis tasks, such as debugging, reverse-engineering, investigating plagiarism, and malware analysis. We empirically evaluate our method on 11 popular Linux programs, and show that it is capable of producing meaningful alignments in the presence of various code transformations such as optimization or obfuscation, and that it easily scales to traces with tens of millions of instructions.","","","10.1109/ASE.2017.8115647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115647","","Optimization;Time series analysis;Syntactics;Concrete;Malware;Semantics;Computer architecture","invasive software;Linux;program compilers;program debugging;program diagnostics","static code obfuscation;trace alignment method;program analysis tasks;malware analysis;code transformations;robust instruction-level trace alignment;binary code;program trace alignment;dynamic instruction instances;machine code level;source code;dynamic analysis;static analysis;Linux programs","","","25","","","","","IEEE","IEEE Conferences"
"General LTL Specification Mining (T)","C. Lemieux; D. Park; I. Beschastnikh","Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada; Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada; Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","81","92","Temporal properties are useful for describing and reasoning about software behavior, but developers rarely write down temporal specifications of their systems. Prior work on inferring specifications developed tools to extract likely program specifications that fit particular kinds of tool-specific templates. This paper introduces Texada, a new temporal specification mining tool for extracting specifications in linear temporal logic (LTL) of arbitrary length and complexity. Texada takes a user-defined LTL property type template and a log of traces as input and outputs a set of instantiations of the property type (i.e., LTL formulas) that are true on the traces in the log. Texada also supports mining of almost invariants: properties with imperfect confidence. We formally describe Texada's algorithms and evaluate the tool's performance and utility.","","","10.1109/ASE.2015.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371998","specification mining;linear temporal logic;dynamic analysis","Semantics;Context;Data mining;Cognition;Software;Complexity theory;Software engineering","data mining;formal specification;temporal logic","LTL specification mining;temporal property;software behavior;program specification;tool-specific template;Texada;temporal specification mining tool;linear temporal logic;arbitrary length;user-defined LTL property type template;LTL formula","","32","47","","","","","IEEE","IEEE Conferences"
"RuntimeSearch: Ctrl+F for a running program","M. Sulír; J. Porubän","Technical University of Košice, Slovakia; Technical University of Košice, Slovakia","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","388","393","Developers often try to find occurrences of a certain term in a software system. Traditionally, a text search is limited to static source code files. In this paper, we introduce a simple approach, RuntimeSearch, where the given term is searched in the values of all string expressions in a running program. When a match is found, the program is paused and its runtime properties can be explored with a traditional debugger. The feasibility and usefulness of RuntimeSearch is demonstrated on a medium-sized Java project.","","","10.1109/ASE.2017.8115651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115651","program comprehension;dynamic analysis;debugger;text search;concept location","Runtime;Debugging;Java;Tools;Graphical user interfaces;Instruments","Java;program compilers;program debugging;program diagnostics","RuntimeSearch;ctrl+f;running program;software system;text search;static source code files;string expressions;traditional debugger;medium-sized Java project","","1","27","","","","","IEEE","IEEE Conferences"
"Towards contextual and on-demand code clone management by continuous monitoring","G. Zhang; X. Peng; Z. Xing; Shihai Jiang; Hai Wang; W. Zhao","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","497","507","Effective clone management is essential for developers to recognize the introduction and evolution of code clones, to judge their impact on software quality, and to take appropriate measures if required. Our previous study shows that cloning practice is not simply a technical issue. It must be interpreted and considered in a larger context from technical, personal, and organizational perspectives. In this paper, we propose a contextual and on-demand code clone management approach called CCEvents (Code Cloning Events). Our approach provides timely notification about relevant code cloning events for different stakeholders through continuous monitoring of code repositories. It supports on-demand customization of clone monitoring strategies in specific technical, personal, and organizational contexts using a domain-specific language. We implemented the proposed approach and conducted an empirical study with an industrial project. The results confirm the requirements for contextual and on-demand code clone management and show the effectiveness of CCEvents in providing timely code cloning notifications and in helping to achieve effective clone management.","","","10.1109/ASE.2013.6693107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693107","","Cloning;Monitoring;Context;Organizations;Outsourcing;Navigation;Detectors","software quality;source code (software)","continuous monitoring;software quality;CCEvents;code cloning events;contextual and on-demand code clone management approach;code repositories continuous monitoring;clone monitoring strategies;domain-specific language;organizational contexts;code cloning notifications","","5","30","","","","","IEEE","IEEE Conferences"
"Model based test validation and oracles for data acquisition systems","D. Di Nardo; N. Alshahwan; L. C. Briand; E. Fourneret; T. Nakić-Alfirević; V. Masquelier","Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; SES S.A., Betzdorf, Luxembourg; SES S.A., Betzdorf, Luxembourg","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","540","550","This paper presents an automated, model based test validation and oracle approach for systems with complex input and output structures, such as Data Acquisition (DAQ) systems, which are common in many sectors including the satellite communications industry. We present a customised modelling methodology for such systems and a tool that automatically validates test inputs and, after test execution, applies an oracle that is based on mappings between the input and output. We also apply our proposed approach and tool to a complex industrial DAQ system and investigate the scalability and effectiveness of the approach in validating test cases, the DAQ system, or its specifications (captured as models). The results of the case study show that the approach is indeed scalable with respect to two dimensions: (1) model size and (2) test validation and oracle execution time. The size of the model for the DAQ system under study remains within practical bounds, and far below that of typical system models, as it includes a class diagram with 68 classes and 49 constraints. The developed test validation and oracles tool can handle satellite transmission files up to two GB within practical time constraints, taking, on a standard PC, less than three minutes for test validation and less than 50 minutes for applying the oracle. The approach was also effective in automatically applying the oracle successfully for the actual test suite of the DAQ system, accurately identifying all issues and violations that were expected, thus showing that an approach based on models can be sufficiently accurate.","","","10.1109/ASE.2013.6693111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693111","","Unified modeling language;Data acquisition;Data models;Testing;Complexity theory;Context;Context modeling","automatic testing;data acquisition;file organisation;program testing;program verification;Unified Modeling Language","automated model based test validation;complex input structures;complex output structures;data acquisition systems;satellite communication industry;customised modelling methodology;test execution;complex industrial DAQ system;oracle execution time;class diagram;satellite transmission file handling;time constraints;standard PC","","6","32","","","","","IEEE","IEEE Conferences"
"Access-Path Abstraction: Scaling Field-Sensitive Data-Flow Analysis with Unbounded Access Paths (T)","J. Lerch; J. Späth; E. Bodden; M. Mezini","Tech. Univ. Darmstadt, Darmstadt, Germany; Fraunhofer SIT, Lancaster, UK; Tech. Univ. Darmstadt, Darmstadt, Germany; Tech. Univ. Darmstadt, Darmstadt, Germany","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","619","629","Precise data-flow analyses frequently model field accesses through access paths with varying length. While using longer access paths increases precision, their size must be bounded to assure termination, and should anyway be small to enable a scalable analysis. We present Access-Path Abstraction, which for the first time combines efficiency with maximal precision. At control-flow merge points Access-Path Abstraction represents all those access paths that are rooted at the same base variable through this base variable only. The full access paths are reconstructed on demand where required. This makes it unnecessary to bound access paths to a fixed maximal length. Experiments with Stanford SecuriBench and the Java Class Library compare our open-source implementation against a field-based approach and against a field-sensitive approach that uses bounded access paths. The results show that the proposed approach scales as well as a field-based approach, whereas the approach using bounded access paths runs out of memory.","","","10.1109/ASE.2015.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372049","static analysis;access path;field sensitive","Analytical models;Scalability;Explosions;Open source software;Context;Computational modeling;Target tracking","data flow analysis;Java;public domain software","access-path abstraction;field-sensitive data-flow analysis;unbounded access paths;field accesses;scalable analysis;control-flow merge points;Stanford SecuriBench;Java class library;open-source implementation;field-based approach","","8","20","","","","","IEEE","IEEE Conferences"
"Static Window Transition Graphs for Android (T)","S. Yang; H. Zhang; H. Wu; Y. Wang; D. Yan; A. Rountev","Ohio State Univ., Columbus, OH, USA; Ohio State Univ., Columbus, OH, USA; Ohio State Univ., Columbus, OH, USA; Ohio State Univ., Columbus, OH, USA; Google Inc., Mountain View, CA, USA; Ohio State Univ., Columbus, OH, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","658","668","This work develops a static analysis to create a model of the behavior of an Android application's GUI. We propose the window transition graph (WTG), a model representing the possible GUI window sequences and their associated events and callbacks. A key component and contribution of our work is the careful modeling of the stack of currently-active windows, the changes to this stack, and the effects of callbacks related to these changes. To the best of our knowledge, this is the first detailed study of this important static analysis problem for Android. We develop novel analysis algorithms for WTG construction and traversal, based on this modeling of the window stack. We also describe an application of the WTG for GUI test generation, using path traversals. The evaluation of the proposed algorithms indicates their effectiveness and practicality.","","","10.1109/ASE.2015.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372053","Android;GUI;static analysis;control-flow analysis;testing","Androids;Humanoid robots;Graphical user interfaces;Analytical models;Smart phones;Pressing;Hardware","graph theory;graphical user interfaces;mobile computing;program diagnostics;smart phones","window transition graph;WTG;Android;static analysis;graphical user interface;GUI window sequence;window stack modelling","","24","52","","","","","IEEE","IEEE Conferences"
"IntPTI: Automatic integer error repair with proper-type inference","X. Cheng; M. Zhou; X. Song; M. Gu; J. Sun","School of Software, TNLIST, KLISS, Tsinghua University, China; School of Software, TNLIST, KLISS, Tsinghua University, China; Electrical and Computer Engineering, Portland State University, USA; School of Software, TNLIST, KLISS, Tsinghua University, China; School of Software, TNLIST, KLISS, Tsinghua University, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","996","1001","Integer errors in C/C++ are caused by arithmetic operations yielding results which are unrepresentable in certain type. They can lead to serious safety and security issues. Due to the complicated semantics of C/C++ integers, integer errors are widely harbored in real-world programs and it is error-prone to repair them even for experts. An automatic tool is desired to 1) automatically generate fixes which assist developers to correct the buggy code, and 2) provide sufficient hints to help developers review the generated fixes and better understand integer types in C/C++. In this paper, we present a tool IntPTI that implements the desired functionalities for C programs. IntPTI infers appropriate types for variables and expressions to eliminate representation issues, and then utilizes the derived types with fix patterns codified from the successful human-written patches. IntPTI provides a user-friendly web interface which allows users to review and manage the fixes. We evaluate IntPTI on 7 real-world projects and the results show its competitive repair accuracy and its scalability on large code bases. The demo video for IntPTI is available at: https://youtu.be/9Tgd4A_FgZM.","","","10.1109/ASE.2017.8115718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115718","integer error;type inference;fix pattern","Maintenance engineering;Tools;Semantics;Security;Scalability;Runtime;Computer bugs","human computer interaction;inference mechanisms;Internet;probability;program debugging;program diagnostics;security of data;user interfaces","complicated semantics;C/C++ integers;integer errors;automatic tool;generated fixes;tool IntPTI;desired functionalities;appropriate types;derived types;fix patterns;competitive repair accuracy;automatic integer error repair;proper-type inference;arithmetic operations;security issues;integer types","","1","31","","","","","IEEE","IEEE Conferences"
"Managing software evolution through semantic history slicing","Y. Li","Department of Computer Science, University of Toronto, Toronto, ON, Canada","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1014","1017","Software change histories are results of incremental updates made by developers. As a side-effect of the software development process, version history is a surprisingly useful source of information for understanding, maintaining and reusing software. However, traditional commit-based sequential organization of version histories lacks semantic structure and thus are insufficient for many development tasks that require high-level, semantic understanding of program functionality, such as locating feature implementations and porting hot fixes. In this work, we propose to use well-organized unit tests as identifiers for corresponding software functionalities. We then present a family of automated techniques which analyze the semantics of historical changes and assist developers in many everyday practical settings. For validation, we evaluate our approaches on a benchmark of developer-annotated version history instances obtained from real-world open source software projects on GitHub.","","","10.1109/ASE.2017.8115722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115722","software changes;version histories;program analysis;software reuse","History;Semantics;Software;Computer bugs;Heuristic algorithms;Algorithm design and analysis","program slicing;program testing;public domain software;software maintenance;software reusability","semantic history slicing;incremental updates;software development process;sequential organization;semantic structure;program functionality;real-world open source software projects;software evolution management;software functionalities;software reuse;GitHub;software maintenance;software understanding","","","24","","","","","IEEE","IEEE Conferences"
"Ranger: Parallel analysis of alloy models by range partitioning","N. Rosner; J. H. Siddiqui; N. Aguirre; S. Khurshid; M. F. Frias","Department of Computer Science, FCEyN, UBA, Argentina; Department of Computer Science, LUMS School of Science and Engineering, Pakistan; Department of Computer Science, FCEFQyN, UNRC, Argentina; Department of Electrical and Computer Engineering, The University of Texas at Austin, USA; Department of Software Engineering, Instituto Tecnológico de Buenos Aires, Argentina","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","147","157","We present a novel approach for parallel analysis of models written in Alloy, a declarative extension of first-order logic based on relations. The Alloy language is supported by the fully automatic Alloy Analyzer, which translates models into propositional formulas and uses off-the-shelf SAT technology to solve them. Our key insight is that the underlying constraint satisfaction problem can be split into subproblems of lesser complexity by using ranges of candidate solutions, which partition the space of all candidate solutions. Conceptually, we define a total ordering among the candidate solutions, split this space of candidates into ranges, and let independent SAT searches take place within these ranges' endpoints. Our tool, Ranger, embodies our insight. Experimental evaluation shows that Ranger provides substantial speedups (in several cases, superlinear ones) for a variety of hard-to-solve Alloy models, and that adding more hardware reduces analysis costs almost linearly.","","","10.1109/ASE.2013.6693075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693075","Static analysis;Alloy;Parallel analysis;SAT","Metals;Analytical models;Partitioning algorithms;Computational modeling;Hardware;Vectors;Scalability","computability;constraint satisfaction problems;parallel processing;specification languages","parallel analysis;range partitioning;first-order logic;Alloy language models;propositional formulas;off-the-shelf SAT technology;constraint satisfaction problem;candidate solution space partitioning;range endpoints;Ranger tool;analysis cost reduction;Alloy Analyzer","","6","40","","","","","IEEE","IEEE Conferences"
"Parallel bug-finding in concurrent programs via reduced interleaving instances","T. L. Nguyen; P. Schrammel; B. Fischer; S. L. Torre; G. Parlato","University of Southampton, UK; University of Sussex, UK; Stellenbosch University, South Africa; Universita degli Studi di Salerno, Italy; University of Southampton, UK","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","753","764","Concurrency poses a major challenge for program verification, but it can also offer an opportunity to scale when subproblems can be analysed in parallel. We exploit this opportunity here and use a parametrizable code-to-code translation to generate a set of simpler program instances, each capturing a reduced set of the original program's interleavings. These instances can then be checked independently in parallel. Our approach does not depend on the tool that is chosen for the final analysis, is compatible with weak memory models, and amplifies the effectiveness of existing tools, making them find bugs faster and with fewer resources. We use Lazy-CSeq as an off-the-shelf final verifier to demonstrate that our approach is able, already with a small number of cores, to find bugs in the hardest known concurrency benchmarks in a matter of minutes, whereas other dynamic and static tools fail to do so in hours.","","","10.1109/ASE.2017.8115686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115686","Verification;concurrency;sequentialization;swarm verification","Computer bugs;Tools;Concurrent computing;Instruction sets;Programming;Model checking","concurrency control;multi-threading;program debugging;program verification","weak memory models;off-the-shelf final verifier;dynamic tools;static tools;parallel bug-finding;concurrent programs;reduced interleaving instances;program verification;parametrizable code-to-code translation;simpler program instances;capturing a reduced set;original program;concurrency benchmarks","","3","50","","","","","IEEE","IEEE Conferences"
"FiB: Squeezing loop invariants by interpolation between forward/backward predicate transformers","S. Lin; J. Sun; H. Xiao; Y. Liu; D. Sanán; H. Hansen","School of Computer Science and Engineering, Nanyang Technological University, Singapore; Singapore University of Technology and Design, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Tampere University of Technology, Finland","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","793","803","Loop invariant generation is a fundamental problem in program analysis and verification. In this work, we propose a new approach to automatically constructing inductive loop invariants. The key idea is to aggressively squeeze an inductive invariant based on Craig interpolants between forward and backward reachability analysis. We have evaluated our approach by a set of loop benchmarks, and experimental results show that our approach is promising.","","","10.1109/ASE.2017.8115690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115690","","Reachability analysis;Interpolation;Tools;Syntactics;Sun;Computer science;Benchmark testing","formal verification;interpolation;program control structures;program diagnostics;program verification;reachability analysis","loop benchmarks;FiB;invariant generation;fundamental problem;program analysis;inductive loop invariants;inductive invariant;Craig interpolants;reachability analysis","","1","53","","","","","IEEE","IEEE Conferences"
"Crowd intelligence enhances automated mobile testing","K. Mao; M. Harman; Y. Jia","Facebook London, Facebook, 10 Brock Street, London, NW1 3FG, UK CREST, University College London, Malet Place, London, WC1E 6BT, UK; Facebook London, Facebook, 10 Brock Street, London, NW1 3FG, UK CREST, University College London, Malet Place, London, WC1E 6BT, UK; Facebook London, Facebook, 10 Brock Street, London, NW1 3FG, UK CREST, University College London, Malet Place, London, WC1E 6BT, UK","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","16","26","We show that information extracted from crowd-based testing can enhance automated mobile testing. We introduce Polariz, which generates replicable test scripts from crowd-based testing, extracting cross-app `motif' events: automatically-inferred reusable higher-level event sequences composed of lower-level observed event actions. Our empirical study used 434 crowd workers from Mechanical Turk to perform 1,350 testing tasks on 9 popular Google Play apps, each with at least 1 million user installs. The findings reveal that the crowd was able to achieve 60.5% unique activity coverage and proved to be complementary to automated search-based testing in 5 out of the 9 subjects studied. Our leave-one-out evaluation demonstrates that coverage attainment can be improved (6 out of 9 cases, with no disimprovement on the remaining 3) by combining crowd-based and search-based testing.","","","10.1109/ASE.2017.8115614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115614","Crowdsourced Software Engineering;Mobile App Testing;Test Generation","Testing;Mobile communication;Tools;Data mining;Androids;Humanoid robots;Mobile handsets","automatic testing;mobile computing;program testing","replicable test scripts;cross-app motif events;reusable higher-level event sequences;lower-level observed event actions;crowd workers;automated search;testing tasks;crowd intelligence;automated mobile testing;Google Play apps;crowd-based testing;search-based testing","","9","42","","","","","IEEE","IEEE Conferences"
"Supporting bug investigation using history analysis","F. Servant","University of California, Irvine, U.S.A.","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","754","757","In my research, I propose an automated technique to support bug investigation by using a novel analysis of the history of the source code. During the bug-fixing process, developers spend a high amount of manual effort investigating the bug in order to answer a series of questions about it. My research will support developers in answering the following questions about a bug: Who is the most suitable developer to fix the bug?, Where is the bug located?, When was the bug inserted? and Why was the bug inserted?","","","10.1109/ASE.2013.6693150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693150","","History;Visualization;Software;Software engineering;Computer bugs;Debugging;Conferences","program debugging;program diagnostics","bug investigation support;history analysis;automated technique;source code;bug-fixing process","","1","25","","","","","IEEE","IEEE Conferences"
"Tracking and Analyzing Cross-Cutting Activities in Developers' Daily Work (N)","L. Bao; Z. Xing; X. Wang; B. Zhou","Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","277","282","Developers use many software applications to process large amounts of diverse information in their daily work. The information is usually meaningful beyond the context of an application that manages it. However, as different applications function independently, developers have to manually track, correlate and re-find cross-cutting information across separate applications. We refer to this difficulty as information fragmentation problem. In this paper, we present ActivitySpace, an interapplication activity tracking and analysis framework for tackling information fragmentation problem in software development. ActivitySpace can monitor the developer's activity in many applications at a low enough level to obviate application-specific support while accounting for the ways by which low-level activity information can be effectively aggregated to reflect the developer's activity at higher-level of abstraction. A system prototype has been implemented on Microsoft Windows. Our preliminary user study showed that the ActivitySpace system is promising in supporting interapplication information needs in developers' daily work.","","","10.1109/ASE.2015.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372016","","Software;Monitoring;History;Java;Mice;Databases;Context","software development management","software application;information fragmentation problem;ActivitySpace;interapplication activity tracking;software development;cross-cutting activities","","8","22","","","","","IEEE","IEEE Conferences"
"Fixing Recurring Crash Bugs via Analyzing Q&A Sites (T)","Q. Gao; H. Zhang; J. Wang; Y. Xiong; L. Zhang; H. Mei","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","307","318","Recurring bugs are common in software systems, especially in client programs that depend on the same framework. Existing research uses human-written templates, and is limited to certain types of bugs. In this paper, we propose a fully automatic approach to fixing recurring crash bugs via analyzing Q&A sites. By extracting queries from crash traces and retrieving a list of Q&A pages, we analyze the pages and generate edit scripts. Then we apply these scripts to target source code and filter out the incorrect patches. The empirical results show that our approach is accurate in fixing real-world crash bugs, and can complement existing bug-fixing approaches.","","","10.1109/ASE.2015.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372020","","Computer bugs;Web pages;Search engines;Registers;Context;Software","program debugging;query processing;source code (software)","recurring crash bugs;Q&A sites;software systems;human-written templates;query extraction;crash traces;edit scripts;source code;real-world crash bugs;bug-fixing approaches","","27","58","","","","","IEEE","IEEE Conferences"
"Comprehensive failure characterization","M. J. Gerrard; M. B. Dwyer","University of Nebraska-Lincoln, Lincoln, NE, USA; University of Nebraska-Lincoln, Lincoln, NE, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","365","376","There is often more than one way to trigger a fault. Standard static and dynamic approaches focus on exhibiting a single witness for a failing execution. In this paper, we study the problem of computing a comprehensive characterization which safely bounds all failing program behavior while exhibiting a diversity of witnesses for those failures. This information can be used to facilitate software engineering tasks ranging from fault localization and repair to quantitative program analysis for reliability. Our approach combines the results of overapproximating and underapproximating static analyses in an alternating iterative framework to produce upper and lower bounds on the failing input space of a program, which we call a comprehensive failure characterization (CFC). We evaluated a prototype implementation of this alternating framework on a set of 168 C programs from the SV-COMP benchmarks, and the data indicate that it is possible to efficiently, accurately, and safely characterize failure spaces.","","","10.1109/ASE.2017.8115649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115649","","Upper bound;Tools;Maintenance engineering;Software;Manuals;Standards","iterative methods;program diagnostics;program verification;software engineering","comprehensive failure characterization;dynamic approaches focus;comprehensive characterization;program behavior;software engineering tasks;fault localization;quantitative program analysis;overapproximating analyses;underapproximating static analyses;alternating iterative framework;upper bounds;lower bounds","","1","52","","","","","IEEE","IEEE Conferences"
"Exploring regular expression comprehension","C. Chapman; P. Wang; K. T. Stolee","Sandia National Laboratories, Albuquerque, NM, USA; Department of Computer Science, North Carolina State University, USA; Department of Computer Science, North Carolina State University, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","405","416","The regular expression (regex) is a powerful tool employed in a large variety of software engineering tasks. However, prior work has shown that regexes can be very complex and that it could be difficult for developers to compose and understand them. This work seeks to identify code smells that impact comprehension. We conduct an empirical study on 42 pairs of behaviorally equivalent but syntactically different regexes using 180 participants and evaluate the understandability of various regex language features. We further analyze regexes in GitHub to find the community standards or the common usages of various features. We found that some regex expression representations are more understandable than others. For example, using a range (e.g., [0-9]) is often more understandable than a default character class (e.g., [\d]). We also found that the DFA size of a regex significantly affects comprehension for the regexes studied. The larger the DFA of a regex (up to size eight), the more understandable it was. Finally, we identify smelly and non-smelly regex representations based on a combination of community standards and understandability metrics.","","","10.1109/ASE.2017.8115653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115653","Regular expression comprehension;equivalence class;regex representations","Tools;Standards;Measurement;Pattern matching;Automata;Syntactics;Concrete","formal languages;software maintenance;software metrics","regular expression comprehension;regex language features;regex expression representations;nonsmelly regex representations;software engineering tasks;regexes;smelly regex representations;community standards;understandability metrics","","8","43","","","","","IEEE","IEEE Conferences"
"Automated unit testing of large industrial embedded software using concolic testing","Y. Kim; Y. Kim; Taeksu Kim; Gunwoo Lee; Y. Jang; M. Kim","CS Dept. KAIST, South Korea; Samsung Electronics, South Korea; Samsung Electronics, South Korea; Samsung Electronics, South Korea; Samsung Electronics, South Korea; CS Dept. KAIST, South Korea","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","519","528","Current testing practice in industry is often ineffective and slow to detect bugs, since most projects utilize manually generated test cases. Concolic testing alleviates this problem by automatically generating test cases that achieve high coverage. However, specialized execution platforms and resource constraints of embedded software hinder application of concolic testing to embedded software. To overcome these limitations, we have developed CONcrete and symBOLic (CONBOL) testing framework to unit test large size industrial embedded software automatically. To address the aforementioned limitations, CONBOL tests target units on a host PC platform by generating symbolic unit testing drivers/stubs automatically and applying heuristics to reduce false alarms caused by the imprecise drivers/stubs. We have applied CONBOL to four million lines long industrial embedded software and detected 24 new crash bugs. Furthermore, the development team of the target software adopted CONBOL to their development process to apply CONBOL to the revised target software regularly.","","","10.1109/ASE.2013.6693109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693109","","Testing;Computer bugs;Arrays;Embedded software;Hardware","embedded systems;program testing","automated unit testing;large size industrial embedded software;concolic testing;crash bugs detection;specialized execution platforms;embedded software resource constraints;concrete and symbolic testing framework;CONBOL testing framework;host PC platform;symbolic unit testing drivers;false alarm reduction;imprecise driver-stubs;heuristics","","18","36","","","","","IEEE","IEEE Conferences"
"AutoComment: Mining question and answer sites for automatic comment generation","E. Wong; Jinqiu Yang; Lin Tan","University of Waterloo, Ontario, Canada; University of Waterloo, Ontario, Canada; University of Waterloo, Ontario, Canada","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","562","567","Code comments improve software maintainability. To address the comment scarcity issue, we propose a new automatic comment generation approach, which mines comments from a large programming Question and Answer (Q&A) site. Q&A sites allow programmers to post questions and receive solutions, which contain code segments together with their descriptions, referred to as code-description mappings.We develop AutoComment to extract such mappings, and leverage them to generate description comments automatically for similar code segments matched in open-source projects. We apply AutoComment to analyze Java and Android tagged Q&A posts to extract 132,767 code-description mappings, which help AutoComment to generate 102 comments automatically for 23 Java and Android projects. The user study results show that the majority of the participants consider the generated comments accurate, adequate, concise, and useful in helping them understand the code.","","","10.1109/ASE.2013.6693113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693113","automated comment generation;documentation;program comprehension;natural language processing for software engineering","Java;Software;Androids;Humanoid robots;Databases;Cloning;Natural language processing","Android (operating system);data mining;Java;public domain software;question answering (information retrieval);software maintenance","AutoComment;programming question-and-answer site mining;automatic comment generation;code comments;software maintainability improvement;comment scarcity issue;code segments;open-source projects;Java tagged Q&A post analysis;Android tagged Q&A post analysis;code-description mapping extraction;program comprehension;natural language processing;software engineering","","61","23","","","","","IEEE","IEEE Conferences"
"String Analysis of Android Applications (N)","J. D. Vecchio; F. Shen; K. M. Yee; B. Wang; S. Y. Ko; L. Ziarek","NA; SUNY - Univ. at Buffalo, Buffalo, NY, USA; SUNY - Univ. at Buffalo, Buffalo, NY, USA; SUNY - Univ. at Buffalo, Buffalo, NY, USA; SUNY - Univ. at Buffalo, Buffalo, NY, USA; SUNY - Univ. at Buffalo, Buffalo, NY, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","680","685","The desire to understand mobile applications has resulted in researchers adapting classical static analysis techniques to the mobile domain. Examination of data and control flows in Android apps is now a common practice to classify them. Important to these analyses is a fine-grained examination and understanding of strings, since in Android they are heavily used in intents, URLs, reflection, and content providers. Rigorous analysis of string creation, usage, and value characteristics offers additional information to increase precision of app classification. This paper shows that inter-procedural static analysis that specifically targets string construction and usage can be used to reveal valuable insights for classifying Android apps. To this end, we first present case studies to illustrate typical uses of strings in Android apps. We then present the results of our analysis on real-world malicious and benign apps. Our analysis examines how strings are created and used for URL objects, Java reflection, and Android intents, and infers the actual string values used as much as possible. Our results demonstrate that string disambiguation based on creation, usage, and value indeed provides additional information that may be used to improve precision of classifying application behaviors.","","","10.1109/ASE.2015.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372055","","Androids;Humanoid robots;Smart phones;Uniform resource locators;Java;Malware;Servers","Android (operating system);Java","string analysis;Android applications;fine-grained examination;URL objects;Java reflection;Android intents;string disambiguation","","1","23","","","","","IEEE","IEEE Conferences"
"Towards a software vulnerability prediction model using traceable code patterns and software metrics","K. Z. Sultana","Department of Computer Science and Engineering, Mississippi State University, MS, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1022","1025","Software security is an important aspect of ensuring software quality. The goal of this study is to help developers evaluate software security using traceable patterns and software metrics during development. The concept of traceable patterns is similar to design patterns but they can be automatically recognized and extracted from source code. If these patterns can better predict vulnerable code compared to traditional software metrics, they can be used in developing a vulnerability prediction model to classify code as vulnerable or not. By analyzing and comparing the performance of traceable patterns with metrics, we propose a vulnerability prediction model. This study explores the performance of some code patterns in vulnerability prediction and compares them with traditional software metrics. We use the findings to build an effective vulnerability prediction model. We evaluate security vulnerabilities reported for Apache Tomcat, Apache CXF and three stand-alone Java web applications. We use machine learning and statistical techniques for predicting vulnerabilities using traceable patterns and metrics as features. We found that patterns have a lower false negative rate and higher recall in detecting vulnerable code than the traditional software metrics.","","","10.1109/ASE.2017.8115724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115724","","Predictive models;Software metrics;Security;Tools;Software;Testing","Internet;Java;learning (artificial intelligence);security of data;software metrics;software quality","software vulnerability prediction model;traceable code patterns;software security;software quality;traceable patterns;source code;vulnerable code;traditional software metrics;effective vulnerability prediction model;security vulnerabilities","","2","14","","","","","IEEE","IEEE Conferences"
"Software model checking for distributed systems with selector-based, non-blocking communication","C. Artho; M. Hagiya; R. Potter; Y. Tanabe; F. Weitl; M. Yamamoto","AIST/RISEC, Amagasaki, Japan; The University of Tokyo, Japan; The University of Tokyo, Japan; National Institute of Informatics, Tokyo, Japan; Chiba University, Japan; Chiba University, Japan","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","169","179","Many modern software systems are implemented as client/server architectures, where a server handles multiple clients concurrently. Testing does not cover the outcomes of all possible thread and communication schedules reliably. Software model checking, on the other hand, covers all possible outcomes but is often limited to subsets of commonly used protocols and libraries. Earlier work in cache-based software model checking handles implementations using socket-based TCP/IP networking, with one thread per client connection using blocking input/output. Recently, servers using non-blocking, selector-based input/output have become prevalent. This paper describes our work extending the Java PathFinder extension net-iocache to such software, and the application of our tool to modern server software.","","","10.1109/ASE.2013.6693077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693077","software model checking;caching;software verification;distributed systems;non-blocking input/output;selector-based input/output","Servers;Java;Software;Message systems;Libraries;Model checking;Computer architecture","client-server systems;formal verification","distributed systems;selector-based nonblocking communication;client-server architectures;thread schedule;communication schedule;cache-based software model checking;socket-based TCP-IP networking;transport control protocol;Internet protocol;blocking input-output;Java PathFinder extension;input-output cache;server software","","10","23","","","","","IEEE","IEEE Conferences"
"Automated planning for software architecture evolution","J. M. Barnes; A. Pandey; D. Garlan","Institute for Software Research, Carnegie Mellon University, Pittsburgh, PA, USA; Institute for Software Research, Carnegie Mellon University, Pittsburgh, PA, USA; Institute for Software Research, Carnegie Mellon University, Pittsburgh, PA, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","213","223","In previous research, we have developed a theoretical framework to help software architects make better decisions when planning software evolution. Our approach is based on representation and analysis of candidate evolution paths-sequences of transitional architectures leading from the current system to a desired target architecture. One problem with this kind of approach is that it imposes a heavy burden on the software architect, who must explicitly define and model these candidate paths. In this paper, we show how automated planning techniques can be used to support automatic generation of evolution paths, relieving this burden on the architect. We illustrate our approach by applying it to a data migration scenario, showing how this architecture evolution problem can be translated into a planning problem and solved using existing automated planning tools.","","","10.1109/ASE.2013.6693081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693081","","Computer architecture;Planning;Software architecture;Software;Connectors;Measurement;Availability","planning;software architecture","software architecture evolution;candidate evolution paths;transitional architectures;target architecture;automated planning techniques;automatic generation;data migration scenario;architecture evolution problem;automated planning tools","","12","28","","","","","IEEE","IEEE Conferences"
"Quick verification of concurrent programs by iteratively relaxed scheduling","P. Metzler; H. Saissi; P. Bokor; N. Suri","Technische Univeristät Darmstadt, Germany; Technische Univeristät Darmstadt, Germany; Technische Univeristät Darmstadt, Germany; Technische Univeristät Darmstadt, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","776","781","The most prominent advantage of software verification over testing is a rigorous check of every possible software behavior. However, large state spaces of concurrent systems, due to non-deterministic scheduling, result in a slow automated verification process. Therefore, verification introduces a large delay between completion and deployment of concurrent software. This paper introduces a novel iterative approach to verification of concurrent programs that drastically reduces this delay. By restricting the execution of concurrent programs to a small set of admissible schedules, verification complexity and time is drastically reduced. Iteratively adding admissible schedules after their verification eventually restores non-deterministic scheduling. Thereby, our framework allows to find a sweet spot between a low verification delay and sufficient execution time performance. Our evaluation of a prototype implementation on well-known benchmark programs shows that after verifying only few schedules of the program, execution time overhead is competitive to existing deterministic multi-threading frameworks.","","","10.1109/ASE.2017.8115688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115688","","Schedules;Delays;Concurrent computing;Programming;Model checking;Software","concurrency control;iterative methods;multi-threading;program verification;scheduling","quick verification;iteratively relaxed scheduling;software verification;rigorous check;concurrent systems;nondeterministic scheduling;slow automated verification process;concurrent software;iterative approach;admissible schedules;verification complexity;low verification delay;sufficient execution time performance;software behavior;concurrent program verification;execution time overhead;deterministic multithreading frameworks","","","19","","","","","IEEE","IEEE Conferences"
"Parsimony: An IDE for example-guided synthesis of lexers and parsers","A. Leung; S. Lerner","University of California, San Diego, USA; University of California, San Diego, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","815","825","We present Parsimony, a programming-by-example development environment for synthesizing lexers and parsers by example. Parsimony provides a graphical interface in which the user presents examples simply by selecting and labeling sample text in a text editor. An underlying synthesis engine then constructs syntactic rules to solve the system of constraints induced by the supplied examples. Parsimony is more expressive and usable than prior programming-by-example systems for parsers in several ways: Parsimony can (1) synthesize lexer rules in addition to productions, (2) solve for much larger constraint systems over multiple examples, rather than handling examples one-at-a-time, and (3) infer much more complex sets of productions, such as entire algebraic expression grammars, by detecting instances of well-known grammar design patterns. The results of a controlled user study across 18 participants show that users are able to perform lexing and parsing tasks faster and with fewer mistakes when using Parsimony as compared to a traditional parsing workflow.","","","10.1109/ASE.2017.8115692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115692","Lexer;parser;program synthesis;programming-by-example","Automata;Grammar;Syntactics;Data structures;Standards","computational linguistics;grammars;graphical user interfaces;program compilers","supplied examples;Parsimony;programming-by-example systems;example-guided synthesis;programming-by-example development environment;synthesize lexer rules;synthesis engine","","","28","","","","","IEEE","IEEE Conferences"
"Sketch-guided GUI test generation for mobile applications","C. Zhang; H. Cheng; E. Tang; X. Chen; L. Bu; X. Li","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","38","43","Mobile applications with complex GUIs are very popular today. However, generating test cases for these applications is often tedious professional work. On the one hand, manually designing and writing elaborate GUI scripts requires expertise. On the other hand, generating GUI scripts with record and playback techniques usually depends on repetitive work that testers need to interact with the application over and over again, because only one path is recorded in an execution. Automatic GUI testing focuses on exploring combinations of GUI events. As the number of combinations is huge, it is still necessary to introduce a test interface for testers to reduce its search space. This paper presents a sketch-guided GUI test generation approach for testing mobile applications, which provides a simple but expressive interface for testers to specify their testing purposes. Testers just need to draw a few simple strokes on the screenshots. Then our approach translates the strokes to a testing model and initiates a model-based automatic GUI testing. We evaluate our sketch-guided approach on a few real-world Android applications collected from the literature. The results show that our approach can achieve higher coverage than existing automatic GUI testing techniques with just 10-minute sketching for an application.","","","10.1109/ASE.2017.8115616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115616","","Graphical user interfaces;Testing;Layout;Shape;Connectors;Mobile applications;Grammar","graphical user interfaces;mobile computing;program testing","mobile applications;professional work;elaborate GUI scripts;playback techniques;GUI events;test interface;GUI test generation approach;real-world Android applications;automatic GUI testing techniques","","2","23","","","","","IEEE","IEEE Conferences"
"Detecting and fixing emergent behaviors in Distributed Software Systems using a message content independent method","F. Hendijani Fard","Department of Electrical and Computer Engineering, University of Calgary, 2500 University DR., N.W., Alberta, Canada (T2N 1N4)","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","746","749","This research is intended to automatically detect emergent behaviors of scenario based Distributed Software Systems (DSS) in design phase. The direct significance of our work is reducing the cost of verifying DSS for unexpected behavior in execution time. Existing approaches have some drawbacks which we try to cover in our work. The main contributions are modeling the DSS components as a social network and not using behavioral modeling, detecting components with no emergent behavior, and investigating the interactions of instances of one type.","","","10.1109/ASE.2013.6693148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693148","Emergent behavior;distributed software system;multiagent system","Decision support systems;Model checking;Multi-agent systems;Conferences;Unified modeling language;Social network services;Educational institutions","distributed processing;formal verification;social networking (online)","emergent behavior;distributed software system;message content independent method;DSS component;social network","","","27","","","","","IEEE","IEEE Conferences"
"Perceived language complexity in GitHub issue discussions and their effect on issue resolution","D. Kavaler; S. Sirovica; V. Hellendoorn; R. Aranovich; V. Filkov","Department of Computer Science, University of California at Davis, USA; Department of Computer Science, University of California at Davis, USA; Department of Computer Science, University of California at Davis, USA; Department of Linguistics, University of California at Davis, USA; Department of Computer Science, University of California at Davis, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","72","83","Modern software development is increasingly collaborative. Open Source Software (OSS) are the bellwether; they support dynamic teams, with tools for code sharing, communication, and issue tracking. The success of an OSS project is reliant on team communication. E.g., in issue discussions, individuals rely on rhetoric to argue their position, but also maintain technical relevancy. Rhetoric and technical language are on opposite ends of a language complexity spectrum: the former is stylistically natural; the latter is terse and concise. Issue discussions embody this duality, as developers use rhetoric to describe technical issues. The style mix in any discussion can define group culture and affect performance, e.g., issue resolution times may be longer if discussion is imprecise. Using GitHub, we studied issue discussions to understand whether project-specific language differences exist, and to what extent users conform to a language norm. We built project-specific and overall GitHub language models to study the effect of perceived language complexity on multiple responses. We find that experienced users conform to project-specific language norms, popular individuals use overall GitHub language rather than project-specific language, and conformance to project-specific language norms reduces issue resolution times. We also provide a tool to calculate project-specific perceived language complexity.","","","10.1109/ASE.2017.8115620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115620","","Complexity theory;Pragmatics;Rhetoric;Speech;Software;Standards;Employment","Internet;public domain software;software maintenance;specification languages","GitHub issue discussions;modern software development;Open Source Software;issue tracking;OSS project;team communication;technical language;language complexity spectrum;technical issues;issue resolution times;project-specific language differences;language norm;GitHub language;project-specific perceived language complexity;code sharing;technical relevancy;rhetoric language","","1","50","","","","","IEEE","IEEE Conferences"
"Preventing erosion of architectural tactics through their strategic implementation, preservation, and visualization","M. Mirakhorli","DePaul University, School of Computing, Chicago, IL 60604, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","762","765","Nowadays, a successful software production is increasingly dependent on how the final deployed system addresses customers' and users' quality concerns such as security, reliability, availability, interoperability, performance and many other types of such requirements. In order to satisfy such quality concerns, software architects are accountable for devising and comparing various alternate solutions, assessing the trade-offs, and finally adopting strategic design decisions which optimize the degree to which each of the quality concerns is satisfied. Although designing and implementing a good architecture is necessary, it is not usually enough. Even a good architecture can deteriorate in subsequent releases and then fail to address those concerns for which it was initially designed. In this work, we present a novel traceability approach for automating the construction of traceabilty links for architectural tactics and utilizing those links to implement a change impact analysis infrastructure to mitigate the problem of architecture degradation. Our approach utilizes machine learning methods to detect tactic-related classes. The detected tactic-related classes are then mapped to a Tactic Traceability Pattern. We train our trace algorithm using code extracted from fifty performance-centric and safety-critical open source software systems and then evaluate it against a real case study.","","","10.1109/ASE.2013.6693152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693152","Architecture;traceability;tactics;traceability patterns;machine learning","Computer architecture;Software;Heart beat;Software architecture;Software reliability","learning (artificial intelligence);safety-critical software;software architecture;software quality","architectural tactic;software production;security;reliability;interoperability;software architect;traceabilty link;change impact analysis infrastructure;machine learning;tactic-related class;tactic traceability pattern;performance-centric open source software system;safety-critical open source software system","","1","25","","","","","IEEE","IEEE Conferences"
"Automated Tagging of Software Projects Using Bytecode and Dependencies (N)","S. Vargas-Baldrich; M. Linares-Vásquez; D. Poshyvanyk","Univ. Nac. de Colombia, Bogota, Colombia; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","289","294","Several open and closed source repositories group software systems and libraries to allow members of particular organizations or the open source community to take advantage of them. However, to make this possible, it is necessary to have effective ways of searching and browsing the repositories. Software tagging is the process of assigning terms (i.e., tags or labels) to software assets in order to describe features and internal details, making the task of understanding software easier and potentially browsing and searching through a repository more effective. We present Sally, an automatic software tagging approach that is able to produce meaningful tags for Maven-based software projects by analyzing their bytecode and dependency relations without any special requirements from developers. We compared tags generated by Sally to the ones in two widely used online repositories, and the tags generated by a state-of-the-art categorization approach. The results suggest that Sally is able to generate expressive tags without relying on machine learning-based models.","","","10.1109/ASE.2015.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372018","","Feature extraction;Tagging;Data mining;Software systems;Software algorithms;Support vector machines","information retrieval;Internet;project management;public domain software;software management","closed source repository group software systems;open source repository group software systems;open source community;term assignment;software tagging;software assets;automatic software tagging approach;Maven-based software projects;bytecode;dependency relations;online repositories;categorization approach;Sally","","5","21","","","","","IEEE","IEEE Conferences"
"Synthesizing Web Element Locators (T)","K. Bajaj; K. Pattabiraman; A. Mesbah","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","331","341","To programmatically interact with the user interface of a web application, element locators are used to select and retrieve elements from the Document Object Model (DOM). Element locators are used in JavaScript code, Cascading stylesheets, and test cases to interact with the runtime DOM of the webpage. Constructing these element locators is, however, challenging due to the dynamic nature of the DOM. We find that locators written by web developers can be quite complex, and involve selecting multiple DOM elements. We present an automated technique for synthesizing DOM element locators using examples provided interactively by the developer. The main insight in our approach is that the problem of synthesizing complex multi-element locators can be expressed as a constraint solving problem over the domain of valid DOM states in a web application. We implemented our synthesis technique in a tool called LED, which provides an interactive drag and drop support inside the browser for selecting positive and negative examples. We find that LED supports at least 86% of the locators used in the JavaScript code of deployed web applications, and that the locators synthesized by LED have a recall of 98% and a precision of 63%. LED is fast, taking only 0.23 seconds on average to synthesize a locator.","","","10.1109/ASE.2015.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372022","Program synthesis;Programming by example;Element locators;CSS selectors;Web applications","Light emitting diodes;Cascading style sheets;Mathematical model;Writing;HTML;Navigation;Programming","Internet;Java;online front-ends;program testing;user interfaces","Web element locator synthesis;user interface;document object model;DOM;JavaScript code;Webpage;DOM element locator synthesis;Web application;LED;program synthesis;live editor-for-DOM","","2","36","","","","","IEEE","IEEE Conferences"
"Improved query reformulation for concept location using CodeRank and document structures","M. M. Rahman; C. K. Roy","Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","428","439","During software maintenance, developers usually deal with a significant number of software change requests. As a part of this, they often formulate an initial query from the request texts, and then attempt to map the concepts discussed in the request to relevant source code locations in the software system (a.k.a., concept location). Unfortunately, studies suggest that they often perform poorly in choosing the right search terms for a change task. In this paper, we propose a novel technique-ACER-that takes an initial query, identifies appropriate search terms from the source code using a novel term weight-CodeRank, and then suggests effective reformulation to the initial query by exploiting the source document structures, query quality analysis and machine learning. Experiments with 1,675 baseline queries from eight subject systems report that our technique can improve 71% of the baseline queries which is highly promising. Comparison with five closely related existing techniques in query reformulation not only validates our empirical findings but also demonstrates the superiority of our technique.","","","10.1109/ASE.2017.8115655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115655","Query reformulation;CodeRank;term weighting;query quality analysis;concept location;data resampling","Natural languages;Periodic structures;Measurement;Java;Software maintenance","learning (artificial intelligence);query formulation;query processing;software maintenance;source code (software);text analysis","initial query;request texts;relevant source code locations;software system;concept location;source document structures;query quality analysis;machine learning;improved query reformulation;software maintenance;software change requests;baseline queries;weight-CodeRank;search terms","","5","55","","","","","IEEE","IEEE Conferences"
"Multi-user variability configuration: A game theoretic approach","J. García-Galán; P. Trinidad; A. Ruiz-Cortés","Dept. Languages and Computer Systems, University of Seville, Spain; Dept. Languages and Computer Systems, University of Seville, Spain; Dept. Languages and Computer Systems, University of Seville, Spain","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","574","579","Multi-user configuration is a neglected problem in variability-intensive systems area. The appearance of conflicts among user configurations is a main concern. Current approaches focus on avoiding such conflicts, applying the mutual exclusion principle. However, this perspective has a negative impact on users satisfaction, who cannot make any decision fairly. In this work, we propose an interpretation of multi-user configuration as a game theoretic problem. Game theory is a well-known discipline which analyzes conflicts and cooperation among intelligent rational decision-makers. We present a taxonomy of multi-user configuration approaches, and how they can be interpreted as different problems of game theory. We focus on cooperative game theory to propose and automate a tradeoff-based bargaining approach, as a way to solve the conflicts and maximize user satisfaction at the same time.","","","10.1109/ASE.2013.6693115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693115","","Games;Frequency modulation;Game theory;Smart homes;Video on demand;Internet;Proposals","game theory;human computer interaction","multiuser variability configuration;game theoretic approach;intelligent rational decision-makers;multiuser configuration taxonomy;cooperative game theory;tradeoff-based bargaining approach","","1","17","","","","","IEEE","IEEE Conferences"
"Development History Granularity Transformations (N)","K. Muslu; L. Swart; Y. Brun; M. D. Ernst","Univ. of Washington, Seattle, WA, USA; Univ. of Washington, Seattle, WA, USA; Univ. of Washington, Seattle, WA, USA; Univ. of Massachusetts, Amherst, MA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","697","702","Development histories can simplify some software engineering tasks, butdifferent tasks require different history granularities. For example, a history that includes every edit that resulted in compiling code is needed when searching for the cause of a regression, whereas a history that contains only changes relevant to a feature is needed for understanding the evolution of the feature. Unfortunately, today, both manual and automated history generation result in a single-granularity history. This paper introduces the concept of multi-grained development history views and the architecture of Codebase Manipulation, a tool that automatically records a fine-grained history and manages its granularity by applying granularity transformations.","","","10.1109/ASE.2015.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372057","automated version control;fine-grained development history;history rewriting;history transformation;Codebase Manipulation","History;Compounds;Manuals;Maintenance engineering;Software;Computer architecture;Transforms","regression analysis;software engineering","development history granularity transformations;software engineering tasks;compiling code;regression;automated history generation;single-granularity history;multigrained development history views;Codebase Manipulation","","6","50","","","","","IEEE","IEEE Conferences"
"Generating Qualifiable Avionics Software: An Experience Report (E)","A. Wölfl; N. Siegmund; S. Apel; H. Kosch; J. Krautlager; G. Weber-Urbina","Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Airbus Helicopters S.A.S., Germany; Airbus Helicopters S.A.S., Germany","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","726","736","We report on our experience with enhancing the data-management component in the avionics software of the NH90 helicopter at Airbus Helicopters. We describe challenges regarding the evolution of avionics software by means of real-world evolution scenarios that arise in industrial practice. A key role plays a legally-binding certification process, called qualification, which is responsible for most of the development effort and cost. To reduce effort and cost, we propose a novel generative approach to develop qualifiable avionics software by combining model-based and product-line technology. Using this approach, we have already generated code that is running on the NH90 helicopter and that is in the process of replacing the current system code. Based on an interview with two professional developers at Airbus and an analysis of the software repository of the NH90, we systematically compare our approach with established development approaches in the avionics domain, in terms of implementation and qualification effort.","","","10.1109/ASE.2015.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372061","","Aerospace electronics;Helicopters;System software;Interviews;Hardware;Encoding","avionics;helicopters;program compilers;software engineering","qualifiable avionics software;data-management component;NH90 helicopter;Airbus helicopter;legally-binding certification process;model-based technology;product-line technology;software repository analysis","","","26","","","","","IEEE","IEEE Conferences"
"Consistency-preserving edit scripts in model versioning","T. Kehrer; U. Kelter; G. Taentzer","Software Engineering Group, University of Siegen, Germany; Software Engineering Group, University of Siegen, Germany; Philipps-Universität Marburg, Germany","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","191","201","In model-based software development, models are iteratively evolved. To optimally support model evolution, developers need adequate tools for model versioning tasks, including comparison, patching, and merging of models. A significant disadvantage of tools currently available is that they display, and operate with, low-level model changes which refer to internal model representations and which can lead to intermediate inconsistent states. Higher-level consistency-preserving edit operations including refactorings are better suited to explain changes or to resolve conflicts. This paper presents an automatic procedure which transforms a low-level difference into an executable edit script which uses consistency-preserving edit operations only. Edit scripts support consistent model patching and merging on a higher abstraction level. Our approach to edit script generation has been evaluated in a larger real-world case study.","","","10.1109/ASE.2013.6693079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693079","","Unified modeling language;Merging;Semantics;Concrete;Adaptation models;Abstracts;Syntactics","configuration management;software tools","consistency preserving edit scripts;model versioning;software development;internal model representations;automatic procedure;model merging;model comparison;model patching;software tools","","21","41","","","","","IEEE","IEEE Conferences"
"SEDGE: Symbolic example data generation for dataflow programs","K. Li; C. Reichenbach; Y. Smaragdakis; Y. Diao; C. Csallner","Computer Science Department, University of Massachusetts, Amherst, USA; Institute of Informatics, Goethe University Frankfurt, Germany; Department of Informatics, University of Athens, Greece; Computer Science Department, University of Massachusetts, Amherst, USA; Computer Science and Engineering, University of Texas at Arlington, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","235","245","Exhaustive, automatic testing of dataflow (esp. mapreduce) programs has emerged as an important challenge. Past work demonstrated effective ways to generate small example data sets that exercise operators in the Pig platform, used to generate Hadoop map-reduce programs. Although such prior techniques attempt to cover all cases of operator use, in practice they often fail. Our SEDGE system addresses these completeness problems: for every dataflow operator, we produce data aiming to cover all cases that arise in the dataflow program (e.g., both passing and failing a filter). SEDGE relies on transforming the program into symbolic constraints, and solving the constraints using a symbolic reasoning engine (a powerful SMT solver), while using input data as concrete aids in the solution process. The approach resembles dynamic-symbolic (a.k.a. “concolic”) execution in a conventional programming language, adapted to the unique features of the dataflow domain. In third-party benchmarks, SEDGE achieves higher coverage than past techniques for 5 out of 20 PigMix benchmarks and 7 out of 11 SDSS benchmarks and (with equal coverage for the rest of the benchmarks). We also show that our targeting of the high-level dataflow language pays off: for complex programs, state-of-the-art dynamic-symbolic execution at the level of the generated map-reduce code (instead of the original dataflow program) requires many more test cases or achieves much lower coverage than our approach.","","","10.1109/ASE.2013.6693083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693083","","Concrete;Cognition;Benchmark testing;Programming;Educational institutions;Data processing;Extraterrestrial measurements","data flow analysis;program testing;programming languages;reasoning about programs;specification languages","symbolic example data generation;dataflow programs;automatic testing;mapreduce programs;pig platform;Hadoop map-reduce programs;operator use;SEDGE system;dataflow operator;symbolic constraints;symbolic reasoning engine;SMT solver;concolic execution;conventional programming language;dataflow domain;SDSS benchmarks;high-level dataflow language;complex programs;state-of-the-art dynamic-symbolic execution;map-reduce code;test cases","","5","26","","","","","IEEE","IEEE Conferences"
"Programming bots by synthesizing natural language expressions into API invocations","S. Zamanirad; B. Benatallah; M. C. Barukh; F. Casati; C. Rodriguez","School of Computer Science and Engineering, University of New South Wales (UNSW), Sydney, NSW 2052; School of Computer Science and Engineering, University of New South Wales (UNSW), Sydney, NSW 2052; School of Computer Science and Engineering, University of New South Wales (UNSW), Sydney, NSW 2052; University of Trento, Italy / Tomsk Polytechnic University, Russia; School of Computer Science and Engineering, University of New South Wales (UNSW), Sydney, NSW 2052","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","832","837","At present, bots are still in their preliminary stages of development. Many are relatively simple, or developed ad-hoc for a very specific use-case. For this reason, they are typically programmed manually, or utilize machine-learning classifiers to interpret a fixed set of user utterances. In reality, real world conversations with humans require support for dynamically capturing users expressions. Moreover, bots will derive immeasurable value by programming them to invoke APIs for their results. Today, within the Web and Mobile development community, complex applications are being stringed together with a few lines of code - all made possible by APIs. Yet, developers today are not as empowered to program bots in much the same way. To overcome this, we introduce BotBase, a bot programming platform that dynamically synthesizes natural language user expressions into API invocations. Our solution is two faceted: Firstly, we construct an API knowledge graph to encode and evolve APIs; secondly, leveraging the above we apply techniques in NLP, ML and Entity Recognition to perform the required synthesis from natural language user expressions into API calls.","","","10.1109/ASE.2017.8115694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115694","","Natural languages;Programming;Computational modeling;Concrete;Meteorology;Business;Machine learning","application program interfaces;learning (artificial intelligence);natural language processing;object-oriented programming","API;natural language user expression synthesis;BotBase;API knowledge graph;bot programming platform;users expressions;world conversations;user utterances;fixed set;machine-learning classifiers;specific use-case;API invocations;API calls","","1","27","","","","","IEEE","IEEE Conferences"
"Learn&Fuzz: Machine learning for input fuzzing","P. Godefroid; H. Peleg; R. Singh","Microsoft Research, USA; Technion, Israel; Microsoft Research, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","50","59","Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft's new Edge browser. We discuss and measure the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs.","","","10.1109/ASE.2017.8115618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115618","Fuzzing;Deep Learning;Grammar-based Fuzzing;Grammar Learning","Portable document format;Grammar;Training;Probability distribution;Recurrent neural networks","fuzzy set theory;grammars;learning (artificial intelligence);neural nets;probability;program debugging;program testing;security of data","machine learning;input fuzzing;security vulnerabilities;input-parsing code;complex input format;complex security-critical parser;conflicting learning;learnt input probability distribution;neural-network-based statistical machine-learning techniques;PDF parser;Microsoft's new Edge browser","","25","31","","","","","IEEE","IEEE Conferences"
"Are developers aware of the architectural impact of their changes?","M. Paixao; J. Krinke; D. Han; C. Ragkhitwetsagul; M. Harman","University College London, United Kingdom; University College London, United Kingdom; University College London, United Kingdom; University College London, United Kingdom; University College London, United Kingdom","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","95","105","Although considered one of the most important decisions in a software development lifecycle, empirical evidence on how developers perform and perceive architectural changes is still scarce. Given the large implications of architectural decisions, we do not know whether developers are aware of their changes' impact on the software's architecture, whether awareness leads to better changes, and whether automatically making developers aware would prevent degradation. Therefore, we use code review data of 4 open source systems to investigate the intent and awareness of developers when performing changes. We extracted 8,900 reviews for which the commits are available. 2,152 of the commits have changes in their computed architectural metrics, and 338 present significant changes to the architecture. We manually inspected all reviews for commits with significant changes and found that only in 38% of the time developers are discussing the impact of their changes on the architectural structure, suggesting a lack of awareness. Finally, we observed that developers tend to be more aware of the architectural impact of their changes when the architectural structure is improved, suggesting that developers should be automatically made aware when their changes degrade the architectural structure.","","","10.1109/ASE.2017.8115622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115622","Software Architecture;Code Reviews","Couplings;Computer architecture;Measurement;Java;History;Degradation;Software systems","software architecture;software engineering;software maintenance;software metrics;software quality","architectural changes;architectural decisions;computed architectural metrics;time developers;architectural structure;architectural impact;software development lifecycle","","8","44","","","","","IEEE","IEEE Conferences"
"Predicting Delays in Software Projects Using Networked Classification (T)","M. Choetkiertikul; H. K. Dam; T. Tran; A. Ghose","Sch. of Comput. & Inf. Technol., Univ. of Wollongong, Wollongong, NSW, Australia; Sch. of Comput. & Inf. Technol., Univ. of Wollongong, Wollongong, NSW, Australia; Sch. of Inf. Technol., Deakin Univ., Melbourne, VIC, Australia; Sch. of Comput. & Inf. Technol., Univ. of Wollongong, Wollongong, NSW, Australia","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","353","364","Software projects have a high risk of cost and schedule overruns, which has been a source of concern for the software engineering community for a long time. One of the challenges in software project management is to make reliable prediction of delays in the context of constant and rapid changes inherent in software projects. This paper presents a novel approach to providing automated support for project managers and other decision makers in predicting whether a subset of software tasks (among the hundreds to thousands of ongoing tasks) in a software project have a risk of being delayed. Our approach makes use of not only features specific to individual software tasks (i.e. local data) -- as done in previous work -- but also their relationships (i.e. networked data). In addition, using collective classification, our approach can simultaneously predict the degree of delay for a group of related tasks. Our evaluation results show a significant improvement over traditional approaches which perform classification on each task independently: achieving 46% -- 97% precision (49% improved), 46% -- 97% recall (28% improved), 56% -- 75% F-measure (39% improved), and 78% -- 95% Area Under the ROC Curve (16% improved).","","","10.1109/ASE.2015.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372024","Networked classification;Software analytics;Risk management;Machine Learning","Software;Delays;Predictive models;Risk management;Software engineering;Data mining;Information technology","pattern classification;project management;software engineering;software management","Networked Classification;software engineering community;software project management;ROC Curve;F-measure","","5","57","","","","","IEEE","IEEE Conferences"
"O2O service composition with social collaboration","W. Qian; X. Peng; J. Sun; Y. Yu; B. Nuseibeh; W. Zhao","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; Singapore University of Technology and Design, Singapore; School of Computing and Communications, The Open University, UK; School of Computing and Communications, The Open University, UK; School of Computer Science, Fudan University, Shanghai, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","451","461","In Online-to-Offline (O2O) commerce, customer services may need to be composed from online and offline services. Such composition is challenging, as it requires effective selection of appropriate services that, in turn, support optimal combination of both online and offline services. In this paper, we address this challenge by proposing an approach to O2O service composition which combines offline route planning and social collaboration to optimize service selection. We frame general O2O service composition problems using timed automata and propose an optimization procedure that incorporates: (1) a Markov Chain Monte Carlo (MCMC) algorithm to stochastically select a concrete composite service, and (2) a model checking approach to searching for an optimal collaboration plan with the lowest cost given certain time constraint. Our procedure has been evaluated using the simulation of a rich scenario on effectiveness and scalability.","","","10.1109/ASE.2017.8115657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115657","","Collaboration;Concrete;Libraries;Printing;Optimization;Quality of service;Planning","automata theory;customer services;electronic commerce;formal verification;Markov processes;Monte Carlo methods","O2O service composition;social collaboration;customer services;offline route planning;service selection;concrete composite service;optimal collaboration plan;Markov chain Monte Carlo algorithm;model checking;timed automata;online-to-offline coomerce;optimal combination","","2","31","","","","","IEEE","IEEE Conferences"
"Transfer learning for performance modeling of configurable systems: An exploratory analysis","P. Jamshidi; N. Siegmund; M. Velez; C. Kästner; A. Patel; Y. Agarwal","Carnegie Mellon University, USA; Bauhaus-University Weimar, Germany; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","497","508","Modern software systems provide many configuration options which significantly influence their non-functional properties. To understand and predict the effect of configuration options, several sampling and learning strategies have been proposed, albeit often with significant cost to cover the highly dimensional configuration space. Recently, transfer learning has been applied to reduce the effort of constructing performance models by transferring knowledge about performance behavior across environments. While this line of research is promising to learn more accurate models at a lower cost, it is unclear why and when transfer learning works for performance modeling. To shed light on when it is beneficial to apply transfer learning, we conducted an empirical study on four popular software systems, varying software configurations and environmental conditions, such as hardware, workload, and software versions, to identify the key knowledge pieces that can be exploited for transfer learning. Our results show that in small environmental changes (e.g., homogeneous workload change), by applying a linear transformation to the performance model, we can understand the performance behavior of the target environment, while for severe environmental changes (e.g., drastic workload change) we can transfer only knowledge that makes sampling more efficient, e.g., by reducing the dimensionality of the configuration space.","","","10.1109/ASE.2017.8115661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115661","Performance analysis;transfer learning","Hardware;Software systems;Analytical models;Predictive models;Mobile communication;Reliability","learning (artificial intelligence);program diagnostics;software engineering;software performance evaluation","transfer learning;performance modeling;configurable systems;highly dimensional configuration space;performance model;performance behavior;software configurations;software systems","","10","64","","","","","IEEE","IEEE Conferences"
"Learning effective query transformations for enhanced requirements trace retrieval","T. Dietrich; J. Cleland-Huang; Y. Shin","Center of Excellence for Software Traceability (CoEST), School of Computing, DePaul University, Chicago, IL, USA; Center of Excellence for Software Traceability (CoEST), School of Computing, DePaul University, Chicago, IL, USA; Center of Excellence for Software Traceability (CoEST), School of Computing, DePaul University, Chicago, IL, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","586","591","In automated requirements traceability, significant improvements can be realized through incorporating user feedback into the trace retrieval process. However, existing feedback techniques are designed to improve results for individual queries. In this paper we present a novel technique designed to extend the benefits of user feedback across multiple trace queries. Our approach, named Trace Query Transformation (TQT), utilizes a novel form of Association Rule Mining to learn a set of query transformation rules which are used to improve the efficacy of future trace queries. We evaluate TQT using two different kinds of training sets. The first represents an initial set of queries directly modified by human analysts, while the second represents a set of queries generated by applying a query optimization process based on initial relevance feedback for trace links between a set of source and target documents. Both techniques are evaluated using requirements from theWorldVista Healthcare system, traced against certification requirements for the Commission for Healthcare Information Technology. Results show that the TQT technique returns significant improvements in the quality of generated trace links.","","","10.1109/ASE.2013.6693117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693117","requirements traceability;query replacement;contractual requirements;text mining;machine learning;association rules","Training;Association rules;Itemsets;Medical services;Standards;Manuals;Educational institutions","data mining;formal verification;health care;learning (artificial intelligence);medical computing;program diagnostics;query processing;relevance feedback;text analysis","effective query transformation learning;requirement trace retrieval enhancement process;automated requirements traceability;user feedback;trace query transformation;association rule mining;training sets;query optimization process;relevance feedback;source documents;target documents;WorldVista Healthcare system;certification requirements;Commission for Healthcare Information Technology;TQT technique;machine learning;text mining;software engineering activities","","10","23","","","","","IEEE","IEEE Conferences"
"PYTHIA: Generating test cases with oracles for JavaScript applications","S. Mirshokraie; A. Mesbah; K. Pattabiraman","University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","610","615","Web developers often write test cases manually using testing frameworks such as Selenium. Testing JavaScript-based applications is challenging as manually exploring various execution paths of the application is difficult. Also JavaScript's highly dynamic nature as well as its complex interaction with the DOM make it difficult for the tester to achieve high coverage. We present a framework to automatically generate unit test cases for individual JavaScript functions. These test cases are strengthened by automatically generated test oracles capable of detecting faults in JavaScript code. Our approach is implemented in a tool called Pythia. Our preliminary evaluation results point to the efficacy of the approach in achieving high coverage and detecting faults.","","","10.1109/ASE.2013.6693121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693121","test generation;oracles;JavaScript;DOM","Testing;Instruments;Runtime;Browsers;Measurement;Java;Reactive power","automatic test software;Java;program testing;software fault tolerance;software tools;Web services","software tool;document object model;PYTHIA;JavaScript code;faults detection;automatic test oracles generation;JavaScript functions;DOM;complex interaction;manually execution path exploration;software testing;Web developer;JavaScript applications;automatic unit test case generation","","7","20","","","","","IEEE","IEEE Conferences"
"Automatic Detection of Potential Layout Faults Following Changes to Responsive Web Pages (N)","T. A. Walsh; P. McMinn; G. M. Kapfhammer","Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci., Allegheny Coll., USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","709","714","Due to the exponential increase in the number ofmobile devices being used to access the World Wide Web, it iscrucial that Web sites are functional and user-friendly across awide range of Web-enabled devices. This necessity has resulted in the introduction of responsive Web design (RWD), which usescomplex cascading style sheets (CSS) to fluidly modify a Web site's appearance depending on the viewport width of the device in use. Although existing tools may support the testing of responsive Web sites, they are time consuming and error-prone to use because theyrequire manual screenshot inspection at specified viewport widths. Addressing these concerns, this paper presents a method thatcan automatically detect potential layout faults in responsively designed Web sites. To experimentally evaluate this approach, weimplemented it as a tool, called ReDeCheck, and applied itto 5 real-world web sites that vary in both their approach toresponsive design and their complexity. The experiments revealthat ReDeCheck finds 91% of the inserted layout faults.","","","10.1109/ASE.2015.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372059","software testing;responsive web;empirical studies","Layout;Cascading style sheets;Web pages;HTML;Mobile handsets","fault diagnosis;human computer interaction;program testing;Web design","automatic layout fault detection;Web pages;mobile devices;World Wide Web;functional user-friendly Web sites;Web-enabled devices;responsive Web design;RWD;complex cascading style sheets;CSS;Web site appearance;responsive Web site testing;manual screenshot inspection;viewport widths;REDECHECK tool;inserted layout faults","","13","22","","","","","IEEE","IEEE Conferences"
"Mining User Opinions in Mobile App Reviews: A Keyword-Based Approach (T)","P. M. Vu; T. T. Nguyen; H. V. Pham; T. T. Nguyen","NA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","749","759","User reviews of mobile apps often contain complaints or suggestions which are valuable for app developers to improve user experience and satisfaction. However, due to the large volume and noisy-nature of those reviews, manually analyzing them for useful opinions is inherently challenging. To address this problem, we propose MARK, a keyword-based framework for semi-automated review analysis. MARK allows an analyst describing his interests in one or some mobile apps by a set of keywords. It then finds and lists the reviews most relevant to those keywords for further analysis. It can also draw the trends over time of those keywords and detect their sudden changes, which might indicate the occurrences of serious issues. To help analysts describe their interests more effectively, MARK can automatically extract keywords from raw reviews and rank them by their associations with negative reviews. In addition, based on a vector-based semantic representation of keywords, MARK can divide a large set of keywords into more cohesive subsets, or suggest keywords similar to the selected ones.","","","10.1109/ASE.2015.85","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372063","Opinion Mining;Review Analysis;Keyword","Batteries;Mobile communication;Dictionaries;Energy consumption;Data mining;Facebook","data mining;mobile computing","mining user opinion;mobile app review;keyword-based approach;app developer;user experience;user satisfaction;keyword-based framework;semiautomated review analysis;vector-based semantic representation;MARK","","27","32","","","","","IEEE","IEEE Conferences"
"Entropy-based test generation for improved fault localization","J. Campos; R. Abreu; G. Fraser; M. d'Amorim","Faculty of Engineering of University of Porto, Portugal; Faculty of Engineering of University of Porto, Portugal; University of Sheffield, United Kingdom; Federal University of Pernambuco, Brazil","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","257","267","Spectrum-based Bayesian reasoning can effectively rank candidate fault locations based on passing/failing test cases, but the diagnostic quality highly depends on the size and diversity of the underlying test suite. As test suites in practice often do not exhibit the necessary properties, we present a technique to extend existing test suites with new test cases that optimize the diagnostic quality. We apply probability theory concepts to guide test case generation using entropy, such that the amount of uncertainty in the diagnostic ranking is minimized. Our ENTBUG prototype extends the search-based test generation tool EVOSUITE to use entropy in the fitness function of its underlying genetic algorithm, and we applied it to seven real faults. Empirical results show that our approach reduces the entropy of the diagnostic ranking by 49% on average (compared to using the original test suite), leading to a 91% average reduction of diagnosis candidates needed to inspect to find the true faulty one.","","","10.1109/ASE.2013.6693085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693085","Fault localization;Test case generation","Entropy;Cognition;Uncertainty;Debugging;Genetic algorithms;Sociology;Statistics","belief networks;entropy;inference mechanisms;probability;program diagnostics;program testing;software fault tolerance","fitness function;EVOSUITE;search-based test generation tool;ENTBUG prototype;diagnostic ranking;entropy;test case generation;probability theory concepts;diagnostic quality;test suite;diagnostic quality;passing-failing test cases;spectrum-based Bayesian reasoning;improved fault localization;entropy-based test generation","","23","40","","","","","IEEE","IEEE Conferences"
"Systematic reduction of GUI test sequences","L. Cheng; Z. Yang; C. Wang","Western Michigan University, Kalamazoo, MI, USA; Western Michigan University, Kalamazoo, MI, USA; University of Southern California, Los Angeles, CA, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","849","860","Graphic user interface (GUI) is an integral part of many software applications. However, GUI testing remains a challenging task. The main problem is to generate a set of high-quality test cases, i.e., sequences of user events to cover the often large input space. Since manually crafting event sequences is labor-intensive and automated testing tools often have poor performance, we propose a new GUI testing framework to efficiently generate progressively longer event sequences while avoiding redundant sequences. Our technique for identifying the redundancy among these sequences relies on statically checking a set of simple and syntactic-level conditions, whose reduction power matches and sometimes exceeds that of classic techniques based on partial order reduction. We have evaluated our method on 17 Java Swing applications. Our experimental results show the new technique, while being sound and systematic, can achieve more than 10X reduction in the number of test sequences compared to the state-of-the-art GUI testing tools.","","","10.1109/ASE.2017.8115696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115696","","Graphical user interfaces;Testing;Tools;Systematics;Java;Redundancy","graphical user interfaces;Java;program testing","redundant sequences;partial order reduction;systematic reduction;GUI test sequences;graphic user interface;software applications;high-quality test cases;automated testing tools;Java Swing applications;syntactic-level condition","","","60","","","","","IEEE","IEEE Conferences"
"Detecting fragile comments","I. K. Ratol; M. P. Robillard","School of Computer Science, McGill University, Montreal, QC, Canada; School of Computer Science, McGill University, Montreal, QC, Canada","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","112","122","Refactoring is a common software development practice and many simple refactorings can be performed automatically by tools. Identifier renaming is a widely performed refactoring activity. With tool support, rename refactorings can rely on the program structure to ensure correctness of the code transformation. Unfortunately, the textual references to the renamed identifier present in the unstructured comment text cannot be formally detected through the syntax of the language, and are thus fragile with respect to identifier renaming. We designed a new rule-based approach to detect fragile comments. Our approach, called Fraco, takes into account the type of identifier, its morphology, the scope of the identifier and the location of comments. We evaluated the approach by comparing its precision and recall against hand-annotated benchmarks created for six target Java systems, and compared the results against the performance of Eclipse's automated in-comment identifier replacement feature. Fraco performed with near-optimal precision and recall on most components of our evaluation data set, and generally outperformed the baseline Eclipse feature. As part of our evaluation, we also noted that more than half of the total number of identifiers in our data set had fragile comments after renaming, which further motivates the need for research on automatic comment refactoring.","","","10.1109/ASE.2017.8115624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115624","Software evolution;refactoring;source code comments;inconsistent code;fragile comments","Tools;Java;Benchmark testing;Syntactics;Morphology;Semantics","Java;object-oriented programming;software maintenance;text analysis","in-comment identifier replacement feature;fragile comments;automatic comment refactoring;rename refactorings;program structure;renamed identifier present;unstructured comment text;Fraco;software development practice","","5","30","","","","","IEEE","IEEE Conferences"
"Model-Driven Allocation Engineering (T)","U. Pohlmann; M. Hüwe","Project Group Mechatron. Syst. Design, Fraunhofer IPT, Paderborn, Germany; Project Group Mechatron. Syst. Design, Fraunhofer IPT, Paderborn, Germany","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","374","384","Cyber-physical systems (CPSs) provide sophisticated functionality and are controlled by networked electronic control units (ECUs). Nowadays, software engineers use component-based development approaches to develop their software. Moreover, software components have to be allocated to an ECU to be executed. Engineers have to cope with topology-, software-, and timing-dependencies and memory-, scheduling-, and routing-constraints. Currently, engineers use linear programs to specify allocation constraints and to derive a feasible allocation automatically. However, encoding the allocation problem as a linear program is a complex and error-prone task. This paper contributes a model-driven, OCL-based allocation engineering approach for reducing the engineering effort and to avoid failures. We validate our approach with an automotive case study modeled with MechatronicUML. Our validation shows that we can specify allocation constraints with less engineering effort and are able to derive feasible allocations automatically.","","","10.1109/ASE.2015.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372026","Cyber-physical systems;Allocation;Deployment;Automotive;Constraints;MechatronicUML","Resource management;Software;Hardware;Actuators;Computer architecture;Brakes;Automotive engineering","constraint handling;cyber-physical systems;linear programming;object-oriented programming;resource allocation;Unified Modeling Language","model-driven allocation engineering;cyber-physical systems;CPS;networked electronic control units;ECU;software engineers;component-based development approach;software component allocation;topology-dependencies;software-dependencies;timing-dependencies;memory-constraints;routing-constraints;scheduling-constraints;linear programs;constraint allocation problem;model-driven OCL-based allocation engineering approach;MechatronicUML","","4","27","","","","","IEEE","IEEE Conferences"
"Executing Model-Based Tests on Platform-Specific Implementations (T)","D. You; S. Rayadurgam; M. P. E. Heimdahl; J. Komp; B. Kim; O. Sokolsky","Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN, USA; Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN, USA; Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN, USA; Medtronic PLC, USA; Dept. of Comput. & Inf. Sci., Univ. of Pennsylvania, Philadelphia, PA, USA; Dept. of Comput. & Inf. Sci., Univ. of Pennsylvania, Philadelphia, PA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","418","428","Model-based testing of embedded real-time systems is challenging because platform-specific details are often abstracted away to make the models amenable to various analyses. Testing an implementation to expose non-conformance to such a model requires reconciling differences arising from these abstractions. Due to stateful behavior, naive comparisons of model and system behaviors often fail causing numerous false positives. Previously proposed approaches address this by being reactively permissive: passing criteria are relaxed to reduce false positives, but may increase false negatives, which is particularly bothersome for safety-critical systems. To address this concern, we propose an automated approach that is proactively adaptive: test stimuli and system responses are suitably modified taking into account platform-specific aspects so that the modified test when executed on the platform-specific implementation exercises the intended scenario captured in the original model-based test. We show that the new framework eliminates false negatives while keeping the number of false positives low for a variety of platform-specific configurations.","","","10.1109/ASE.2015.64","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372030","Model-based testing;platform-specific implementation","Testing;Real-time systems;Computational modeling;Timing;Software;Monitoring;Hardware","embedded systems;program testing;safety-critical software","model-based testing;platform-specific configuration;embedded real-time system;safety-critical system","","","25","","","","","IEEE","IEEE Conferences"
"Diagnosing assumption problems in safety-critical products","M. Rahimi; W. Xiong; J. Cleland-Huang; R. Lutz","School of Computing, Depaul University, Chicago IL, USA; Computer Science, Iowa State University, Ames, IA, USA; Computer Science and Eng., University of Notre Dame, South Bend IN, USA; Computer Science, Iowa State University, Ames, IA, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","473","484","Problems with the correctness and completeness of environmental assumptions contribute to many accidents in safety-critical systems. The problem is exacerbated when products are modified in new releases or in new products of a product line. In such cases existing sets of environmental assumptions are often carried forward without sufficiently rigorous analysis. This paper describes a new technique that exploits the traceability required by many certifying bodies to reason about the likelihood that environmental assumptions are omitted or incorrectly retained in new products. An analysis of over 150 examples of environmental assumptions in historical systems informs the approach. In an evaluation on three safety-related product lines the approach caught all but one of the assumption-related problems. It also provided clearly defined steps for mitigating the identified issues. The contribution of the work is to arm the safety analyst with useful information for assessing the validity of environmental assumptions for a new product.","","","10.1109/ASE.2017.8115659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115659","Environmental assumptions;Safety-critical systems;Product lines;Software traceability","Software;Accidents;Computer science;Hazards;Software product lines;Inspection","production engineering computing;safety-critical software","environmental assumptions;safety-related product lines;assumption-related problems;safety-critical products;safety-critical systems","","1","62","","","","","IEEE","IEEE Conferences"
"A comprehensive study on real world concurrency bugs in Node.js","J. Wang; W. Dou; Y. Gao; C. Gao; F. Qin; K. Yin; J. Wei","State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China; Dept. of Computer Science and Engineering, The Ohio State University, United States; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","520","531","Node.js becomes increasingly popular in building server-side JavaScript applications. It adopts an event-driven model, which supports asynchronous I/O and non-deterministic event processing. This asynchrony and non-determinism can introduce intricate concurrency bugs, and leads to unpredictable behaviors. An in-depth understanding of real world concurrency bugs in Node.js applications will significantly promote effective techniques in bug detection, testing and fixing for Node.js. In this paper, we present NodeCB, a comprehensive study on real world concurrency bugs in Node.js applications. Specifically, we have carefully studied 57 real bug cases from open-source Node.js applications, and have analyzed their bug characteristics, e.g., bug patterns and root causes, bug impacts, bug manifestation, and fix strategies. Through this study, we obtain several interesting findings, which may open up many new research directions in combating concurrency bugs in Node.js. For example, one finding is that two thirds of the bugs are caused by atomicity violation. However, due to lack of locks and transaction mechanism, Node.js cannot easily express and guarantee the atomic intention.","","","10.1109/ASE.2017.8115663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115663","JavaScript;Node.js;event-driven;concurrency bug;empirical study","Computer bugs;Concurrent computing;Instruction sets;Open source software;Databases;Testing","concurrency control;Java;program debugging;program diagnostics;program testing","concurrency bugs;NodeCB;bug manifestation;bug impacts;bug patterns;open-source Node.js applications;bug detection;building server-side JavaScript applications","","5","65","","","","","IEEE","IEEE Conferences"
"Cloud Twin: Native execution of android applications on the Windows Phone","E. Holder; E. Shah; M. Davoodi; E. Tilevich","Dept. of Computer Science, Virginia Tech, Blacksburg, 24061, USA; Dept. of Computer Science, Virginia Tech, Blacksburg, 24061, USA; Dept. of Computer Science, Virginia Tech, Blacksburg, 24061, USA; Dept. of Computer Science, Virginia Tech, Blacksburg, 24061, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","598","603","To successfully compete in the software marketplace, modern mobile applications must run on multiple competing platforms, such as Android, iOS, and Windows Phone. Companies producing mobile applications spend substantial amounts of time, effort, and money to port applications across platforms. Creating individual program versions for different platforms further exacerbates the maintenance burden. This paper presents Cloud Twin, a novel approach to natively executing the functionality of a mobile application written for another platform. The functionality is accessed by means of dynamic cross-platform replay, in which the source application's execution in the cloud is mimicked natively on the target platform. The reference implementation of Cloud Twin natively emulates the behavior of Android applications on a Windows Phone. Specifically, Cloud Twin transmits, via web sockets, the UI actions performed on the Windows Phone to the cloud server, which then mimics the received actions on the Android emulator. The UI updates on the emulator are efficiently captured by means of Aspect Oriented Programming and sent back to be replayed on the Windows Phone. Our case studies with third-party applications indicate that the Cloud Twin approach can become a viable solution to the heterogeneity of the mobile application market.","","","10.1109/ASE.2013.6693119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693119","","Mobile communication;Smart phones;XML;Layout;Sockets;Servers;Androids","aspect-oriented programming;cloud computing;DP industry;market opportunities;mobile computing;operating systems (computers)","cloud twin;Android applications;Windows phone;software marketplace;mobile applications;dynamic cross-platform replay;cloud server;aspect oriented programming","","2","19","","","","","IEEE","IEEE Conferences"
"Automated inference of classifications and dependencies for combinatorial testing","Cu Duy Nguyen; P. Tonella","Fondazione Bruno Kessler, Trento, ITALY; Fondazione Bruno Kessler, Trento, ITALY","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","622","627","Even for small programs, the input space is huge - often unbounded. Partition testing divides the input space into disjoint equivalence classes and combinatorial testing selects a subset of all possible input class combinations, according to criteria such as pairwise coverage. The down side of this approach is that the partitioning of the input space into equivalence classes (input classification) is done manually. It is expensive and requires deep domain and implementation understanding. In this paper, we propose a novel approach to classify test inputs and their dependencies automatically. Firstly, random (or automatically generated) input vectors are sent to the system under test (SUT). For each input vector, an observed “hit vector” is produced by monitoring the execution of the SUT. Secondly, hit vectors are grouped into clusters using machine learning. Each cluster contains similar hit vectors, i.e., similar behaviors, and from them we obtain corresponding clusters of input vectors. Input classes are then extracted for each input parameter straightforwardly. Our experiments with a number of subjects show good results as the automatically generated classifications are the same or very close to the expected ones.","","","10.1109/ASE.2013.6693123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693123","Automated input classifications;combinatorial testing;invariant inference","Vectors;Testing;Concrete;Support vector machine classification;Systematics;Servers;Clustering algorithms","inference mechanisms;learning (artificial intelligence);pattern classification;program testing;reverse engineering","automated inference;combinatorial testing;partition testing;disjoint equivalence classes;input class combinations;pairwise coverage;input classification;deep domain understanding;implementation understanding;system under test;SUT;hit vector;machine learning;input parameter","","","13","","","","","IEEE","IEEE Conferences"
"Ensemble Methods for App Review Classification: An Approach for Software Evolution (N)","E. Guzman; M. El-Haliby; B. Bruegge","Tech. Univ. Munchen, Garching, Germany; Tech. Univ. Munchen, Garching, Germany; Tech. Univ. Munchen, Garching, Germany","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","771","776","App marketplaces are distribution platforms for mobile applications that serve as a communication channel between users and developers. These platforms allow users to write reviews about downloaded apps. Recent studies found that such reviews include information that is useful for software evolution. However, the manual analysis of a large amount of user reviews is a tedious and time consuming task. In this work we propose a taxonomy for classifying app reviews into categories relevant for software evolution. Additionally, we describe an experiment that investigates the performance of individual machine learning algorithms and its ensembles for automatically classifying the app reviews. We evaluated the performance of the machine learning techniques on 4550 reviews that were systematically labeled using content analysis methods. Overall, the ensembles had a better performance than the individual classifiers, with an average precision of 0.74 and 0.59 recall.","","","10.1109/ASE.2015.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372065","User Feedback;Software Evolution;App Reviews;Text Classification","Software;Taxonomy;Support vector machines;Manuals;Google;Labeling;Prediction algorithms","learning (artificial intelligence);mobile computing;pattern classification;software engineering","automatic application review classification;software evolution;mobile applications;communication channel;machine learning algorithms;content analysis methods;individual classifiers;ensemble methods","","33","27","","","","","IEEE","IEEE Conferences"
"Personalized defect prediction","T. Jiang; L. Tan; S. Kim","University of Waterloo, ON, Canada; University of Waterloo, ON, Canada; Hong Kong University of Science and Technology, China","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","279","289","Many defect prediction techniques have been proposed. While they often take the author of the code into consideration, none of these techniques build a separate prediction model for each developer. Different developers have different coding styles, commit frequencies, and experience levels, causing different defect patterns. When the defects of different developers are combined, such differences are obscured, hurting prediction performance. This paper proposes personalized defect prediction-building a separate prediction model for each developer to predict software defects. As a proof of concept, we apply our personalized defect prediction to classify defects at the file change level. We evaluate our personalized change classification technique on six large software projects written in C and Java-the Linux kernel, PostgreSQL, Xorg, Eclipse, Lucene and Jackrabbit. Our personalized approach can discover up to 155 more bugs than the traditional change classification (210 versus 55) if developers inspect the top 20% lines of code that are predicted buggy. In addition, our approach improves the F1-score by 0.01-0.06 compared to the traditional change classification.","","","10.1109/ASE.2013.6693087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693087","Change classification;machine learning;personalized defect prediction;software reliability","Predictive models;Vectors;Mars;Syntactics;Computer bugs;Training;Feature extraction","Java;Linux;program compilers","personalized defect prediction;separate prediction model;coding styles;commit frequencies;experience levels;different defect patterns;software defect prediction;C software projects;java software projects;Linux kernel;PostgreSQL;Xorg;Eclipse;Lucene;Jackrabbit","","61","59","","","","","IEEE","IEEE Conferences"
"Automatically partition software into least privilege components using dynamic data dependency analysis","Y. Wu; J. Sun; Y. Liu; J. S. Dong","Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Nanyang Technological University, Singapore; School of Computing, National University of Singapore, Singapore","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","323","333","The principle of least privilege requires that software components should be granted only necessary privileges, so that compromising one component does not lead to compromising others. However, writing privilege separated software is difficult and as a result, a large number of software is monolithic, i.e., it runs as a whole without separation. Manually rewriting monolithic software into privilege separated software requires significant effort and can be error prone. We propose ProgramCutter, a novel approach to automatically partitioning monolithic software using dynamic data dependency analysis. ProgramCutter works by constructing a data dependency graph whose nodes are functions and edges are data dependencies between functions. The graph is then partitioned into subgraphs where each subgraph represents a least privilege component. The privilege separated software runs each component in a separated process with confined system privileges. We evaluate it by applying it on four open source software. We can reduce the privileged part of the program from 100% to below 22%, while having a reasonable execution time overhead. Since ProgramCutter does not require any expert knowledge of the software, it not only can be used by its developers for software refactoring, but also by end users or system administrators. Our contributions are threefold: (i) we define a quantitative measure of the security and performance of privilege separation; (ii) we propose a graph-based approach to compute the optimal separation based on dynamic information flow analysis; and (iii) the separation process is automatic and does not require expert knowledge of the software.","","","10.1109/ASE.2013.6693091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693091","","Software;Authentication;Educational institutions;Writing;Databases;Performance analysis","data analysis;data flow graphs;program slicing","least privilege components;dynamic data dependency analysis;ProgramCutter;monolithic software automatic partitioning;data dependency graph;open source software;software refactoring;dynamic information flow analysis","","8","31","","","","","IEEE","IEEE Conferences"
"Synthetic data generation for statistical testing","G. Soltana; M. Sabetzadeh; L. C. Briand","SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","872","882","Usage-based statistical testing employs knowledge about the actual or anticipated usage profile of the system under test for estimating system reliability. For many systems, usage-based statistical testing involves generating synthetic test data. Such data must possess the same statistical characteristics as the actual data that the system will process during operation. Synthetic test data must further satisfy any logical validity constraints that the actual data is subject to. Targeting data-intensive systems, we propose an approach for generating synthetic test data that is both statistically representative and logically valid. The approach works by first generating a data sample that meets the desired statistical characteristics, without taking into account the logical constraints. Subsequently, the approach tweaks the generated sample to fix any logical constraint violations. The tweaking process is iterative and continuously guided toward achieving the desired statistical characteristics. We report on a realistic evaluation of the approach, where we generate a synthetic population of citizens' records for testing a public administration IT system. Results suggest that our approach is scalable and capable of simultaneously fulfilling the statistical representativeness and logical validity requirements.","","","10.1109/ASE.2017.8115698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115698","Test Data Generation;Usage-based Statistical Testing;Model-Driven Engineering;UML;OCL","Statistical analysis;Data models;Probabilistic logic;Generators;Unified modeling language;Reliability;Histograms","data analysis;formal logic;program testing;public administration;software reliability;statistical testing","synthetic test data;statistical representativeness;synthetic data generation;system reliability;data-intensive systems;usage profile;usage-based statistical testing;logical constraints;public administration IT system;logical validity requirements","","2","35","","","","","IEEE","IEEE Conferences"
"Automatically generating commit messages from diffs using neural machine translation","S. Jiang; A. Armaly; C. McMillan","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","135","146","Commit messages are a valuable resource in comprehension of software evolution, since they provide a record of changes such as feature additions and bug repairs. Unfortunately, programmers often neglect to write good commit messages. Different techniques have been proposed to help programmers by automatically writing these messages. These techniques are effective at describing what changed, but are often verbose and lack context for understanding the rationale behind a change. In contrast, humans write messages that are short and summarize the high level rationale. In this paper, we adapt Neural Machine Translation (NMT) to automatically ""translate"" diffs into commit messages. We trained an NMT algorithm using a corpus of diffs and human-written commit messages from the top 1k Github projects. We designed a filter to help ensure that we only trained the algorithm on higher-quality commit messages. Our evaluation uncovered a pattern in which the messages we generate tend to be either very high or very low quality. Therefore, we created a quality-assurance filter to detect cases in which we are unable to produce good messages, and return a warning instead.","","","10.1109/ASE.2017.8115626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115626","","Algorithm design and analysis;Software;Natural languages;Software algorithms;Machine learning;Computer bugs;Prediction algorithms","configuration management;language translation;program debugging;public domain software;software maintenance","diffs;neural machine translation;NMT;software evolution;automatic commit message generation","","15","59","","","","","IEEE","IEEE Conferences"
"ICoq: Regression proof selection for large-scale verification projects","A. Celik; K. Palmskog; M. Gligoric","University of Texas at Austin, Austin, TX-78712, USA; University of Illinois at Urbana-Champaign, Urbana, IL-61801, USA; University of Texas at Austin, Austin, TX-78712, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","171","182","Proof assistants such as Coq are used to construct and check formal proofs in many large-scale verification projects. As proofs grow in number and size, the need for tool support to quickly find failing proofs after revising a project increases. We present a technique for large-scale regression proof selection, suitable for use in continuous integration services, e.g., Travis CI. We instantiate the technique in a tool dubbed ICOQ. ICOQ tracks fine-grained dependencies between Coq definitions, propositions, and proofs, and only checks those proofs affected by changes between two revisions. ICOQ additionally saves time by ignoring changes with no impact on semantics. We applied ICOQ to track dependencies across many revisions in several large Coq projects and measured the time savings compared to proof checking from scratch and when using Coq's timestamp-based toolchain for incremental checking. Our results show that proof checking with ICOQ is up to 10 times faster than the former and up to 3 times faster than the latter.","","","10.1109/ASE.2017.8115630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115630","","Tools;Java;Time measurement;Software;Standards;Semantics","program testing;program verification;project management;regression analysis;theorem proving","Coq projects;proof checking;large-scale verification projects;proof assistants;formal proofs;large-scale regression proof selection;tool dubbed ICOQ;ICOQ additionally;incremental checking","","1","64","","","","","IEEE","IEEE Conferences"
"Automating the Extraction of Model-Based Software Product Lines from Model Variants (T)","J. Martinez; T. Ziadi; T. F. Bissyandé; J. Klein; Y. l. Traon","SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; UPMC Univ. Paris 06, Paris, France; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","396","406","We address the problem of automating 1) the analysis of existing similar model variants and 2) migrating them into a software product line. Our approach, named MoVaPL, considers the identification of variability and commonality in model variants, as well as the extraction of a CVL-compliant Model-based Software Product Line (MSPL) from the features identified on these variants. MoVaPL builds on a generic representation of models making it suitable to any MOF-based models. We apply our approach on variants of the open source ArgoUML UML modeling tool as well as on variants of an In-flight Entertainment System. Evaluation with these large and complex case studies contributed to show how our feature identification with structural constraints discovery and the MSPL generation process are implemented to make the approach valid (i.e., the extracted software product line can be used to regenerate all variants considered) and sound (i.e., derived variants We address the problem of automating 1) the analysis of existing similar model variants and 2) migrating them into a software product line. Our approach, named MoVaPL, considers the identification of variability and commonality in model variants, as well as the extraction of a CVL-compliant Model-based Software Product Line (MSPL) from the features identified on these variants. MoVaPL builds on a generic representation of models making it suitable to any MOF-based models. We apply our approach on variants of the open source ArgoUML UML modeling tool as well as on variants of an In-flight Entertainment System. Evaluation with these large and complex case studies contributed to show how our feature identification with structural constraints discovery and the MSPL generation process are implemented to make the approach valid (i.e., the extracted software product line can be used to regenerate all variants considered) and sound (i.e., derived variants which did not exist are at least structurally valid).which did not exist are at least structurally valid).","","","10.1109/ASE.2015.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372028","software product lines;model driven engineering;reverse engineering;model variants","Unified modeling language;Feature extraction;Computational modeling;Software product lines;Analytical models;Upper bound;Buildings","public domain software;software product lines;Unified Modeling Language","model variant analysis;MoVaPL approach;CVL-compliant model-based software product lines;common variability language;MOF-based models;open source ArgoUML UML modeling tool;in-flight entertainment system;MSPL generation process","","19","39","","","","","IEEE","IEEE Conferences"
"Testing Cross-Platform Mobile App Development Frameworks (T)","N. Boushehrinejadmoradi; V. Ganapathy; S. Nagarakatte; L. Iftode","NA; NA; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","441","451","Mobile app developers often wish to make their apps available on a wide variety of platforms, e.g., Android, iOS, and Windows devices. Each of these platforms uses a different programming environment, each with its own language and APIs for app development. Small app development teams lack the resources and the expertise to build and maintain separate code bases of the app customized for each platform. As a result, we are beginning to see a number of cross-platform mobile app development frameworks. These frameworks allow the app developers to specify the business logic of the app once, using the language and APIs of a home platform (e.g., Windows Phone), and automatically produce versions of the app for multiple target platforms (e.g., iOS and Android). In this paper, we focus on the problem of testing cross-platform app development frameworks. Such frameworks are challenging to develop because they must correctly translate the home platform API to the (possibly disparate) target platform API while providing the same behavior. We develop a differential testing methodology to identify inconsistencies in the way that these frameworks handle the APIs of the home and target platforms. We have built a prototype testing tool, called X-Checker, and have applied it to test Xamarin, a popular framework that allows Windows Phone apps to be cross-compiled into native Android (and iOS) apps. To date, X-Checker has found 47 bugs in Xamarin, corresponding to inconsistencies in the way that Xamarin translates between the semantics of the Windows Phone and the Android APIs. We have reported these bugs to the Xamarin developers, who have already committed patches for twelve of them.","","","10.1109/ASE.2015.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372032","Mobile apps;Cross-platform;Porting","Mobile communication;Smart phones;Computer bugs;Testing;Software;Libraries","Android (operating system);application program interfaces;mobile computing","cross-platform mobile app development frameworks;mobile app developers;Windows devices;programming environment;app development teams;multiple target platforms;home platform API;differential testing methodology;prototype testing tool;X-Checker;Windows Phone apps;Android apps;iOS apps;Android API;Xamarin developers","","4","43","","","","","IEEE","IEEE Conferences"
"A demonstration of simultaneous execution and editing in a development environment","S. P. Reiss; Q. Xin","Department of Computer Science, Brown University, Providence, RI 02912, USA; Department of Computer Science, Brown University, Providence, RI 02912, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","895","900","We introduce a tool within the Code Bubbles development environment that allows for continuous execution as the programmer edits. The tool, SEEDE, shows both the intermediate and final results of execution in terms of variables, control flow, output, and graphics. These results are updated as the user edits. The user can explore the execution to find or fix bugs or use the intermediate values to help write appropriate code. A demonstration video is available at https://www.you-tube.com/watch?v=GpibSxX3Wlw.","","","10.1109/ASE.2017.8115701","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115701","Continuous execution;integrated development environments;debugging;live coding","Java;Tools;Debugging;Encoding;Writing;Data structures;Navigation","program debugging;public domain software","SEEDE;control flow;user edits;intermediate values;editing;Code Bubbles development environment;continuous execution;programmer edits","","","36","","","","","IEEE","IEEE Conferences"
"Renaming and shifted code in structured merging: Looking ahead for precision and performance","O. Leßenich; S. Apel; C. Kästner; G. Seibt; J. Siegmund","Univ. of Passau, Passau, Germany; University of Passau, Germany; Carnegie Mellon University, USA; University of Passau, Germany; University of Passau, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","543","553","Diffing and merging of source-code artifacts is an essential task when integrating changes in software versions. While state-of-the-art line-based merge tools (e.g., git merge) are fast and independent of the programming language used, they have only a low precision. Recently, it has been shown that the precision of merging can be substantially improved by using a language-aware, structured approach that works on abstract syntax trees. But, precise structured merging is NP hard, especially, when considering the notoriously difficult scenarios of renamings and shifted code. To address these scenarios without compromising scalability, we propose a syntax-aware, heuristic optimization for structured merging that employs a lookahead mechanism during tree matching. The key idea is that renamings and shifted code are not arbitrarily distributed, but their occurrence follows patterns, which we address with a syntax-specific lookahead. Our experiments with 48 real-world open-source projects (4,878 merge scenarios with over 400 million lines of code) demonstrate that we can significantly improve matching precision in 28 percent of cases while maintaining performance.","","","10.1109/ASE.2017.8115665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115665","","Merging;Tools;Syntactics;Optimization;Open source software","merging;optimisation;public domain software;software maintenance;trees (mathematics)","shifted code;source-code artifacts;software versions;programming language;abstract syntax trees;syntax-specific lookahead;renaming code;structured merging;language-aware structured approach;NP hard problem;syntax-aware heuristic optimization;lookahead mechanism;tree matching","","3","30","","","","","IEEE","IEEE Conferences"
"Using automatically generated invariants for regression testing and bug localization","P. Sagdeo; N. Ewalt; D. Pal; S. Vasudevan","University of Illinois at Urbana-Champaign, 61801, USA; University of Illinois at Urbana-Champaign, 61801, USA; University of Illinois at Urbana-Champaign, 61801, USA; University of Illinois at Urbana-Champaign, 61801, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","634","639","We present Preambl, an approach that applies automatically generated invariants to regression testing and bug localization. Our invariant generation methodology is Precis, an automatic and scalable engine that uses program predicates to guide clustering of dynamically obtained path information. In this paper, we apply it for regression testing and for capturing program predicates information to guide statistical analysis based bug localization. We present a technique to localize bugs in paths of variable lengths. We are able to map the localized post-deployment bugs on a path to pre-release invariants generated along that path. Our experimental results demonstrate the efficacy of the use of PRECIS for regression testing, as well as the ability of Preambl to zone in on relevant segments of program paths.","","","10.1109/ASE.2013.6693125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693125","","Testing;Instruments;Statistical analysis;Computer bugs;Software;Measurement units;Target tracking","program debugging;regression analysis","automatically generated invariants;regression testing;Preambl;invariant generation methodology;scalable engine;path information;statistical analysis based bug localization;localized post deployment bugs;PRECIS","","","17","","","","","IEEE","IEEE Conferences"
"DRIVER -- A Platform for Collaborative Framework Understanding","N. Flores; A. Aguiar","Fac. of Eng., Dept. of Inf. Eng., Univ. of Porto, Porto, Portugal; Fac. of Eng., Dept. of Inf. Eng., Univ. of Porto, Porto, Portugal","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","783","788","Application frameworks are a powerful technique for large-scale reuse but often very hard to learn from scratch. Although good documentation helps on reducing the learning curve, it is often found lacking, and costly, as it needs to attend different audiences with disparate learning needs. When code and documentation prove insufficient, developers turn to their network of experts. The lack of awareness about the experts, interrupting the wrong people, and experts unavailability are well known hindrances to effective collaboration. This paper presents the DRIVER platform, a collaborative learning environment for framework users to share their knowledge. It provides the documentation on a wiki, where the learning paths of the community of learners can be captured, shared, rated, and recommended, thus tapping into the collective knowledge of the community of framework users. The tool can be obtained at http://bit.ly/driverTool.","","","10.1109/ASE.2015.105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372067","framework;learning;tool;collaborative","Documentation;Knowledge based systems;Information services;Electronic publishing;Internet;Collaboration;Best practices","computer aided instruction;computer science education;groupware;software reusability","DRIVER;collaborative framework understanding;large-scale reuse;learning curve;learning needs;collaborative learning environment","","1","23","","","","","IEEE","IEEE Conferences"
"Lazy-CSeq: A Context-Bounded Model Checking Tool for Multi-threaded C-Programs","O. Inverso; T. L. Nguyen; B. Fischer; S. L. Torre; G. Parlato","Electron. & Comput. Sci., Univ. of Southampton, Southampton, UK; Electron. & Comput. Sci., Univ. of Southampton, Southampton, UK; Div. of Comput. Sci., Stellenbosch Univ., Stellenbosch, South Africa; NA; Electron. & Comput. Sci., Univ. of Southampton, Southampton, UK","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","807","812","Lazy-CSeq is a context-bounded verification tool for sequentially consistent C programs using POSIX threads. It first translates a multi-threaded C program into a bounded nondeterministic sequential C program that preserves bounded reachability for all round-robin schedules up to a given number of rounds. It then reuses existing high-performance bounded model checkers as sequential verification backends. Lazy-CSeq handles the full C language and the main parts of the POSIX thread API, such as dynamic thread creation and deletion, and synchronization via thread join, locks, and condition variables. It supports assertion checking and deadlock detection, and returns counterexamples in case of errors. Lazy-CSeq outperforms other concurrency verification tools and has won the concurrency category of the last two SV-COMP verification competitions.","","","10.1109/ASE.2015.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372071","C programs;concurrency;multi-thread;multi-threaded;bounded model-checking;context-bounded","System recovery;Arrays;Concurrent computing;Context;Programming;Schedules","application program interfaces;C language;formal verification;multi-threading","Lazy-CSeq;context-bounded model checking tool;multithreaded C-programs;context-bounded verification tool;bounded nondeterministic sequential C program;bounded reachability;round-robin schedules;sequential verification backends;model checkers;POSIX thread API;assertion checking;deadlock detection;concurrency verification tools;SV-COMP verification competitions","","20","39","","","","","IEEE","IEEE Conferences"
"Variability-aware performance prediction: A statistical learning approach","J. Guo; K. Czarnecki; S. Apel; N. Siegmund; A. Wąsowski","University of Waterloo, Canada; University of Waterloo, Canada; University of Passau, Germany; University of Passau, Germany; IT University of Copenhagen, Denmark","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","301","311","Configurable software systems allow stakeholders to derive program variants by selecting features. Understanding the correlation between feature selections and performance is important for stakeholders to be able to derive a program variant that meets their requirements. A major challenge in practice is to accurately predict performance based on a small sample of measured variants, especially when features interact. We propose a variability-aware approach to performance prediction via statistical learning. The approach works progressively with random samples, without additional effort to detect feature interactions. Empirical results on six real-world case studies demonstrate an average of 94% prediction accuracy based on small random samples. Furthermore, we investigate why the approach works by a comparative analysis of performance distributions. Finally, we compare our approach to an existing technique and guide users to choose one or the other in practice.","","","10.1109/ASE.2013.6693089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693089","","Predictive models;Feature extraction;Silicon;Software systems;Correlation;Measurement;Accuracy","configuration management;learning (artificial intelligence);software performance evaluation;statistical analysis","variability-aware performance prediction;statistical learning;configurable software systems;program variants","","36","27","","","","","IEEE","IEEE Conferences"
"Improving bug localization using structured information retrieval","R. K. Saha; M. Lease; S. Khurshid; D. E. Perry","Department of Electrical and Computer Engineering, The University of Texas at Austin, USA; School of Information, The University of Texas at Austin, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","345","355","Locating bugs is important, difficult, and expensive, particularly for large-scale systems. To address this, natural language information retrieval techniques are increasingly being used to suggest potential faulty source files given bug reports. While these techniques are very scalable, in practice their effectiveness remains low in accurately localizing bugs to a small number of files. Our key insight is that structured information retrieval based on code constructs, such as class and method names, enables more accurate bug localization. We present BLUiR, which embodies this insight, requires only the source code and bug reports, and takes advantage of bug similarity data if available. We build BLUiR on a proven, open source IR toolkit that anyone can use. Our work provides a thorough grounding of IR-based bug localization research in fundamental IR theoretical and empirical knowledge and practice. We evaluate BLUiR on four open source projects with approximately 3,400 bugs. Results show that BLUiR matches or outperforms a current state-of-the-art tool across applications considered, even when BLUiR does not use bug similarity data used by the other tool.","","","10.1109/ASE.2013.6693093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693093","Bug localization;information retrieval;search","Computer bugs;Measurement;Accuracy;Information retrieval;Indexing;Java;Mathematical model","information retrieval;natural language processing;program debugging;public domain software","bug localization;structured information retrieval;large-scale systems;natural language information retrieval;code constructs;BLUiR;open source IR toolkit;source code;bug reports;bug similarity data","","95","46","","","","","IEEE","IEEE Conferences"
"APIBot: Question answering bot for API documentation","Y. Tian; F. Thung; A. Sharma; D. Lo","School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","153","158","As the carrier of Application Programming Interfaces (APIs) knowledge, API documentation plays a crucial role in how developers learn and use an API. It is also a valuable information resource for answering API-related questions, especially when developers cannot find reliable answers to their questions online/offline. However, finding answers to API-related questions from API documentation might not be easy because one may have to manually go through multiple pages before reaching the relevant page, and then read and understand the information inside the relevant page to figure out the answers. To deal with this challenge, we develop APIBot, a bot that can answer API questions given API documentation as an input. APIBot is built on top of SiriusQA, the QA system from Sirius, a state of the art intelligent personal assistant. To make SiriusQA work well under software engineering scenario, we make several modifications over SiriusQA by injecting domain specific knowledge. We evaluate APIBot on 92 API questions, answers of which are known to be present in Java 8 documentation. Our experiment shows that APIBot can achieve a Hit@5 score of 0.706.","","","10.1109/ASE.2017.8115628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115628","API Documentation;Question Answering;Bot","Documentation;Knowledge discovery;Natural languages;Probabilistic logic;Training;Software engineering;Software","application program interfaces;Java;question answering (information retrieval);software engineering","API documentation;APIBot;question answering bot;application programming interface knowledge;API-related question answering;SiriusQA;intelligent personal assistant;software engineering scenario;domain specific knowledge;Java 8 documentation;Hit@5 score","","2","21","","","","","IEEE","IEEE Conferences"
"Proof-based coverage metrics for formal verification","E. Ghassabani; A. Gacek; M. W. Whalen; M. P. E. Heimdahl; L. Wagner","Department of Computer Science & Engineering, University of Minnesota, MN, USA; Rockwell Collins, Advanced Technology Center, IA, USA; Department of Computer Science & Engineering, University of Minnesota, MN, USA; Department of Computer Science & Engineering, University of Minnesota, MN, USA; Rockwell Collins, Advanced Technology Center, IA, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","194","199","When using formal verification on critical software, an important question involves whether we have we specified enough properties for a given implementation model. To address this question, coverage metrics for property-based formal verification have been proposed. Existing metrics are usually based on mutation, where the implementation model is repeatedly modified and re-analyzed to determine whether mutant models are ""killed"" by the property set. These metrics tend to be very expensive to compute, as they involve many additional verification problems. This paper proposes an alternate family of metrics that can be computed using the recently introduced idea of Inductive Validity Cores (IVCs). IVCs determine a minimal set of model elements necessary to establish a proof. One of the proposed metrics is both rigorous and substantially cheaper to compute than mutation-based metrics. In addition, unlike the mutation-based techniques, the design elements marked as necessary by the metric are guaranteed to preserve provability. We demonstrate the metrics on a large corpus of examples.","","","10.1109/ASE.2017.8115632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115632","Coverage;requirements completeness;formal verification;inductive proofs;inductive validity cores","Measurement;Computational modeling;Software;Safety;Mathematical model;Testing;Analytical models","formal verification","formal verification;mutant models;additional verification problems;mutation-based techniques;proof-based coverage metrics;critical software;inductive validity cores;IVC","","2","33","","","","","IEEE","IEEE Conferences"
"Mutation-Based Fault Localization for Real-World Multilingual Programs (T)","S. Hong; B. Lee; T. Kwak; Y. Jeon; B. Ko; Y. Kim; M. Kim","KAIST, Daejeon, South Korea; GIST, Gwangju, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea; GIST, Gwangju, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","464","475","Programmers maintain and evolve their software in a variety of programming languages to take advantage of various control/data abstractions and legacy libraries. The programming language ecosystem has diversified over the last few decades, and non-trivial programs are likely to be written in more than a single language. Unfortunately, language interfaces such as Java Native Interface and Python/C are difficult to use correctly and the scope of fault localization goes beyond language boundaries, which makes debugging multilingual bugs challenging. To overcome the aforementioned limitations, we propose a mutation-based fault localization technique for real-world multilingual programs. To improve the accuracy of locating multilingual bugs, we have developed and applied new mutation operators as well as conventional mutation operators. The results of the empirical evaluation for six non-trivial real-world multilingual bugs are promising in that the proposed technique identifies the buggy statements as the most suspicious statements for all six bugs.","","","10.1109/ASE.2015.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372034","Multilingual Programs;Debugging;Fault Localization;Mutation Analysis;Mutation Based Fault Localization","Computer bugs;Debugging;Java;Safety;Testing;Libraries;Programming","program debugging;program testing","programming languages;control abstraction;legacy libraries;programming language ecosystem;fault localization;multilingual bug debugging;mutation-based fault localization technique;real-world multilingual programs;multilingual bug location;mutation operators;empirical evaluation;nontrivial real-world multilingual bugs;buggy statement identification;suspicious statement identification;data abstraction","","15","51","","","","","IEEE","IEEE Conferences"
"ModelWriter: Text and model-synchronized document engineering platform","F. Erata; C. Gardent; B. Gyawali; A. Shimorina; Y. Lussaud; B. Tekinerdogan; G. Kardas; A. Monceaux","Information Technology Group, Wageningen University and Research Centre, The Netherlands; CNRS, LORIA, UMR 7503 Vandoeuvre-les-Nancy, F-54500, Nancy, France; CNRS, LORIA, UMR 7503 Vandoeuvre-les-Nancy, F-54500, Nancy, France; CNRS, LORIA, UMR 7503 Vandoeuvre-les-Nancy, F-54500, Nancy, France; System Engineering Platforms, Airbus Group Innovations, Toulouse, France; Information Technology Group, Wageningen University and Research Centre, The Netherlands; Ege University, International Computer Institute, Izmir, Turkey; UNIT Information Technologies R&D Ltd., Izmir, Turkey","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","907","912","The ModelWriter platform provides a generic framework for automated traceability analysis. In this paper, we demonstrate how this framework can be used to trace the consistency and completeness of technical documents that consist of a set of System Installation Design Principles used by Airbus to ensure the correctness of aircraft system installation. We show in particular, how the platform allows the integration of two types of reasoning: reasoning about the meaning of text using semantic parsing and description logic theorem proving; and reasoning about document structure using first-order relational logic and finite model finding for traceability analysis.","","","10.1109/ASE.2017.8115703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115703","","Semantics;Grammar;Cognition;Atmospheric modeling;Hydraulic systems;Analytical models;Tools","aerospace engineering;document handling;formal logic;inference mechanisms;program diagnostics;text analysis;theorem proving","Airbus;aircraft system installation;semantic parsing;document structure;finite model;document engineering platform;ModelWriter platform;automated traceability analysis;description logic theorem;system installation design principles","","1","32","","","","","IEEE","IEEE Conferences"
"Detecting unknown inconsistencies in web applications","F. S. Ocariza; K. Pattabiraman; A. Mesbah","University of British Columbia, Vancouver, BC, Canada; University of British Columbia, Vancouver, BC, Canada; University of British Columbia, Vancouver, BC, Canada","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","566","577","Although there has been increasing demand for more reliable web applications, JavaScript bugs abound in web applications. In response to this issue, researchers have proposed automated fault detection tools, which statically analyze the web application code to find bugs. While useful, these tools either only target a limited set of bugs based on predefined rules, or they do not detect bugs caused by cross-language interactions, which occur frequently in web application code. To address this problem, we present an anomaly-based inconsistency detection approach, implemented in a tool called HOLOCRON. The main novelty of our approach is that it does not look for hard-coded inconsistency classes. Instead, it applies subtree pattern matching to infer inconsistency classes and association rule mining to detect inconsistencies that occur both within a single language, and between two languages. We evaluated HOLOCRON, and it successfully detected 51 previously unreported inconsistencies - including 18 bugs and 33 code smells - in 12 web applications.","","","10.1109/ASE.2017.8115667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115667","JavaScript;fault detection;cross-language interactions","Computer bugs;Tools;Encoding;Transforms;Computer languages;Testing","data mining;fault diagnosis;program debugging;program diagnostics","JavaScript bugs;fault detection tools;inconsistency detection approach;hard-coded inconsistency classes;association rule mining;Web application code;unreported inconsistencies","","1","55","","","","","IEEE","IEEE Conferences"
"Rethinking pointer reasoning in symbolic execution","E. Coppa; D. C. D'Elia; C. Demetrescu","Department of Computer, Control, and Management Engineering, Sapienza University of Rome, Italy; Department of Computer, Control, and Management Engineering, Sapienza University of Rome, Italy; Department of Computer, Control, and Management Engineering, Sapienza University of Rome, Italy","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","613","618","Symbolic execution is a popular program analysis technique that allows seeking for bugs by reasoning over multiple alternative execution states at once. As the number of states to explore may grow exponentially, a symbolic executor may quickly run out of space. For instance, a memory access to a symbolic address may potentially reference the entire address space, leading to a combinatorial explosion of the possible resulting execution states. To cope with this issue, state-of-the-art executors concretize symbolic addresses that span memory intervals larger than some threshold. Unfortunately, this could result in missing interesting execution states, e.g., where a bug arises. In this paper we introduce MEMSIGHT, a new approach to symbolic memory that reduces the need for concretization, hence offering the opportunity for broader state explorations and more precise pointer reasoning. Rather than mapping address instances to data as previous tools do, our technique maps symbolic address expressions to data, maintaining the possible alternative states resulting from the memory referenced by a symbolic address in a compact, implicit form. A preliminary experimental investigation on prominent benchmarks from the DARPA Cyber Grand Challenge shows that MemSight enables the exploration of states unreachable by previous techniques.","","","10.1109/ASE.2017.8115671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115671","","Concrete;Weapons;Cognition;Indexes;Merging;Load modeling;Computer bugs","program debugging;program diagnostics;program testing;program verification","symbolic execution;symbolic executor;memory access;span memory intervals;symbolic memory;address instances;bugs;address space;execution states;program analysis technique;pointer reasoning;symbolic address expressions","","1","12","","","","","IEEE","IEEE Conferences"
"ExPort: Detecting and visualizing API usages in large source code repositories","E. Moritz; M. Linares-Vásquez; D. Poshyvanyk; M. Grechanik; C. McMillan; M. Gethers","The College of William and Mary, Williamsburg, VA, USA; The College of William and Mary, Williamsburg, VA, USA; The College of William and Mary, Williamsburg, VA, USA; University of Illinois at Chicago, USA; University of Notre Dame, IN, USA; University of Maryland Baltimore County, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","646","651","This paper presents a technique for automatically mining and visualizing API usage examples. In contrast to previous approaches, our technique is capable of finding examples of API usage that occur across several functions in a program. This distinction is important because of a gap between what current API learning tools provide and what programmers need: current tools extract relatively small examples from single files/functions, even though programmers use APIs to build large software. The small examples are helpful in the initial stages of API learning, but leave out details that are helpful in later stages. Our technique is intended to fill this gap. It works by representing software as a Relational Topic Model, where API calls and the functions that use them are modeled as a document network. Given a starting API, our approach can recommend complex API usage examples mined from a repository of over 14 million Java methods.","","","10.1109/ASE.2013.6693127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693127","API usage;visualization;call graph;code search","Visualization;Software;Java;Portfolios;Databases;Prototypes;Concrete","application program interfaces;data mining;learning (artificial intelligence);program visualisation;source code (software)","ExPort;API usage visualization;API usage detection;large source code repositories;automatic API usage mining;API learning tools;relational topic model;document network;Java methods","","26","27","","","","","IEEE","IEEE Conferences"
"Assessing the maturity of requirements through argumentation: A good enough approach","V. Veerappa; R. Harrison","Oxford Brookes University, UK; Oxford Brookes University, UK","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","670","675","Requirements engineers need to be confident that enough requirements analysis has been done before a project can move forward. In the context of KAOS, this information can be derived from the soundness of the refinements: sound refinements indicate that the requirements in the goal-graph are mature enough or good enough for implementation. We can estimate how close we are to `good enough' requirements using the judgments of experts and other data from the goals. We apply Toulmin's model of argumentation to evaluate how sound refinements are. We then implement the resulting argumentation model using Bayesian Belief Networks and provide a semi-automated way aided by Natural Language Processing techniques to carry out the proposed evaluation. We have performed an initial validation on our work using a small case-study involving an electronic document management system.","","","10.1109/ASE.2013.6693131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693131","Soundness of refinements;Bayesian belief networks;maturity of requirements","Natural language processing;Context;Bayes methods;Probability distribution;Educational institutions;Tagging;Reliability","Bayes methods;document handling;formal verification;natural language processing","requirements engineers;requirements analysis;KAOS context;sound refinements;goal graph;Bayesian belief networks;natural language processing techniques;electronic document management system","","1","32","","","","","IEEE","IEEE Conferences"
"Recommending API Usages for Mobile Apps with Hidden Markov Model","T. T. Nguyen; H. V. Pham; P. M. Vu; T. T. Nguyen","Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA; Comput. Sci. Dept., Utah State Univ., Logan, UT, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","795","800","Mobile apps often rely heavily on standard API frameworks and libraries. However, learning to use those APIs is often challenging due to the fast-changing nature of API frameworks and the insufficiency of documentation and code examples. This paper introduces DroidAssist, a recommendation tool for API usages of Android mobile apps. The core of DroidAssist is HAPI, a statistical, generative model of API usages based on Hidden Markov Model. With HAPIs trained from existing mobile apps, DroidAssist could perform code completion for method calls. It can also check existing call sequences to detect and repair suspicious (i.e. unpopular) API usages.","","","10.1109/ASE.2015.109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372069","Statistical code completion;API usage","Hidden Markov models;Androids;Humanoid robots;Mobile communication;Data mining;Maintenance engineering;Documentation","application program interfaces;hidden Markov models;mobile computing;recommender systems;statistical analysis","API usage recommendation;hidden Markov model;DroidAssist recommendation tool;Android mobile applications;HAPI;statistical generative model;code completion;method calls;call sequences;suspicious API usage detection;suspicious API usage repair","","13","22","","","","","IEEE","IEEE Conferences"
"Detecting and characterizing semantic inconsistencies in ported code","B. Ray; M. Kim; S. Person; N. Rungta","The University of Texas at Austin, USA; The University of Texas at Austin, USA; NASA Langley Research Center, Hampton, USA; NASA Ames Research Center, Mountain View, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","367","377","Adding similar features and bug fixes often requires porting program patches from reference implementations and adapting them to target implementations. Porting errors may result from faulty adaptations or inconsistent updates. This paper investigates (1) the types of porting errors found in practice, and (2) how to detect and characterize potential porting errors. Analyzing version histories, we define five categories of porting errors, including incorrect control- and data-flow, code redundancy, inconsistent identifier renamings, etc. Leveraging this categorization, we design a static control- and data-dependence analysis technique, SPA, to detect and characterize porting inconsistencies. Our evaluation on code from four open-source projects shows that SPA can detect porting inconsistencies with 65% to 73% precision and 90% recall, and identify inconsistency types with 58% to 63% precision and 92% to 100% recall. In a comparison with two existing error detection tools, SPA improves precision by 14 to 17 percentage points.","","","10.1109/ASE.2013.6693095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693095","","Context;Linux;Semantics;Cloning;Syntactics;OFDM;History","error detection;program debugging;program diagnostics;public domain software","semantic inconsistency detection;semantic inconsistency characterization;ported code;bug fixes;porting errors;incorrect control;data-flow;code redundancy;inconsistent identifier renamings;static control;data-dependence analysis technique;open-source projects;error detection tools","","14","22","","","","","IEEE","IEEE Conferences"
"Synergizing Specification Miners through Model Fissions and Fusions (T)","T. B. Le; X. D. Le; D. Lo; I. Beschastnikh","Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore; Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore; Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore; Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","115","125","Software systems are often developed and released without formal specifications. For those systems that are formally specified, developers have to continuously maintain and update the specifications or have them fall out of date. To deal with the absence of formal specifications, researchers have proposed techniques to infer the missing specifications of an implementation in a variety of forms, such as finite state automaton (FSA). Despite the progress in this area, the efficacy of the proposed specification miners needs to improve if these miners are to be adopted. We propose SpecForge, a new specification mining approach that synergizes many existing specification miners. SpecForge decomposes FSAs that are inferred by existing miners into simple constraints, through a process we refer to as model fission. It then filters the outlier constraints and fuses the constraints back together into a single FSA (i.e., model fusion). We have evaluated SpecForge on execution traces of 10 programs, which includes 5 programs from DaCapo benchmark, to infer behavioral models of 13 library classes. Our results show that SpecForge achieves an average precision, recall and F-measure of 90.57%, 54.58%, and 64.21% respectively. SpecForge outperforms the best performing baseline by 13.75% in terms of F-measure.","","","10.1109/ASE.2015.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372001","Specification Mining;Synergizing Miners;Model Fission;Model Fusion","Inference algorithms;Automata;Libraries;Benchmark testing;Software;Manuals;Software engineering","data mining;finite state machines;formal specification","specification miners;model fissions;model fusions;software systems;formal specifications;specification maintenance;finite state automaton;FSA;SpecForge;specification mining approach;outlier constraints;DaCapo benchmark;behavioral models;F-measure","","16","37","","","","","IEEE","IEEE Conferences"
"Modular verification of interrupt-driven software","C. Sung; M. Kusano; C. Wang","University of Southern, California Los Angeles, CA, USA; Virginia Tech Blacksburg, VA, USA; University of Southern California, Los Angeles, CA, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","206","216","Interrupts have been widely used in safety-critical computer systems to handle outside stimuli and interact with the hardware, but reasoning about interrupt-driven software remains a difficult task. Although a number of static verification techniques have been proposed for interrupt-driven software, they often rely on constructing a monolithic verification model. Furthermore, they do not precisely capture the complete execution semantics of interrupts such as nested invocations of interrupt handlers. To overcome these limitations, we propose an abstract interpretation framework for static verification of interrupt-driven software that first analyzes each interrupt handler in isolation as if it were a sequential program, and then propagates the result to other interrupt handlers. This iterative process continues until results from all interrupt handlers reach a fixed point. Since our method never constructs the global model, it avoids the up-front blowup in model construction that hampers existing, non-modular, verification techniques. We have evaluated our method on 35 interrupt-driven applications with a total of 22,541 lines of code. Our results show the method is able to quickly and more accurately analyze the behavior of interrupts.","","","10.1109/ASE.2017.8115634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115634","","Tools;Computer bugs;Model checking;Semantics;Instruction sets","formal verification;interrupts;program diagnostics;program verification","interrupt-driven software;static verification techniques;interrupt handlers;interrupt-driven applications;safety-critical computer systems","","1","45","","","","","IEEE","IEEE Conferences"
"Fuzzing the Rust Typechecker Using CLP (T)","K. Dewey; J. Roesch; B. Hardekopf","Univ. of California, Santa Barbara, Santa Barbara, CA, USA; Univ. of California, Santa Barbara, Santa Barbara, CA, USA; Univ. of California, Santa Barbara, Santa Barbara, CA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","482","493","Language fuzzing is a bug-finding technique for testing compilers and interpreters, its effectiveness depends upon the ability to automatically generate valid programs in the language under test. Despite the proven success of language fuzzing, there is a severe lack of tool support for fuzzing statically-typed languages with advanced type systems because existing fuzzing techniques cannot effectively and automatically generate well-typed programs that use sophisticated types. In this work we describe how to automatically generate well-typed programs that use sophisticated type systems by phrasing the problem of well-typed program generation in terms of Constraint Logic Programming (CLP). In addition, we describe how to specifically target the typechecker implementation for testing, unlike all existing work which ignores the typechecker. We focus on typechecker precision bugs, soundness bugs, and consistency bugs. We apply our techniques to Rust, a complex, industrial-strength language with a sophisticated type system.","","","10.1109/ASE.2015.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372036","","Testing;Computer bugs;Grammar;Java;Engines;Logic programming;Syntactics","logic programming;program debugging;program testing","rust typechecker;language fuzzing;CLP;constraint logic programming;bug-finding technique;compiler testing;interpreter testing;well-typed program generation;typechecker precision bugs;soundness bugs;consistency bugs;Rust language","","5","61","","","","","IEEE","IEEE Conferences"
"Optimistic Shared Memory Dependence Tracing (T)","Y. Jiang; D. Li; C. Xu; X. Ma; J. Lu","Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China; Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China; Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China; Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","524","534","Inter-thread shared memory dependences are crucial to understanding the behavior of concurrent systems, as such dependences are the cornerstone of time-travel debugging and further predictive trace analyses. To enable effective and efficient shared memory dependence tracing, we present an optimistic scheme addressing the challenge of capturing exact dependences between unsynchronized events to reduce the probe effect of program instrumentation. Specifically, our approach achieved a wait-free fast path for thread-local reads on x86-TSO relaxed memory systems, and simultaneously achieved precise tracing of exact read-after-write, write-after-write and write-after-read dependences on the fly. We implemented an open-source RWTrace tool, and evaluation results show that our approach not only achieves efficient shared memory dependence tracing, but also scales well on a multi-core computer system.","","","10.1109/ASE.2015.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372040","concurrency;shared memory dependence;dynamic analysis","Instruction sets;Memory management;Synchronization;Algorithm design and analysis;Benchmark testing;Computer science;Debugging","program debugging;shared memory systems","optimistic shared memory dependence tracing;interthread shared memory dependence;time-travel debugging;predictive trace analysis;program instrumentation;x86-TSO relaxed memory system;open-source RWTrace tool;multicore computer system","","2","35","","","","","IEEE","IEEE Conferences"
"DSSynth: An automated digital controller synthesis tool for physical plants","A. Abate; I. Bessa; D. Cattaruzza; L. Chaves; L. Cordeiro; C. David; P. Kesseli; D. Kroening; E. Polgreen","University of Oxford, Oxford, United Kingdom; Federal University of Amazonas, Manaus, Brazil; University of Oxford, Oxford, United Kingdom; Federal University of Amazonas, Manaus, Brazil; University of Oxford, Oxford, United Kingdom; University of Oxford, Oxford, United Kingdom; University of Oxford, Oxford, United Kingdom; University of Oxford, Oxford, United Kingdom; University of Oxford, Oxford, United Kingdom","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","919","924","We present an automated MATLAB Toolbox, named DSSynth (Digital-System Synthesizer), to synthesize sound digital controllers for physical plants that are represented as linear timeinvariant systems with single input and output. In particular, DSSynth synthesizes digital controllers that are sound w.r.t. stability and safety specifications. DSSynth considers the complete range of approximations, including time discretization, quantization effects and finite-precision arithmetic (and its rounding errors). We demonstrate the practical value of this toolbox by automatically synthesizing stable and safe controllers for intricate physical plant models from the digital control literature. The resulting toolbox enables the application of program synthesis to real-world control engineering problems. A demonstration can be found at https://youtu.be_hLQslRcee8.","","","10.1109/ASE.2017.8115705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115705","Formal Synthesis;Digital Control Systems;MATLAB Toolbox;Finite-Word Length;Verification","MATLAB;Mathematical model;Transfer functions;Tools;Digital control;Engines","control engineering computing;control system synthesis;digital control;linear systems;stability","automated digital controller synthesis tool;physical plants;linear timeinvariant systems;intricate physical plant models;digital control literature;real-world control engineering problems;automated MATLAB toolbox;digital-system synthesizer;DSSynth;sound digital controller synthesis","","","30","","","","","IEEE","IEEE Conferences"
"Constraint-based automatic symmetry detection","S. J. Zhang; J. Sun; C. Sun; Y. Liu; J. Ma; J. S. Dong","Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; National University of Singapore, Singapore; Nanyang Technological University, Singapore; Singapore University of Technology and Design, Singapore; National University of Singapore, Singapore","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","15","25","We present an automatic approach to detecting symmetry relations for general concurrent models. Despite the success of symmetry reduction in mitigating state explosion problem, one essential step towards its soundness and effectiveness, i.e., how to discover sufficient symmetries with least human efforts, is often either overlooked or oversimplified. In this work, we show how a concurrent model can be viewed as a constraint satisfaction problem (CSP), and present an algorithm capable of detecting symmetries arising from the CSP which induce automorphisms of the model. To the best of our knowledge, our method is the first approach that can automatically detect both process and data symmetries as demonstrated via a number of systems.","","","10.1109/ASE.2013.6693062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693062","","Arrays;Protocols;Color;Space exploration;Transforms;Cost accounting;Lead","concurrency theory;constraint satisfaction problems","constraint-based automatic symmetry detection;general concurrent models;symmetry reduction;state explosion problem;human efforts;constraint satisfaction problem;CSP;automorphisms;data symmetries","","1","37","","","","","IEEE","IEEE Conferences"
"Automatic testing of symbolic execution engines via program generation and differential testing","T. Kapus; C. Cadar","Imperial College London, United Kingdom; Imperial College London, United Kingdom","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","590","600","Symbolic execution has attracted significant attention in recent years, with applications in software testing, security, networking and more. Symbolic execution tools, like CREST, KLEE, FuzzBALL, and Symbolic PathFinder, have enabled researchers and practitioners to experiment with new ideas, scale the technique to larger applications and apply it to new application domains. Therefore, the correctness of these tools is of critical importance. In this paper, we present our experience extending compiler testing techniques to find errors in both the concrete and symbolic execution components of symbolic execution engines. The approach used relies on a novel way to create program versions, in three different testing modes-concrete, single-path and multi-path-each exercising different features of symbolic execution engines. When combined with existing program generation techniques and appropriate oracles, this approach enables differential testing within a single symbolic execution engine. We have applied our approach to the KLEE, CREST and FuzzBALL symbolic execution engines, where it has discovered 20 different bugs exposing a variety of important errors having to do with the handling of structures, division, modulo, casting, vector instructions and more, as well as issues related to constraint solving, compiler optimisations and test input replay.","","","10.1109/ASE.2017.8115669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115669","","Testing;Engines;Tools;Computer bugs;Concrete;Program processors;Instruments","optimising compilers;program diagnostics;program testing;program verification","differential testing;single symbolic execution engine;test input replay;automatic testing;software testing;Symbolic PathFinder;symbolic execution components;symbolic execution tools;program generation techniques;compiler testing techniques;concrete testing mode;single-path testing mode;multipath testing mode;KLEE execution engine;CREST symbolic execution engine;FuzzBALL symbolic execution engine;compiler optimisations;constraint solving","","1","34","","","","","IEEE","IEEE Conferences"
"Tortoise: Interactive system configuration repair","A. Weiss; A. Guha; Y. Brun","Northeastern University, Boston, MA, USA 02115; University of Massachusetts, Amherst, Amherst, MA, USA 01003; University of Massachusetts, Amherst, Amherst, MA, USA 01003","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","625","636","System configuration languages provide powerful abstractions that simplify managing large-scale, networked systems. Thousands of organizations now use configuration languages, such as Puppet. However, specifications written in configuration languages can have bugs and the shell remains the simplest way to debug a misconfigured system. Unfortunately, it is unsafe to use the shell to fix problems when a system configuration language is in use: a fix applied from the shell may cause the system to drift from the state specified by the configuration language. Thus, despite their advantages, configuration languages force system administrators to give up the simplicity and familiarity of the shell. This paper presents a synthesis-based technique that allows administrators to use configuration languages and the shell in harmony. Administrators can fix errors using the shell and the technique automatically repairs the higher-level specification written in the configuration language. The approach (1) produces repairs that are consistent with the fix made using the shell; (2) produces repairs that are maintainable by minimizing edits made to the original specification; (3) ranks and presents multiple repairs when relevant; and (4) supports all shells the administrator may wish to use. We implement our technique for Puppet, a widely used system configuration language, and evaluate it on a suite of benchmarks under 42 repair scenarios. The top-ranked repair is selected by humans 76% of the time and the human-equivalent repair is ranked 1.31 on average.","","","10.1109/ASE.2017.8115673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115673","","Maintenance engineering;Computer bugs;Web servers;Organizations;Benchmark testing","formal specification;large-scale systems;program debugging;specification languages","configuration languages force system administrators;system configuration language;interactive system configuration repair;misconfigured system;large-scale networked systems;synthesis-based technique;Puppet;human-equivalent repair;Tortoise","","6","63","","","","","IEEE","IEEE Conferences"
"A pattern-based approach to parametric specification mining","G. Reger; H. Barringer; D. Rydeheard","University of Manchester, United Kingdom; University of Manchester, United Kingdom; University of Manchester, United Kingdom","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","658","663","This paper presents a technique for using execution traces to mine parametric temporal specifications in the form of quantified event automata (QEA) - previously introduced as an expressive and efficient formalism for runtime verification. We consider a pattern-based mining approach that uses a pattern library to generate and check potential properties over given traces, and then combines successful patterns. By using predefined models to measure the tool's precision and recall we demonstrate that our approach can effectively and efficiently extract specifications in realistic scenarios.","","","10.1109/ASE.2013.6693129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693129","","Libraries;Automata;Training;Satellites;Runtime;Pattern matching;Complexity theory","automata theory;data mining;formal specification;program verification;software libraries","pattern-based approach;parametric specification mining;execution traces;parametric temporal specifications;quantified event automata;QEA;runtime verification;pattern-based mining approach;pattern library","","13","18","","","","","IEEE","IEEE Conferences"
"Model/code co-refactoring: An MDE approach","J. von Pilgrim; B. Ulke; A. Thies; F. Steimann","Lehrgebiet Programmiersysteme, Fernuniversität in Hagen, Germany; Lehrgebiet Programmiersysteme, Fernuniversität in Hagen, Germany; Lehrgebiet Programmiersysteme, Fernuniversität in Hagen, Germany; Lehrgebiet Programmiersysteme, Fernuniversität in Hagen, Germany","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","682","687","Model-driven engineering suggests that models are the primary artefacts of software development. This means that models may be refactored even after code has been generated from them, in which case the code must be changed to reflect the refactoring. However, as we show neither re-generating the code from the refactored model nor applying an equivalent refactoring to the generated code is sufficient to keep model and code in sync - rather, model and code need to be refactored jointly. To enable this, we investigate the technical requirements of model/code co-refactoring, and implement a model-driven solution that we evaluate using a set of open-source programs and their structural models. Results suggest that our approach is feasible.","","","10.1109/ASE.2013.6693133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693133","Model-driven engineering;refactoring;constraints","Unified modeling language;Java;DSL;Adaptation models;Biological system modeling;Synchronization","program compilers;software engineering","code corefactoring;MDE;model driven engineering;software development;code regeneration;refactored model;equivalent refactoring;model driven solution;open source programs;structural models","","7","19","","","","","IEEE","IEEE Conferences"
"CIVL: Formal Verification of Parallel Programs","M. Zheng; M. S. Rogers; Z. Luo; M. B. Dwyer; S. F. Siegel","Dept. of Comput. & Inf. Sci., Univ. of Delaware, Newark, DE, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska - Lincoln, Lincoln, NE, USA; Dept. of Comput. & Inf. Sci., Univ. of Delaware, Newark, DE, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska - Lincoln, Lincoln, NE, USA; Dept. of Comput. & Inf. Sci., Univ. of Delaware, Newark, DE, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","830","835","CIVL is a framework for static analysis and verification of concurrent programs. One of the main challenges to practical application of these techniques is the large number of ways to express concurrency: MPI, OpenMP, CUDA, and Pthreads, for example, are just a few of many ""concurrency dialects"" in wide use today. These dialects are constantly evolving and it is increasingly common to use several of them in a single ""hybrid"" program. CIVL addresses these problems by providing a concurrency intermediate verification language, CIVL-C, as well as translators that consume C programs using these dialects and produce CIVL-C. Analysis and verification tools which operate on CIVL-C can then be applied easily to a wide variety of concurrent C programs. We demonstrate CIVL's error detection and verification capabilities on (1) an MPI+OpenMP program that estimates π and contains a subtle race condition, and (2) an MPI-based 1d-wave simulator that fails to conform to a simple sequential implementation.","","","10.1109/ASE.2015.99","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372075","software verification;parallel programs;MPI;OpenMP;function equivalence;symbolic execution;model checking","Concurrent computing;Libraries;Standards;Graphics processing units;Government;Electronic mail;Maintenance engineering","C language;parallel programming;program diagnostics;program verification","CIVL;formal verification;parallel program;static analysis;concurrent program;CUDA;Pthread;hybrid program;concurrency intermediate verification language;C program;MPI-plus-OpenMP program;MPI-based 1d-wave simulator","","8","34","","","","","IEEE","IEEE Conferences"
"Characterizing and detecting resource leaks in Android applications","C. Guo; J. Zhang; J. Yan; Z. Zhang; Y. Zhang","State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences, Beijing, China; Technology Center of Software Engineering Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences, Beijing, China","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","389","398","Android phones come with a host of hardware components embedded in them, such as Camera, Media Player and Sensor. Most of these components are exclusive resources or resources consuming more memory/energy than general. And they should be explicitly released by developers. Missing release operations of these resources might cause serious problems such as performance degradation or system crash. These kinds of defects are called resource leaks. This paper focuses on resource leak problems in Android apps, and presents our lightweight static analysis tool called Relda, which can automatically analyze an application's resource operations and locate the resource leaks. We propose an automatic method for detecting resource leaks based on a modified Function Call Graph, which handles the features of event-driven mobile programming by analyzing the callbacks defined in Android framework. Our experimental data shows that Relda is effective in detecting resource leaks in real Android apps.","","","10.1109/ASE.2013.6693097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693097","Android apps;resource leak;static analysis","Androids;Humanoid robots;Cameras;Smart phones;Media;Java;Mobile communication","Android (operating system);mobile computing;program diagnostics;resource allocation","resource leaks characterization;resource leaks detection;Android applications;camera component;media player component;sensor component;resource leak problems;Relda tool;lightweight static analysis tool;application resource operations;callbacks;event-driven mobile programming;function call graph","","36","49","","","","","IEEE","IEEE Conferences"
"Dynamically Testing GUIs Using Ant Colony Optimization (T)","S. Carino; J. H. Andrews","Dept. of Comput. Sci., Univ. of Western Ontario, London, ON, Canada; Dept. of Comput. Sci., Univ. of Western Ontario, London, ON, Canada","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","138","148","In this paper we introduce a dynamic GUI test generator that incorporates ant colony optimization. We created two ant systems for generating tests. Our first ant system implements the normal ant colony optimization algorithm in order to traverse the GUI and find good event sequences. Our second ant system, called AntQ, implements the antq algorithm that incorporates Q-Learning, which is a behavioral reinforcement learning technique. Both systems use the same fitness function in order to determine good paths through the GUI. Our fitness function looks at the amount of change in the GUI state that each event causes. Events that have a larger impact on the GUI state will be favored in future tests. We compared our two ant systems to random selection. We ran experiments on six subject applications and report on the code coverage and fault finding abilities of all three algorithms.","","","10.1109/ASE.2015.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372003","","Graphical user interfaces;Testing;Ant colony optimization;Generators;Context;Heuristic algorithms;Computer architecture","ant colony optimisation;graphical user interfaces;learning (artificial intelligence);program testing","dynamic GUI test generator;ant colony optimization algorithm;AntQ;Q-Learning;behavioral reinforcement learning technique;fitness function;code coverage;fault finding abilities","","5","38","","","","","IEEE","IEEE Conferences"
"Static detection of asymptotic resource side-channel vulnerabilities in web applications","J. Chen; O. Olivo; I. Dillig; C. Lin","The University of Texas at Austin, United States; The University of Texas at Austin, United States; The University of Texas at Austin, United States; The University of Texas at Austin, United States","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","229","239","Web applications can leak confidential user information due to the presence of unintended side-channel vulnerabilities in code. One particularly subtle class of side-channel vulnerabilities arises due to resource usage imbalances along different execution paths of a program. Such side-channel vulnerabilities are especially severe if the resource usage imbalance is asymptotic. This paper formalizes the notion of asymptotic resource side-channels and presents a lightweight static analysis algorithm for automatically detecting them. Based on these ideas, we have developed a tool called SCANNER that detects resource-related side-channel vulnerabilities in PHP applications. SCANNER has found 18 zero-day security vulnerabilities in 10 different web applications and reports only 2 false positives. The vulnerabilities uncovered by SCANNER can be exploited using cross-site search attacks to extract various kinds of confidential information, such as a user's medications or purchase history.","","","10.1109/ASE.2017.8115636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115636","","Security;Timing;Databases;Algorithm design and analysis;Tools;Time factors","cryptography;Internet;program diagnostics","resource usage imbalance;asymptotic resource side-channels;SCANNER;PHP applications;zero-day security vulnerabilities;static detection;asymptotic resource side-channel vulnerabilities;confidential user information;unintended side-channel vulnerabilities;execution paths;Web applications;lightweight static analysis algorithm","","","48","","","","","IEEE","IEEE Conferences"
"Automatically assessing crashes from heap overflows","L. He; Y. Cai; H. Hu; P. Su; Z. Liang; Y. Yang; H. Huang; J. Yan; X. Jia; D. Feng","Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Computer Science, National University of Singapore; Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Trusted Computing and Information Assurance Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","274","279","Heap overflow is one of the most widely exploited vulnerabilities, with a large number of heap overflow instances reported every year. It is important to decide whether a crash caused by heap overflow can be turned into an exploit. Efficient and effective assessment of exploitability of crashes facilitates to identify severe vulnerabilities and thus prioritize resources. In this paper, we propose the first metrics to assess heap overflow crashes based on both the attack aspect and the feasibility aspect. We further present HCSIFTER, a novel solution to automatically assess the exploitability of heap overflow instances under our metrics. Given a heap-based crash, HCSIFTER accurately detects heap overflows through dynamic execution without any source code or debugging information. Then it uses several novel methods to extract program execution information needed to quantify the severity of the heap overflow using our metrics. We have implemented a prototype HCSIFTER and applied it to assess nine programs with heap overflow vulnerabilities. HCSIFTER successfully reports that five heap overflow vulnerabilities are highly exploitable and two overflow vulnerabilities are unlikely exploitable. It also gave quantitatively assessments for other two programs. On average, it only takes about two minutes to assess one heap overflow crash. The evaluation result demonstrates both effectiveness and efficiency of HC Sifter.","","","10.1109/ASE.2017.8115640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115640","Memory error;Heap overflow;Vulnerability assessment","Computer crashes;Measurement;Tools;Payloads;Indexes;Data mining;Layout","program debugging;program diagnostics;security of data","HCSIFTER;metrics;heap overflow vulnerabilities;heap overflow crash;HC Sifter;widely exploited vulnerabilities;crashes facilitates","","","25","","","","","IEEE","IEEE Conferences"
"Development Emails Content Analyzer: Intention Mining in Developer Discussions (T)","A. D. Sorbo; S. Panichella; C. A. Visaggio; M. D. Penta; G. Canfora; H. C. Gall","NA; Univ. of Zurich, Zurich, Switzerland; Univ. of Sannio, Benevento, Italy; NA; Univ. of Sannio, Benevento, Italy; Univ. of Zurich, Zurich, Switzerland","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","12","23","Written development communication (e.g. mailing lists, issue trackers) constitutes a precious source of information to build recommenders for software engineers, for example aimed at suggesting experts, or at redocumenting existing source code. In this paper we propose a novel, semi-supervised approach named DECA (Development Emails Content Analyzer) that uses Natural Language Parsing to classify the content of development emails according to their purpose (e.g. feature request, opinion asking, problem discovery, solution proposal, information giving etc), identifying email elements that can be used for specific tasks. A study based on data from Qt and Ubuntu, highlights a high precision (90%) and recall (70%) of DECA in classifying email content, outperforming traditional machine learning strategies. Moreover, we successfully used DECA for re-documenting source code of Eclipse and Lucene, improving the recall, while keeping high precision, of a previous approach based on ad-hoc heuristics.","","","10.1109/ASE.2015.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371991","Unstructured Data Mining;Natural Language Processing;Empirical Study","Electronic mail;Proposals;Natural languages;Taxonomy;Bandwidth;Pragmatics;Software","data mining;electronic mail;grammars;learning (artificial intelligence);natural language processing;pattern classification;program compilers;recommender systems;software engineering;source code (software)","development emails content analyzer;DECA;intention mining;software development;semisupervised approach;natural language parsing;content classification;source code;recommender system","","24","59","","","","","IEEE","IEEE Conferences"
"Towards precise metrics for predicting graph query performance","B. Izsó; Z. Szatmári; G. Bergmann; Á. Horváth; I. Ráth","Department of Measurement and Information Systems, Budapest University of Technology and Economics, Hungary; Department of Measurement and Information Systems, Budapest University of Technology and Economics, Hungary; Department of Measurement and Information Systems, Budapest University of Technology and Economics, Hungary; Department of Measurement and Information Systems, Budapest University of Technology and Economics, Hungary; Department of Measurement and Information Systems, Budapest University of Technology and Economics, Hungary","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","421","431","Queries are the foundations of data intensive applications. In model-driven software engineering (MDSE), model queries are core technologies of tools and transformations. As software models are rapidly increasing in size and complexity, most MDSE tools frequently exhibit scalability issues that decrease developer productivity and increase costs. As a result, choosing the right model representation and query evaluation approach is a significant challenge for tool engineers. In the current paper, we aim to provide a benchmarking framework for the systematic investigation of query evaluation performance. More specifically, we experimentally evaluate (existing and novel) query and instance model metrics to highlight which provide sufficient performance estimates for different MDSE scenarios in various model query tools. For that purpose, we also present a comparative benchmark, which is designed to differentiate model representation and graph query evaluation approaches according to their performance when using large models and complex queries.","","","10.1109/ASE.2013.6693100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693100","Performance benchmark;Model queries;Model metrics;Query metrics","Measurement;Benchmark testing;Query processing;Resource description framework;Unified modeling language;Scalability;Engines","data models;graph theory;query processing;software reliability","graph query performance prediction;data intensive applications;model-driven software engineering;model queries;software models;MDSE tools;query evaluation approach;instance model metrics;model representation","","5","39","","","","","IEEE","IEEE Conferences"
"Automatically Generating Test Templates from Test Names (N)","B. Zhang; E. Hill; J. Clause","Univ. of Delaware, Newark, DE, USA; Drew Univ., Madison, NJ, USA; Univ. of Delaware, Newark, DE, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","506","511","Existing specification-based testing techniques require specifications that either do not exist or are too difficult to create. As a result, they often fall short of their goal of helping developers test expected behaviors. In this paper we present a novel, natural language-based approach that exploits the descriptive nature of test names to generate test templates. Similar to how modern IDEs simplify development by providing templates for common constructs such as loops, test templates can save time and lower the cognitive barrier for writing tests. The results of our evaluation show that the approach is feasible: despite the difficulty of the task, when test names contain a sufficient amount of information, the approach's accuracy is over 80% when parsing the relevant information from the test name and generating the template.","","","10.1109/ASE.2015.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372038","","Testing;Semantics;Concrete;Writing;Software;Speech;Encoding","natural language processing;program testing","natural language-based approach;descriptive test names;cognitive barrier;writing tests;test names;automatic test template generation","","3","21","","","","","IEEE","IEEE Conferences"
"Practically Tunable Static Analysis Framework for Large-Scale JavaScript Applications (T)","Y. Ko; H. Lee; J. Dolby; S. Ryu","NA; NA; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","541","551","We present a novel approach to analyze large-scale JavaScript applications statically by tuning the analysis scalability possibly giving up its soundness. For a given sound static baseline analysis of JavaScript programs, our framework allows users to define a sound approximation of selected executions that they are interested in analyzing, and it derives a tuned static analysis that can analyze the selected executions practically. The selected executions serve as parameters of the framework by taking trade-off between the scalability and the soundness of derived analyses. We formally describe our framework in abstract interpretation, and implement two instances of the framework. We evaluate them by analyzing large-scale real-world JavaScript applications, and the evaluation results show that the framework indeed empowers users to experiment with different levels of scalability and soundness. Our implementation provides an extra level of scalability by deriving sparse versions of derived analyses, and the implementation is publicly available.","","","10.1109/ASE.2015.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372042","","Scalability;Libraries;Reactive power;Sensitivity;Tuning;Approximation methods;Concrete","Java;program diagnostics","practically tunable static analysis framework;large-scale JavaScript applications;JavaScript programs;tuned static analysis;selected executions approximation;abstract interpretation;sparse versions","","6","34","","","","","IEEE","IEEE Conferences"
"CogniCrypt: Supporting developers in using cryptography","S. Krüger; S. Nadi; M. Reif; K. Ali; M. Mezini; E. Bodden; F. Göpfert; F. Günther; C. Weinert; D. Demmler; R. Kamath","Paderborn University, Germany; University of Alberta, Canada; Technische Universität Darmstadt, Germany; University of Alberta, Canada; Technische Universität Darmstadt, Germany; Paderborn University, Germany; Technische Universität Darmstadt, Germany; Technische Universität Darmstadt, Germany; Technische Universität Darmstadt, Germany; Technische Universität Darmstadt, Germany; Technische Universität Darmstadt, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","931","936","Previous research suggests that developers often struggle using low-level cryptographic APIs and, as a result, produce insecure code. When asked, developers desire, among other things, more tool support to help them use such APIs. In this paper, we present CogniCrypt, a tool that supports developers with the use of cryptographic APIs. CogniCrypt assists the developer in two ways. First, for a number of common cryptographic tasks, CogniCrypt generates code that implements the respective task in a secure manner. Currently, CogniCrypt supports tasks such as data encryption, communication over secure channels, and long-term archiving. Second, CogniCrypt continuously runs static analyses in the background to ensure a secure integration of the generated code into the developer's workspace. This video demo showcases the main features of CogniCrypt: youtube.com/watch?v=JUq5mRHfAWY.","","","10.1109/ASE.2017.8115707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115707","Cryptography;Code Generation;Variability Modeling;Code Analysis","Tools;Ciphers;Encryption;Java","application program interfaces;cryptography","CogniCrypt;cryptographic tasks;data encryption;long-term archiving;static analysis;low-level cryptographic API","","6","28","","","","","IEEE","IEEE Conferences"
"EventFlowSlicer: A tool for generating realistic goal-driven GUI tests","J. A. Saddler; M. B. Cohen","Department of Computer Science & Engineering, University of Nebraska-Lincoln, Lincoln, NE 68588-0115, USA; Department of Computer Science & Engineering, University of Nebraska-Lincoln, Lincoln, NE 68588-0115, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","955","960","Most automated testing techniques for graphical user interfaces (GUIs) produce test cases that are only concerned with covering the elements (widgets, menus, etc.) on the interface, or the underlying program code, with little consideration of test case semantics. This is effective for functional testing where the aim is to find as many faults as possible. However, when one wants to mimic a real user for evaluating usability, or when it is necessary to extensively test important end-user tasks of a system, or to generate examples of how to use an interface, this generation approach fails. Capture and replay techniques can be used, however there are often multiple ways to achieve a particular goal, and capturing all of these is usually too time consuming and unrealistic. Prior work on human performance regression testing introduced a constraint based method to filter test cases created by a functional test case generator, however that work did not capture the specifications, or directly generate only the required tests and considered only a single type of test goal. In this paper we present EventFlowSlicer, a tool that allows the GUI tester to specify and generate all realistic test cases relevant to achieve a stated goal. The user first captures relevant events on the interface, then adds constraints to provide restrictions on the task. An event flow graph is extracted containing only the widgets of interest for that goal. Next all test cases are generated for edges in the graph which respect the constraints. The test cases can then be replayed using a modified version of GUITAR. A video demonstration of EventFlowSlicer can be found at https://youtu.be/hw7WYz8WYVU.","","","10.1109/ASE.2017.8115711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115711","Software test generation;graphical user interfaces;goal-based testing","Color;Tools;Testing;Graphical user interfaces;Keyboards;Java","graphical user interfaces;program testing","realistic goal-driven GUI tests;automated testing techniques;graphical user interfaces;test case semantics;important end-user tasks;human performance regression testing;functional test case generator","","1","21","","","","","IEEE","IEEE Conferences"
"Efficient data race prediction with incremental reasoning on time-stamped lock history","M. K. Ganai","NEC Labs America, Princeton, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","37","47","We present an efficient data race prediction algorithm that uses lock-reordering based incremental search on time-stamped lock histories for solving multiple races effectively. We balance prediction accuracy, coverage, and performance with a specially designed pairwise reachability algorithm that can store and re-use past search results, thereby, amortizing the cost of reasoning over redundant and overlapping search space. Compared to graph-based search algorithms, our algorithm incurs much smaller overhead due to amortization, and can potentially be used while a program under test is executing. To demonstrate such a possibility, we implemented our approach as an incremental Predictive Analysis (iPA) module in a predictive testing framework. Our approach can handle traces with a few hundreds to half a million events, and predict known/unknown real data races with a performance penalty of less than 4% in addition to what is incurred by runtime race detectors.","","","10.1109/ASE.2013.6693064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693064","","Instruction sets;Testing;History;Synchronization;Cognition;Accuracy;Vectors","multi-threading;prediction theory;program debugging;program testing;reachability analysis;reasoning about programs;redundancy;search problems;software reliability","efficient data race prediction algorithm;incremental reasoning;time stamped lock history;lock reordering based incremental search;pairwise reachability algorithm;redundant search space;overlapping search space;amortization;program under test execution;incremental predictive analysis;iPA module;predictive testing;runtime race detector;multi-threaded programs","","1","37","","","","","IEEE","IEEE Conferences"
"Elixir: Effective object-oriented program repair","R. K. Saha; Y. Lyu; H. Yoshida; M. R. Prasad","Fujitsu Laboratories of America, Sunnyvale, CA, USA; University of Southern California, Los Angeles, CA, USA; Fujitsu Laboratories of America, Sunnyvale, CA, USA; Fujitsu Laboratories of America, Sunnyvale, CA, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","648","659","This work is motivated by the pervasive use of method invocations in object-oriented (OO) programs, and indeed their prevalence in patches of OO-program bugs. We propose a generate-and-validate repair technique, called ELIXIR designed to be able to generate such patches. ELIXIR aggressively uses method calls, on par with local variables, fields, or constants, to construct more expressive repair-expressions, that go into synthesizing patches. The ensuing enlargement of the repair space, on account of the wider use of method calls, is effectively tackled by using a machine-learnt model to rank concrete repairs. The machine-learnt model relies on four features derived from the program context, i.e., the code surrounding the potential repair location, and the bug report. We implement ELIXIR and evaluate it on two datasets, the popular Defects4J dataset and a new dataset Bugs.jar created by us, and against 2 baseline versions of our technique, and 5 other techniques representing the state of the art in program repair. Our evaluation shows that ELIXIR is able to increase the number of correctly repaired bugs in Defects4J by 85% (from 14 to 26) and by 57% in Bugs.jar (from 14 to 22), while also significantly out-performing other state-of-the-art repair techniques including ACS, HD-Repair, NOPOL, PAR, and jGenProg.","","","10.1109/ASE.2017.8115675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115675","","Maintenance engineering;Computer bugs;Java;Tools;Software;Object oriented modeling;Concrete","learning (artificial intelligence);object-oriented programming;program debugging","OO-program bugs;generate- validate repair technique;-validate repair technique;called ELIXIR;expressive repair-expressions;synthesizing patches;repair space;machine-learnt model;concrete repairs;program context;potential repair location;bug report;popular Defects4J dataset;dataset Bugs.jar;correctly repaired bugs;state-of-the-art repair techniques;HD-Repair;PAR;object-oriented program repair","","17","45","","","","","IEEE","IEEE Conferences"
"Model repair and transformation with Echo","N. Macedo; T. Guimarães; A. Cunha","HASLAB - High Assurance Software Laboratory, INESC TEC & Universidade do Minho, Braga, Portugal; HASLAB - High Assurance Software Laboratory, INESC TEC & Universidade do Minho, Braga, Portugal; HASLAB - High Assurance Software Laboratory, INESC TEC & Universidade do Minho, Braga, Portugal","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","694","697","Models are paramount in model-driven engineering. In a software project many models may coexist, capturing different views of the system or different levels of abstraction. A key and arduous task in this development method is to keep all such models consistent, both with their meta-models (and the respective constraints) and among themselves. This paper describes Echo, a tool that aims at simplifying this task by automating inconsistency detection and repair using a solver based engine. Consistency between different models can be specified by bidirectional model transformations, and is guaranteed to be recovered by minimal updates on the inconsistent models. The tool is freely available as an Eclipse plugin, developed on top of the popular EMF framework, and supports constraints and transformations specified in the OMG standard languages OCL and QVT-R, respectively.","","","10.1109/ASE.2013.6693135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693135","","Unified modeling language;Maintenance engineering;Object oriented modeling;Metals;Standards;Computational modeling;Semantics","software maintenance","model repair;Echo;model-driven engineering;software project;development method;meta-models;inconsistency detection automation;solver based engine;bidirectional model transformations;Eclipse plugin;EMF framework;OMG standard languages;OCL;QVT-R","","11","15","","","","","IEEE","IEEE Conferences"
"GRT: An Automated Test Generator Using Orchestrated Program Analysis","L. Ma; C. Artho; C. Zhang; H. Sato; J. Gmeiner; R. Ramler","Univ. of Tokyo, Tokyo, Japan; ITRI, AIST, Tsukuba, Japan; Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Tokyo, Tokyo, Japan; Software Competence Center, Hagenberg, Austria; Software Competence Center, Hagenberg, Austria","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","842","847","While being highly automated and easy to use, existing techniques of random testing suffer from low code coverage and defect detection ability for practical software applications. Most tools use a pure black-box approach, which does not use knowledge specific to the software under test. Mining and leveraging the information of the software under test can be promising to guide random testing to overcome such limitations. Guided Random Testing (GRT) implements this idea. GRT performs static analysis on software under test to extract relevant knowledge and further combines the information extracted at run-time to guide the whole test generation procedure. GRT is highly configurable, with each of its six program analysis components implemented as a pluggable module whose parameters can be adjusted. Besides generating test cases, GRT also automatically creates a test coverage report. We show our experience in GRT tool development and demonstrate its practical usage using two concrete application scenarios.","","","10.1109/ASE.2015.102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372077","Automatic test generation;random testing;bug detection;static analysis;dynamic analysis","Testing;Data mining;Generators;Libraries;Impurities;Software systems","program diagnostics;program testing","GRT;automated test generator;orchestrated program analysis;random testing;low code coverage;defect detection ability;black-box approach;software under test;static analysis;program analysis components;test coverage report","","8","38","","","","","IEEE","IEEE Conferences"
"ActivitySpace: A Remembrance Framework to Support Interapplication Information Needs","L. Bao; D. Ye; Z. Xing; X. Xia; X. Wang","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","864","869","Developers' daily work produces, transforms, and communicates cross-cutting information across applications, including IDEs, emails, Q&A sites, Twitter, and many others. However, these applications function independently of one another. Even though each application has their own effective information management mechanisms, cross-cutting information across separate applications creates a problem of information fragmentation, forcing developers to manually track, correlate, and re-find cross-cutting information across applications. In this paper, we present ActivitySpace, a remembrance framework that unobtrusively tracks and analyze a developer's daily work in separate applications, and provides various semantic and episodic UIs that help developers correlate and re-find cross-cutting information across applications based on information content, time and place of his/her activities. Through a user study of 8 participants, we demonstrate how ActivitySpace helps to tackle information fragmentation problem in developers' daily work.","","","10.1109/ASE.2015.90","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372081","","History;Semantics;Software;Mice;Databases;Computers;Image color analysis","software development management;user interfaces","ActivitySpace;remembrance framework;interapplication information needs;information management mechanism;information fragmentation;semantic UI;episodic UI","","7","21","","","","","IEEE","IEEE Conferences"
"Dynamically transforming data structures","E. Österlund; W. Löwe","Software Technology Group, Linnaeus University, Växjö, Sweden; Software Technology Group, Linnaeus University, Växjö, Sweden","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","410","420","Fine-tuning which data structure implementation to use for a given problem is sometimes tedious work since the optimum solution depends on the context, i.e., on the operation sequences, actual parameters as well as on the hardware available at run time. Sometimes a data structure with higher asymptotic time complexity performs better in certain contexts because of lower constants. The optimal solution may not even be possible to determine at compile time. We introduce transformation data structures that dynamically change their internal representation variant based on a possibly changing context. The most suitable variant is selected at run time rather than at compile time. We demonstrate the effect on performance with a transformation ArrayList data structure using an array variant and a linked hash bag variant as alternative internal representations. Using our transformation ArrayList, the standard DaCapo benchmark suite shows a performance gain of 5.19% in average.","","","10.1109/ASE.2013.6693099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693099","","Context;Abstracts;Arrays;Algorithm design and analysis;Switches;Complexity theory","data structures","transformation ArrayList data structure;hash bag variant;DaCapo benchmark suite;internal representation variant;possibly changing context","","1","15","","","","","IEEE","IEEE Conferences"
"Array Shadow State Compression for Precise Dynamic Race Detection (T)","J. R. Wilcox; P. Finch; C. Flanagan; S. N. Freund","Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA; Cognius, Boston, MA, USA; Comput. Sci. Dept., Univ. of California, Santa Cruz, Santa Cruz, CA, USA; Comput. Sci. Dept., Williams Coll., Williamstown, MA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","155","165","Precise dynamic race detectors incur significant time and space overheads, particularly for array-intensive programs, due to the need to store and manipulate analysis (or shadow) state for every element of every array. This paper presents SlimState, a precise dynamic race detector that uses an adaptive, online algorithm to optimize array shadow state representations. SlimState is based on the insight that common array access patterns lead to analogous patterns in array shadow state, enabling optimized, space efficient representations of array shadow state with no loss in precision. We have implemented SlimState for Java. Experiments on a variety of benchmarks show that array shadow compression reduces the space and time overhead of race detection by 27% and 9%, respectively. It is particularly effective for array-intensive programs, reducing space and time overheads by 35% and 17%, respectively, on these programs.","","","10.1109/ASE.2015.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372005","concurrency;data race detection;dynamic analysis","Arrays;Clocks;Instruction sets;Detectors;Synchronization;Heuristic algorithms;Java","Java;program testing;system monitoring","array shadow state compression;precise dynamic race detection;SLIMSTATE;adaptive online algorithm;array shadow state representations;array access patterns;analogous patterns;space efficient representations;Java;space overhead;time overhead;array-intensive programs","","11","46","","","","","IEEE","IEEE Conferences"
"All about activity injection: Threats, semantics, and detection","S. Lee; S. Hwang; S. Ryu","KAIST, Korea; LG Electronics, Korea; KAIST, Korea","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","252","262","Android supports seamless user experience by maintaining activities from different apps in the same activity stack. While such close inter-app communication is essential in the Android framework, the powerful inter-app communication contains vulnerabilities that can inject malicious activities into a victim app's activity stack to hijack user interaction flows. In this paper, we demonstrate activity injection attacks with a simple malware, and formally specify the activity activation mechanism using operational semantics. Based on the operational semantics, we develop a static analysis tool, which analyzes Android apps to detect activity injection attacks. Our tool is fast enough to analyze real-world Android apps in 6 seconds on average, and our experiments found that 1,761 apps out of 129,756 real-world Android apps inject their activities into other apps' tasks.","","","10.1109/ASE.2017.8115638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115638","","Androids;Humanoid robots;Electronic mail;Smart phones;Semantics;Malware","Android (operating system);invasive software;mobile computing;program diagnostics","Android framework;malicious activities;user interaction;activity injection attacks;activity activation mechanism;operational semantics;victim application activity stack;real-world Android application;interapplication communication","","","55","","","","","IEEE","IEEE Conferences"
"UI driven Android application reduction","J. Huang; Y. Aafer; D. Perry; X. Zhang; C. Tian","Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA; Huawei R&D, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","286","296","While smartphones and mobile apps have been an integral part of our life, modern mobile apps tend to contain a lot of rarely used functionalities. For example, applications contain advertisements and offer extra features such as recommended news stories in weather apps. While these functionalities are not essential to an app, they nonetheless consume power, CPU cycles and bandwidth. In this paper, we design a UI driven approach that allows customizing an Android app by removing its unwanted functionalities. In particular, our technique displays the UI and allows the user to select elements denoting functionalities that she wants to remove. Using this information, our technique automatically removes all the code elements related to the selected functionalities, including all the relevant background tasks. The underlying analysis is a type system, in which each code element is tagged with a type indicating if it should be removed. From the UI hints, our technique infers types for all other code elements and reduces the app accordingly. We implement a prototype and evaluate it on 10 real-world Android apps. The results show that our approach can accurately discover the removable code elements and lead to substantial resource savings in the reduced apps.","","","10.1109/ASE.2017.8115642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115642","","Meteorology;Androids;Humanoid robots;Mobile communication;Real-time systems;Prototypes","Android (operating system);mobile computing;smart phones;user interfaces","UI driven Android application reduction;smartphones;integral part;modern mobile apps;advertisements;offer extra features;recommended news stories;UI driven approach;code element;UI hints;real-world Android apps;removable code elements;UI;CPU","","","38","","","","","IEEE","IEEE Conferences"
"How do Developers Document Database Usages in Source Code? (N)","M. Linares-Vásquez; B. Li; C. Vendome; D. Poshyvanyk","Coll. of William & Mary, Williamsburg, VA, USA; Coll. of William & Mary, Williamsburg, VA, USA; Coll. of William & Mary, Williamsburg, VA, USA; Coll. of William & Mary, Williamsburg, VA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","36","41","Database-centric applications (DCAs) usually contain a large number of tables, attributes, and constraints describing the underlying data model. Understanding how database tables and attributes are used in the source code along with the constraints related to these usages is an important component of DCA maintenance. However, documenting database-related operations and their constraints in the source code is neither easy nor common in practice. In this paper, we present a two-fold empirical study aimed at identifying how developers document database usages at source code method level. In particular, (i) we surveyed open source developers to understand their practices on documenting database usages in source code, and (ii) we mined a large set of open source projects to measure to what extent database-related methods are commented and if these comments are updated during evolution. Although 58% of the developers claimed to find value in method comments describing database usages, our findings suggest that 77% of 33K+ methods in 3.1K+ open-source Java projects with database accesses were completely undocumented.","","","10.1109/ASE.2015.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371993","","Databases;Documentation;Java;Data mining;Electronic mail;Software;Data models","database management systems;document handling;public domain software;software maintenance;source code (software)","database centric applications;underlying data model;database tables;DCA maintenance;documenting database related operations;source code method level;open source projects;database related methods","","7","31","","","","","IEEE","IEEE Conferences"
"Mining branching-time scenarios","D. Fahland; D. Lo; S. Maoz","Eindhoven University of Technology, The Netherlands; Singapore Management University, Singapore; Tel Aviv University, Israel","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","443","453","Specification mining extracts candidate specification from existing systems, to be used for downstream tasks such as testing and verification. Specifically, we are interested in the extraction of behavior models from execution traces. In this paper we introduce mining of branching-time scenarios in the form of existential, conditional Live Sequence Charts, using a statistical data-mining algorithm. We show the power of branching scenarios to reveal alternative scenario-based behaviors, which could not be mined by previous approaches. The work contrasts and complements previous works on mining linear-time scenarios. An implementation and evaluation over execution trace sets recorded from several real-world applications shows the unique contribution of mining branching-time scenarios to the state-of-the-art in specification mining.","","","10.1109/ASE.2013.6693102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693102","","Semantics;Context;Educational institutions;Data mining;Abstracts;Weight measurement;Testing","data mining;formal verification;program testing;statistical analysis","behavior models extraction;branching-time scenarios mining;conditional live sequence charts;statistical data-mining algorithm","","17","42","","","","","IEEE","IEEE Conferences"
"Variable Feature Usage Patterns in PHP (T)","M. Hills","East Carolina Univ., Greenville, NC, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","563","573","PHP allows the names of variables, classes, functions, methods, and properties to be given dynamically, as expressions that, when evaluated, return an identifier as a string. While this provides greater flexibility for programmers, it also makes PHP programs harder to precisely analyze and understand. In this paper we present a number of patterns designed to recognize idiomatic uses of these features that can be statically resolved to a precise set of possible names. We then evaluate these patterns across a corpus of 20 open-source systems totaling more than 3.7 million lines of PHP, showing how often these patterns occur in actual PHP code, demonstrating their effectiveness at statically determining the names that can be used at runtime, and exploring anti-patterns that indicate when the identifier computation is truly dynamic.","","","10.1109/ASE.2015.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372044","Static analysis;dynamic language features;usage patterns;PHP","Reactive power;Arrays;Runtime;Feature extraction;Pattern recognition;Open source software;Engines","object-oriented languages;object-oriented methods;public domain software","variable feature usage patterns;PHP programs;open-source systems;PHP code;anti-patterns;object-oriented language","","6","22","","","","","IEEE","IEEE Conferences"
"Taco: A tool to generate tensor algebra kernels","F. Kjolstad; S. Chou; D. Lugato; S. Kamil; S. Amarasinghe","MIT CSAIL, USA; MIT CSAIL, USA; CEA, France; Adobe, USA; MIT CSAIL, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","943","948","Tensor algebra is an important computational abstraction that is increasingly used in data analytics, machine learning, engineering, and the physical sciences. However, the number of tensor expressions is unbounded, which makes it hard to develop and optimize libraries. Furthermore, the tensors are often sparse (most components are zero), which means the code has to traverse compressed formats. To support programmers we have developed taco, a code generation tool that generates dense, sparse, and mixed kernels from tensor algebra expressions. This paper describes the taco web and command-line tools and discusses the benefits of a code generator over a traditional library. See also the demo video at tensor-compiler.org/ase2017.","","","10.1109/ASE.2017.8115709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115709","Tensor algebra;linear algebra;sparse;compiler","Tensile stress;Tools;Kernel;Indexes;Libraries;Linear algebra","data analysis;learning (artificial intelligence);mathematics computing;program compilers;software libraries;tensors","tensor algebra kernels;data analytics;machine learning;physical sciences;tensor expressions;compressed formats;code generation tool;dense kernels;mixed kernels;tensor algebra expressions;taco web;command-line tools;code generator;computational abstraction;sparse kernels","","2","25","","","","","IEEE","IEEE Conferences"
"FEMIR: A tool for recommending framework extension examples","M. Asaduzzaman; C. K. Roy; K. A. Schneider; D. Hou","Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada; Electrical and Computer Engineering Department, Clarkson University, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","967","972","Software frameworks enable developers to reuse existing well tested functionalities instead of taking the burden of implementing everything from scratch. However, to meet application specific requirements, the frameworks need to be customized via extension points. This is often done by passing a framework related object as an argument to an API call. To enable such customizations, the object can be created by extending a framework class, implementing an interface, or changing the properties of the object via API calls. However, it is both a common and non-trivial task to find all the details related to the customizations. In this paper, we present a tool, called FEMIR, that utilizes partial program analysis and graph mining technique to detect, group, and rank framework extension examples. The tool extends existing code completion infrastructure to inform developers about customization choices, enabling them to browse through extension points of a framework, and frequent usages of each point in terms of code examples. A video demo is made available at https://asaduzzamanparvez.wordpress.com/femir.","","","10.1109/ASE.2017.8115713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115713","API;framework;reuse;extension point;extension;partial program analysis;graph mining","Tools;Receivers;Proposals;Java;Indexes;Tree data structures","application program interfaces;data mining;graph theory;program diagnostics","software frameworks;tested functionalities;application specific requirements;framework related object;API call;framework class;partial program analysis;graph mining technique;rank framework extension examples;customization choices;code examples;FEMIR","","1","8","","","","","IEEE","IEEE Conferences"
"Improving efficiency of dynamic analysis with dynamic dependence summaries","V. K. Palepu; G. Xu; J. A. Jones","University of California, Irvine, USA; University of California, Irvine, USA; University of California, Irvine, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","59","69","Modern applications make heavy use of third-party libraries and components, which poses new challenges for efficient dynamic analysis. To perform such analyses, transitive dependent components at all layers of the call stack must be monitored and analyzed, and as such may be prohibitively expensive for systems with large libraries and components. As an approach to address such expenses, we record, summarize, and reuse dynamic dataflows between inputs and outputs of components, based on dynamic control and data traces. These summarized dataflows are computed at a fine-grained instruction level; the result of which, we call “dynamic dependence summaries.” Although static summaries have been proposed, to the best of our knowledge, this work presents the first technique for dynamic dependence summaries. The benefits to efficiency of such summarization may be afforded with losses of accuracy. As such, we evaluate the degree of accuracy loss and the degree of efficiency gain when using dynamic dependence summaries of library methods. On five large programs from the DaCapo benchmark (for which no existing whole-program dynamic dependence analyses have been shown to scale) and 21 versions of NANOXML, the summarized dependence analysis provided 90% accuracy and a speed-up of 100% (i.e., ×2), on average, when compared to traditional exhaustive dynamic dependence analysis.","","","10.1109/ASE.2013.6693066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693066","Program analysis;Dynamic analysis;Dynamic Slicing;Data-flow;Summarization","Arrays;Concrete;Abstracts;Libraries;Indexes;Java;Accuracy","instruction sets;program diagnostics;software libraries","dynamic program analysis;third-party libraries;transitive dependent components;dynamic dataflows;dynamic control;data traces;fine-grained instruction level;dynamic dependence summaries;degree of accuracy loss evaluation;degree of efficiency gain evaluation;library methods;DaCapo benchmark;NANOXML;summarized dependence analysis;exhaustive dynamic dependence analysis;large object-oriented libraries","","6","34","","","","","IEEE","IEEE Conferences"
"Operator-based and random mutant selection: Better together","L. Zhang; M. Gligoric; D. Marinov; S. Khurshid","University of Texas, Austin, 78712, USA; University of Illinois, Urbana, 61801, USA; University of Illinois, Urbana, 61801, USA; University of Texas, Austin, 78712, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","92","102","Mutation testing is a powerful methodology for evaluating the quality of a test suite. However, the methodology is also very costly, as the test suite may have to be executed for each mutant. Selective mutation testing is a well-studied technique to reduce this cost by selecting a subset of all mutants, which would otherwise have to be considered in their entirety. Two common approaches are operator-based mutant selection, which only generates mutants using a subset of mutation operators, and random mutant selection, which selects a subset of mutants generated using all mutation operators. While each of the two approaches provides some reduction in the number of mutants to execute, applying either of the two to medium-sized, real-world programs can still generate a huge number of mutants, which makes their execution too expensive. This paper presents eight random sampling strategies defined on top of operator-based mutant selection, and empirically validates that operator-based selection and random selection can be applied in tandem to further reduce the cost of mutation testing. The experimental results show that even sampling only 5% of mutants generated by operator-based selection can still provide precise mutation testing results, while reducing the average mutation testing time to 6.54% (i.e., on average less than 5 minutes for this study).","","","10.1109/ASE.2013.6693070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693070","","Testing;Standards;Java;Power measurement;Correlation;Educational institutions;Libraries","cost reduction;program testing;software quality","operator-based mutant selection;random mutant selection;mutation testing;test suite quality evaluation;cost reduction;random sampling strategies","","27","65","","","","","IEEE","IEEE Conferences"
"Boosting complete-code tool for partial program","H. Zhong; X. Wang","Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Department of Computer Science, University of Texas at San Antonio, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","671","681","To improve software quality, researchers and practitioners have proposed static analysis tools for various purposes (e.g., detecting bugs, anomalies, and vulnerabilities). Although many such tools are powerful, they typically need complete programs where all the code names (e.g., class names, method names) are resolved. In many scenarios, researchers have to analyze partial programs in bug fixes (the revised source files can be viewed as a partial program), tutorials, and code search results. As a partial program is a subset of a complete program, many code names in partial programs are unknown. As a result, despite their syntactical correctness, existing complete-code tools cannot analyze partial programs, and existing partial-code tools are limited in both their number and analysis capability. Instead of proposing another tool for analyzing partial programs, we propose a general approach, called GRAPA, that boosts existing tools for complete programs to analyze partial programs. Our major insight is that after unknown code names are resolved, tools for complete programs can analyze partial programs with minor modifications. In particular, GRAPA locates Java archive files to resolve unknown code names, and resolves the remaining unknown code names from resolved code names. To illustrate GRAPA, we implement a tool that leverages the state-of-the-art tool, WALA, to analyze Java partial programs. We thus implemented the first tool that is able to build system dependency graphs for partial programs, complementing existing tools. We conduct an evaluation on 8,198 partial-code commits from four popular open source projects. Our results show that GRAPA fully resolved unknown code names for 98.5% bug fixes, with an accuracy of 96.1% in total. Furthermore, our results show the significance of GRAPA's internal techniques, which provides insights on how to integrate with more complete-code tools to analyze partial programs.","","","10.1109/ASE.2017.8115677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115677","Partial program;program analysis;boosting complete-code tool","Tools;Computer bugs;Boosting;Java;Data mining;Software;Syntactics","graph theory;Java;program debugging;program diagnostics;public domain software;software quality","unknown code names;partial program;complete-code tool;partial-code tools;software quality improvement;GRAPA;Java archive files;Java partial program analysis","","3","44","","","","","IEEE","IEEE Conferences"
"AnswerBot: Automated generation of answer summary to developers' technical questions","B. Xu; Z. Xing; X. Xia; D. Lo","College of Computer Science and Technology, Zhejiang University, China; School of Engineering and Computer Science, Australian National University, Australia; Department of Computer Science, University of British Columbia, Canada; School of Information Systems, Singapore Management University, Singapore","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","706","716","The prevalence of questions and answers on domain-specific Q&A sites like Stack Overflow constitutes a core knowledge asset for software engineering domain. Although search engines can return a list of questions relevant to a user query of some technical question, the abundance of relevant posts and the sheer amount of information in them makes it difficult for developers to digest them and find the most needed answers to their questions. In this work, we aim to help developers who want to quickly capture the key points of several answer posts relevant to a technical question before they read the details of the posts. We formulate our task as a query-focused multi-answer-posts summarization task for a given technical question. Our proposed approach AnswerBot contains three main steps : 1) relevant question retrieval, 2) useful answer paragraph selection, 3) diverse answer summary generation. To evaluate our approach, we build a repository of 228,817 Java questions and their corresponding answers from Stack Overflow. We conduct user studies with 100 randomly selected Java questions (not in the question repository) to evaluate the quality of the answer summaries generated by our approach, and the effectiveness of its relevant question retrieval and answer paragraph selection components. The user study results demonstrate that answer summaries generated by our approach are relevant, useful and diverse; moreover, the two components are able to effectively retrieve relevant questions and select salient answer paragraphs for summarization.","","","10.1109/ASE.2017.8115681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115681","Summary generation;question retrieval","Synchronization;Java;Tools;Knowledge discovery;Google;Search engines","Java;query processing;question answering (information retrieval);search engines","Stack Overflow;question repository;answer summary;relevant question retrieval;answer paragraph selection components;salient answer paragraphs;automated generation;core knowledge asset;software engineering domain;search engines;user query;relevant posts;answer posts;multianswer-posts summarization task;domain-specific Q&A;randomly selected Java questions;AnswerBot","","7","30","","","","","IEEE","IEEE Conferences"
"OCRA: A tool for checking the refinement of temporal contracts","A. Cimatti; M. Dorigatti; S. Tonetta","FBK-irst, Trento, Italy; FBK-irst, Trento, Italy; FBK-irst, Trento, Italy","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","702","705","Contract-based design enriches a component model with properties structured in pairs of assumptions and guarantees. These properties are expressed in term of the variables at the interface of the components, and specify how a component interacts with its environment: the assumption is a property that must be satisfied by the environment of the component, while the guarantee is a property that the component must satisfy in response. Contract-based design has been recently proposed in many methodologies for taming the complexity of embedded systems. In fact, contract-based design enables stepwise refinement, compositional verification, and reuse of components. However, only few tools exist to support the formal verification underlying these methods. OCRA (Othello Contracts Refinement Analysis) is a new tool that provides means for checking the refinement of contracts specified in a linear-time temporal logic. The specification language allows to express discrete as well as metric real-time constraints. The underlying reasoning engine allows checking if the contract refinement is correct. OCRA has been used in different projects and integrated in CASE tools.","","","10.1109/ASE.2013.6693137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693137","","Contracts;Cognition;Model checking;Context;Embedded systems;Unified modeling language;Automata","formal specification;object-oriented programming;program verification;software reusability;software tools;specification languages;temporal logic","OCRA tool;temporal contract refinement checking;component interface model;contract-based design;stepwise refinement;compositional verification;component reuse;formal verification;Othello Contracts Refinement Analysis;linear-time temporal logic;specification language;discrete constraints;metric constraints;reasoning engine;CASE tools","","44","26","","","","","IEEE","IEEE Conferences"
"SiPL -- A Delta-Based Modeling Framework for Software Product Line Engineering","C. Pietsch; T. Kehrer; U. Kelter; D. Reuling; M. Ohrndorf","Software Eng. Group, Univ. of Siegen, Siegen, Germany; Software Eng. Group, Univ. of Siegen, Siegen, Germany; Software Eng. Group, Univ. of Siegen, Siegen, Germany; Software Eng. Group, Univ. of Siegen, Siegen, Germany; Software Eng. Group, Univ. of Siegen, Siegen, Germany","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","852","857","Model-based development has become a widely-used approach to implement software, e.g. for embedded systems. Models replace source code as primary executable artifacts in these cases. Software product line technologies for these domains must be able to generate models as instances of an SPL. This need is addressed among others by an implementation technology for SPLs known as delta modeling. Current approaches to delta modeling require deltas to be written manually using delta languages, and they offer only very limited support for creating and testing a network of deltas. This paper presents a new approach to delta modeling and a supporting tool suite: the abstract notion of a delta is refined to be a consistency-preserving edit script which is generated by comparing two models. The rich structure of edit scripts allows us to detect conflicts and further relations between deltas statically and to implement restructurings in delta sets such as the merging of two deltas. We illustrate the tooling using a case study.","","","10.1109/ASE.2015.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372079","software product line engineering;model-based development;delta modeling;model differencing","Unified modeling language;Visualization;Standards;Graphical user interfaces;Software product lines;Software packages","software product lines","delta-based modeling framework;software product line engineering;SiPL;source code;software product line technology;SPL;delta language","","4","30","","","","","IEEE","IEEE Conferences"
"The iMPAcT Tool: Testing UI Patterns on Mobile Applications","I. C. Morgado; A. C. R. Paiva","Dept. of Inf. Eng., Univ. of Porto, Porto, Portugal; Dept. of Inf. Eng., Univ. of Porto, Porto, Portugal","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","876","881","This paper presents the iMPAcT tool that tests recurring behaviour, i.e., UI Patterns, on mobile applications. This tool is implemented in Java and makes use of Android's APIs UI Automator and UiAutomation. The tool automatically explores a mobile application in order to automatically identify and test UI Patterns. Each UI Pattern has a test strategy, Test Patterns, associated, which is applied when an UI Pattern is found. The approach works on top of a catalogue of UI Patterns, which determines which UI Patterns are to be tested, and what should their correct behaviour be, and may be used for any application.","","","10.1109/ASE.2015.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372083","Mobile Testing;UI Patterns;Pattern-based testing;Reverse Engineering","Testing;Mobile communication;Androids;Humanoid robots;Mobile applications;Layout;Pattern matching","Android (operating system);application program interfaces;data flow analysis;Java;mobile computing","iMPAcT tool;UI pattern testing;mobile applications;recurring behaviour testing;Java;Android API;UI Automator;UiAutomation","","9","34","","","","","IEEE","IEEE Conferences"
"JaConTeBe: A Benchmark Suite of Real-World Java Concurrency Bugs (T)","Z. Lin; D. Marinov; H. Zhong; Y. Chen; J. Zhao","Sch. Of Software, Shanghai Jiao Tong Univ., Shanghai, China; Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China; Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China; Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","178","189","Researchers have proposed various approaches to detect concurrency bugs and improve multi-threaded programs, but performing evaluations of the effectiveness of these approaches still remains a substantial challenge. We survey the existing evaluations and find out that they often use code or bugs not representative of real world. To improve representativeness, we have prepared JaConTeBe, a benchmark suite of 47 confirmed concurrency bugs from 8 popular open-source projects, supplemented with test cases for reproducing buggy behaviors. Running three approaches on JaConTeBe shows that our benchmark suite confirms some limitations of the three approaches. We submitted JaConTeBe to the SIR repository (a software-artifact repository for rigorous controlled experiments), and it was included as a part of SIR.","","","10.1109/ASE.2015.87","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372007","Java concurrency bugs;evaluations;benchmark suite;SIR;JaConTeBe","Computer bugs;Benchmark testing;Concurrent computing;Java;System recovery;Open source software","Java;multi-threading;program debugging;public domain software","JaConTeBe;real-world Java concurrency bugs;benchmark suite;multithreaded programs;open-source projects;test cases;buggy behaviors;SIR repository;software-artifact repository","","8","85","","","","","IEEE","IEEE Conferences"
"Study and Refactoring of Android Asynchronous Programming (T)","Y. Lin; S. Okur; D. Dig","Comput. Sci. Dept., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Comput. Sci. Dept., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","224","235","To avoid unresponsiveness, a core part of mobile development is asynchronous programming. Android providesseveral async constructs that developers can use. However, developers can still use the inappropriate async constructs, which result in memory leaks, lost results, and wasted energy. Fortunately, refactoring tools can eliminate these problems by transforming async code to use the appropriate constructs. In this paper we conducted a formative study on a corpusof 611 widely-used Android apps to map the asynchronouslandscape of Android apps, understand how developers retrofit asynchrony, and learn about barriers encountered by developers. Based on this study, we designed, implemented, and evaluated ASYNCDROID, a refactoring tool which enables Android developers to transform existing improperly-used async constructs into correct constructs. Our empirical evaluation shows that ASYNCDROID is applicable, accurate, and saves developers effort. We submitted 45 refactoring patches, and developers consider that the refactorings are useful.","","","10.1109/ASE.2015.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372011","Refactoring;Android;Asynchronous","Androids;Humanoid robots;Graphical user interfaces;Receivers;Programming;Registers;Transforms","Android (operating system);mobile computing;software maintenance","mobile development;Android asynchronous programming;Android application;asynchronous landscape;ASYNCDROID;refactoring tool;Android developers;improperly-used async constructs;refactoring patches","","23","51","","","","","IEEE","IEEE Conferences"
"Automated cross-platform inconsistency detection for mobile apps","M. Fazzini; A. Orso","Georgia Institute of Technology, USA; Georgia Institute of Technology, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","308","318","Testing of Android apps is particularly challenging due to the fragmentation of the Android ecosystem in terms of both devices and operating system versions. Developers must in fact ensure not only that their apps behave as expected, but also that the apps' behavior is consistent across platforms. To support this task, we propose DiffDroid, a new technique that helps developers automatically find cross-platform inconsistencies (CPIs) in mobile apps. DiffDroid combines input generation and differential testing to compare the behavior of an app on different platforms and identify possible inconsistencies. Given an app, DiffDroid (1) generates test inputs for the app, (2) runs the app with these inputs on a reference device and builds a model of the app behavior, (3) runs the app with the same inputs on a set of other devices, and (4) compares the behavior of the app on these different devices with the model of its behavior on the reference device. We implemented DiFFDRoiD and performed an evaluation of our approach on 5 benchmarks and over 130 platforms. our results show that DiFFDRoiD can identify CPis on real apps efficiently and with a limited number of false positives. DiFFDRoiD and our experimental infrastructure are publicly available.","","","10.1109/ASE.2017.8115644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115644","","Testing;Androids;Humanoid robots;Encoding;Performance evaluation;Analytical models","Android (operating system);mobile computing;program testing","mobile apps;DiffDroid;DiFFDRoiD;automated cross-platform inconsistency detection;Android apps;cross-platform inconsistencies","","6","45","","","","","IEEE","IEEE Conferences"
"Synthesising Interprocedural Bit-Precise Termination Proofs (T)","H. Chen; C. David; D. Kroening; P. Schrammel; B. Wachter","Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","53","64","Proving program termination is key to guaranteeing absence of undesirable behaviour, such as hanging programs and even security vulnerabilities such as denial-of-service attacks. To make termination checks scale to large systems, interprocedural termination analysis seems essential, which is a largely unexplored area of research in termination analysis, where most effort has focussed on difficult single-procedure problems. We present a modular termination analysis for C programs using template-based interprocedural summarisation. Our analysis combines a context-sensitive, over-approximating forward analysis with the inference of under-approximating preconditions for termination. Bit-precise termination arguments are synthesised over lexicographic linear ranking function templates. Our experimental results show that our tool 2LS outperforms state-of-the-art alternatives, and demonstrate the clear advantage of interprocedural reasoning over monolithic analysis in terms of efficiency, while retaining comparable precision.","","","10.1109/ASE.2015.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371995","program analysis;termination analysis;interprocedural analysis;synthesis;abstract interpretation","Context;Algorithm design and analysis;Encoding;Semantics;Computer crime;Computer bugs","C language;computer network security;inference mechanisms;program diagnostics;theorem proving","synthesising interprocedural bit-precise termination proof;program termination;security vulnerability;denial-of-service attack;large system;interprocedural termination analysis;modular termination analysis;C program;template-based interprocedural summarisation;context-sensitive forward analysis;over-approximating forward analysis;inference;bit-precise termination argument;lexicographic linear ranking function template;interprocedural reasoning;monolithic analysis","","9","64","","","","","IEEE","IEEE Conferences"
"Scalable product line configuration: A straw to break the camel's back","A. S. Sayyad; J. Ingram; T. Menzies; H. Ammar","Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","465","474","Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a “seed” in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes.","","","10.1109/ASE.2013.6693104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693104","Variability models;automated configuration;multiobjective optimization;evolutionary algorithms;SMT solvers","Biological system modeling;Optimization;Software;Analytical models;Linux;Sociology;Statistics","evolutionary computation;learning (artificial intelligence);Linux;operating system kernels;software product lines","scalable product line configuration;software product lines;Linux kernel;indicator-based evolutionary algorithm;IBEA;competing objectives;static learning;evolutionary learning;model structure;precomputed solution;randomly-generated initial population;seed solution;feature-rich seed","","44","34","","","","","IEEE","IEEE Conferences"
"Divide-and-Conquer Approach for Multi-phase Statistical Migration for Source Code (T)","A. T. Nguyen; T. T. Nguyen; T. N. Nguyen","NA; NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","585","596","Prior research shows that directly applying phrase-based SMT on lexical tokens to migrate Java to C# produces much semantically incorrect code. A key limitation is the use of sequences in phrase-based SMT to model and translate source code with well-formed structures. We propose mppSMT, a divide-and-conquer technique to address that with novel training and migration algorithms using phrase-based SMT in three phases. First, mppSMT treats a program as a sequence of syntactic units and maps/translates such sequences in two languages to one another. Second, with a syntax-directed fashion, it deals with the tokens within syntactic units by encoding them with semantic symbols to represent their data and token types. This encoding via semantic symbols helps better migration of API usages. Third, the lexical tokens corresponding to each sememe are mapped or migrated. The resulting sequences of tokens are merged together to form the final migrated code. Such divide-and-conquer and syntax-direction strategies enable phrase-based SMT to adapt well to syntactical structures in source code, thus, improving migration accuracy. Our empirical evaluation on several real-world systems shows that 84.8 -- 97.9% and 70 -- 83% of the migrated methods are syntactically and semantically correct, respectively. 26.3 -- 51.2% of total migrated methods are exactly matched to the human-written C# code in the oracle. Compared to Java2CSharp, a rule-based migration tool, it achieves higher semantic accuracy from 6.6 -- 57.7% relatively. Importantly, it does not require manual labeling for training data or manual definition of rules.","","","10.1109/ASE.2015.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372046","Language Migration;Statistical Machine Translation;Syntax-directed Translation","Syntactics;Java;Computational modeling;Training;Semantics;Training data;Decoding","divide and conquer methods;language translation;source code (software)","divide-and-conquer approach;multiphase statistical migration;source code;mppSMT;migration algorithms;phrase-based SMT;semantic symbols;API usages;lexical tokens;human-written C# code;oracle;statistical machine translation","","18","51","","","","","IEEE","IEEE Conferences"
"Copy and Paste Redeemed (T)","K. Narasimhan; C. Reichenbach","Inst. fur Inf., Goethe Univ. Frankfurt, Frankfurt, Germany; Inst. fur Inf., Goethe Univ. Frankfurt, Frankfurt, Germany","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","630","640","Modern software development relies on code reuse, which software engineers typically realise through handwritten abstractions, such as functions, methods, or classes. However, such abstractions can be challenging to develop and maintain. One alternative form of re-use is copy-paste-modify, a methodology in which developers explicitly duplicate source code to adapt the duplicate for a new purpose. We observe that copy-paste-modify can be substantially faster to use than manual abstraction, and past research strongly suggests that it is a popular technique among software developers. We therefore propose that software engineers should forego hand-written abstractions in favour of copying and pasting. However, empirical evidence also shows that copy-paste-modify complicates software maintenance and increases the frequency of bugs. To address this concern, we propose a software tool that merges together similar pieces of code and automatically creates suitable abstractions. This allows software developers to get the best of both worlds: custom abstraction together with easy re-use. To demonstrate the feasibility of our approach, we have implemented and evaluated a prototype merging tool for C++ on a number of near-miss clones (clones with some modifications) in popular Open Source packages. We found that maintainers find our algorithmically created abstractions to be largely preferable to existing duplicated code.","","","10.1109/ASE.2015.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372050","Refactoring;Clone management;Software Engineering;Static Analysis;Software evolution","Cloning;Software;Manuals;Software algorithms;Merging;Algorithm design and analysis;Face","C++ listings;public domain software;software reusability;software tools;source code (software)","modern software development;code reuse;software engineers;handwritten abstractions;copy-paste-modify;source code duplication;software developers;hand-written abstractions;software tool;prototype merging tool;C++;open source packages","","6","18","","","","","IEEE","IEEE Conferences"
"Opiner: An opinion search and summarization engine for APIs","G. Uddin; F. Khomh","School of Computer Science, McGill University, Montréal, QC, Canada; SWAT Lab, Polytechnique Montréal, QC, Canada","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","978","983","Opinions are key determinants to many of the activities related to software development. The perceptions of developers about an API, and the choices they make about whether and how they should use it, may, to a considerable degree, be conditioned upon how other developers see and evaluate the API. Given the plethora of APIs available for a given development task and the advent of developer forums as the media to share opinions about those APIs, it can be challenging for a developer to make informed decisions about an API to support the task. We introduce Opiner, our opinion search and summarization engine for API reviews. The server side of Opiner collects and summarizes opinions about APIs by crawling online developer forums and by associating the opinions found in the forum posts to the APIs discussed in the posts. The client side of Opiner is a Website that presents different summarized viewpoints of the opinions about the APIs in an online search engine. We evaluated Opiner by asking Industrial developers to select APIs for two development tasks. We found that developers were interested to use our proposed summaries of API reviews and that while combined with Stack Overflow, Opiner helped developers to make the right decision with more accuracy and confidence. The Opiner online search engine is available at: http://opiner.polymtl.ca. A video demo is available at: https://youtu.be/XAXpfmg5Lqs.","","","10.1109/ASE.2017.8115715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115715","Opinion mining;API informal documentation;opinion summaries;study;summary quality","Databases;Portals;Engines;Detectors;Software;Search engines","application program interfaces;Internet;search engines","online developer forums;development tasks;API reviews;summarization engine;software development;industrial developers;opiner online search engine","","2","28","","","","","IEEE","IEEE Conferences"
"Bita: Coverage-guided, automatic testing of actor programs","S. Tasharofi; M. Pradel; Y. Lin; R. Johnson","Department of Computer Science, University of Illinois, Urbana, 61801, USA; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, University of Illinois, Urbana, 61801, USA; Department of Computer Science, University of Illinois, Urbana, 61801, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","114","124","Actor programs are concurrent programs where concurrent entities communicate asynchronously by exchanging messages. Testing actor programs is challenging because the order of message receives depends on the non-deterministic scheduler and because exploring all schedules does not scale to large programs. This paper presents Bita, a scalable, automatic approach for testing non-deterministic behavior of actor programs. The key idea is to generate and explore schedules that are likely to reveal concurrency bugs because these schedules increase the schedule coverage. We present three schedule coverage criteria for actor programs, an algorithm to generate feasible schedules that increase coverage, and a technique to force a program to comply with a schedule. Applying Bita to real-world actor programs implemented in Scala reveals eight previously unknown concurrency bugs, of which six have already been fixed by the developers. Furthermore, we show our approach to find bugs 122× faster than random scheduling, on average.","","","10.1109/ASE.2013.6693072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693072","","Schedules;Receivers;Concurrent computing;Computer bugs;Testing;Programming;Postal services","message passing;multiprocessing programs;program debugging;program testing;scheduling","Bita;coverage-guided testing;automatic testing;actor programs;concurrent programs;message exchange;concurrency bugs;scheduling","","8","54","","","","","IEEE","IEEE Conferences"
"Context-aware integrated development environment command recommender systems","M. Gasparic; T. Gurbanov; F. Ricci","Free University of Bozen-Bolzano, Piazza Domenicani, 3, 39100 Bolzano, Italy; Free University of Bozen-Bolzano, Piazza Domenicani, 3, 39100 Bolzano, Italy; Free University of Bozen-Bolzano, Piazza Domenicani, 3, 39100 Bolzano, Italy","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","688","693","Integrated development environments (IDEs) are complex applications that integrate multiple tools for creating and manipulating software project artifacts. To improve users' knowledge and the effectiveness of usage of the available functionality, the inclusion of recommender systems into IDEs has been proposed. We present a novel IDE command recommendation algorithm that, by taking into account the contexts in which a developer works and in which different commands are usually executed, is able to provide relevant recommendations. We performed an empirical comparison of the proposed algorithm with state-of-the-art IDE command recommenders on a real-world data set. The algorithms were evaluated in terms of precision, recall, F1, k-tail, and with a new evaluation metric that is specifically measuring the usefulness of contextual recommendations. The experiments revealed that in terms of the contextual relevance and usefulness of recommendations the proposed algorithm outperforms existing algorithms.","","","10.1109/ASE.2017.8115679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115679","","Prediction algorithms;Context modeling;Algorithm design and analysis;Software;Java;Recommender systems;Software algorithms","project management;recommender systems;software engineering;software management;ubiquitous computing","context-aware integrated development environment command recommender systems;integrated development environments;software project artifacts;IDE command recommenders;available functionality;contextual recommendations;IDE command recommendation algorithm;complex applications","","2","17","","","","","IEEE","IEEE Conferences"
"The rise of the (modelling) bots: Towards assisted modelling via social networks","S. Pérez-Soler; E. Guerra; J. de Lara; F. Jurado","Universidad Autónoma de Madrid (Spain); Universidad Autónoma de Madrid (Spain); Universidad Autónoma de Madrid (Spain); Universidad Autónoma de Madrid (Spain)","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","723","728","We are witnessing a rising role of mobile computing and social networks to perform all sorts of tasks. This way, social networks like Twitter or Telegram are used for leisure, and they frequently serve as a discussion media for work-related activities. In this paper, we propose taking advantage of social networks to enable the collaborative creation of models by groups of users. The process is assisted by modelling bots that orchestrate the collaboration and interpret the users' inputs (in natural language) to incrementally build a (meta-)model. The advantages of this modelling approach include ubiquity of use, automation, assistance, natural user interaction, traceability of design decisions, possibility to incorporate coordination protocols, and seamless integration with the user's normal daily usage of social networks. We present a prototype implementation called SOCIO, able to work over several social networks like Twitter and Telegram, and a preliminary evaluation showing promising results.","","","10.1109/ASE.2017.8115683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115683","Collaborative modelling;meta-modelling;social networks;natural language processing","Computational modeling;Collaboration;Twitter;Windows;Prototypes","groupware;mobile computing;natural languages;social networking (online);user interfaces","social networks;assisted modelling;natural user interaction;mobile computing;Twitter;Telegram;natural language;SOCIO;modelling bots;collaborative creation","","5","17","","","","","IEEE","IEEE Conferences"
"CSeq: A concurrency pre-processor for sequential C verification tools","B. Fischer; O. Inverso; G. Parlato","Division of Computer Science, Stellenbosch University, South Africa; Electronics and Computer Science, University of Southampton, UK; Electronics and Computer Science, University of Southampton, UK","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","710","713","Sequentialization translates concurrent programs into equivalent nondeterministic sequential programs so that the different concurrent schedules no longer need to be handled explicitly. It can thus be used as a concurrency preprocessing technique for automated sequential program verification tools. Our CSeq tool implements a novel sequentialization for C programs using pthreads, which extends the Lal/Reps sequentialization to support dynamic thread creation. CSeq now works with three different backend tools, CBMC, ESBMC, and LLBMC, and is competitive with state-of-the-art verification tools for concurrent programs.","","","10.1109/ASE.2013.6693139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693139","","Concurrent computing;Instruction sets;Context;Programming;Benchmark testing","C language;concurrency control;parallel programming;program interpreters;program verification","sequential C verification tools;concurrency preprocessor;concurrent program translation;equivalent nondeterministic sequential programs;concurrency preprocessing technique;automated sequential program verification tools;CSeq tool;C program sequentialization;pthreads;Lal-Reps sequentialization;dynamic thread creation;CBMC;ESBMC;LLBMC;backend tools","","18","18","","","","","IEEE","IEEE Conferences"
"Stability of Self-Adaptive Software Architectures","M. Salama","Sch. of Comput. Sci., Univ. of Birmingham, Birmingham, UK","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","886","889","Stakeholders and organisations are increasingly looking for long-lived software. As architectures have a profound effect on the operational life-time of the software and the quality of the service provision, architectural stability could be considered a primary criterion towards achieving the long-livety of the software. Architectural stability is envisioned as the next step in quality attributes, combining many inter-related qualities. This research suggests the notion of behavioural stability as a primary criterion for evaluating whether the architecture maintains achieving the expected quality attributes, maintaining architecture robustness, and evaluating how well the architecture accommodates run-time evolutionary changes. The research investigates the notion of architecture stability at run-time in the context of self-adaptive software architectures. We expect to define, characterise and analyse this intuitive concept, as well as identify the consequent trade-offs to be dynamically managed and enhance the self-adaptation process for a long-lived software.","","","10.1109/ASE.2015.93","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372085","","Computer architecture;Stability criteria;Software;Software architecture;Adaptation models;Robustness","software architecture;software quality;stability","self-adaptive software architecture;architectural stability;software operational life-time;service provision quality","","1","12","","","","","IEEE","IEEE Conferences"
"Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges (T)","S. Shamshiri; R. Just; J. M. Rojas; G. Fraser; P. McMinn; A. Arcuri","Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA; Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Scienta, Norway","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","201","211","Rather than tediously writing unit tests manually, tools can be used to generate them automatically - sometimes even resulting in higher code coverage than manual testing. But how good are these tests at actually finding faults? To answer this question, we applied three state-of-the-art unit test generation tools for Java (Randoop, EvoSuite, and Agitar) to the 357 real faults in the Defects4J dataset and investigated how well the generated test suites perform at detecting these faults. Although the automatically generated test suites detected 55.7% of the faults overall, only 19.9% of all the individual test suites detected a fault. By studying the effectiveness and problems of the individual tools and the tests they generate, we derive insights to support the development of automated unit test generators that achieve a higher fault detection rate. These insights include 1) improving the obtained code coverage so that faulty statements are executed in the first instance, 2) improving the propagation of faulty program states to an observable output, coupled with the generation of more sensitive assertions, and 3) improving the simulation of the execution environment to detect faults that are dependent on external factors such as date and time.","","","10.1109/ASE.2015.86","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372009","automated test generation;test effectiveness;unit testing;empirical study;regression testing","Java;Testing;Generators;Writing;Manuals;Software","automatic test software;fault diagnosis;Java;program testing","unit test generation tools;Java;Randoop;EvoSuite;Agitar;Defects4J dataset;test suites;automated unit test generators;code coverage;faulty statements;faulty program state propagation;observable output;sensitive assertions;execution environment simulation;fault detection","","50","46","","","","","IEEE","IEEE Conferences"
"Reverse Engineering Mobile Application User Interfaces with REMAUI (T)","T. A. Nguyen; C. Csallner","Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA; Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","248","259","When developing the user interface code of a mobile application, in practice a big gap exists between the digital conceptual drawings of graphic artists and working user interface code. Currently, programmers bridge this gap manually, by reimplementing the conceptual drawings in code, which is cumbersome and expensive. To bridge this gap, we introduce the first technique to automatically Reverse Engineer Mobile Application User Interfaces (REMAUI). On a given input bitmap REMAUI identifies user interface elements such as images, texts, containers, and lists, via computer vision and optical character recognition (OCR) techniques. In our experiments on 488 screenshots of over 100 popular third-party Android and iOS applications, REMAUI-generated user interfaces were similar to the originals, both pixel-by-pixel and in terms of their runtime user interface hierarchies. REMAUI's average overall runtime on a standard desktop computer was 9 seconds.","","","10.1109/ASE.2015.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372013","","Graphical user interfaces;Mobile applications;Smart phones;Layout;Optical character recognition software;Containers","Android (operating system);computer vision;iOS (operating system);mobile computing;optical character recognition;reverse engineering;user interfaces","reverse engineering mobile application user interfaces;digital conceptual drawings;graphic artists;working user interface code;input bitmap;user interface elements identification;computer vision;optical character recognition techniques;OCR techniques;third-party Android;iOS applications;REMAUI-generated user interfaces;runtime user interface hierarchies;standard desktop computer","","15","55","","","","","IEEE","IEEE Conferences"
"DSIbin: Identifying dynamic data structures in C/C++ binaries","T. Rupprecht; X. Chen; D. H. White; J. H. Boockmann; G. Lüttgen; H. Bos","University of Bamberg, Germany; Microsoft, Canada; University of Bamberg, Germany; University of Bamberg, Germany; University of Bamberg, Germany; Vrije Universiteit Amsterdam, The Netherlands","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","331","341","Reverse engineering binary code is notoriously difficult and, especially, understanding a binary's dynamic data structures. Existing data structure analyzers are limited wrt. program comprehension: they do not detect complex structures such as skip lists, or lists running through nodes of different types such as in the Linux kernel's cyclic doubly-linked list. They also do not reveal complex parent-child relationships between structures. The tool DSI remedies these shortcomings but requires source code, where type information on heap nodes is available. We present DSIbin, a combination of DSI and the type excavator Howard for the inspection of C/C++ binaries. While a naive combination already improves upon related work, its precision is limited because Howard's inferred types are often too coarse. To address this we auto-generate candidates of refined types based on speculative nested-struct detection and type merging; the plausibility of these hypotheses is then validated by DSI. We demonstrate via benchmarking that DSIbin detects data structures with high precision.","","","10.1109/ASE.2017.8115646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115646","Data structure identification;reverse engineering;dynamic data structures;pointer programs;type recovery","Tools;Shape;Data structures;Linux;Kernel;Benchmark testing;Merging","binary codes;C++ language;data structures;excavators;Linux;program diagnostics;reverse engineering","DSIbin;dynamic data structure identification;C-C++ binaries;data structure analysis;Howards inferred types;nested-struct detection;type excavator Howard;source code;tool DSI;complex parent-child relationships;Linux kernel;skip lists;complex structures;program comprehension;reverse engineering binary code","","4","39","","","","","IEEE","IEEE Conferences"
"Crust: A Bounded Verifier for Rust (N)","J. Toman; S. Pernsteiner; E. Torlak","Dept. of Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA; Dept. of Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA; Dept. of Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","75","80","Rust is a modern systems language that provides guaranteed memory safety through static analysis. However, Rust includes an escape hatch in the form of ""unsafe code,"" which the compiler assumes to be memory safe and to preserve crucial pointer aliasing invariants. Unsafe code appears in many data structure implementations and other essential libraries, and bugs in this code can lead to memory safety violations in parts of the program that the compiler otherwise proved safe. We present CRUST, a tool combining exhaustive test generation and bounded model checking to detect memory safety errors, as well as violations of Rust's pointer aliasing invariants within unsafe library code. CRUST requires no programmer annotations, only an indication of the modules to check. We evaluate CRUSTon data structures from the Rust standard library. It detects memory safety bugs that arose during the library's development and remained undetected for several months.","","","10.1109/ASE.2015.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371997","SMT-based verification;test generation;memory safety","Arrays;Libraries;Safety;Computer bugs;Indexes;Standards","data structures;formal verification;program compilers;program debugging;program diagnostics;program testing;software libraries","CRUST;Rust;static analysis;compiler;pointer aliasing invariants;data structure implementations;memory safety violations;exhaustive test generation;bounded model checking;unsafe library code;memory safety bugs","","5","10","","","","","IEEE","IEEE Conferences"
"TrEKer: Tracing error propagation in operating system kernels","N. Coppik; O. Schwahn; S. Winter; N. Suri","DEEDS Group, TU Darmstadt, Darmstadt, Germany; DEEDS Group, TU Darmstadt, Darmstadt, Germany; DEEDS Group, TU Darmstadt, Darmstadt, Germany; DEEDS Group, TU Darmstadt, Darmstadt, Germany","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","377","387","Modern operating systems (OSs) consist of numerous interacting components, many of which are developed and maintained independently of one another. In monolithic systems, the boundaries of and interfaces between such components are not strictly enforced at runtime. Therefore, faults in individual components may directly affect other parts of the system in various ways. Software fault injection (SFI) is a testing technique to assess the resilience of a software system in the presence of faulty components. Unfortunately, SFI tests of OSs are inconclusive if they do not lead to observable failures, as corruptions of the internal software state may not be visible at its interfaces and, yet, affect the subsequent execution of the OS beyond the duration of the test. In this paper we present TrEKer, a fully automated approach for identifying how faulty OS components affect other parts of the system. TrEKer combines static and dynamic analyses to achieve efficient tracing on the granularity of memory accesses. We demonstrate TrEKer's ability to support SFI oracles by accurately tracing the effects of faults injected into three widely used Linux kernel modules.","","","10.1109/ASE.2017.8115650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115650","Software Fault Injection;Robustness Testing;Test Oracles;Execution Tracing;Operating Systems","Kernel;Hardware;Instruments;Testing;Fault diagnosis","fault diagnosis;Linux;operating system kernels;software fault tolerance","faulty components;SFI tests;observable failures;internal software state;fully automated approach;faulty OS components;efficient tracing;SFI oracles;modern operating systems;numerous interacting components;monolithic systems;software fault injection;testing technique;Linux kernel modules;tracing error propagation;operating system kernels;software system resilience;OS;TrEKer","","1","40","","","","","IEEE","IEEE Conferences"
"A comparative analysis of software architecture recovery techniques","J. Garcia; I. Ivkovic; N. Medvidovic","Computer Science Department, University of Southern California, Los Angeles, 90089, USA; Wilfrid Laurier University, 75 University Avenue West, Waterloo, ON, N2L 3C5, Canada; Computer Science Department, University of Southern California, Los Angeles, 90089, USA","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","486","496","Many automated techniques of varying accuracy have been developed to help recover the architecture of a software system from its implementation. However, rigorously assessing these techniques has been hampered by the lack of architectural “ground truths”. Over the past several years, we have collected a set of eight architectures that have been recovered from open-source systems and independently, carefully verified. In this paper, we use these architectures as ground truths in performing a comparative analysis of six state-of-the-art software architecture recovery techniques. We use a number of metrics to assess each technique for its ability to identify a system's architectural components and overall architectural structure. Our results suggest that two of the techniques routinely outperform the rest, but even the best of the lot has surprisingly low accuracy. Based on the empirical data, we identify several avenues of future research in software architecture recovery.","","","10.1109/ASE.2013.6693106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693106","","Computer architecture;Accuracy;Vectors;Clustering algorithms;Algorithm design and analysis;Software architecture;Java","formal verification;software architecture;software maintenance","software system architecture recovery techniques;open source systems;ground truths;system architectural components;architectural structure","","37","51","","","","","IEEE","IEEE Conferences"
"Minimizing CPU time shortage risks in integrated embedded software","S. Nejati; M. Adedjouma; L. C. Briand; J. Hellebaut; J. Begey; Y. Clement","SnT Center, University of Luxembourg, Luxembourg; SnT Center, University of Luxembourg, Luxembourg; SnT Center, University of Luxembourg, Luxembourg; Delphi Automotive Systems, Luxembourg; Delphi Automotive Systems, Luxembourg; Delphi Automotive Systems, Luxembourg","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","529","539","A major activity in many industries is to integrate software artifacts such that the functional and performance requirements are properly taken care of. In this paper, we focus on the problem of minimizing the risk of CPU time shortage in integrated embedded systems. In order to minimize this risk, we manipulate the start time (offset) of the software executables such that the system real-time constraints are satisfied, and further, the maximum CPU time usage is minimized. We develop a number of search-based optimization algorithms, specifically designed to work for large search spaces, to compute offsets for concurrent software executables with the objective of minimizing CPU usage. We evaluated and compared our algorithms by applying them to a large automotive software system. Our experience shows that our algorithms can automatically generate offsets such that the maximum CPU usage is very close to the known lower bound imposed by the domain constraints. Further, our approach finds limits on the maximum CPU usage lower than those found by a random strategy, and is not slower than a random strategy. Finally, our work achieves better results than the CPU usage minimization techniques devised by domain experts.","","","10.1109/ASE.2013.6693110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693110","","Software;Automotive engineering;Real-time systems;Software algorithms;Industries;Synchronization","embedded systems;integrated software;search problems","CPU time shortage risks minimization;integrated embedded software;integrated embedded systems;search-based optimization algorithms;automotive software system;random strategy","","3","27","","","","","IEEE","IEEE Conferences"
"Exploiting Domain and Program Structure to Synthesize Efficient and Precise Data Flow Analyses (T)","E. Sherman; M. B. Dwyer","NA; NA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","608","618","A key challenge in implementing an efficient and precise data flow analysis is determining how to abstract the domain of values that a program variable can take on and how to update abstracted values to reflect program semantics. Such updates are performed by a transfer function and recent work by Thakur, Elder and Reps defined the bilateral algorithm for computing the most precise transfer function for a given abstract domain. In this paper, we identify and exploit the special case where abstract domains are comprised of disjoint subsets. For such domains, transfer functions computed using a customized algorithm can improve performance and in combination with symbolic modeling of block-level transfer functions improve precision as well. We implemented these algorithms in Soot and used them to perform data flow analysis on more than 100 non-trivial Java methods drawn from open source projects. Our experimental data are promising as they demonstrate that a 25-fold reduction in analysis time can be achieved and precision can be increased relative to existing methods.","","","10.1109/ASE.2015.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372048","Data flow analysis;transfer function;abstract domain","Transfer functions;Algorithm design and analysis;Concrete;Computational modeling;Semantics;Lattices;Computer science","data flow analysis;Java;transfer functions","program structure;domain structure;data flow analysis;program semantics;bilateral algorithm;abstract domains;disjoint subsets;symbolic modeling;block-level transfer functions;Soot;Java methods;open source projects","","3","29","","","","","IEEE","IEEE Conferences"
"Covert Communication in Mobile Applications (T)","J. Rubin; M. I. Gordon; N. Nguyen; M. Rinard","Massachusetts Inst. of Technol., Cambridge, MA, USA; Massachusetts Inst. of Technol., Cambridge, MA, USA; Global InfoTek Inc., USA; Massachusetts Inst. of Technol., Cambridge, MA, USA","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","647","657","This paper studies communication patterns in mobile applications. Our analysis shows that 63% of the external communication made by top-popular free Android applications from Google Play has no effect on the user-observable application functionality. To detect such covert communication in an efficient manner, we propose a highly precise and scalable static analysis technique: it achieves 93% precision and 61% recall compared to the empirically determined ""ground truth"", and runs in a matter of a few minutes. Furthermore, according to human evaluators, in 42 out of 47 cases, disabling connections deemed covert by our analysis leaves the delivered application experience either completely intact or with only insignificant interference. We conclude that our technique is effective for identifying and disabling covert communication. We then use it to investigate communication patterns in the 500 top-popular applications from Google Play.","","","10.1109/ASE.2015.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372052","communication;mobile applications;Android;application analysis","Google;Androids;Humanoid robots;Mobile applications;Interference;Servers;Visualization","Android (operating system);mobile computing;program diagnostics","covert communication;mobile applications;communication patterns;top-popular free Android applications;Google Play;user-observable application functionality;scalable static analysis technique;ground truth;human evaluators;application experience","","7","36","","","","","IEEE","IEEE Conferences"
"Kobold: Web usability as a service","J. Grigera; A. Garrido; G. Rossi","LIFIA, Universidad Nacional de La Plata, Argentina, Also at CIC, Argentina; LIFIA, Universidad Nacional de La Plata, Argentina, Also at CONICET, Argentina; LIFIA, Universidad Nacional de La Plata, Argentina, Also at CONICET, Argentina","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","990","995","While Web applications have become pervasive in today's business, social interaction and information exchange, their usability is often deficient, even being a key factor for a website success. Usability problems repeat across websites, and many of them have been catalogued, but usability evaluation and repair still remains expensive. There are efforts from both the academy and industry to automate usability testing or to provide automatic statistics, but they rarely offer concrete solutions. These solutions appear as guidelines or patterns that developers can follow manually. This paper presents Kobold, a tool that detects usability problems from real user interaction (UI) events and repairs them automatically when possible, at least suggesting concrete solutions. By using the refactoring technique and its associated concept of bad smell, Kobold mines UI events to detect usability smells and applies usability refactorings on the client to correct them. The purpose of Kobold is to deliver usability advice and solutions as a service (SaaS) for developers, allowing them to respond to feedback of the real use of their applications and improve usability incrementally, even when there are no usability experts on the team. Kobold is available at: http://autorefactoring.lifia.info.unlp.edu.ar. A screencast is available at https://youtu.be/c-myYPMUh0Q.","","","10.1109/ASE.2017.8115717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115717","Web Usability;Software as a Service;Usability Refactoring","Usability;Tools;Concrete;Software as a service;Servers;Automation;Business","business data processing;Internet;software maintenance;software quality;Web sites","user interaction events;Kobold mines;usability refactorings;Web usability;Web applications;social interaction;information exchange;usability evaluation;automatic statistics;Web site","","2","13","","","","","IEEE","IEEE Conferences"
"BLITZ: Compositional bounded model checking for real-world programs","C. Y. Cho; V. D'Silva; D. Song","University of California, Berkeley, USA; DSO National Laboratories, Singapore; DSO National Laboratories, Singapore","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","136","146","Bounded Model Checking (BMC) for software is a precise bug-finding technique that builds upon the efficiency of modern SAT and SMT solvers. BMC currently does not scale to large programs because the size of the generated formulae exceeds the capacity of existing solvers. We present a new, compositional and property-sensitive algorithm that enables BMC to automatically find bugs in large programs. A novel feature of our technique is to decompose the behaviour of a program into a sequence of BMC instances and use a combination of satisfying assignments and unsatisfiability proofs to propagate information across instances. A second novelty is to use the control- and data-flow of the program as well as information from proofs to prune the set of variables and procedures considered and hence, generate smaller instances. Our tool BLITZ outperforms existing tools and scales to programs with over 100,000 lines of code. BLITZ automatically and efficiently discovers bugs in widely deployed software including new vulnerabilities in Internet infrastructure software.","","","10.1109/ASE.2013.6693074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693074","","Input variables;Computer bugs;Semantics;Model checking;Software;Indium phosphide;Internet","computability;data flow computing;Internet;program debugging;program verification","BLITZ;compositional bounded model checking;real-world programs;BMC;bug-finding technique;SAT solver;SMT solver;compositional algorithm;property-sensitive algorithm;control-flow;data-flow;Internet infrastructure software","","9","21","","","","","IEEE","IEEE Conferences"
"Promoting secondary orders of event pairs in randomized scheduling using a randomized stride","M. Abdelrasoul","North Carolina State University, USA","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","741","752","Because of the wide use of randomized scheduling in concurrency testing research, it is important to understand randomized scheduling and its limitations. This work analyzes how randomized scheduling discovers concurrency bugs by focusing on the probabilities of the two possible orders of a pair of events. Analysis shows that the disparity between probabilities can be large for programs that encounter a large number of events during execution. Because sets of ordered event pairs define conditions for discovering concurrency bugs, this disparity can make some concurrency bugs highly unlikely. The complementary nature of the two possible orders also indicates a potential trade-off between the probability of discovering frequently-occurring and infrequently-occurring concurrency bugs. To help address this trade-off in a more balanced way, randomized-stride scheduling is proposed, where scheduling granularity for each thread is adjusted using a randomized stride calculated based on thread length. With some assumptions, strides can be calculated to allow covering the least likely event pair orders. Experiments confirm the analysis results and also suggest that randomized-stride scheduling is more effective for discovering concurrency bugs compared to the original randomized scheduling implementation, and compared to other algorithms in recent literature.","","","10.1109/ASE.2017.8115685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115685","Multithreading;software debugging;software quality;parallel programming;scheduling algorithms","Computer bugs;Concurrent computing;Testing;Instruction sets;Scheduling algorithms;Message systems;Scheduling","concurrency control;probability;processor scheduling;program debugging","secondary orders;concurrency testing research;probabilities;ordered event pairs;randomized-stride scheduling;scheduling granularity;event pair orders;infrequently-occurring concurrency bugs;frequently-occurring concurrency bugs","","","53","","","","","IEEE","IEEE Conferences"
"Systematically testing background services of mobile apps","L. L. Zhang; C. M. Liang; Y. Liu; E. Chen","University of Science and Technology of China, China; Microsoft Research, China; Microsoft Research, China; University of Science and Technology of China, China","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","4","15","Contrary to popular belief, mobile apps can spend a large fraction of time running ""hidden"" as background services. And, bugs in services can translate into crashes, energy depletion, device slow-down, etc. Unfortunately, without necessary testing tools, developers can only resort to telemetries from user devices in the wild. To this end, Snowdrop is a testing framework that systematically identifies and automates background services in Android apps. Snowdrop realizes a service-oriented approach that does not assume all inter-component communication messages are explicitly coded in the app bytecode. Furthermore, to improve the completeness of test inputs generated, Snowdrop infers field values by exploiting the similarity in how developers name variables. We evaluate Snowdrop by testing 848 commercially available mobile apps. Empirical results show that Snowdrop can achieve 20.91% more code path coverage than pathwise test input generators, and 64.11% more coverage than random test input generators.","","","10.1109/ASE.2017.8115613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115613","App background services;test input generation;Android Intents","Testing;Androids;Humanoid robots;Tools;Mobile communication;Generators;Telemetry","Android (operating system);mobile computing;program testing;service-oriented architecture","background services;Android apps;Snowdrop;app bytecode;pathwise test input generators;random test input generators;user devices;testing tools;service-oriented approach;intercomponent communication messages;code path coverage","","4","46","","","","","IEEE","IEEE Conferences"
"The interactive verification debugger: Effective understanding of interactive proof attempts","M. Hentschel; R. Hähnle; R. Bubel","TU Darmstadt, Darmstadt, Germany; TU Darmstadt, Darmstadt, Germany & Università degli Studi di Torino, Torino, Italy; TU Darmstadt, Darmstadt, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","846","851","The Symbolic Execution Debugger (SED) is an extension of the Eclipse debug platform for interactive symbolic execution. Like a traditional debugger, the SED can be used to locate the origin of a defect and to increase program understanding. However, as it is based on symbolic execution, all execution paths are explored simultaneously. We demonstrate an extension of the SED called Interactive Verification Debugger (IVD) for inspection and understanding of formal verification attempts. By a number of novel views, the IVD allows to quickly comprehend interactive proof situations and to debug the reasons for a proof attempt that got stuck. It is possible to perform interactive proofs completely from within the IVD. It can be experimentally demonstrated that the IVD is more effective in understanding proof attempts than a conventional prover user interface. A screencast explaining proof attempt inspection with the IVD is available at youtu.be/8e-q9Jf1h_w.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582826","Symbolic Execution;Debugging;Program Execution Visualization;Verification;Proof Understanding","Java;Inspection;Software;Visualization;Indexes;User interfaces;Debugging","interactive systems;program debugging;program verification;theorem proving;user interfaces","interactive verification debugger;IVD;interactive proof attempt;symbolic execution debugger;SED;Eclipse debug platform;interactive symbolic execution;formal verification attempt","","","15","","","","","IEEE","IEEE Conferences"
"Automated testing and notification of mobile app privacy leak-cause behaviours","J. C. J. Keng","School of Information Systems, Singapore Management University","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","880","883","I describe the design, implementation and evaluation of a novel hybrid static/dynamic analysis system for automatically uncovering and testing for the user-triggered causes and paths of privacy leaks in Android applications (privacy `leak-causes'). I describe how I plan to further evaluate and demonstrate improvements in accuracy, coverage and testing speed of my hybrid testing approach against other currently available systems. I also show how user privacy is improved by the presentation of information on leak-causes in a field study as privacy notices. I present plans to investigate which of the commonly utilized mobile notification mechanisms is best suited to the presentation of leak-causes, as well as how users may set better privacy control policies with the information provided.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582832","","Privacy;Testing;Data privacy;Androids;Humanoid robots;Smart phones;Mobile communication","data privacy;mobile computing;program diagnostics;program testing","mobile app privacy leak-cause behaviour;mobile application;hybrid static-dynamic analysis system;user-triggered causes;Android applications;user privacy;privacy notices;mobile notification mechanism;privacy control policy","","","16","","","","","IEEE","IEEE Conferences"
"Statistical analysis of large sets of models","Ö. Babur","Eindhoven University of Technology, 5600 MB Eindhoven, The Netherlands","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","888","891","Many applications in Model-Driven Engineering involve processing multiple models, e.g. for comparing and merging of model variants into a common domain model. Despite many sophisticated techniques for model comparison, little attention has been given to the initial data analysis and filtering activities. These are hard to ignore especially in the case of a large dataset, possibly with outliers and sub-groupings. We would like to develop a generic approach for model comparison and analysis for large datasets; using techniques from information retrieval, natural language processing and machine learning. We are implementing our approach as an open framework and have so far evaluated it on public datasets involving domain analysis, repository management and model searching scenarios.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582834","Model-driven engineering;model comparison;vector space model;clustering","Biological system modeling;Analytical models;Computational modeling;Feature extraction;Merging;Data models;Natural language processing","data analysis;information filtering;learning (artificial intelligence);natural language processing;software engineering;statistical analysis","statistical analysis;model large set;model-driven engineering;filtering activities;generic approach;model comparison;large dataset analysis;information retrieval;natural language processing;machine learning;domain analysis;repository management;model searching scenarios","","","17","","","","","IEEE","IEEE Conferences"
"API recommendation system for software development","F. Thung","School of Information Systems, Singapore Management University","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","896","899","Nowadays, software developers often utilize existing third party libraries and make use of Application Programming Interface (API) to develop a software. However, it is not always obvious which library to use or whether the chosen library will play well with other libraries in the system. Furthermore, developers need to spend some time to understand the API to the point that they can freely use the API methods and putting the right parameters inside them. In this work, I plan to automatically recommend relevant APIs to developers. This API recommendation can be divided into multiple stages. First, we can recommend relevant libraries provided a given task to complete. Second, we can recommend relevant API methods that developer can use to program the required task. Third, we can recommend correct parameters for a given method according to its context. Last but not least, we can recommend how different API methods can be combined to achieve a given task. In effort to realize this API recommendation system, I have published two related papers. The first one deals with recommending additional relevant API libraries given known useful API libraries for the target program. This system can achieve recall rate@5 of 0.852 and recall rate@10 of 0.894 in recommending additional relevant libraries. The second one deals with recommending relevant API methods a given target API and a textual description of the task. This system can achieve recall-rate@5 of 0.690 and recall-rate@10 of 0.779. The results for both system indicate that the systems are useful and capable in recommending the right API/library reasonably well. Currently, I am working on another system which can recommend web APIs (i.e., libraries) given a description of the task. I am also working on a system that recommends correct parameters given an API method. In the future, I also plan to realize API composition recommendation for the given task.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582836","API;Library;Recommendation System","Libraries;Feature extraction;Training;Software;Databases;History;Context","application program interfaces;recommender systems;software libraries","API recommendation system;software development;application programming interface;API libraries;textual description;recall-rate","","","25","","","","","IEEE","IEEE Conferences"
"Changing microsoft's build: Revolution or evolution","W. Schulte","Microsoft, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","2","2","Tens of thousands of Microsoft engineers build and test hundreds of software products several times a day. It is essential that this continuous integration scales, guarantees short feedback cycles, and functions reliably with minimal human intervention. During the past three years TSE's charter has been to shorten this cycle time. We went after this goal in two ways: Evolution via CloudBuild and Revolution via Concord. CloudBuild is a build service infrastructure, now being used by all major product groups in Microsoft, like Azure, Bing, Office, SQL except for Windows. CloudBuild addresses all aspects of a continuous integration workflow, like builds, test and code analysis, but also drops, package and symbol creation and storage. CloudBuild supports multiple build languages as long as they fulfill a coarse grained IO based contract. CloudBuild uses content based caching to run build-related tasks only when needed. Lastly, it builds on many machines in parallel. The speed ups of build and testing range from 1.2x to 10x. CloudBuild aims to rapidly onboard teams and hence has to support non-deterministic build tools and specification languages that under-declare dependencies. CloudBuild, being a reliable build service in the presence of unreliable components, currently achieves service availability better than 99%. Windows went a different path. Their past build exhaust was so massive that building Windows in the cloud and bringing the build results back for testing on corp.-net. was considered infeasible. So they decided to move to a new build language, codename Concord. By construction, Concord guarantees reliable builds, no over-build, and allows for efficient distribution. Adopting Concord has led to immense performance improvements, we have seen up to 100X speedup for Windows builds. But the path has been long and rocky, since it not only requires a substantial rewrite of existing build logic, but also all related developer and build lab processes have to change. Whether evolution or revolution is the right path forward - the verdict is still out.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582738","Build-system;build-language;build-automation;build-as-a-service","","cache storage;cloud computing;parallel machines;program testing;software performance evaluation;specification languages","microsoft build changing;software product testing;software product building;continuous integration scales;short feedback cycles;functions reliably;minimal human intervention;cloudbuild evolution;concord revolution;content based caching;parallel machines;non deterministic build tools;specification languages;performance improvements","","","","","","","","IEEE","IEEE Conferences"
"AnModeler: A tool for generating domain models from textual specifications","J. S. Thakur; A. Gupta","Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, India, Jabalpur Engineering College, Jabalpur, India; Indian Institute of Information Technology, Design and Manufacturing Jabalpur, India","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","828","833","This paper presents AnModeler, a tool for generating analysis models from software requirements specified using use cases. The tool uses the Stanford natural language parser to extract type dependencies (TDs) and parts of speech tags (POS-tags) of sentences from input Use Case Specification (UCS). Then, it identifies sentence structures using a set of rules framed based on Hornby's verb patterns. With the information of the TDs, POS tags, and the identified sentence structures, the tool discovers domain elements, viz.: domain objects (including their attributes and operations) and interactions between them; it consolidates the domain information as a class diagram (as well as a sequence diagram). An experiment conducted on 10 UCSs with two industry experts as subjects showed that the analysis class diagrams generated by AnModeler were remarkably close to those generated by the two industry experts. Being lightweight and easy to use, the tool can also be used to assist students and young developers in acquiring object-oriented domain modeling skills quickly. Link to a short demonstration video: https://youtu.be/_Ct-qF4Y1fU.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582823","Automated tool for analysis modeling;Model transformation;Analysis class diagram;Problem level sequence diagram;Template code;Automated approach","Analytical models;Object oriented modeling;Software;Unified modeling language;Industries;Visualization;Java","diagrams;grammars;natural languages;object-oriented methods;software engineering;text analysis","AnModeler;domain model generating tool;textual specifications;analysis model generation;software requirements;Stanford natural language parser;type dependency extraction;TD extraction;parts of speech tags;POS-tags;use case specification;UCS;Hornby verb patterns;identified sentence structures;domain elements;domain information;sequence diagram;analysis class diagrams generated;object-oriented domain modeling","","","23","","","","","IEEE","IEEE Conferences"
"Factoring requirement dependencies in software requirement selection using graphs and integer programming","D. Mougouei","School of Computer Science, Engineering, and Mathematics, Flinders University, Adelaide, Australia","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","884","887","Software requirement selection is to find a subset of requirements (so-called optimal set) that gives the highest customer value for a release of software while keeping the cost within the budget. Several industrial studies however, have demonstrated that requirements of software projects are intricately interdependent and these interdependencies impact the values of requirements. Furthermore, the strengths of dependency relations among requirements vary in the context of real-world projects. For instance, requirements can be strongly or weakly interdependent. Therefore, it is important to consider both the existence and the strengths of dependency relations during requirement selection. The existing selection models however, have ignored either requirement dependencies altogether or the strengths of those dependencies. This research proposes an Integer programming model for requirement selection which considers both the existence and strengths of requirement dependencies. We further contribute a graph-based dependency modeling technique for capturing requirement dependencies and the their corresponding strengths. Automated/semi-automated techniques will also be devised to identify requirement dependencies and the strengths of those dependencies.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582833","Software Requirement Selection;Software Requirement Dependencies;Graph;Integer Programming","Software;Computational modeling;Planning;Linear programming;Requirements engineering;Complexity theory;Optimization","formal specification;formal verification;graph theory;integer programming;project management;software management;software selection;systems analysis","requirement dependencies;software requirement selection;graphs;optimal set;budgeted cost;software project requirements;dependency relations;integer programming model;graph-based dependency modeling technique;automated techniques","","","38","","","","","IEEE","IEEE Conferences"
"Developer targeted analytics: Supporting software development decisions with runtime information","J. Cito","Software evolution & architecture lab, University of Zurich, Switzerland","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","892","895","Runtime information of deployed software has been used by business and operations units to make informed decisions under the term “analytics”. However, decisions made by software engineers in the course of evolving software have, for the most part, been based on personal belief and gut-feeling. This could be attributed to software development being, for the longest time, viewed as an activity that is detached from the notion of operating software in a production environment. In recent years, this view has been challenged with the emergence of the DevOps movement, which aim is to promote cross-functional capabilities of development and operations activities within teams. This shift in process and mindset requires analytics tools that specifically target software developers. In this research, I investigate approaches to support developers in their decision-making by incorporating runtime information in source code and provide live feedback in IDEs by predicting the impact of code changes.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582835","Developer Targeted Analytics;Software Analytics;Performance Engineering","Runtime;Uncertainty;Production;Decision making;Software performance;Computational modeling","business data processing;decision making;software engineering;source code (software)","software development decisions;runtime information;business unit;operation unit;developer targeted analytics;decision making;source code;software analytics;performance engineering","","","31","","","","","IEEE","IEEE Conferences"
"Program generation for performance","M. Püschel","Department of Computer Science, ETH Zurich, Switzerland","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","1","1","It has become extraordinarily difficult to write software that performs close to optimally on complex modern microarchitectures. Particularly plagued are domains that require complex mathematical computations such as multimedia processing, communication, control, graphics, and machine learning. In these domains, performance-critical components are usually written in C (with possible extensions) and often even in assembly, carefully “tuned” to the platform's architecture and microarchitecture. The result is usually long, rather unreadable code that needs to be re-written or re-tuned with every platform upgrade. On the other hand, the performance penalty for relying on straightforward, non-tuned, “more elegant” implementations can be often a factor of 10, 100, or even more. The overall problem is one of productivity, maintainability, and quality (namely performance), i.e., software engineering. However, even though a large set of sophisticated software engineering theory and tools exist, it appears that to date this community has not focused much on mathematical computations nor performance in the detailed, close-to-optimal sense above. The reason for the latter may be that performance, unlike various aspects of correctness, is not syntactic in nature (and in reality is often even unpredictable and, well, messy). The aim of this talk is to draw attention to the performance/productivity problem for mathematical applications and to make the case for a more interdisciplinary attack. As a set of thoughts in this direction we offer some of the lessons we have learned in the last decade in our own research on Spiral (www.spiral.net), a program generation framework for numerical kernels. Key techniques used in Spiral include staged declarative domain-specific languages to express algorithm knowledge and algorithm transformations, the use of platform-cognizant rewriting systems for parallelism and locality optimizations, and the use of search and machine learning techniques to navigate possible spaces of choices. Experimental results show that the codegenerated by Spiral competes with, and sometimes outperforms, the best available human-written code. Spiral has been used to generate part of Intel's commercial libraries IPP and MKL.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582737","Program generation;automatic programming;parallelization;vectorization;rewriting systems;Fourier transform;matrix algebra","","learning (artificial intelligence);program compilers;rewriting systems;software architecture;software maintenance;software performance evaluation;software quality","program generation framework;software performance;performance-critical component;platform architecture;software maintainability;software quality;software engineering;rewriting system;machine learning","","","","","","","","IEEE","IEEE Conferences"
"The power of probabilistic thinking","D. S. Rosenblum","National University of Singapore, Singapore","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","3","3","Traditionally, software engineering has dealt in absolutes. For instance, we talk about a system being “correct” or “incorrect”, with the shades of grey in between occasionally acknowledged but rarely dealt with explicitly. And we typically employ logical, algebraic, relational and other representations and techniques that help us reason about software in such absolute terms. There of course have been notable exceptions to this, such as the use of statistical techniques in testing and debugging. But by and large, both researchers and practitioners have favored the relative comfort of an absolutist viewpoint in all aspects of development. In this talk, I will argue the benefits of taking a more thoroughly probabilistic approach in software engineering. Software engineering is rife with stochastic phenomena, and the vast majority of software systems operate in an environment of uncertain, random behavior, which suits an explicit probabilistic characterization. Furthermore, this uncertainty is becoming ever more pronounced in new software systems and platforms, such as the Internet of Things and autonomous vehicles, with their frequent imprecise outputs and heavy reliance on machine learning. To illustrate more deeply some of the considerations involved in taking a probabilistic approach, I will talk about some recent research I have been doing in probabilistic verification.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582739","Probabilistic reasoning;software engineering;stochastic behavior","","learning (artificial intelligence);program debugging;program testing;program verification;uncertainty handling","probabilistic thinking;software engineering;testing;debugging;stochastic phenomena;machine learning;probabilistic verification","","","","","","","","IEEE","IEEE Conferences"
"SimilarTech: Automatically recommend analogical libraries across different programming languages","C. Chen; Z. Xing","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","834","839","Third-party libraries are an integral part of many software projects. It often happens that developers need to find analogical libraries that can provide comparable features to the libraries they are already familiar with. Existing methods to find analogical libraries are limited by the community-curated list of libraries, blogs, or Q&A posts, which often contain overwhelming or out-of-date information. This paper presents our tool SimilarTech (https://graphofknowledge. appspot.com/similartech) that makes it possible to automatically recommend analogical libraries by incorporating tag embeddings and domain-specific relational and categorical knowledge mined from Stack Overflow. SimilarTech currently supports recommendation of 6,715 libraries across 6 different programming languages. We release our SimilarTech website for public use. The SimilarTech website attracts more than 2,400 users in the past 6 months. We observe two typical usage patterns of our website in the website visit logs which can satisfy different information needs of developers. The demo video can be seen at https://youtu.be/ubx8h4D4ieE.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582824","","Libraries;Java;Knowledge based systems;Operating systems;Tagging;Mobile communication","programming languages;software libraries","SimilarTech tool;third-party libraries;programming languages;software projects;analogical libraries;domain-specific relational knowledge;tag embeddings;categorical knowledge","","","19","","","","","IEEE","IEEE Conferences"
"Conc-iSE: Incremental symbolic execution of concurrent software","S. Guo; M. Kusano; C. Wang","Department of ECE, Virginia Tech, Blacksburg, VA, USA; Department of ECE, Virginia Tech, Blacksburg, VA, USA; Department of CS, University of Southern California, Los Angeles, CA, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","531","542","Software updates often introduce new bugs to existing code bases. Prior regression testing tools focus mainly on test case selection and prioritization whereas symbolic execution tools only handle code changes in sequential software. In this paper, we propose the first incremental symbolic execution method for concurrent software to generate new tests by exploring only the executions affected by code changes between two program versions. Specifically, we develop an inter-thread and inter-procedural change-impact analysis to check if a statement is affected by the changes and then leverage the information to choose executions that need to be re-explored. We also check if execution summaries computed in the previous program can be used to avoid redundant explorations in the new program. We have implemented our method in an incremental symbolic execution tool called Conc-iSE and evaluated it on a large set of multithreaded C programs. Our experiments show that the new method can significantly reduce the overall symbolic execution time when compared with state-of-the-art symbolic execution tools such as KLEE.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582788","Symbolic execution;Concurrency;Partial order reduction;Weakest precondition","Software;Testing;Concurrent computing;Algorithm design and analysis;Software algorithms;Computer bugs;Programming","C language;concurrency (computers);multi-threading;program debugging;program testing","Conc-iSE;concurrent software incremental symbolic execution;software updates;bugs;code bases;regression testing tools;test case selection;test case prioritization;sequential software;program versions;interthread change-impact analysis;interprocedural change-impact analysis;execution summaries;multithreaded C programs","","","49","","","","","IEEE","IEEE Conferences"
"Identifying domain elements from textual specifications","J. S. Thakur; A. Gupta","Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, India, Jabalpur Engineering College, Jabalpur, India; Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, India","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","566","577","Analysis modeling refers to the task of identifying domain objects, their attributes and operations, and the relationships between these objects from software requirements specifications which are usually written in some natural language. There have been a few efforts to automate this task, but they seem to be largely constrained by the language related issues as well as the lack of a systematic transformation process. In this paper, we propose a systematic, automated transformation approach which first interprets the specification sentences based on the Hornby's verb patterns, and then uses semantic relationships between the words in the sentences, obtained from Type Dependencies using Stanford NL Parser, to identify the domain elements from them. With the help of a controlled experiment, we show that the analysis class diagrams generated by the proposed approach are far more correct, far more complete and less redundant than those generated by the exiting automated approaches.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582792","Model transformation;Analysis modeling;Analysis class diagram;Automated approach;Natural Language Processing","Analytical models;Semantics;Unified modeling language;Natural language processing;Object recognition;Software;Marine vehicles","diagrams;formal specification;grammars;natural language processing;text analysis","domain elements;textual specifications;analysis modeling;domain objects identification;software requirements specifications;natural language;systematic automated transformation approach;specification sentences;Hornby verb patterns;semantic relationships;type dependencies;Stanford NL parser;analysis class diagrams","","","45","","","","","IEEE","IEEE Conferences"
"SOFIA: An automated security oracle for black-box testing of SQL-injection vulnerabilities","M. Ceccato; C. D. Nguyen; D. Appelt; L. C. Briand","Fondazione Bruno Kessler, Trento, Italy; SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","167","177","Security testing is a pivotal activity in engineering secure software. It consists of two phases: generating attack inputs to test the system, and assessing whether test executions expose any vulnerabilities. The latter phase is known as the security oracle problem. In this work, we present SOFIA, a Security Oracle for SQL-Injection Vulnerabilities. SOFIA is programming-language and source-code independent, and can be used with various attack generation tools. Moreover, because it does not rely on known attacks for learning, SOFIA is meant to also detect types of SQLi attacks that might be unknown at learning time. The oracle challenge is recast as a one-class classification problem where we learn to characterise legitimate SQL statements to accurately distinguish them from SQLi attack statements. We have carried out an experimental validation on six applications, among which two are large and widely-used. SOFIA was used to detect real SQLi vulnerabilities with inputs generated by three attack generation tools. The obtained results show that SOFIA is computationally fast and achieves a recall rate of 100% (i.e., missing no attacks) with a low false positive rate (0.6%).","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582755","Security testing;Security oracle;SQL-injection","Security;Testing;Databases;Payloads;Context;Software;Servers","pattern classification;program testing;security of data;SQL","SOFIA;automated security oracle;black-box testing;SQL-injection vulnerabilities;security testing;test executions;programming-language;attack generation tools;one-class classification problem;legitimate SQL statements;SQLi attack statements","","","28","","","","","IEEE","IEEE Conferences"
"An extensible framework for variable-precision data-flow analyses in MPS","T. Szabó; S. Alperovich; S. Erdweg; M. Voelter","itemis, Germany / Delft University of Technology, Netherlands; JetBrains, Czechia; Delft University of Technology, Netherlands; independent/itemis, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","870","875","Data-flow analyses are used as part of many software engineering tasks: they are the foundations of program understanding, refactorings and optimized code generation. Similar to general-purpose languages (GPLs), state-of-the-art domain-specific languages (DSLs) also require sophisticated data-flow analyses. However, as a consequence of the different economies of DSL development and their typically relatively fast evolution, the effort for developing and evolving such analyses must be lowered compared to GPLs. This tension can be resolved with dedicated support for data-flow analyses in language workbenches. In this tool paper we present MPS-DF, which is the component in the MPS language workbench that supports the definition of data-flow analyses for DSLs. Language developers can define data-flow graph builders declaratively as part of a language definition and compute analysis results efficiently based on these data-flow graphs. MPS-DF is extensible such that it does not compromise the support for language composition in MPS. Additionally, clients of MPS-DF analyses can run the analyses with variable precision thus trading off precision for performance. This allows clients to tailor an analysis to a particular use case.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582830","Data-flow Analysis;Domain-specific Language;Language Workbench;Inter-procedural Analysis","DSL;Lattices;Syntactics;Algorithm design and analysis;Software;Encoding;Switches","data flow analysis;data flow graphs;program compilers;software maintenance;specification languages","extensible framework;data flow analysis;MPS-DF analysis;software engineering;software refactoring;code generation;general-purpose language;GPL;domain-specific language;DSL;data flow graph","","","19","","","","","IEEE","IEEE Conferences"
"Efficient detection of inconsistencies in a multi-developer engineering environment","A. Demuth; M. Riedl-Ehrenleitner; A. Egyed","Institute for Software Systems Engineering, Johannes Kepler University, Linz, Austria; Institute for Software Systems Engineering, Johannes Kepler University, Linz, Austria; Institute for Software Systems Engineering, Johannes Kepler University, Linz, Austria","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","590","601","Software developers work concurrently on different kinds of development artifacts such as requirements, architecture, design, or source code. To keep these development artifacts consistent, developers have a wide range of consistency checking approaches available. However, most existing consistency checkers work best in context of single tools and they are not well suited when development artifacts are distributed among different tools and are being modified concurrently by many developers. This paper presents a novel, cloud-based approach to consistency checking in a multi-developer/-tool engineering environment. It allows instant consistency checking even if developers and their tools are distributed and even if they do not have access to all artifacts. It does this by systematically reusing consistency checking knowledge to keep the memory/CPU cost of consistency checking to a small constant overhead per developer. The feasibility and scalability of our approach is demonstrated through an empirical validation with 22 partly industrial system models. A prototype implementation implementation is available through the DesignSpace Engineering Cloud.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582794","Incremental Consistency Checking;Multi-Developer Engineering;Model-Driven Engineering","Unified modeling language;Context;Software systems;Context modeling;Scalability","cloud computing;formal verification;software tools","inconsistency detection;multideveloper engineering environment;software development;consistency checker;cloud-based approach;software tool","","","40","","","","","IEEE","IEEE Conferences"
"Local-based active classification of test report to assist crowdsourced testing","J. Wang; S. Wang; Q. Cui; Q. Wang","Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Electrical and Computer Engineering, University of Waterloo, Canada; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","190","201","In crowdsourced testing, an important task is to identify the test reports that actually reveal fault - true fault, from the large number of test reports submitted by crowd workers. Most existing approaches towards this problem utilized supervised machine learning techniques, which often require users to manually label a large amount of training data. Such process is time-consuming and labor-intensive. Thus, reducing the onerous burden of manual labeling while still being able to achieve good performance is crucial. Active learning is one potential technique to address this challenge, which aims at training a good classifier with as few labeled data as possible. Nevertheless, our observation on real industrial data reveals that existing active learning approaches generate poor and unstable performances on crowdsourced testing data. We analyze the deep reason and find that the dataset has significant local biases. To address the above problems, we propose LOcal-based Active ClassiFication (LOAF) to classify true fault from crowdsourced test reports. LOAF recommends a small portion of instances which are most informative within local neighborhood, and asks user their labels, then learns classifiers based on local neighborhood. Our evaluation on 14,609 test reports of 34 commercial projects from one of the Chinese largest crowdsourced testing platforms shows that our proposed LOAF can generate promising results. In addition, its performance is even better than existing supervised learning approaches which built on large amounts of labelled historical data. Moreover, we also implement our approach and evaluate its usefulness using real-world case studies. The feedbacks from testers demonstrate its practical value.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582757","Crowdsourced Testing;Test Report Classification;Active Learning","Testing;Software;Feature extraction;Labeling;Training data;Speech recognition;Manuals","learning (artificial intelligence);program debugging;program testing","local-based active classification;test report;crowdsourced testing;supervised machine learning technique;active learning;LOAF","","","44","","","","","IEEE","IEEE Conferences"
"Taming Android fragmentation: Characterizing and detecting compatibility issues for Android apps","L. Wei; Y. Liu; S. Cheung","Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","226","237","Android ecosystem is heavily fragmented. The numerous combinations of different device models and operating system versions make it impossible for Android app developers to exhaustively test their apps. As a result, various compatibility issues arise, causing poor user experience. However, little is known on the characteristics of such fragmentation-induced compatibility issues and no mature tools exist to help developers quickly diagnose and fix these issues. To bridge the gap, we conducted an empirical study on 191 real-world compatibility issues collected from popular open-source Android apps. Our study characterized the symptoms and root causes of compatibility issues, and disclosed that the patches of these issues exhibit common patterns. With these findings, we propose a technique named FicFinder to automatically detect compatibility issues in Android apps. FicFinder performs static code analysis based on a model that captures Android APIs as well as their associated context by which compatibility issues are triggered. FicFinder reports actionable debugging information to developers when it detects potential issues. We evaluated FicFinder with 27 large-scale open-source Android apps. The results show that FicFinder can precisely detect compatibility issues in these apps and uncover previously-unknown issues.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582761","Android fragmentation;compatibility issues","Androids;Humanoid robots;Computer bugs;Hardware;Open source software;Ecosystems","Android (operating system);application program interfaces;program debugging;program diagnostics;program testing;public domain software","Android fragmentation;compatibility issue detection;Android ecosystem;device model;operating system version;app testing;fragmentation-induced compatibility issue;open-source Android apps;FicFinder;static code analysis;Android API;actionable debugging information","","","70","","","","","IEEE","IEEE Conferences"
"GUICat: GUI testing as a service","L. Cheng; J. Chang; Z. Yang; C. Wang","Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","858","863","GUIs are event-driven applications where the flow of the program is determined by user actions such as mouse clicks and key presses. GUI testing is a challenging task not only because of the combinatorial explosion in the number of event sequences, but also because of the difficulty to cover the large number of data values. We propose GUICat, the first cloud-based GUI testing framework that simultaneously generates event sequences and data values. It is a white-box GUI testing tool that augments traditional sequence generation techniques with concolic execution. We also propose a cloud-based parallel algorithm for mitigating both event sequence explosion and data value explosion, by distributing the con-colic execution tasks over public clouds such as Amazon EC2. We have evaluated the tool on standard GUI testing benchmarks and showed that GUICat significantly outperforms state-of-the-art GUI testing tools. The video demo URL is https://youtu.be/rfnnQOmZqj4.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582828","Symbolic execution;Test generation;GUI testing;Cloud","Graphical user interfaces;Testing;Instruments;Cloud computing;Explosions;Java;Computational modeling","cloud computing;graphical user interfaces;parallel algorithms;program testing","GUICat;combinatorial explosion;cloud-based GUI testing framework;event sequences;data values;sequence generation;concolic execution;cloud-based parallel algorithm;con-colic execution tasks","","","14","","","","","IEEE","IEEE Conferences"
"Greedy combinatorial test case generation using unsatisfiable cores","A. Yamada; A. Biere; C. Artho; T. Kitamura; E. Choi","University of Innsbruck, Austria; Johannes Kepler University, Austria; National Institute of Advanced Industrial Science and Technology (AIST), Japan; National Institute of Advanced Industrial Science and Technology (AIST), Japan; National Institute of Advanced Industrial Science and Technology (AIST), Japan","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","614","624","Combinatorial testing aims at covering the interactions of parameters in a system under test, while some combinations may be forbidden by given constraints (forbidden tuples). In this paper, we illustrate that such forbidden tuples correspond to unsatisfiable cores, a widely understood notion in the SAT solving community. Based on this observation, we propose a technique to detect forbidden tuples lazily during a greedy test case generation, which significantly reduces the number of required SAT solving calls. We further reduce the amount of time spent in SAT solving by essentially ignoring constraints while constructing each test case, but then “amending” it to obtain a test case that satisfies the constraints, again using unsatisfiable cores. Finally, to complement a disturbance due to ignoring constraints, we implement an efficient approximative SAT checking function in the SAT solver Lingeling. Through experiments we verify that our approach significantly improves the efficiency of constraint handling in our greedy combinatorial testing algorithm.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582796","Combinatorial testing;test case generation;SAT solving","Linux;Browsers;Approximation algorithms;Software testing;Software algorithms;Software","computability;constraint handling;greedy algorithms;program testing","greedy combinatorial test case generation;unsatisfiable cores;parameter interactions;forbidden tuples;SAT solving community;SAT solving calls;SAT checking function;SAT solver Lingeling;constraint handling","","","38","","","","","IEEE","IEEE Conferences"
"CrowdService: Serving the individuals through mobile crowdsourcing and service composition","X. Peng; J. Gu; T. H. Tan; J. Sun; Y. Yu; B. Nuseibeh; W. Zhao","School of Computer Science, Fudan University, China; School of Computer Science, Fudan University, China; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Department of Computing and Communications, The Open University, UK; Department of Computing and Communications, The Open University, UK; School of Computer Science, Fudan University, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","214","219","Some user needs in real life can only be accomplished by leveraging the intelligence and labor of other people via crowdsourcing tasks. For example, one may want to confirm the validity of the description of a secondhand laptop by asking someone else to inspect the laptop on site. To integrate these crowdsourcing tasks into user applications, it is required that crowd intelligence and labor be provided as easily accessible services (e.g., Web services), which can be called crowd services. In this paper, we develop a framework named CrowdService which supplies crowd intelligence and labor as publicly accessible crowd services via mobile crowd-sourcing. We implement the proposed framework on the Android platform and evaluate its usability with a user study.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582759","mobile crowdsourcing;service composition;reliability","Crowdsourcing;Web services;Inspection;Portable computers;Mobile communication;Business;Mobile handsets","Android (operating system);mobile computing;outsourcing;Web services","CrowdService;mobile crowdsourcing;service composition;crowdsourcing tasks;crowd intelligence;labor;Web services;publicly accessible crowd services;Android platform","","","14","","","","","IEEE","IEEE Conferences"
"HybriDroid: Static analysis framework for Android hybrid applications","S. Lee; J. Dolby; S. Ryu","KAIST, South Korea; IBM Research, USA; KAIST, South Korea","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","250","261","Mobile applications (apps) have long invaded the realm of desktop apps, and hybrid apps become a promising solution for supporting multiple mobile platforms. Providing both platform-specific functionalities via native code like native apps and user interactions via JavaScript code like web apps, hybrid apps help developers build multiple apps for different platforms without much duplicated efforts. However, most hybrid apps are developed in multiple programming languages with different semantics, which may be vulnerable to programmer errors. Moreover, because untrusted JavaScript code may access device-specific features via native code, hybrid apps may be vulnerable to various security attacks. Unfortunately, no existing tools can help hybrid app developers by detecting errors or security holes. In this paper, we present HybriDroid, a static analysis framework for Android hybrid apps. We investigate the semantics of Android hybrid apps especially for the interoperation mechanism of Android Java and JavaScript. Then, we design and implement a static analysis framework that analyzes inter-communication between Android Java and JavaScript. As example analyses supported by HybriDroid, we implement a bug detector that identifies programmer errors due to the hybrid semantics, and a taint analyzer that finds information leaks cross language boundaries. Our empirical evaluation shows that the tools are practically usable in that they found previously uncovered bugs in real-world Android hybrid apps and possible information leaks via a widely-used advertising platform.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582763","Android;hybrid applications;static analysis;multi-language analysis;analysis framework","Java;Androids;Humanoid robots;Web pages;Semantics;Bridges;Mobile communication","Android (operating system);Java;mobile computing;program debugging;program diagnostics;security of data;smart phones","HybriDroid;static analysis framework;Android hybrid application;mobile application;security attack;interoperation mechanism;Android Java;JavaScript;bug detector;programmer error identification;taint analyzer","","8","51","","","","","IEEE","IEEE Conferences"
"Applying combinatorial test data generation to big data applications","N. Li; Y. Lei; H. R. Khan; J. Liu; Y. Guo","Research and Development, Medidata Solutions, New York, NY, USA; Dept. of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA; Research and Development, Medidata Solutions, New York, NY, USA; Research and Development, Medidata Solutions, New York, NY, USA; Dept. of Computer Science, George Mason University, Fairfax, VA, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","637","647","Big data applications (e.g., Extract, Transform, and Load (ETL) applications) are designed to handle great volumes of data. However, processing such great volumes of data is time-consuming. There is a need to construct small yet effective test data sets during agile development of big data applications. In this paper, we apply a combinatorial test data generation approach to two real-world ETL applications at Medidata. In our approach, we first create Input Domain Models (IDMs) automatically by analyzing the original data source and incorporating constraints manually derived from requirements. Next, the IDMs are used to create test data sets that achieve t-way coverage, which has shown to be very effective in detecting software faults. The generated test data sets also satisfy all the constraints identified in the first step. To avoid creating IDMs from scratch when there is a change to the original data source or constraints, our approach extends the original IDMs with additional information. The new IDMs, which we refer to as Adaptive IDMs (AIDMs), are updated by comparing the changes against the additional information, and are then used to generate new test data sets. We implement our approach in a tool, called comBinatorial big daTa Test dAta Generator (BIT-TAG). Our experience shows that combinatorial testing can be effectively applied to big data applications. In particular, the test data sets created using our approach for the two ETL applications are only a small fraction of the original data source, but we were able to detect all the faults found with the original data source.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582798","Big Data Testing;Combinatorial Testing;Input Domain Model;Adaptive Input Domain Model;Test Data Generation","Testing;Databases;Data mining;Research and development;Data models","Big Data;program testing","real-world ETL applications;Medidata;input domain models;adaptive IDM;AIDM;combinatorial big data test data generator;BIT-TAG","","","27","","","","","IEEE","IEEE Conferences"
"Move-optimized source code tree differencing","G. Dotzler; M. Philippsen","Friedrich-Alexander University Erlangen-Nürnberg (FAU), Germany, Programming Systems Group; Friedrich-Alexander University Erlangen-Nürnberg (FAU), Germany, Programming Systems Group","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","660","671","When it is necessary to express changes between two source code files as a list of edit actions (an edit script), modern tree differencing algorithms are superior to most text-based approaches because they take code movements into account and express source code changes more accurately. We present 5 general optimizations that can be added to state-of-the-art tree differencing algorithms to shorten the resulting edit scripts. Applied to Gumtree, RTED, JSync, and ChangeDistiller, they lead to shorter scripts for 1898% of the changes in the histories of 9 open-source software repositories. These optimizations also are parts of our novel Move-optimized Tree DIFFerencing algorithm (MTD-IFF) that has a higher accuracy in detecting moved code parts. MTDIFF (which is based on the ideas of ChangeDistiller) further shortens the edit script for another 20% of the changes in the repositories. MTDIFF and all the benchmarks are available under an open-source license.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582801","Tree Differencing;Optimizations;Source Code","Optimization;Open source software;Runtime;Complexity theory;Programming;History","optimisation;public domain software;software maintenance;source code (software)","move-optimized source code tree differencing algorithm;source code files;edit actions;edit script;text-based approaches;code movements;source code changes;optimizations;Gumtree;RTED;JSync;ChangeDistiller;open-source software repositories;MTD-IFF;moved code parts;open-source license;software maintenance","","","42","","","","","IEEE","IEEE Conferences"
"Fine-tuning spectrum based fault localisation with frequent method item sets","G. Laghari; A. Murgia; S. Demeyer","ANSYMO - Universiteit Antwerpen, Belgium; ANSYMO - Universiteit Antwerpen, Belgium; ANSYMO - Universiteit Antwerpen, Belgium","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","274","285","Continuous integration is a best practice adopted in modern software development teams to identify potential faults immediately upon project build. Once a fault is detected it must be repaired immediately, hence continuous integration provides an ideal testbed for experimenting with the state of the art in fault localisation. In this paper we propose a variant of what is known as spectrum based fault localisation, which leverages patterns of method calls by means of frequent itemset mining. We compare our variant (we refer to it as patterned spectrum analysis) against the state of the art and demonstrate on 351 real faults drawn from five representative open source java projects that patterned spectrum analysis is more effective in localising the fault.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582765","Automated developer tests;Continuous integration;Spectrum based fault localisation;Statistical debugging","Spectral analysis;Debugging;Software;Itemsets;Servers;Context;Maintenance engineering","data mining;fault location;program debugging;software engineering","fine-tuning spectrum;item sets;continuous integration;software development teams;project build;fault detection;ideal testbed;spectrum based fault localisation;frequent itemset mining;pattern spectrum analysis;statistical debugging","","","54","","","","","IEEE","IEEE Conferences"
"Automatic runtime recovery via error handler synthesis","T. Gu; C. Sun; X. Ma; J. Lü; Z. Su","Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science, University of California, Davis, USA; Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science, University of California, Davis, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","684","695","Software systems are often subject to unexpected runtime errors. Automatic runtime recovery (ARR) techniques aim to recover them from erroneous states and maintain them functional in the field. This paper proposes Ares, a novel, practical approach for ARR. Our key insight is leveraging a system's inherent error handling support to recover from unexpected errors. To this end, we synthesize error handlers in two ways: error transformation and early return. We also equip Ares with a lightweight in-vivo testing infrastructure to select the promising synthesis method and avoid potentially dangerous error handlers. Unlike existing ARR techniques with heavyweight mechanisms (e.g., checkpoint-restart and runtime monitoring), our approach expands the intrinsic capability of runtime error resilience in software systems to handle unexpected errors. Ares's lightweight mechanism makes it practical and easy to be integrated into production environments. We have implemented Ares on top of both the Java HotSpot VM and Android ART, and applied it to recover from 52 real-world bugs. The results are promising - Ares successfully recovers from 39 of them and incurs negligible overhead.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582803","automatic runtime recovery;JVM;exception handling","Runtime;Computer bugs;Java;Software systems;Testing;Resilience;Androids","error handling;Java;program debugging;program testing;virtual machines","automatic runtime recovery;error handler synthesis;software systems;ARR techniques;erroneous states;Ares;error transformation;early return;testing infrastructure;runtime error resilience;production environments;Java HotSpot VM;Android ART;real-world bugs","","","30","","","","","IEEE","IEEE Conferences"
"An empirical study on dependence clusters for effort-aware fault-proneness prediction","Y. Yang; M. Harman; J. Krinke; S. Islam; D. Binkley; Y. Zhou; B. Xu","Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science, University College London, UK; Department of Computer Science, University College London, UK; School of Architecture, Computing and Engineering, University of East London, UK; Department of Computer Science, Loyola University Maryland, USA; Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science and Technology, Nanjing University, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","296","307","A dependence cluster is a set of mutually inter-dependent program elements. Prior studies have found that large dependence clusters are prevalent in software systems. It has been suggested that dependence clusters have potentially harmful effects on software quality. However, little empirical evidence has been provided to support this claim. The study presented in this paper investigates the relationship between dependence clusters and software quality at the function-level with a focus on effort-aware fault-proneness prediction. The investigation first analyzes whether or not larger dependence clusters tend to be more fault-prone. Second, it investigates whether the proportion of faulty functions inside dependence clusters is significantly different from the proportion of faulty functions outside dependence clusters. Third, it examines whether or not functions inside dependence clusters playing a more important role than others are more fault-prone. Finally, based on two groups of functions (i.e., functions inside and outside dependence clusters), the investigation considers a segmented fault-proneness prediction model. Our experimental results, based on five well-known open-source systems, show that (1) larger dependence clusters tend to be more fault-prone; (2) the proportion of faulty functions inside dependence clusters is significantly larger than the proportion of faulty functions outside dependence clusters; (3) functions inside dependence clusters that play more important roles are more fault-prone; (4) our segmented prediction model can significantly improve the effectiveness of effort-aware fault-proneness prediction in both ranking and classification scenarios. These findings help us better understand how dependence clusters influence software quality.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582767","Dependence clusters;fault-proneness;fault prediction;network analysis","Predictive models;Software quality;Data models;Computer science;Servers;Syntactics","pattern classification;pattern clustering;public domain software;software fault tolerance;software quality","dependence cluster;effort-aware fault-proneness prediction;mutually interdependent program element;software quality;open-source system;ranking;classification","","","42","","","","","IEEE","IEEE Conferences"
"DistIA: A cost-effective dynamic impact analysis for distributed programs","H. Cai; D. Thain","School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","344","355","Dynamic impact analysis is a fundamental technique for understanding the impact of specific program entities, or changes to them, on the rest of the program for concrete executions. However, existing techniques are either inapplicable or of very limited utility for distributed programs running in multiple concurrent processes. This paper presents DISTIA, a dynamic analysis of distributed systems that predicts impacts propagated both within and across process boundaries by partially ordering distributed method-execution events, inferring causality from the ordered events, and exploiting message-passing semantics. We applied DISTIA to large distributed systems of various architectures and sizes, for which it on average finishes the entire analysis within one minute and safely reduces impact-set sizes by over 43% relative to existing options with run-time overhead less than 8%. Moreover, two case studies initially demonstrated the precision of DISTIA and its utility in distributed system understanding. While conservative thus subject to false positives, DistIA balances precision and efficiency to offer cost-effective options for evolving distributed programs.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582771","Impact analysis;distributed systems;dynamic partial ordering","Performance analysis;Servers;Algorithm design and analysis;Clocks;Software;Heuristic algorithms;Message passing","concurrency control;distributed processing;software architecture;system monitoring","DISTIA;dynamic impact analysis;distributed program;concurrent process;dynamic partial ordering;distributed method-execution event;causality inference;distributed system architecture","","","67","","","","","IEEE","IEEE Conferences"
"Battery-aware transformations in mobile applications","J. Cito; J. Rubin; P. Stanley-Marbell; M. Rinard","University of Zurich, Zurich, Switzerland; MIT, Cambridge, MA, USA; MIT, Cambridge, MA, USA; MIT, Cambridge, MA, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","702","707","We present an adaptive binary transformation system for reducing the energy impact of advertisements and analytics in mobile applications. Our approach accommodates both the needs of mobile app developers to obtain income from advertisements and the desire of mobile device users for longer battery life. Our technique automatically identifies recurrent advertisement and analytics requests and throttles these requests based on a mobile device's battery status. Of the Android applications we analyzed, 75% have at least one connection that exhibits such recurrent requests. Our automated detection scheme classifies these requests with 100% precision and 80.5% recall. Applying the proposed battery-aware transformations to a representative mobile application reduces the power consumption of the mobile device by 5.8%, without the negative effect of completely removing advertisements.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582805","Energy efficiency;battery lifetime;mobile advertisements;program analysis","Batteries;Mobile communication;Smart phones;Androids;Humanoid robots;Instruments","advertising;Android (operating system);mobile computing;power aware computing","battery-aware transformations;mobile applications;adaptive binary transformation system;energy impact reduction;advertisements;analytics;mobile device battery status;Android applications","","","17","","","","","IEEE","IEEE Conferences"
"IncA: A DSL for the definition of incremental program analyses","T. Szabó; S. Erdweg; M. Voelter","itemis, Germany / Delft University of Technology, Netherlands; Delft University of Technology, Netherlands; independent / itemis, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","320","331","Program analyses support software developers, for example, through error detection, code-quality assurance, and by enabling compiler optimizations and refactorings. To provide real-time feedback to developers within IDEs, an analysis must run efficiently even if the analyzed code base is large. To achieve this goal, we present a domain-specific language called IncA for the definition of efficient incremental program analyses that update their result as the program changes. IncA compiles analyses into graph patterns and relies on existing incremental matching algorithms. To scale IncA analyses to large programs, we describe optimizations that reduce caching and prune change propagation. Using IncA, we have developed incremental control flow and points-to analysis for C, well-formedness checks for DSLs, and 10 FindBugs checks for Java. Our evaluation demonstrates significant speedups for all analyses compared to their non-incremental counterparts.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582769","Static Analysis;Incremental Computation;Domain-specific Language;Language Workbench","Runtime;DSL;Java;Pattern matching;Program processors;Optimization","Java;program diagnostics;software engineering;specification languages","IncA analysis;domain-specific language;DSL;incremental program analysis;static program analysis;software development;Java","","","41","","","","","IEEE","IEEE Conferences"
"LockPeeker: Detecting latent locks in Java APIs","Z. Lin; H. Zhong; Y. Chen; J. Zhao","School of Software, ShanghaiJiao Tong University, China; Department of Computer Science and Engineering, ShanghaiJiao Tong University, China; Department of Computer Science and Engineering, ShanghaiJiao Tong University, China; Department of Advanced Information Technology, Kyushu University, Japan","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","368","378","Detecting lock-related defects has long been a hot research topic in software engineering. Many efforts have been spent on detecting such deadlocks in concurrent software systems. However, latent locks may be hidden in application programming interface (API) methods whose source code may not be accessible to developers. Many APIs have latent locks. For example, our study has shown that J2SE alone can have 2,000+ latent locks. As latent locks are less known by developers, they can cause deadlocks that are hard to perceive or diagnose. Meanwhile, the state-of-the-art tools mostly handle API methods as black boxes, and cannot detect deadlocks that involve such latent locks. In this paper, we propose a novel black-box testing approach, called LockPeeker, that reveals latent locks in Java APIs. The essential idea of LockPeeker is that latent locks of a given API method can be revealed by testing the method and summarizing the locking effects during testing execution. We have evaluated LockPeeker on ten real-world Java projects. Our evaluation results show that (1) LockPeeker detects 74.9% of latent locks in API methods, and (2) it enables state-of-the-art tools to detect deadlocks that otherwise cannot be detected.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582773","Latent lock;deadlock detection;API method","System recovery;Java;Testing;Analytical models;Computer bugs;Cryptography;Software","application program interfaces;concurrency control;Java;program testing;software fault tolerance;source code (software)","LockPeeker;latent locks detection;Java API;lock-related defects detection;software engineering;deadlocks;concurrent software systems;application programming interface;source code;J2SE;black-box testing;locking effects;testing execution","","","34","","","","","IEEE","IEEE Conferences"
"An empirical investigation into the nature of test smells","M. Tufano; F. Palomba; G. Bavota; M. Di Penta; R. Oliveto; A. De Lucia; D. Poshyvanyk","The College of William and Mary, USA; University of Salerno, Italy; Università della Svizzera italiana (USI), Switzerland; University of Sannio, Italy; University of Molise, Italy; University of Salerno, Italy; The College of William and Mary, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","4","15","Test smells have been defined as poorly designed tests and, as reported by recent empirical studies, their presence may negatively affect comprehension and maintenance of test suites. Despite this, there are no available automated tools to support identification and repair of test smells. In this paper, we firstly investigate developers' perception of test smells in a study with 19 participants. The results show that developers generally do not recognize (potentially harmful) test smells, highlighting that automated tools for identifying such smells are much needed. However, to build effective tools, deeper insights into the test smells phenomenon are required. To this aim, we conducted a large-scale empirical investigation aimed at analyzing (i) when test smells occur in source code, (ii) what their survivability is, and (iii) whether their presence is associated with the presence of design problems in production code (code smells). The results indicate that test smells are usually introduced when the corresponding test code is committed in the repository for the first time, and they tend to remain in a system for a long time. Moreover, we found various unexpected relationships between test and code smells. Finally, we show how the results of this study can be used to build effective automated tools for test smell detection and refactoring.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582740","Test Smells;Mining Software Repositories;Software Evolution","Production;Maintenance engineering;Data mining;Testing;History;Software systems","software maintenance;source code (software)","test smells;test suites maintenance;automated tools;source code;production code;code smells","","","45","","","","","IEEE","IEEE Conferences"
"Mining input grammars from dynamic taints","M. Höschele; A. Zeller","Saarland University, Saarland Informatics Campus, Saarbrücken, Germany; Saarland University, Saarland Informatics Campus, Saarbrücken, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","720","725","Knowing which part of a program processes which parts of an input can reveal the structure of the input as well as the structure of the program. In a URL http://www.example.com/path/, for instance, the protocol http, the host www.example.com, and the path path would be handled by different functions and stored in different variables. Given a set of sample inputs, we use dynamic tainting to trace the data flow of each input character, and aggregate those input fragments that would be handled by the same function into lexical and syntactical entities. The result is a context-free grammar that reflects valid input structure. In its evaluation, our AUTOGRAM prototype automatically produced readable and structurally accurate grammars for inputs like URLs, spreadsheets or configuration files. The resulting grammars not only allow simple reverse engineering of input formats, but can also directly serve as input for test generators.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582807","Input formats;context-free grammars;dynamic tainting;fuzzing","Grammar;Protocols;Uniform resource locators;Java;Instruments;Software;Ports (Computers)","context-free grammars;data flow analysis;data mining;file organisation;spreadsheet programs","input grammars mining;dynamic taints;program structure;data flow;context-free grammar;AUTOGRAM prototype;URL;spreadsheets;configuration files","","","6","","","","","IEEE","IEEE Conferences"
"Reflection-aware static analysis of Android apps","L. Li; T. F. Bissyandé; D. Octeau; J. Klein","SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; CSE, Pennsylvania State University, USA; SnT, University of Luxembourg, Luxembourg","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","756","761","We demonstrate the benefits of DroidRA, a tool for taming reflection in Android apps. DroidRA first statically extracts reflection-related object values from a given Android app. Then, it leverages the extracted values to boost the app in a way that reflective calls are no longer a challenge for existing static analyzers. This is achieved through a bytecode instrumentation approach, where reflective calls are supplemented with explicit traditional Java method calls which can be followed by state-of-the-art analyzers which do not handle reflection. Instrumented apps can thus be completely analyzed by existing static analyzers, which are no longer required to be modified to support reflection-aware analysis. The video demo of DroidRA can be found at https://youtu.be/-HW0V68aAWc.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582811","Android;Static Analysis;Reflection;DroidRA","Androids;Humanoid robots;Java;Smart phones;Coal;Instruments;Runtime","Android (operating system);Java;program diagnostics;reflection","reflection-aware static analysis;Android apps;DroidRA benefits;taming reflection tool;reflection-related object values extraction;reflective calls;bytecode instrumentation approach;Java method calls;reflection-aware analysis","","3","30","","","","","IEEE","IEEE Conferences"
"Static race detection for device drivers: The Goblint approach","V. Vojdani; K. Apinis; V. Rõtov; H. Seidl; V. Vene; R. Vogler","University of Tartu, Estonia; University of Tartu, Estonia; University of Tartu, Estonia; Technische Universität, München, Germany; University of Tartu, Estonia; Technische Universität, München, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","391","402","Device drivers rely on fine-grained locking to ensure safe access to shared data structures. For human testers, concurrency makes such code notoriously hard to debug; for automated reasoning, dynamically allocated memory and low-level pointer manipulation poses significant challenges. We present a flexible approach to data race analysis, implemented in the open source Goblint static analysis framework that combines different pointer and value analyses in order to handle a wide range of locking idioms, including locks allocated dynamically as well as locks stored in arrays. To the best of our knowledge, this is the most ambitious effort, having lasted well over ten years, to create a fully automated static race detection tool that can deal with most of the intricate locking schemes found in Linux device drivers. Our evaluation shows that these analyses are sufficiently precise, but practical use of these techniques requires inferring environmental and domain-specific assumptions.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582775","Concurrency;race condition;abstract interpretation","Decision support systems;Servers","authorisation;concurrency (computers);data structures;device drivers;inference mechanisms;Linux;program debugging;program diagnostics;public domain software","static race detection;fine-grained locking;safe access;shared data structures;human testers;concurrency;debug;automated reasoning;low-level pointer manipulation;open source Goblint static analysis;Linux device drivers","","","46","","","","","IEEE","IEEE Conferences"
"Optimizing customized program coverage","P. Ohmann; D. B. Brown; N. Neelakandan; J. Linderoth; B. Liblit","University of Wisconsin-Madison, Madison, WI, USA; University of Wisconsin-Madison, Madison, WI, USA; University of Wisconsin-Madison, Madison, WI, USA; University of Wisconsin-Madison, Madison, WI, USA; University of Wisconsin-Madison, Madison, WI, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","27","38","Program coverage is used across many stages of software development. While common during testing, program coverage has also found use outside the test lab, in production software. However, production software has stricter requirements on run-time overheads, and may limit possible program instrumentation. Thus, optimizing the placement of probes to gather program coverage is important. We introduce and study the problem of customized program coverage optimization. We generalize previous work that optimizes for complete coverage instrumentation with a system that adapts optimization to customizable program coverage requirements. Specifically, our system allows a user to specify desired coverage locations and to limit legal instrumentation locations. We prove that the problem of determining optimal coverage probes is NP-hard, and we present a solution based on mixed integer linear programming. Due to the computational complexity of the problem, we also provide two practical approximation approaches. We evaluate the effectiveness of our approximations across a diverse set of benchmarks, and show that our techniques can substantially reduce instrumentation while allowing the user immense freedom in defining coverage requirements. When naive instrumentation is dense or expensive, our optimizations succeed in lowering execution time overheads.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582742","Debugging;mixed integer linear optimization;program coverage","Probes;Software;Optimization;Debugging;Monitoring;Context","computational complexity;integer programming;linear programming;program testing;software engineering","software development;testing;production software;run-time overheads;customized program coverage optimization;legal instrumentation locations;NP-hard;mixed integer linear programming;computational complexity","","","40","","","","","IEEE","IEEE Conferences"
"Practical guidelines for change recommendation using association rule mining","L. Moonen; S. Di Alesio; D. Binkley; T. Rolfsnes","Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Loyola University Maryland, Baltimore, Maryland, USA; Simula Research Laboratory, Oslo, Norway","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","732","743","Association rule mining is an unsupervised learning technique that infers relationships among items in a data set. This technique has been successfully used to analyze a system's change history and uncover evolutionary coupling between system artifacts. Evolutionary coupling can, in turn, be used to recommend artifacts that are potentially affected by a given set of changes to the system. In general, the quality of such recommendations is affected by (1) the values selected for various parameters of the mining algorithm, (2) characteristics of the set of changes used to derive a recommendation, and (3) characteristics of the system's change history for which recommendations are generated. In this paper, we empirically investigate the extent to which certain choices for these factors affect change recommendation. Specifically, we conduct a series of systematic experiments on the change histories of two large industrial systems and eight large open source systems, in which we control the size of the change set for which to derive a recommendation, the measure used to assess the strength of the evolutionary coupling, and the maximum size of historical changes taken into account when inferring these couplings. We use the results from our study to derive a number of practical guidelines for applying association rule mining for change recommendation.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582809","Evolutionary coupling;association rule mining;parameter tuning;change recommendations;change impact analysis","Couplings;History;Data mining;Software;Algorithm design and analysis;Guidelines;Size measurement","data mining;recommender systems;unsupervised learning","change recommendation;association rule mining;unsupervised learning technique;evolutionary coupling;recommendation quality;open source systems","","","41","","","","","IEEE","IEEE Conferences"
"An end-user oriented tool suite for development of mobile applications","Z. Zhai; B. Cheng; M. Niu; Z. Wang; Y. Feng; J. Chen","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","768","773","In this paper, we show an end-user oriented tool suite for mobile application development. The advantages of this tool suite are that the graphical user interface (GUI), as well as the application logic can both be developed in a rapid and simple way, and web-based services on the Internet can be integrated into our platform by end-users. This tool suite involves three sub-systems, namely ServiceAccess, EasyApp and LSCE. ServiceAccess takes charge of the registration and management of heterogeneous services, and can export different form of services according to the requirements of the other sub-systems. EasyApp is responsible for developing GUI in the form of mobile app. LSCE takes charge of creating the application logic that can be invoked by mobile app directly. Finally, a development case is presented to illustrate the development process using this tool suite. The URL of demo video: https://youtu.be/mM2WkU1_k-w.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582813","Mobile application;end-user development;visual development environment;cross-platform","Mobile communication;Libraries;Mobile applications;Servers;Web services;Graphical user interfaces;Visualization","formal logic;graphical user interfaces;mobile computing;software tools","end-user oriented tool suite;mobile application development;graphical user interface;GUI;application logic","","","21","","","","","IEEE","IEEE Conferences"
"Traceability maintenance: Factors and guidelines","S. Maro; A. Anjorin; R. Wohlrab; J. Steghöfer","Chalmers | University of Gothenburg, Sweden; University of Paderborn, Paderborn, Germany; Chalmers | University of Gothenburg, Sweden; Chalmers | University of Gothenburg, Sweden","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","414","425","Traceability is an important concern for numerous software engineering activities. Establishing traceability links is a challenging and cost-intensive task, which is uneconomical without suitable strategies for maintaining high link quality. Current approaches to Traceability Management (TM), however, often make important assumptions and choices without ensuring that the consequences and implications for trace-ability maintenance are feasible and desirable in practice. In this paper, therefore, we identify a set of core factors that influence how the quality of traceability links can be maintained. For each factor, we discuss relevant challenges and provide guidelines on how best to ensure viable traceability maintenance in a practical TM approach. Our guidelines are meant to be used by tool developers and users to select the most appropriate TM approach for their needs. Our results are based on and supported by data collected from interviews conducted with: (i) 9 of our industrial and academic project partners to elicit requirements for a TM tool, and (ii) 24 software development stakeholders from 15 industrial cases to provide a broader overview of the current state of the practice on TM. To evaluate the feasibility of our guidelines, we investigate a set of existing TM approaches used in industry with respect to our guidelines.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582777","traceability quality;traceability maintenance;consistency","Unified modeling language;Maintenance engineering;Guidelines;Software;Manuals;Interviews;Computational modeling","software maintenance;software management;software quality","traceability maintenance;traceability quality;software engineering;traceability management;TM","","","31","","","","","IEEE","IEEE Conferences"
"Inferring annotations for device drivers from verification histories","Z. Pavlinovic; A. Lal; R. Sharma","New York University, USA; Microsoft Research, India; Stanford University, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","450","460","This paper studies and optimizes automated program verification. Detailed reasoning about software behavior is often facilitated by program invariants that hold across all program executions. Finding program invariants is in fact an essential step in automated program verification. Automatic discovery of precise invariants, however, can be very difficult in practice. The problem can be simplified if one has access to a candidate set of assertions (or annotations) and the search for invariants is limited over the space defined by these annotations. Then, the main challenge is to automatically generate quality program annotations. We present an approach that infers program annotations automatically by leveraging the history of verifying related programs. Our algorithm extracts high-quality annotations from previous verification attempts, and then applies them for verifying new programs. We present a case study where we applied our algorithm to Microsoft's Static Driver Verifier (SDV). SDV is an industrial-strength tool for verification of Windows device drivers that uses manually-tuned heuristics for obtaining a set of annotations. Our technique inferred program annotations comparable in performance to the existing annotations used in SDV that were devised manually by human experts over years. Additionally, the inferred annotations together with the existing ones improved the performance of SDV overall, proving correct 47% of drivers more while running 22% faster in our experiments.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582781","Program verification;Invariant generation;Learning invariants;Verification history;Big Code","History;Kernel;Manuals;Performance evaluation;Simultaneous localization and mapping;Contracts","device drivers;inference mechanisms;program diagnostics;program verification;software quality","program annotation inference;Windows device driver;program verification;reasoning;software behavior;program invariant;high-quality annotation;Microsoft Static Driver Verifier;SDV","","","28","","","","","IEEE","IEEE Conferences"
"Test case permutation to improve execution time","P. Stratis; A. Rajan","School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","45","50","With the growing complexity of software, the number of test cases needed for effective validation is extremely large. Executing these large test suites is expensive, both in terms of time and energy. Cache misses are known to be one of the main factors contributing to execution time of a software. Cache misses are reduced by increasing the locality of memory references. For a single program run, compiler optimisations help improve data locality and code layout optimisations help improve spatial locality of instructions. Nevertheless, cache locality optimisations have not been proposed and explored across several program runs, which is the case when we run several test cases. In this paper, we propose and evaluate a novel approach to improve instruction locality across test case runs. Our approach measures the distance between test case runs (number of different instructions). We then permute the test cases for execution so that the distance between neighboring test cases is minimised. We hypothesize that test cases executed in this new order for improved instruction locality will reduce time consumed. We conduct a preliminary evaluation with four subject programs and test suites from the SIR repository to answer the following questions, 1. Is execution time of a test suite affected by the order in which test cases are executed? and 2. How does time consumed in executing our permutation compare to random test case permutations? We found that the order in which test cases are executed has a definite impact on execution time. The extent of impact varies, based on program characteristics and test cases. Our approach outperformed more than 97% of random test case permutations on 3 of the 4 subject programs and did better than 93% of the random orderings on the remaining subject program. Using the optimised permutation, we saw a maximum reduction of 7.4% over average random permutation execution time and 34.7% over the worst permutation.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582744","Cache misses;Instruction locality","Optimization;Software;Layout;Software testing;Informatics;Complexity theory","cache storage;optimisation;program compilers","cache misses;memory references;compiler optimisations;data locality;code layout optimisations;spatial locality;cache locality optimisations;instruction locality;SIR repository;test case permutations;random orderings;optimised permutation;average random permutation execution time","","","23","","","","","IEEE","IEEE Conferences"
"MACKE: Compositional analysis of low-level vulnerabilities with symbolic execution","S. Ognawala; M. Ochoa; A. Pretschner; T. Limmer","Technical University of Munich, Germany; Singapore University of Technology and Design, Singapore; Technical University of Munich, Germany; Siemens AG, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","780","785","Concolic (concrete+symbolic) execution has recently gained popularity as an effective means to uncover non-trivial vulnerabilities in software, such as subtle buffer overflows. However, symbolic execution tools that are designed to optimize statement coverage often fail to cover potentially vulnerable code because of complex system interactions and scalability issues of constraint solvers. In this paper, we present a tool (MACKE) that is based on the modular interactions inferred by static code analysis, which is combined with symbolic execution and directed inter-procedural path exploration. This provides an advantage in terms of statement coverage and ability to uncover more vulnerabilities. Our tool includes a novel feature in the form of interactive vulnerability report generation that helps developers prioritize bug fixing based on severity scores. A demo of our tool is available at https://youtu.be/icC3jc3mHEU.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582815","Symbolic execution;Compositional analysis","Computer bugs;Engines;Software;Security;Memory management;Complex systems;Scalability","program debugging;program diagnostics;program testing;software tools","MACKE tool;compositional analysis;low-level vulnerabilities;concolic execution;concrete+symbolic execution;nontrivial software vulnerabilities;buffer overflows;complex system interactions;scalability issues;constraint solvers;modular interactions;static code analysis;directed interprocedural path exploration;interactive vulnerability report generation;bug fixing;severity scores","","","34","","","","","IEEE","IEEE Conferences"
"DSL-maps: From requirements to design of domain-specific languages","A. Pescador; J. de Lara","Computer Science Department, Modelling and Software Engineering Research Group, Universidad Autónoma de Madrid (Spain); Computer Science Department, Modelling and Software Engineering Research Group, Universidad Autónoma de Madrid (Spain)","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","438","443","Domain-Specific Languages (DSLs) are central to Model-Driven Engineering, where they are used for creating models for particular domains. However, current research and tools for building DSLs focus on the design and implementation aspects of the DSL, while the requirements analysis phase, and its automated transition to design is largely neglected. In order to alleviate this situation, we propose DSL-maps, a notation inspired by mind-maps, to represent requirements for DSLs. The notation is supported by a tool, which helps in the automated transition into an initial meta-model design, using a customizable transformation and recommendations from a catalogue of meta-model design patterns.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582779","Domain Specific Languages;Model-Driven Engineering;Domain Analysis;Meta-Modelling Patterns","DSL;Syntactics;Unified modeling language;Software;Connectors;Computational modeling;Concrete","high level languages;pattern recognition;systems analysis","DSL-maps;domain-specific languages;model-driven engineering;requirements analysis phase;mind-maps;meta-model design patterns","","","16","","","","","IEEE","IEEE Conferences"
"APEx: Automated inference of error specifications for C APIs","Y. Kang; B. Ray; S. Jana","Columbia University, USA; University of Virginia, USA; Columbia University, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","472","482","Although correct error handling is crucial to software robustness and security, developers often inadvertently introduce bugs in error handling code. Moreover, such bugs are hard to detect using existing bug-finding tools without correct error specifications. Creating error specifications manually is tedious and error-prone. In this paper, we present a new technique that automatically infers error specifications of API functions based on their usage patterns in C programs. Our key insight is that error-handling code tend to have fewer branching points and program statements than the code implementing regular functionality. Our scheme leverages this property to automatically identify error handling code at API call sites and infer the corresponding error constraints. We then use the error constraints from multiple call sites for robust inference of API error specifications. We evaluated our technique on 217 API functions from 6 different libraries across 28 projects written in C and found that it can identify error-handling paths with an average precision of 94% and recall of 66%. We also found that our technique can infer correct API error specifications with an average precision of 77% and recall of 47%. To further demonstrate the usefulness of the inferred error specifications, we used them to find 118 previously unknown potential bugs (including several security flaws that are currently being fixed by the corresponding developers) in the 28 tested projects.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582783","error handling bugs;specification mining;API errors","Computer bugs;Security;Software;Libraries;Documentation;Algorithm design and analysis;Robustness","C language;error handling;formal specification;program debugging;software tools","APEx;automated inference;error specifications;C APIs;software robustness;software security;software developers;error handling code;bug-finding tools;API functions;C programs;branching points;program statements;software reliability","","","42","","","","","IEEE","IEEE Conferences"
"Testing advanced driver assistance systems using multi-objective search and neural networks","R. Ben Abdessalem; S. Nejati; L. C. Briand; T. Stifter","SnT / University of Luxembourg, Luxembourg; SnT / University of Luxembourg, Luxembourg; SnT / University of Luxembourg, Luxembourg; IEE S.A. Contern, Luxembourg","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","63","74","Recent years have seen a proliferation of complex Advanced Driver Assistance Systems (ADAS), in particular, for use in autonomous cars. These systems consist of sensors and cameras as well as image processing and decision support software components. They are meant to help drivers by providing proper warnings or by preventing dangerous situations. In this paper, we focus on the problem of design time testing of ADAS in a simulated environment. We provide a testing approach for ADAS by combining multi-objective search with surrogate models developed based on neural networks. We use multi-objective search to guide testing towards the most critical behaviors of ADAS. Surrogate modeling enables our testing approach to explore a larger part of the input search space within limited computational resources. We characterize the condition under which the multi-objective search algorithm behaves the same with and without surrogate modeling, thus showing the accuracy of our approach. We evaluate our approach by applying it to an industrial ADAS system. Our experiment shows that our approach automatically identifies test cases indicating critical ADAS behaviors. Further, we show that combining our search algorithm with surrogate modeling improves the quality of the generated test cases, especially under tight and realistic computational resources.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582746","Advanced Driver Assistance Systems;Multi-Objective Search Optimization;Simulation;Surrogate Modeling;Neural Networks","Testing;Computational modeling;Predictive models;Automobiles;Advanced driver assistance systems;Software","automobiles;digital simulation;driver information systems;mobile robots;neural nets;program testing;search problems","advanced driver assistance system testing;multiobjective search algorithm;neural networks;autonomous cars;sensors;cameras;image processing;decision support software components;warnings;dangerous situation prevention;design time testing;simulated environment;surrogate models;critical ADAS behaviors;computational resources","","","59","","","","","IEEE","IEEE Conferences"
"Evaluating the evaluations of code recommender systems: A reality check","S. Proksch; S. Amann; S. Nadi; M. Mezini","Software Technology Group, Technische Universität Darmstadt, Germany; Software Technology Group, Technische Universität Darmstadt, Germany; Software Technology Group, Technische Universität Darmstadt, Germany; Software Technology Group, Technische Universität Darmstadt, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","111","121","While researchers develop many new exciting code recommender systems, such as method-call completion, code-snippet completion, or code search, an accurate evaluation of such systems is always a challenge. We analyzed the current literature and found that most of the current evaluations rely on artificial queries extracted from released code, which begs the question: Do such evaluations reflect real-life usages? To answer this question, we capture 6,189 fine-grained development histories from real IDE interactions. We use them as a ground truth and extract 7,157 real queries for a specific method-call recommender system. We compare the results of such real queries with different artificial evaluation strategies and check several assumptions that are repeatedly used in research, but never empirically evaluated. We find that an evolving context that is often observed in practice has a major effect on the prediction quality of recommender systems, but is not commonly reflected in artificial evaluations.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582750","Empirical Study;Artificial Evaluation;IDE Interaction Data","Context;Recommender systems;Software;Proposals;Benchmark testing;MIMICs;History","program testing;software maintenance","code recommender system;method-call completion;code-snippet completion;code search","","","29","","","","","IEEE","IEEE Conferences"
"CORRECT: Code reviewer recommendation at GitHub for Vendasta technologies","M. M. Rahman; C. K. Roy; J. Redl; J. A. Collins","University of Saskatchewan, Canada; University of Saskatchewan, Canada; Vendasta Technologies, Canada; Google Inc., USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","792","797","Peer code review locates common coding standard violations and simple logical errors in the early phases of software development, and thus, reduces overall cost. Unfortunately, at GitHub, identifying an appropriate code reviewer for a pull request is challenging given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation tool-CORRECT-that considers not only the relevant cross-project work experience (e.g., external library experience) of a developer but also her experience in certain specialized technologies (e.g., Google App Engine) associated with a pull request for determining her expertise as a potential code reviewer. We design our tool using client-server architecture, and then package the solution as a Google Chrome plug-in. Once the developer initiates a new pull request at GitHub, our tool automatically analyzes the request, mines two relevant histories, and then returns a ranked list of appropriate code reviewers for the request within the browser's context. Demo: https://www.youtube.com/watch?v=rXU1wTD6QQ0.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582817","Code reviewer recommendation;cross-project experience;specialized technology experience;GitHub;pull request","History;Software;Libraries;Browsers;Collaboration;Authentication;Encoding","client-server systems;DP industry;Internet;recommender systems;software architecture;software reviews;software tools;source code (software)","CORRECT;code reviewer recommendation tool;GitHub;Vendasta Technologies;peer code review;software development;client-server architecture;Google Chrome plug-in","","","18","","","","","IEEE","IEEE Conferences"
"Visual contract extractor: A tool for reverse engineering visual contracts using dynamic analysis","A. Alshanqiti; R. Heckel; T. Kehrer","Department of Computer Science, University of Leicester, UK; Department of Computer Science, University of Leicester, UK; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","816","821","Visual contracts model the operations of classes, components or services by pre- and post-conditions formalised as graph transformation rules. They provide a precise but intuitive notation to test, document and analyse software systems. However, due to their detailed level of specification of data states and transformations, modelling a real application is a complex and error-prone process. Rather than adopting a top-down modelling approach, we follow a dynamic bottom-up approach to reverse engineer visual contracts from object-oriented programs based on tracing the execution of operations. We developed the Visual Contract Extractor (VCE), a dynamic analysis tool which supports the reverse engineering of visual operation contracts from Java programs. We explore the main features of the tool using two case studies and discuss usage scenarios ranging from traditional program understanding to novel applications in the field of model-based engineering. A screencast demonstrating the tool is provided at https://www.youtube.com/watch?v=VtTx8UHgRGo.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582821","Visual contracts;graph transformation;model extraction;dynamic analysis;reverse engineering;specification mining","Contracts;Visualization;Object oriented modeling;Unified modeling language;Java;Reverse engineering;Analytical models","Java;object-oriented programming;program testing;reverse engineering;software tools","visual contract extractor;reverse engineering;dynamic analysis;preconditions;postconditions;graph transformation rules;software system analysis;software system documentation;software system testing;dynamic bottom-up approach;object-oriented programs;operation execution tracing;VCE;dynamic analysis tool;Java programs;model-based engineering","","","30","","","","","IEEE","IEEE Conferences"
"Precise semantic history slicing through dynamic delta refinement","Y. Li; C. Zhu; J. Rubin; M. Chechik","University of Toronto, Toronto, ON, Canada; University of Toronto, Toronto, ON, Canada; MIT, Cambridge, MA, USA; University of Toronto, Toronto, ON, Canada","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","495","506","Semantic history slicing solves the problem of extracting changes related to a particular high-level functionality from the software version histories. State-of-the-art techniques combine static program analysis and dynamic execution tracing to infer an over-approximated set of changes that can preserve the functional behaviors captured by a test suite. However, due to the conservative nature of such techniques, the sliced histories may contain irrelevant changes. In this paper, we propose a divide-and-conquer-style partitioning approach enhanced by dynamic delta refinement to produce minimal semantic history slices. We utilize deltas in dynamic invariants generated from successive test executions to learn significance of changes with respect to the target functionality. Empirical results indicate that these measurements accurately rank changes according to their relevance to the desired test behaviors and thus partition history slices in an efficient and effective manner.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582785","Semantic history slicing;program analysis;dynamic invariants;software configuration management","History;Semantics;Software;Heuristic algorithms;Runtime;Performance analysis;Organizations","configuration management;program slicing","precise semantic history slicing;dynamic delta refinement;software version histories;static program analysis;dynamic execution tracing;divide and conquer style partitioning approach;software configuration management","","","45","","","","","IEEE","IEEE Conferences"
"Deep learning code fragments for code clone detection","M. White; M. Tufano; C. Vendome; D. Poshyvanyk","Department of Computer Science, College of William and Mary, Williamsburg, Virginia, USA; Department of Computer Science, College of William and Mary, Williamsburg, Virginia, USA; Department of Computer Science, College of William and Mary, Williamsburg, Virginia, USA; Department of Computer Science, College of William and Mary, Williamsburg, Virginia, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","87","98","Code clone detection is an important problem for software maintenance and evolution. Many approaches consider either structure or identifiers, but none of the existing detection techniques model both sources of information. These techniques also depend on generic, handcrafted features to represent code fragments. We introduce learning-based detection techniques where everything for representing terms and fragments in source code is mined from the repository. Our code analysis supports a framework, which relies on deep learning, for automatically linking patterns mined at the lexical level with patterns mined at the syntactic level. We evaluated our novel learning-based approach for code clone detection with respect to feasibility from the point of view of software maintainers. We sampled and manually evaluated 398 file- and 480 method-level pairs across eight real-world Java systems; 93% of the file- and method-level samples were evaluated to be true positives. Among the true positives, we found pairs mapping to all four clone types. We compared our approach to a traditional structure-oriented technique and found that our learning-based approach detected clones that were either undetected or suboptimally reported by the prominent tool Deckard. Our results affirm that our learning-based approach is suitable for clone detection and a tenable technique for researchers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582748","code clone detection;machine learning;deep learning;neural networks;language models;abstract syntax trees","Cloning;Syntactics;Software;Feature extraction;Machine learning;Programming;Transforms","Java;learning (artificial intelligence);software maintenance;source code (software)","deep learning code fragments;code clone detection;software maintenance;software evolution;source code;pattern mined linking;Java systems;Deckard tool","","","115","","","","","IEEE","IEEE Conferences"
"Automatic microbenchmark generation to prevent dead code elimination and constant folding","M. Rodriguez-Cancio; B. Combemale; B. Baudry","University of Rennes 1, France; University of Rennes 1/INRIA, France; INRIA, France","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","132","143","Microbenchmarking evaluates, in isolation, the execution time of small code segments that play a critical role in large applications. The accuracy of a microbenchmark depends on two critical tasks: wrap the code segment into a pay-load that faithfully recreates the execution conditions of the large application; build a scaffold that runs the payload a large number of times to get a statistical estimate of the execution time. While recent frameworks such as the Java Microbenchmark Harness (JMH) address the scaffold challenge, developers have very limited support to build a correct payload. This work focuses on the automatic generation of pay-loads, starting from a code segment selected in a large application. Our generative technique prevents two of the most common mistakes made in microbenchmarks: dead code elimination and constant folding. A microbenchmark is such a small program that can be “over-optimized” by the JIT and result in distorted time measures, if not designed carefully. Our technique automatically extracts the segment into a compilable payload and generates additional code to prevent the risks of “over-optimization”. The whole approach is embedded in a tool called AutoJMH, which generates payloads for JMH scaffolds. We validate the capabilities AutoJMH, showing that the tool is able to process a large percentage of segments in real programs. We also show that AutoJMH can match the quality of payloads handwritten by performance experts and outperform those written by professional Java developers without experience in microbenchmarking.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582752","Performace evaluation;microbencharking;text tagging","Payloads;Java;Optimization;Benchmark testing;Distortion measurement;Time measurement;Software","Java;software performance evaluation","microbenchmark generation;dead code elimination prevention;code segment;Java microbenchmark harness;JMH;over-optimization risk prevention;AutoJMH tool","","","36","","","","","IEEE","IEEE Conferences"
"CVExplorer: Identifying candidate developers by mining and exploring their open source contributions","G. J. Greene; B. Fischer","CAIR, CSIR Meraka, Computer Science Division, University of Stellenbosch, South Africa; CAIR, CSIR Meraka, Computer Science Division, University of Stellenbosch, South Africa","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","804","809","Open source code contributions contain a large amount of technical skill information about developers, which can help to identify suitable candidates for a particular development job and therefore impact the success of a development team. We develop CVExplorer as a tool to extract, visualize, and explore relevant technical skills data from GitHub, such as languages and libraries used. It allows non-technical users to filter and identify developers according to technical skills demonstrated across all of their open source contributions, in order to support more accurate candidate identification. We demonstrate the usefulness of CVExplorer by using it to recommend candidates for open positions in two companies. A video demonstration of the tool is available at https:// youtu.be/xRxK-wa7PME.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582819","Identifying candidate developers;Developer skills identification;Mining software repositories","Java;Tag clouds;Data mining;Software;Aggregates;Data visualization","data visualisation;human resource management;public domain software;software engineering;source code (software)","CVExplorer;candidate developers identification;open source code contributions;technical skills data visualization;GitHub","","1","27","","","","","IEEE","IEEE Conferences"
"Symbolic execution of stored procedures in database management systems","M. S. Mahmood; M. A. Ghafoor; J. H. Siddiqui","Department of Computer Science, LUMS School of Science and Engineering, Lahore, Pakistan; Department of Computer Science, LUMS School of Science and Engineering, Lahore, Pakistan; Department of Computer Science, LUMS School of Science and Engineering, Lahore, Pakistan","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","519","530","Stored procedures in database management systems are often used to implement complex business logic. Correctness of these procedures is critical for correct working of the system. However, testing them remains difficult due to many possible states of data and database constraints. This leads to mostly manual testing. Newer tools offer automated execution for unit testing of stored procedures but the test cases are still written manually. In this paper, we propose a novel approach of using dynamic symbolic execution to automatically generate test cases and corresponding database states for stored procedures. We treat values in database tables as symbolic, model the constraints on data imposed by the schema and by the SQL statements executed by the stored procedure. We use an SMT solver to find values that will drive the stored procedure on a particular execution path. We instrument the internal execution plans generated by PostgreSQL database management system to extract constraints and use the Z3 SMT solver to generate test cases consisting of table data and procedure inputs. Our evaluation using stored procedures from a large business application shows that this technique can uncover bugs that lead to schema constraint violations and user defined exceptions.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582787","Symbolic Execution;Stored Procedures;SQL","Remuneration;Testing;Instruments;Servers;Analytical models;Database systems","database management systems;program testing;SQL","stored procedures;database management systems;complex business logic;database constraints;automated execution;unit testing;test cases;dynamic symbolic execution;database tables;SQL statements;execution path;internal execution plans;PostgreSQL;Z3 SMT solver","","","36","","","","","IEEE","IEEE Conferences"
"Towards bounded model checking using nonlinear programming solver","M. Nishi","Center for Technology Innovation, R&D Group, Hitachi Ltd, Japan","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","560","565","Due to their complexity, currently available bounded model checking techniques based on Boolean Satisfiability and Satisfiability Modulo Theories inadequately handle non-linear floating-point and integer arithmetic. Using a numerical approach, we reduce a bounded model checking problem to a constraint satisfaction problem. Currently available techniques attempt to solve the constraint problem but can guarantee neither global convergence nor correctness. Using the IPOPT and ANTIGONE non-linear programming (NLP) solvers, we transform the original constraint satisfaction problem from one having disjunctions of constraints into one having conjunctions of constraints with a few introduced auxiliary variables. The transformation lowers the computing cost and preserves the Boolean structure of the original problem while complying with limits of NLP solvers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582791","Bounded Model Checking;Nonlinear Programming;SAT","Model checking;Convergence;Software;Mathematical model;Encoding;Programming","Boolean algebra;computability;formal verification;nonlinear programming","nonlinear programming solver;Boolean satisfiability;Satisfiability Modulo Theories;nonlinear floating point;integer arithmetic;bounded model checking problem;constraint satisfaction problem;constraint problem;global convergence;IPOPT;ANTIGONE nonlinear programming;NLP solvers;auxiliary variables;Boolean structure","","","20","","","","","IEEE","IEEE Conferences"
"Finding access control bugs in web applications with CanCheck","I. Bocić; T. Bultan","Department of Computer Science, University of California, Santa Barbara, USA; Department of Computer Science, University of California, Santa Barbara, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","155","166","Access control bugs in web applications can have dire consequences since many web applications store private and sensitive data. In this paper we present an automated verification technique for access control in Ruby on Rails (Rails) applications. Our technique starts by automatically extracting a model that captures 1) the ways the data is accessed and modified by the application, 2) the access control policy of the application, and 3) the authorization checks used for access control policy enforcement. Then, it automatically translates this model to first order logic and uses automated theorem provers to check whether the declared access control policy is correctly enforced by the implementation. We implemented our technique in a tool called CanCheck. Using CanCheck on open source Rails applications, we found numerous previously unknown exploitable access control bugs as well as several deficiencies in access control policies.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582754","Access Control;Logic-based Verification;Web Applications","Rails;Authorization;Computer bugs;Data models;Software;Databases","authorisation;data privacy;formal logic;formal verification;Internet;program debugging;public domain software;theorem proving","access control bugs;Web applications;CanCheck;private data;sensitive data;automated verification;Ruby on Rails;first order logic;automated theorem provers;open source Rails applications","","","38","","","","","IEEE","IEEE Conferences"
"TeeVML: Tool support for semi-automatic integration testing environment emulation","J. Liu; J. Grundy; I. Avazpour; M. Abdelrazek","School of Software and Electrical Engineering, Swinburne University of Technology, Hawthorn, VIC 3122, Australia; School of Information Technology, Deakin University, Burwood, VIC 3125, Australia; School of Information Technology, Deakin University, Burwood, VIC 3125, Australia; School of Information Technology, Deakin University, Burwood, VIC 3125, Australia","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","840","845","Software environment emulation provides a means for simulating an operational environment of a system. This process involves approximation of systems' external behaviors and their communications with a system to be tested in the environment. Development of such an environment is a tedious task and involves complex low level coding. Model driven engineering is an avenue to raise the level of abstraction beyond programming by specifying solution directly using problem domain concepts. In this paper we propose a novel domain-specific modeling tool to generate complex testing environments. Our tool employs a suite of domain-specific visual modeling languages for modeling emulation environment at a high level of abstraction. These high level specifications are then automatically transformed to runtime environment for application integration testing, boosting development productivity and ease of use. The tool demonstration video can be accessed here: https://youtu.be/H3Vg20Juq80.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582825","Model-driven engineering;domain-specific visual modeling language;software component interface description;testing environment emulation","Testing;Software;Emulation;Unified modeling language;Protocols;Visualization;Banking","formal specification;program testing;software tools;specification languages","TeeVML;tool support;application integration testing;software environment emulation;model-driven engineering;domain-specific visual modelling language;high level specification","","","13","","","","","IEEE","IEEE Conferences"
"Model-based whitebox fuzzing for program binaries","V. Pham; M. Böhme; A. Roychoudhury","School of Computing, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","543","553","Many real-world programs take highly structured and complex files as inputs. The automated testing of such programs is non-trivial. If the test does not adhere to a specific file format, the program returns a parser error. For symbolic execution-based whitebox fuzzing the corresponding error handling code becomes a significant time sink. Too much time is spent in the parser exploring too many paths leading to trivial parser errors. Naturally, the time is better spent exploring the functional part of the program where failure with valid input exposes deep and real bugs in the program. In this paper, we suggest to leverage information about the file format and data chunks of existing, valid files to swiftly carry the exploration beyond the parser code. We call our approach Modelbased Whitebox Fuzzing (MoWF) because the file format input model of blackbox fuzzers can be exploited as a constraint on the vast input space to rule out most invalid inputs during path exploration in symbolic execution. We evaluate on 13 vulnerabilities in 8 large program binaries with 6 separate file formats and found that MoWF exposes all vulnerabilities while both, traditional whitebox fuzzing and model-based blackbox fuzzing, expose only less than half, respectively. Our experiments also demonstrate that MoWF exposes 70% vulnerabilities without any seed inputs.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582789","Symbolic Execution;Program Binaries","Data models;Testing;Computer bugs;Libraries;Grammar;Browsers;Media","error handling;program compilers;program debugging;program testing;security of data","model-based whitebox fuzzing;MoWF;program binaries;automated program testing;parser error;symbolic execution-based whitebox fuzzing;error handling code;bugs;path exploration;program vulnerabilities;model-based blackbox fuzzing","","","27","","","","","IEEE","IEEE Conferences"
"Continuous detection of design flaws in evolving object-oriented programs using incremental multi-pattern matching","S. Peldszus; G. Kulcsár; M. Lochau; S. Schulze","Institute for Software Technology, University of Koblenz-Landau, Germany; Real-Time Systems Lab, TU Darmstadt, Germany; Real-Time Systems Lab, TU Darmstadt, Germany; Institute of Software Technology Systems, TU Hamburg-Harburg, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","578","589","Design flaws in object-oriented programs may seriously corrupt code quality thus increasing the risk for introducing subtle errors during software maintenance and evolution. Most recent approaches identify design flaws in an ad-hoc manner, either focusing on software metrics, locally restricted code smells, or on coarse-grained architectural anti-patterns. In this paper, we utilize an abstract program model capturing high-level object-oriented code entities, further augmented with qualitative and quantitative design-related information such as coupling/cohesion. Based on this model, we propose a comprehensive methodology for specifying object-oriented design flaws by means of compound rules integrating code metrics, code smells and anti-patterns in a modular way. This approach allows for efficient, automated design-flaw detection through incremental multi-pattern matching, by facilitating systematic information reuse among multiple detection rules as well as between subsequent detection runs on continuously evolving programs. Our tool implementation comprises well-known anti-patterns for Java programs. The results of our experimental evaluation show high detection precision, scalability to real-size programs, as well as a remarkable gain in efficiency due to information reuse.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582793","design-flaw detection;continuous software evolution;object-oriented software architecture","Motion pictures;Software metrics;Object oriented modeling;Java;Software maintenance","formal specification;Java;object-oriented programming;pattern matching;software architecture;software maintenance;software metrics;software quality","continuous design flaw detection;evolving object-oriented program;incremental multipattern matching;code quality;software maintenance;software evolution;software metrics;locally restricted code smell;coarse-grained architectural antipattern;abstract program model;high-level object-oriented code entities;object-oriented design flaw specification;code metrics;systematic information reuse;Java program","","","42","","","","","IEEE","IEEE Conferences"
"Supporting oracle construction via static analysis","J. Chen; Y. Bai; D. Hao; L. Zhang; L. Zhang; B. Xie; H. Mei","Key Laboratory of High Confidence Software Technologies (Peking University), MoE; Key Laboratory of High Confidence Software Technologies (Peking University), MoE; Key Laboratory of High Confidence Software Technologies (Peking University), MoE; Department of Computer Science, University of Texas at Dallas, 75080, USA; Key Laboratory of High Confidence Software Technologies (Peking University), MoE; Key Laboratory of High Confidence Software Technologies (Peking University), MoE; Key Laboratory of High Confidence Software Technologies (Peking University), MoE","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","178","189","In software testing, the program under test is usually executed with test inputs and checked against a test oracle, which is a mechanism to verify whether the program behaves as expected. Selecting the right oracle data to observe is crucial in test oracle construction. In the literature, researchers have proposed two dynamic approaches to oracle data selection by analyzing test execution information (e.g., variables' values or interaction information). However, collecting such information during program execution may incur extra cost. In this paper, we present the first static approach to oracle data selection, SODS (Static Oracle Data Selection). In particular, SODS first identifies the substitution relationships between candidate oracle data by constructing a probabilistic substitution graph based on the definition-use chains of the program under test, then estimates the fault-observing capability of each candidate oracle data, and finally selects a subset of oracle data with strong fault-observing capability. For programs with analyzable test code, we further extend SODS via pruning the probabilistic substitution graph based on 0-1-CFA call graph analysis. The experimental study on 11 subject systems written in C or Java demonstrates that our static approach is more effective and much more efficient than state-of-the-art dynamic approaches in most cases.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582756","Test oracle;oracle data selection;static analysis","Software testing;Probabilistic logic;Software;Java;Fault diagnosis","C language;graph theory;Java;probability;program diagnostics;program testing;source code (software)","oracle construction;static analysis;software testing;program under test;test oracle;dynamic approach;oracle data selection;test execution information analysis;variable values;interaction information;program execution;SODS;static oracle data selection;substitution relationships;definition-use chains;fault-observing capability estimation;test code analysis;probabilistic substitution graph;0-1-CFA call graph analysis;C language;Java language","","","79","","","","","IEEE","IEEE Conferences"
"QUICKAR: Automatic query reformulation for concept location using crowdsourced knowledge","M. M. Rahman; C. K. Roy","Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science, University of Saskatchewan, Canada","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","220","225","During maintenance, software developers deal with numerous change requests made by the users of a software system. Studies show that the developers find it challenging to select appropriate search terms from a change request during concept location. In this paper, we propose a novel technique-QUICKAR-that automatically suggests helpful reformulations for a given query by leveraging the crowdsourced knowledge from Stack Overflow. It determines semantic similarity or relevance between any two terms by analyzing their adjacent word lists from the programming questions of Stack Overflow, and then suggests semantically relevant queries for concept location. Experiments using 510 queries from two software systems suggest that our technique can improve or preserve the quality of 76% of the initial queries on average which is promising. Comparison with one baseline technique validates our preliminary findings, and also demonstrates the potential of our technique.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582760","Query reformulation;crowdsourced knowledge;semantic relevance;word co-occurrence;adjacency list;Stack Overflow","Software;Semantics;Java;Programming;Vocabulary;Databases;Context","query processing;software maintenance","QUICKAR;automatic query reformulation;concept location;crowdsourced knowledge;software maintenance;Stack Overflow programming questions;semantic similarity;semantically relevant queries","","","24","","","","","IEEE","IEEE Conferences"
"Verifying Simulink Stateflow model: Timed automata approach","Y. Yang; Y. Jiang; M. Gu; J. Sun","School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","852","857","Simulink Stateflow is widely used for the model-driven development of software. However, the increasing demand of rigorous verification for safety critical applications brings new challenge to the Simulink Stateflow because of the lack of formal semantics. In this paper, we present STU, a self-contained toolkit to bridge the Simulink Stateflow and a well-defined rigorous verification. The tool translates the Simulink Stateflow into the Uppaal timed automata for verification. Compared to existing work, more advanced and complex modeling features in Stateflow such as the event stack, conditional action and timer are supported. Then, with the strong verification power of Uppaal, we can not only find design defects that are missed by the Simulink Design Verifier, but also check more important temporal properties. The evaluation on artificial examples and real industrial applications demonstrates the effectiveness.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582827","Simulink Stateflow;Uppaal Timed Automaton;Verification","Automata;Software packages;Switches;Clocks;Junctions;Semantics;Synchronization","automata theory;program verification;software tools","Simulink Stateflow model verification;Uppaal timed automata;model-driven development;STU toolkit","","1","15","","","","","IEEE","IEEE Conferences"
"Towards efficient and effective automatic program repair","X. D. Le","School of Information Systems, Singapore Management University, Singapore","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","876","879","Automatic Program Repair (APR) has recently been an emerging research area, addressing an important challenge in software engineering. APR techniques, if effective and efficient, can greatly help software debugging and maintenance. Recently proposed APR techniques can be generally classified into two families, namely search-based and semantics-based APR methods. To produce repairs, search based APR techniques generate huge populations of possible repairs, i.e., search space, and lazily search for the best one among the search space. Semantics-based APR techniques utilize constraint solving and program synthesis to make search space more tractable, and find those repairs that conform to semantics constraints extracted via symbolic execution. Despite recent advances in APR, search-based APR still suffers from search space explosion problem, while the semantics-based APR could be hindered by limited capability of constraint solving and program synthesis. Furthermore, both APR families may be subject to overfitting, in which generated repairs do not generalize to other test sets. This thesis works towards enhancing both effectiveness and efficiency in order for APR to be practically adopted in foreseeable future. To achieve this goal, other than using test cases as the primary criteria for traversing the search space, we designed a new feature used for a new search-based APR technique to effectively traverse the search space, wherein bug fix history is used to evaluate the quality of repair candidates. We also developed a deductive-reasoning-based repair technique that combines search-based and semantics-based approaches to enhance the repair capability, while ensuring the soundness of generated repairs. We also leveraged machine-learning techniques to build a predictive model that predicts whether an APR technique is effective in fixing particular bugs. In the future, we plan to synergize many existing APR techniques, improve our predictive model, and adopt the advances of other fields such as test case generation and program synthesis for APR.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582831","Automatic Program Repair;Deductive Reasoning;Mining Software Repository;Genetic Programming","Maintenance engineering;Computer bugs;History;Software;Semantics;Syntactics;Search problems","inference mechanisms;learning (artificial intelligence);program debugging;semantic networks;software maintenance","automatic program repair;software engineering;software debugging;software maintenance;search-based APR method;semantics-based APR method;semantic constraint extraction;symbolic execution;deductive reasoning;machine learning;bug fixing","","","29","","","","","IEEE","IEEE Conferences"
"How good are the specs? A study of the bug-finding effectiveness of existing Java API specifications","O. Legunsen; W. U. Hassan; X. Xu; G. Roşu; D. Marinov","Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","602","613","Runtime verification can be used to find bugs early, during software development, by monitoring test executions against formal specifications (specs). The quality of runtime verification depends on the quality of the specs. While previous research has produced many specs for the Java API, manually or through automatic mining, there has been no large-scale study of their bug-finding effectiveness. We present the first in-depth study of the bug-finding effectiveness of previously proposed specs. We used JavaMOP to monitor 182 manually written and 17 automatically mined specs against more than 18K manually written and 2.1M automatically generated tests in 200 open-source projects. The average runtime overhead was under 4.3x. We inspected 652 violations of manually written specs and (randomly sampled) 200 violations of automatically mined specs. We reported 95 bugs, out of which developers already fixed 74. However, most violations, 82.81% of 652 and 97.89% of 200, were false alarms. Our empirical results show that (1) runtime verification technology has matured enough to incur tolerable runtime overhead during testing, and (2) the existing API specifications can find many bugs that developers are willing to fix; however, (3) the false alarm rates are worrisome and suggest that substantial effort needs to be spent on engineering better specs and properly evaluating their effectiveness.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582795","runtime verification;specification quality;empirical study","Runtime;Computer bugs;Monitoring;Synchronization;Open source software;Java;Testing","application program interfaces;program debugging;program testing;program verification;public domain software","Java API specifications;software development;test executions monitoring;formal specifications;runtime verification;bug-finding effectiveness;Java-MOP;manually written specs;open-source projects;runtime overhead;automatically mined specs;tolerable runtime overhead;false alarm rates","","","63","","","","","IEEE","IEEE Conferences"
"Multi-objective test report prioritization using image understanding","Y. Feng; J. A. Jones; Z. Chen; C. Fang","Department of Informatics, University of California, Irvine, USA; Department of Informatics, University of California, Irvine, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","202","213","In crowdsourced software testing, inspecting the large number of test reports is an overwhelming but inevitable software maintenance task. In recent years, to alleviate this task, many text-based test-report classification and prioritization techniques have been proposed. However in the mobile testing domain, test reports often consist of more screenshots and shorter descriptive text, and thus text-based techniques may be ineffective or inapplicable. The shortage and ambiguity of natural-language text information and the well defined screenshots of activity views within mobile applications motivate our novel technique based on using image understanding for multi-objective test-report prioritization. In this paper, by taking the similarity of screenshots into consideration, we present a multi-objective optimization-based prioritization technique to assist inspections of crowdsourced test reports. In our technique, we employ the Spatial Pyramid Matching (SPM) technique to measure the similarity of the screenshots, and apply the natural-language processing technique to measure the distance between the text of test reports. Furthermore, to validate our technique, an experiment with more than 600 test reports and 2500 images is conducted. The experimental results show that image-understanding techniques can provide benefit to test-report prioritization for most applications.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582758","Crowdsourced Testing;Test Report Prioritization;Image Understanding;Multi-Objective Optimization","Testing;Mobile communication;Computer bugs;Software;Mobile applications;Image color analysis;Inspection","image classification;image matching;mobile computing;natural language processing;program testing;text analysis","multiobjective test report prioritization;image understanding;crowdsourced software testing;software maintenance task;text-based test-report classification;mobile testing domain;screenshots;descriptive text;natural-language text information;mobile applications;spatial pyramid matching;SPM","","","41","","","","","IEEE","IEEE Conferences"
"Automated model-based Android GUI testing using multi-level GUI comparison criteria","Y. Baek; D. Bae","Korea Advanced Institute of Science and Technology (KAIST) Daeieon. Republic of Korea; Korea Advanced Institute of Science and Technology (KAIST) Daeieon. Republic of Korea","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","238","249","Automated Graphical User Interface (GUI) testing is one of the most widely used techniques to detect faults in mobile applications (apps) and to test functionality and usability. GUI testing exercises behaviors of an application under test (AUT) by executing events on GUIs and checking whether the app behaves correctly. In particular, because Android leads in market share of mobile OS platforms, a lot of research on automated Android GUI testing techniques has been performed. Among various techniques, we focus on model-based Android GUI testing that utilizes a GUI model for systematic test generation and effective debugging support. Since test inputs are generated based on the underlying model, accurate GUI modeling of an AUT is the most crucial factor in order to generate effective test inputs. However, most modern Android apps contain a number of dynamically constructed GUIs that make accurate behavior modeling more challenging. To address this problem, we propose a set of multi-level GUI Comparison Criteria (GUICC) that provides the selection of multiple abstraction levels for GUI model generation. By using multilevel GUICC, we conducted empirical experiments to identify the influence of GUICC on testing effectiveness. Results show that our approach, which performs model-based testing with multi-level GUICC, achieved higher effectiveness than activity-based GUI model generation. We also found that multi-level GUICC can alleviate the inherent state explosion problems of existing a single-level GUICC for behavior modeling of real-world Android apps by flexibly manipulating GUICC.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582762","GUI testing;Android application testing;GUI model generation;GUI comparison criteria;Model-based test input generation","Graphical user interfaces;Testing;Androids;Humanoid robots;Space exploration;Analytical models;Mobile communication","Android (operating system);fault diagnosis;graphical user interfaces;mobile computing;program debugging;program testing","automated model-based Android GUI testing;multilevel GUI comparison criteria;multilevel GUICC;automated graphical user interface testing;fault detection;mobile applications;functionality testing;usability testing;application under test;mobile OS platforms;systematic test generation;debugging support;AUT GUI modeling;GUI model generation;single-level GUICC;Android apps behavior modeling","","2","27","","","","","IEEE","IEEE Conferences"
"An automated collaborative requirements engineering tool for better validation of requirements","N. A. Moketar; M. Kamalrudin; S. Sidek; M. Robinson; J. Grundy","Innovative Software System and Services Group, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia; Innovative Software System and Services Group, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia; Innovative Software System and Services Group, Universiti Teknikal Malaysia Melaka, Melaka, Malaysia; Fulgent Corporation, USA; Faculty of Science Engineering and Built Environment, School of Information Technology, Melbourne Burwood Campus, Deakin University, Victoria 3125, Australia","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","864","869","This demo introduces an automated collaborative requirements engineering tool, called TestMEReq, which is used to promote effective communication and collaboration between client-stakeholders and requirements engineers for better requirements validation. Our tool is augmented with real time communication and collaboration support to allow multiple stakeholders to collaboratively validate the same set of requirements. We have conducted a user study focusing on validating requirements using TestMEReq with a few groups of requirements engineers and client stakeholders. The study shows that our automated tool support is able to assist requirements engineers to effectively communicate with client-stakeholders to better validate the requirements virtually in real time. (Demo video: https://www.youtube.com/watch?v=7sWLOx-N4Jo).","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582829","Abstract test;Essential Use Cases;Essential User Interface;requirement-based testing;requirements validation;communication and collaboration","Collaboration;Stakeholders;Software;Testing;User interfaces;Libraries;Prototypes","formal specification;formal verification;groupware;program testing","automated collaborative requirement engineering tool;requirements validation;TestMEReq","","","12","","","","","IEEE","IEEE Conferences"
"Towards automatically generating descriptive names for unit tests","B. Zhang; E. Hill; J. Clause","University of Delaware, Newark, DE, USA; Drew University, Madison, NJ, USA; University of Delaware, Newark, DE, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","625","636","During maintenance, developers often need to understand the purpose of a test. One of the most potentially useful sources of information for understanding a test is its name. Ideally, test names are descriptive in that they accurately summarize both the scenario and the expected outcome of the test. Despite the benefits of being descriptive, test names often fall short of this goal. In this paper we present a new approach for automatically generating descriptive names for existing test bodies. Using a combination of natural-language program analysis and text generation, the technique creates names that summarize the test's scenario and the expected outcome. The results of our evaluation show that, (1) compared to alternative approaches, the names generated by our technique are significantly more similar to human-generated names and are nearly always preferred by developers, (2) the names generated by our technique are preferred over or are equivalent to the original test names in 83% of cases, and (3) our technique is several orders of magnitude faster than manually writing test names.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582797","Unit testing;Descriptive names;Maintenance","Testing;Maintenance engineering;Software maintenance;Natural languages;Semantics;Prototypes","natural language processing;program testing;software maintenance","descriptive name;unit testing;software maintenance;test name;natural-language program analysis;text generation","","","34","","","","","IEEE","IEEE Conferences"
"Automatic test image generation using procedural noise","M. Patrick; M. D. Castle; R. O. J. H. Stutt; C. A. Gilligan","Department of Plant Sciences, University of Cambridge, United Kingdom; Department of Plant Sciences, University of Cambridge, United Kingdom; Department of Plant Sciences, University of Cambridge, United Kingdom; Department of Plant Sciences, University of Cambridge, United Kingdom","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","654","659","It is difficult to test programs that input images, due to the large number of (pixel) values that must be chosen and the complex ways these values interact. Typically, such programs are tested manually, using images that have known results. However, this is a laborious process and limited in the range of tests that can be applied. We introduce a new approach for testing programs that input images automatically, using procedural noise and spatial statistics to create inputs that are both realistic and can easily be tuned to have specific properties. The effectiveness of our approach is illustrated on an epidemiological simulation of a recently introduced tree pest in Great Britain: Oriental Chestnut Gall Wasp. Our approach produces images that match the real landscapes more closely than other techniques and can be used (alongside metamorphic relations) to detect smaller (artificially introduced) errors with greater accuracy.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582800","software testing;image processing;test data generation","Software;Testing;Genetic algorithms;White noise;Histograms;Imaging;Image generation","image denoising;image matching;program testing","automatic test image generation;procedural noise;image pixels;program testing;spatial statistics;epidemiological simulation;tree pest;Great Britain;Oriental chestnut gall wasp;image matching;real landscapes","","","18","","","","","IEEE","IEEE Conferences"
"Locus: Locating bugs from software changes","M. Wen; R. Wu; S. Cheung","Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","262","273","Various information retrieval (IR) based techniques have been proposed recently to locate bugs automatically at the file level. However, their usefulness is often compromised by the coarse granularity of files and the lack of contextual information. To address this, we propose to locate bugs using software changes, which offer finer granularity than files and provide important contextual clues for bug-fixing. We observe that bug inducing changes can facilitate the bug fixing process. For example, it helps triage the bug fixing task to the developers who committed the bug inducing changes or enables developers to fix bugs by reverting these changes. Our study further identifies that change logs and the naturally small granularity of changes can help boost the performance of IR-based bug localization. Motivated by these observations, we propose an IR-based approach Locus to locate bugs from software changes, and evaluate it on six large open source projects. The results show that Locus outperforms existing techniques at the source file level localization significantly. MAP and MRR in particular have been improved, on average, by 20.1% and 20.5%, respectively. Locus is also capable of locating the inducing changes within top 5 for 41.0% of the bugs. The results show that Locus can significantly reduce the number of lines needing to be scanned to locate the bug compared with existing techniques.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582764","bug localization;software changes;information retrieval;software analytics","Computer bugs;Software;Debugging;History;Information retrieval;Natural languages;Manuals","information retrieval;program debugging","Locus;software changes;information retrieval;bug-fixing;bug inducing changes;IR-based bug localization;source file level localization;MAP;MRR","","","46","","","","","IEEE","IEEE Conferences"
"Generating test cases to expose concurrency bugs in android applications","H. Tang; G. Wu; J. Wei; H. Zhong","State key Laboratory of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China; State key Laboratory of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China; State key Laboratory of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China; State key Laboratory of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","648","653","Mobile systems usually support an event-based model of concurrent programming. This model, although advantageous to maintain responsive user interfaces, may lead to subtle concurrency errors due to unforeseen threads interleaving coupled with non-deterministic reordering of asynchronous events. These bugs are very difficult to reproduce even by the same user action sequences that trigger them, due to the undetermined schedules of underlying events and threads. In this paper, we proposed RacerDroid, a novel technique that aims to expose concurrency bugs in android applications by actively controlling event schedule and thread interleaving, given the test cases that have potential data races. By exploring the state model of the application constructed dynamically, our technique starts first to generate a test case that has potential data races based on the results obtained from existing static or dynamic race detection technique. Then it reschedules test cases execution by actively controlling event dispatching and thread interleaving to determine whether such potential races really lead to thrown exceptions or assertion violations. Our preliminary experiments show that RacerDroid is effective, and it confirms real data races, while at the same time eliminates false warnings for Android apps found in the wild.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582799","record/replay;data race;mobile application;Android;testing","Message systems;Androids;Humanoid robots;Concurrent computing;Computer bugs;Instruments;Data models","Android (operating system);concurrency control;mobile computing;program debugging;program testing;smart phones;user interfaces","test case generation;concurrency bug;Android application;mobile system;event-based model;concurrent programming;user interface;RacerDroid technique;smart phone","","","28","","","","","IEEE","IEEE Conferences"
"Migrating cascading style sheets to preprocessors by introducing mixins","D. Mazinanian; N. Tsantalis","Computer Science and Software Engineering, Concordia University, Montreal, Canada; Computer Science and Software Engineering, Concordia University, Montreal, Canada","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","672","683","Cascading Style Sheets (CSS) is the standard language for styling web documents and is extensively used in the industry. However, CSS lacks constructs that would allow code reuse (e.g., functions). Consequently, maintaining CSS code is often a cumbersome and error-prone task. Preprocessors (e.g., Less and Sass) have been introduced to fill this gap, by extending CSS with the missing constructs. Despite the clear maintainability benefits coming from the use of preprocessors, there is currently no support for migrating legacy CSS code to preprocessors. In this paper, we propose a technique for automatically detecting duplicated style declarations in CSS code that can be migrated to preprocessor functions (i.e., mixins). Our technique can parameterize differences in the style values of duplicated declarations, and ensure that the migration will not change the presentation semantics of the web documents. The evaluation has shown that our technique is able to detect 98% of the mix-ins that professional developers introduced in websites and Style Sheet libraries, and can safely migrate real CSS code.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582802","Cascading style sheets;refactoring;duplication;migration","Cascading style sheets;Syntactics;HTML;Browsers;Software;Semantics;Libraries","document handling;hypermedia markup languages;Internet;programming languages;software maintenance;software reusability","cascading style sheet;CSS;mixin;preprocessor function;Web document styling;code reuse;code maintenance;hypermedia markup language;HTML","","","44","","","","","IEEE","IEEE Conferences"
"Recommending relevant classes for bug reports using multi-objective search","R. Almhana; W. Mkaouer; M. Kessentini; A. Ouni","Computer and Information Science Department, University of Michigan, Dearborn, MI, USA; Computer and Information Science Department, University of Michigan, Dearborn, MI, USA; Computer and Information Science Department, University of Michigan, Dearborn, MI, USA; Graduate School of Information Science and Technology, Osaka University, Osaka, Japan","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","286","295","Developers may follow a tedious process to find the cause of a bug based on code reviews and reproducing the abnormal behavior. In this paper, we propose an automated approach to finding and ranking potential classes with the respect to the probability of containing a bug based on a bug report description. Our approach finds a good balance between minimizing the number of recommended classes and maximizing the relevance of the proposed solution using a multi-objective optimization algorithm. The relevance of the recommended classes (solution) is estimated based on the use of the history of changes and bug-fixing, and the lexical similarity between the bug report description and the API documentation. We evaluated our system on 6 open source Java projects, using the version of the project before fixing the bug of many bug reports. The experimental results show that the search-based approach significantly outperforms three state-of-the-art methods in recommending relevant files for bug reports. In particular, our multi-objective approach is able to successfully locate the true buggy methods within the top 10 recommendations for over 87% of the bug reports.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582766","Search-based software engineering;bug reports;multi-objective optimization;software maintenance","Computer bugs;Search problems;Software engineering;Optimization;Software;History;Documentation","application program interfaces;estimation theory;Java;optimisation;probability;program debugging;public domain software;search problems;software maintenance","class recommendation;bug report description;multiobjective search;probability;multiobjective optimization algorithm;relevance estimation;API documentation;open source Java project;software maintenance","","","28","","","","","IEEE","IEEE Conferences"
"What developers want and need from program analysis: An empirical study","M. Christakis; C. Bird","Microsoft Research, Redmond, USA; Microsoft Research, Redmond, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","332","343","Program Analysis has been a rich and fruitful field of research for many decades, and countless high quality program analysis tools have been produced by academia. Though there are some well-known examples of tools that have found their way into routine use by practitioners, a common challenge faced by researchers is knowing how to achieve broad and lasting adoption of their tools. In an effort to understand what makes a program analyzer most attractive to developers, we mounted a multi-method investigation at Microsoft. Through interviews and surveys of developers as well as analysis of defect data, we provide insight and answers to four high level research questions that can help researchers design program analyzers meeting the needs of software developers. First, we explore what barriers hinder the adoption of program analyzers, like poorly expressed warning messages. Second, we shed light on what functionality developers want from analyzers, including the types of code issues that developers care about. Next, we answer what non-functional characteristics an analyzer should have to be widely used, how the analyzer should fit into the development process, and how its results should be reported. Finally, we investigate defects in one of Microsoft's flagship software services, to understand what types of code issues are most important to minimize, potentially through program analysis.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582770","program analysis;code defects","Software;Security;Interviews;Companies;Ecosystems;Software engineering;Pain","program diagnostics;software engineering","high quality program analysis tools;multimethod investigation;functionality developers;software developers;code issues;Microsoft software services;software defect analysis","","","52","","","","","IEEE","IEEE Conferences"
"Mining revision histories to detect cross-language clones without intermediates","X. Cheng; Z. Peng; L. Jiang; H. Zhong; H. Yu; J. Zhao","Department of Computer Science and Engineering, ShanghaiJiao Tong University, China; School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore; Department of Computer Science and Engineering, ShanghaiJiao Tong University, China; School of Software, ShanghaiJiao Tong University, China; Department of Advanced Information Technology, Kyushu University, Japan","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","696","701","To attract more users on different platforms, many projects release their versions in multiple programming languages (e.g., Java and C#). They typically have many code snippets that implement similar functionalities, i.e., cross-language clones. Programmers often need to track and modify cross-language clones consistently to maintain similar functionalities across different language implementations. In literature, researchers have proposed approaches to detect cross-language clones, mostly for languages that share a common intermediate language (such as the .NET language family) so that techniques for detecting single-language clones can be applied. As a result, those approaches cannot detect cross-language clones for many projects that are not implemented in a .NET language. To overcome the limitation, in this paper, we propose a novel approach, CLCMiner, that detects cross-language clones automatically without the need of an intermediate language. Our approach mines such clones from revision histories, which reflect how programmers maintain cross-language clones in practice. We have implemented a prototype tool for our approach and conducted an evaluation on five open source projects that have versions in Java and C#. The results show that CLCMiner achieves high accuracy and point to promising future work.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582804","cross-language clone;diff;revision history","Cloning;Java;C# languages;History;Grammar;Software","data mining;programming languages;software maintenance","revision histories mining;cross-language clones detection;intermediate language;.NET language family;single-language clones detection;CLCMiner;open source projects;Java language;C# language","","1","21","","","","","IEEE","IEEE Conferences"
"StraightTaint: Decoupled offline symbolic taint analysis","J. Ming; D. Wu; J. Wang; G. Xiao; P. Liu","College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA 16802, USA; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA 16802, USA; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA 16802, USA; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA 16802, USA; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA 16802, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","308","319","Taint analysis has been widely applied in ex post facto security applications, such as attack provenance investigation, computer forensic analysis, and reverse engineering. Unfortunately, the high runtime overhead imposed by dynamic taint analysis makes it impractical in many scenarios. The key obstacle is the strict coupling of program execution and taint tracking logic code. To alleviate this performance bottleneck, recent work seeks to offload taint analysis from program execution and run it on a spare core or a different CPU. However, since the taint analysis has heavy data and control dependencies on the program execution, the massive data in recording and transformation overshadow the benefit of decoupling. In this paper, we propose a novel technique to allow very lightweight logging, resulting in much lower execution slowdown, while still permitting us to perform full-featured offline taint analysis. We develop StraightTaint, a hybrid taint analysis tool that completely decouples the program execution and taint analysis. StraightTaint relies on very lightweight logging of the execution information to reconstruct a straight-line code, enabling an offline symbolic taint analysis without frequent data communication with the application. While StraightTaint does not log complete runtime or input values, it is able to precisely identify the causal relationships between sources and sinks, for example. Compared with traditional dynamic taint analysis tools, StraightTaint has much lower application runtime overhead.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582768","Taint analysis;Decoupling;Offline;Symbolic taint analysis","Runtime;Security;Performance analysis;Reverse engineering;Registers;Malware","program diagnostics;security of data","StraightTaint;decoupled offline symbolic taint analysis;ex post facto security applications;attack provenance investigation;computer forensic analysis;reverse engineering;program execution strict coupling;taint tracking logic code;lightweight logging;full-featured offline taint analysis;hybrid taint analysis tool;straight-line code reconstruction","","","54","","","","","IEEE","IEEE Conferences"
"Radius aware probabilistic testing of deadlocks with guarantees","Y. Cait; Z. Yang","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","356","367","Concurrency bugs only occur under certain interleaving. Existing randomized techniques are usually ineffective. PCT innovatively generates scheduling, before executing a program, based on priorities and priority change points. Hence, it provides a probabilistic guarantee to trigger concurrency bugs. PCT randomly selects priority change points among all events, which might be effective for non-deadlock concurrency bugs. However, deadlocks usually involve two or more threads and locks, and require more ordering constraints to be triggered. We interestingly observe that, every two events of a deadlock usually occur within a short range. We generally formulate this range as the bug Radius, to denote the max distance of every two events of a concurrency bug. Based on the bug radius, we propose RPro (Radius aware Probabilistic testing) for triggering deadlocks. Unlike PCT, RPro selects priority change points within the radius of the targeted deadlocks but not among all events. Hence, it guarantees larger probabilities to trigger deadlocks. We have implemented RPro and PCT and evaluated them on a set of real-world benchmarks containing 10 unique deadlocks. The experimental results show that RPro triggered all deadlocks with higher probabilities (i.e., >7.7x times larger on average) than that by PCT. We also evaluated RPro with radius varying from 1 to 150 (or 300). The result shows that the radius of a deadlock is much smaller (i.e., from 2 to 114 in our experiment) than the number of all events. This further confirms our observation and makes RPro meaningful in practice.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582772","Deadlock;random testing;bug radius;multithreaded program","Computer bugs;System recovery;Concurrent computing;Probabilistic logic;Instruction sets;Benchmark testing","concurrency control;probability;program debugging;program testing;system recovery","radius aware probabilistic testing;RPro;deadlock triggering;concurrency bug;probabilistic guarantee","","","66","","","","","IEEE","IEEE Conferences"
"Bugram: Bug detection with n-gram language models","S. Wang; D. Chollak; D. Movshovitz-Attias; L. Tan","Electrical and Computer Engineering, University of Waterloo, Canada; Electrical and Computer Engineering, University of Waterloo, Canada; Computer Science Department, Carnegie Mellon University, USA; Electrical and Computer Engineering, University of Waterloo, Canada","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","708","719","To improve software reliability, many rule-based techniques have been proposed to infer programming rules and detect violations of these rules as bugs. These rule-based approaches often rely on the highly frequent appearances of certain patterns in a project to infer rules. It is known that if a pattern does not appear frequently enough, rules are not learned, thus missing many bugs. In this paper, we propose a new approach - Bugram - that leverages n-gram language models instead of rules to detect bugs. Bugram models program tokens sequentially, using the n-gram language model. Token sequences from the program are then assessed according to their probability in the learned model, and low probability sequences are marked as potential bugs. The assumption is that low probability token sequences in a program are unusual, which may indicate bugs, bad practices, or unusual/special uses of code of which developers may want to be aware. We evaluate Bugram in two ways. First, we apply Bugram on the latest versions of 16 open source Java projects. Results show that Bugram detects 59 bugs, 42 of which are manually verified as correct, 25 of which are true bugs and 17 are code snippets that should be refactored. Among the 25 true bugs, 23 cannot be detected by PR-Miner. We have reported these bugs to developers, 7 of which have already been confirmed by developers (4 of them have already been fixed), while the rest await confirmation. Second, we further compare Bugram with three additional graph- and rule-based bug detection tools, i.e., JADET, Tikanga, and GrouMiner. We apply Bugram on 14 Java projects evaluated in these three studies. Bugram detects 21 true bugs, at least 10 of which cannot be detected by these three tools. Our results suggest that Bugram is complementary to existing rule-based bug detection approaches.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582806","Bug Detection;Static Code Analysis;N-gram Language Model","Computer bugs;Software;Programming;Java;Buildings;Semantics;Software reliability","inference mechanisms;Java;knowledge based systems;natural language processing;probability;program debugging;public domain software;software reliability","Bugram;bug detection;n-gram language model;software reliability;rule-based technique;programming rule inference;probability sequence;open source Java project","","","57","","","","","IEEE","IEEE Conferences"
"Learning a dual-language vector space for domain-specific cross-lingual question retrieval","G. Chen; C. Chen; Z. Xing; B. Xu","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; College of Computer Science and Technology, Zhejiang University, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","744","755","The lingual barrier limits the ability of millions of non-English speaking developers to make effective use of the tremendous knowledge in Stack Overflow, which is archived in English. For cross-lingual question retrieval, one may use translation-based methods that first translate the non-English queries into English and then perform monolingual question retrieval in English. However, translation-based methods suffer from semantic deviation due to inappropriate translation, especially for domain-specific terms, and lexical gap between queries and questions that share few words in common. To overcome the above issues, we propose a novel cross-lingual question retrieval based on word embed-dings and convolutional neural network (CNN) which are the state-of-the-art deep learning techniques to capture word- and sentence-level semantics. The CNN model is trained with large amounts of examples from Stack Overflow duplicate questions and their corresponding translation by machine, which guides the CNN to learn to capture informative word and sentence features to recognize and quantify semantic similarity in the presence of semantic deviations and lexical gaps. A uniqueness of our approach is that the trained CNN can map documents in two languages (e.g., Chinese queries and English questions) in a dual-language vector space, and thus reduce the cross-lingual question retrieval problem to a simple k-nearest neighbors search problem in the dual-language vector space, where no query or question translation is required. Our evaluation shows that our approach significantly outperforms the translation-based method, and can be extended to dual-language documents retrieval from different sources.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582810","Cross-lingual question retrieval;Word embeddings;Convolutional Neural Network;Dual-Language Vector Space","Semantics;Neural networks;Context;Google;Inspection;Predictive models;Convolution","language translation;learning (artificial intelligence);natural language processing;neural nets;query processing;question answering (information retrieval);search problems;text analysis","dual-language vector space;domain-specific cross-lingual question retrieval;lingual barrier;nonEnglish speaking developers;Stack Overflow;translation-based method;monolingual question retrieval;semantic deviation;domain-specific terms;lexical gap;word embeddings;convolutional neural network;deep learning technique;word-level semantics capture;sentence-level semantics capture;CNN model training;machine translation;semantic similarity;document mapping;Chinese queries;English questions;k-nearest neighbor search problem;dual-language document retrieval","","","47","","","","","IEEE","IEEE Conferences"
"Sound static deadlock analysis for C/Pthreads","D. Kroening; D. Poetzl; P. Schrammel; B. Wachter","University of Oxford, Oxford, UK; University of Oxford, Oxford, UK; University of Sussex, Brighton, UK; SSW-Trading GmbH, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","379","390","We present a static deadlock analysis for C/Pthreads. The design of our method has been guided by the requirement to analyse real-world code. Our approach is sound (i.e., misses no deadlocks) for programs that have defined behaviour according to the C standard and the Pthreads specification, and is precise enough to prove deadlock-freedom for a large number of such programs. The method consists of a pipeline of several analyses that build on a new context- and thread-sensitive abstract interpretation framework. We further present a lightweight dependency analysis to identify statements relevant to deadlock analysis and thus speed up the overall analysis. In our experimental evaluation, we succeeded to prove deadlock-freedom for 292 programs from the Debian GNU/Linux distribution with in total 2.3 MLOC in 4 hours.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582774","deadlock analysis;static analysis;abstract interpretation","System recovery;Instruction sets;Pipelines;Computer bugs;Standards;Concurrent computing;Scalability","C language;formal specification;Linux;program diagnostics","sound static deadlock analysis;C/Pthreads;real-world code analysis;C standard;Pthreads specification;deadlock-freedom;context-sensitive abstract interpretation framework;thread-sensitive abstract interpretation framework;lightweight dependency analysis;Debian GNU/Linux distribution;time 4 hour","","","45","","","","","IEEE","IEEE Conferences"
"Evaluating non-adequate test-case reduction","M. A. Alipour; A. Shi; R. Gopinath; D. Marinov; A. Groce","School of Electrical Engineering and Computer Science, Oregon State University, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA; School of Electrical Engineering and Computer Science, Oregon State University, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, USA; School of Electrical Engineering and Computer Science, Oregon State University, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","16","26","Given two test cases, one larger and one smaller, the smaller test case is preferred for many purposes. A smaller test case usually runs faster, is easier to understand, and is more convenient for debugging. However, smaller test cases also tend to cover less code and detect fewer faults than larger test cases. Whereas traditional research focused on reducing test suites while preserving code coverage, recent work has introduced the idea of reducing individual test cases, rather than test suites, while still preserving code coverage. Other recent work has proposed non-adequately reducing test suites by not even preserving all the code coverage. This paper empirically evaluates a new combination of these two ideas, non-adequate reduction of test cases, which allows for a wide range of trade-offs between test case size and fault detection. Our study introduces and evaluates C%-coverage reduction (where a test case is reduced to retain at least C% of its original coverage) and N-mutant reduction (where a test case is reduced to kill at least N of the mutants it originally killed). We evaluate the reduction trade-offs with varying values of C% and N for four real-world C projects: Mozilla's SpiderMonkey JavaScript engine, the YAFFS2 flash file system, Grep, and Gzip. The results show that it is possible to greatly reduce the size of many test cases while still preserving much of their fault-detection capability.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582741","test reduction;test adequacy;coverage;mutation testing","Debugging;Size measurement;Computer science;Electrical engineering;Fault detection;Engines;Software","fault diagnosis;fault tolerant computing;program debugging;program testing","nonadequate test-case reduction;software debugging;code coverage;fault detection;test suite reduction;test case size;N-mutant reduction;Mozilla SpiderMonkey JavaScript engine;YAFFS2 flash file system;Grep;Gzip;software testing","","","27","","","","","IEEE","IEEE Conferences"
"Phrase-based extraction of user opinions in mobile app reviews","P. M. Vu; H. V. Pham; T. T. Nguyen; T. T. Nguyen","Computer Science Department, Utah State University; Computer Science Department, Utah State University; Computer Science Department, Utah State University; Computer Science Department, Utah State University","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","726","731","Mobile app reviews often contain useful user opinions like bug reports or suggestions. However, looking for those opinions manually in thousands of reviews is ineffective and time-consuming. In this paper, we propose PUMA, an automated, phrase-based approach to extract user opinions in app reviews. Our approach includes a technique to extract phrases in reviews using part-of-speech (PoS) templates; a technique to cluster phrases having similar meanings (each cluster is considered as a major user opinion); and a technique to monitor phrase clusters with negative sentiments for their outbreaks over time. We used PUMA to study two popular apps and found that it can reveal severe problems of those apps reported in their user reviews.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582808","Opinion Mining;Review Analysis;Phrase Extraction","Artificial neural networks;Mobile communication;Facebook;Games;Monitoring;Batteries;Computer bugs","feature extraction;mobile computing;pattern clustering;sentiment analysis;software reviews","phrase-based extraction;user opinion;mobile app review;PUMA;part-of-speech template;PoS template;phrase clustering","","","19","","","","","IEEE","IEEE Conferences"
"Relda2: An effective static analysis tool for resource leak detection in Android apps","T. Wu; J. Liu; X. Deng; J. Yan; J. Zhang","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","762","767","Resource leak is a common bug in Android applications (apps for short). In general, it is caused by missing release operations of the resources provided by Android (like Camera, Media Player and Sensors) that require programmers to explicitly release them. It might lead to several serious problems for the app and system, such as performance degradation and system crash. This paper presents Relda2, a light-weight, scalable and practical static analysis tool, for detecting resource leaks in the byte-code of Android apps automatically. It supports two analysis techniques (flow-insensitive for quick scanning and flow-sensitive for accurate scanning), and performs inter-procedural analysis to get more precise bug reports. In addition, our tool is practical to analyze real-world apps, and has been applied to 103 Android apps, including industry applications and open source programs. We have found 67 real resource leaks in these apps, which we confirmed manually. A demo video of our tool can be found at the website: https://www.youtube.com/watch?v=Mk-MFcHpTds.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582812","Android apps;resource leak;static analysis;byte-code","Androids;Humanoid robots;Computer bugs;Smart phones;Software;Leak detection","Android (operating system);program diagnostics","Relda2;static analysis tool;resource leak detection;Android apps;light-weight static analysis;scalable static analysis;interprocedural analysis;open source program;byte-code","","","14","","","","","IEEE","IEEE Conferences"
"An empirical evaluation of two user interfaces of an interactive program verifier","M. Hentschel; R. Hähnle; R. Bubel","TU Darmstadt, Dept. of Computer Science, Darmstadt, Germany; TU Darmstadt, Dept. of Computer Science, Darmstadt, Germany; TU Darmstadt, Dept. of Computer Science, Darmstadt, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","403","413","Theorem provers have highly complex interfaces, but there are not many systematic studies of their usability and effectiveness. Specifically, for interactive theorem provers the ability to quickly comprehend intermediate proof situations is of pivotal importance. In this paper we present the (as far as we know) first empirical study that systematically compares the effectiveness of different user interfaces of an interactive theorem prover. We juxtapose two different user interfaces of the interactive verifier KeY: the traditional one which focuses on proof objects and a more recent one that provides a view akin to an interactive debugger. We carefully designed a controlled experiment where users were given various proof understanding tasks that had to be solved with alternating interfaces. We provide statistical evidence that the conjectured higher effectivity of the debugger-like interface is not just a hunch.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582776","Verification;Proof Understanding;Empirical Evaluation","User interfaces;Usability;Inspection;Standards;Java","interactive systems;program debugging;program verification;theorem proving;user interfaces","empirical evaluation;user interface;interactive program verifier;theorem prover;proof object;interactive debugger","","","14","","","","","IEEE","IEEE Conferences"
"The IDE as a scriptable information system","D. Asenov; P. Müller; L. Vogel","Dept. of Computer Science, ETH Zurich, Switzerland; Dept. of Computer Science, ETH Zurich, Switzerland; Ergon Informatik AG, Zurich, Switzerland","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","444","449","Software engineering is extremely information-intensive. Every day developers work with source code, version repositories, issue trackers, documentation, web-based and other information resources. However, three key aspects of information work lack good support: (i) combining information from different sources; (ii) flexibly presenting collected information to enable easier comprehension; and (iii) automatically acting on collected information, for example to perform a refactoring. Poor support for these activities makes many common development tasks time-consuming and error-prone. We propose an approach that directly addresses these three issues by integrating a flexible query mechanism into the development environment. Our approach enables diverse ways to process and visualize information and can be extended via scripts. We demonstrate how an implementation of the approach can be used to rapidly write queries that meet a wide range of information needs.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582780","code queries;software visualization;refactoring","Visualization;Heating;Data visualization;Information services;Software;Engines;Computer bugs","data visualisation;information needs;programming environments;query processing;software maintenance;source code (software)","IDE;scriptable information system;software engineering;source code;version repositories;issue trackers;documentation;Web-based system;information resources;refactoring;query mechanism;development environment;information processing;information visualization;information needs","","","19","","","","","IEEE","IEEE Conferences"
"What makes killing a mutant hard","W. Visser","Department of Computer Science, Stellenbosch University, South Africa","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","39","44","Mutation operators have been studied at length to determine which ones are the “best” at some metric (for example creates the least equivalent mutants, creates hard-to-kill mutants, etc.). These studies though have focused on specific test suites, where the test inputs and oracles are fixed, which leads to results that are strongly influenced by the test suites and thus makes the conclusions potentially less general. In this paper we consider all test inputs and we assume we have no prior knowledge about the likelihood of any specific inputs. We will also show how varying the strength of the oracle have a big impact on the results. We only consider a few mutation operators (mostly relational), only a handful of programs to mutate (amenable to probabilistic symbolic execution), and only consider how likely it is that a mutant is killed. A core finding is that the likelihood of reaching the source line where the mutation is applied, is an important contributor to the likelihood of killing the mutant and when we control for this we can see which operators create mutations that are too easy versus very hard to kill.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582743","Mutation Testing;Probabilistic Symbolic Execution","Java;Testing;Radiation detectors;Probabilistic logic;Measurement;Software","probability;program testing;source code (software)","mutation operator;test suite;test input;probabilistic symbolic execution;source line","","","16","","","","","IEEE","IEEE Conferences"
"Model driven design of heterogeneous synchronous embedded systems","H. Zhang; Y. Jiang; H. Liu; H. Zhang; M. Gu; J. Sun","School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; Department of Computer Science, University of Illinois at Urbana-Champaign, Illinois, USA; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China; School of Software, Tsinghua University, TNLIST, KLISS, Beijing, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","774","779","Synchronous embedded systems are becoming more and more complicated and are usually implemented with integrated hardware/software solutions. This implementation manner brings new challenges to the traditional model-driven design environments such as SCADE and STATEMATE, that supports pure hardware or software design. In this paper, we propose a co-design tool Tsmart-Edola to facilitate the system developers, and automatically generate the executable VHDL code and C code from the formal verified SyncBlock computation model. SyncBlock is a lightweight high-level system specification model with well defined syntax, simulation and formal semantics. Based on which, the graphical model editor, graphical simulator, verification translator, and code generator are implemented and seamlessly integrated into the Tsmart-Edola. For evaluation, we apply Tsmart-Edola to the design of a real-world train controller based on the international standard IEC 61375. Several critical ambiguousness or bugs in the standard are detected during formal verification of the constructed system model. Furthermore, the generated VHDL code and C code of Tsmart-Edola outperform that of the state-of-the-art tools in terms of synthesized gate array resource consumption and binary code size. The abstract demo video address is : https://youtu.be/D9ROyJmKZ4s The tool, user manual and examples can be downloaded: http://sts.thss.tsinghua.edu.cn/Tsmart-Edola/.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582814","model driven development;computation model;hardwaresoftware co-design","Computational modeling;Hardware;Ports (Computers);Software;Generators;Graphical models;Semantics","embedded systems;formal specification;formal verification;hardware-software codesign","model driven design;heterogeneous synchronous embedded system;SCADE;STATEMATE;Tsmart-Edola;VHDL code;C code;SyncBlock computation model;lightweight high-level system specification;formal semantics;graphical model editor;graphical simulator;verification translator;code generator;real-world train controller;formal verification","","","19","","","","","IEEE","IEEE Conferences"
"Usage, costs, and benefits of continuous integration in open-source projects","M. Hilton; T. Tunnell; K. Huang; D. Marinov; D. Dig","Oregon State University, USA; University of Illinois, USA; University of Illinois, USA; University of Illinois, USA; Oregon State University, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","426","437","Continuous integration (CI) systems automate the compilation, building, and testing of software. Despite CI rising as a big success story in automated software engineering, it has received almost no attention from the research community. For example, how widely is CI used in practice, and what are some costs and benefits associated with CI? Without answering such questions, developers, tool builders, and researchers make decisions based on folklore instead of data. In this paper, we use three complementary methods to study the usage of CI in open-source projects. To understand which CI systems developers use, we analyzed 34,544 open-source projects from GitHub. To understand how developers use CI, we analyzed 1,529,291 builds from the most commonly used CI system. To understand why projects use or do not use CI, we surveyed 442 developers. With this data, we answered several key questions related to the usage, costs, and benefits of CI. Among our results, we show evidence that supports the claim that CI helps projects release more often, that CI is widely adopted by the most popular projects, as well as finding that the overall percentage of projects using CI continues to grow, making it important and timely to focus more research on CI.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582778","continuous integration;mining software repositories","Open source software;Automation;History;Tunneling;Buildings;Testing","costing;program compilers;program testing;public domain software;software engineering","open-source projects;continuous integration systems;CI systems;software compilation;software building;software testing;automated software engineering;GitHub;CI usage;CI costs;CI benefits","","2","56","","","","","IEEE","IEEE Conferences"
"Array length inference for C library bindings","A. J. Maas; H. Nazaré; B. Liblit","University of Wisconsin-Madison, Madison, WI, USA; Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; University of Wisconsin-Madison, Madison, WI, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","461","471","Simultaneous use of multiple programming languages (polyglot programming) assists in creating efficient, coherent, modern programs in the face of legacy code. However, manually creating bindings to low-level languages like C is tedious and error-prone. We offer relief in the form of an automated suite of analyses, designed to enhance the quality of automatically produced bindings. These analyses recover high-level array length information that is missing from C's type system. We emit annotations in the style of GObject-Introspection, which produces bindings from annotations on function signatures. We annotate each array argument as terminated by a special sentinel value, fixed-length, or of length determined by another argument. These properties help produce more idiomatic, efficient bindings. We correctly annotate at least 70% of all arrays with these length types, and our results are comparable to those produced by human annotators, but take far less time to produce.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582782","FFI;foreign function interfaces;bindings;libraries;static analysis;type inference","Libraries;High level languages;Data mining;Memory management;Production;Safety;Programming","","","","","24","","","","","IEEE","IEEE Conferences"
"Predicting semantically linkable knowledge in developer online forums via convolutional neural network","B. Xu; D. Ye; Z. Xing; X. Xia; G. Chen; S. Li","College of Computer Science and Technology, Zhejiang University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; College of Computer Science and Technology, Zhejiang University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; College of Computer Science and Technology, Zhejiang University, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","51","62","Consider a question and its answers in Stack Overflow as a knowledge unit. Knowledge units often contain semantically relevant knowledge, and thus linkable for different purposes, such as duplicate questions, directly linkable for problem solving, indirectly linkable for related information. Recognising different classes of linkable knowledge would support more targeted information needs when users search or explore the knowledge base. Existing methods focus on binary relatedness (i.e., related or not), and are not robust to recognize different classes of semantic relatedness when linkable knowledge units share few words in common (i.e., have lexical gap). In this paper, we formulate the problem of predicting semantically linkable knowledge units as a multiclass classification problem, and solve the problem using deep learning techniques. To overcome the lexical gap issue, we adopt neural language model (word embeddings) and convolutional neural network (CNN) to capture word- and document-level semantics of knowledge units. Instead of using human-engineered classifier features which are hard to design for informal user-generated content, we exploit large amounts of different types of user-created knowledge-unit links to train the CNN to learn the most informative wordlevel and document-level features for the multiclass classification task. Our evaluation shows that our deep-learning based approach significantly and consistently outperforms traditional methods using traditional word representations and human-engineered classifier features.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582745","Link prediction;Semantic relatedness;Multiclass classification;Deep learning;Mining software repositories","Semantics;Knowledge engineering;Software;Uniform resource locators;Complex networks;Machine learning;Social network services","data mining;learning (artificial intelligence);neural nets;pattern classification;social networking (online)","semantically linkable knowledge prediction;developer online forums;convolutional neural network;Stack Overflow;knowledge unit;information needs;binary relatedness;multiclass classification problem;deep learning techniques;neural language model;word embeddings;CNN;word-level semantics;document-level semantics;human-engineered classifier features;informal user-generated content;word representation","","","51","","","","","IEEE","IEEE Conferences"
"BovInspector: Automatic inspection and repair of buffer overflow vulnerabilities","F. Gao; L. Wang; X. Li","State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, 210023, China; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, 210023, China; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, 210023, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","786","791","Buffer overflow is one of the most common types of software vulnerabilities. Various static analysis and dynamic testing techniques have been proposed to detect buffer overflow vulnerabilities. With automatic tool support, static buffer overflow detection technique has been widely used in academia and industry. However, it tends to report too many false positives fundamentally due to the lack of software execution information. Currently, static warnings can only be validated by manual inspection, which significantly limits the practicality of the static analysis. In this paper, we present BovInspector, a tool framework for automatic static buffer overflow warnings inspection and validated bugs repair. Given the program source code and static buffer overflow vulnerability warnings, BovInspector first performs warning reachability analysis. Then, BovInspector executes the source code symbolically under the guidance of reachable warnings. Each reachable warning is validated and classified by checking whether all the path conditions and the buffer overflow constraints can be satisfied simultaneously. For each validated true warning, BovInspector fix it with three predefined strategies. BovInspector is complementary to prior static buffer overflow discovery schemes. Experimental results on real open source programs show that BovInspector can automatically inspect on average of 74.9% of total warnings, and false warnings account for about 25% to 100% (on average of 59.9%) of the total inspected warnings. In addition, the automatically generated patches fix all target vulnerabilities. Further information regarding the implementation and experimental results of BovInspector is available at http://bovinspectortool.github.io/project/. And a short video for demonstrating the capabilities of BovInspector is now available at https://youtu.be/IMdcksROJDg.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582816","Buffer Overflow;Symbolic Execution;Validation;Automatic Repair","Maintenance engineering;Software;Engines;Testing;Inspection;Reachability analysis;Explosions","inspection;program debugging;program diagnostics;program testing;public domain software;source code (software)","BovInspector;buffer overflow vulnerabilities repair;software vulnerabilities;static analysis;dynamic testing techniques;static buffer overflow detection technique;tool framework;automatic static buffer overflow warnings inspection;bugs repair;program source code;warning reachability analysis;path conditions;buffer overflow constraints;static buffer overflow discovery schemes;open source programs","","","21","","","","","IEEE","IEEE Conferences"
"Lightweight collection and storage of software repository data with DataRover","T. Kowark; C. Matthies; M. Uflacker; H. P. H. Plattner","Institute, University of Potsdam, August-Bebel-Str. 88 Potsdam, Germany; Institute, University of Potsdam, August-Bebel-Str. 88 Potsdam, Germany; Institute, University of Potsdam, August-Bebel-Str. 88 Potsdam, Germany; Institute, University of Potsdam, August-Bebel-Str. 88 Potsdam, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","810","815","The ease of setting up collaboration infrastructures for software engineering projects creates a challenge for researchers that aim to analyze the resulting data. As teams can choose from various available software-as-a-service solutions and can configure them with a few clicks, researchers have to create and maintain multiple implementations for collecting and aggregating the collaboration data in order to perform their analyses across different setups. The DataRover system presented in this paper simplifies this task by only requiring custom source code for API authentication and querying. Data transformation and linkage is performed based on mappings, which users can define based on sample responses through a graphical front end. This allows storing the same input data in formats and databases most suitable for the intended analysis without requiring additional coding. Furthermore, API responses are continuously monitored to detect changes and allow users to update their mappings and data collectors accordingly. A screencast of the described use cases is available at https: //youtu.be/mt4ztff4SfU.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582820","Data Collection;Data Mapping Definition;Link Discovery;API monitoring;Data Storage","Software;Databases;Data collection;Programming;Collaboration;Couplings;Monitoring","application program interfaces;database management systems;project management;query processing;software engineering;software management;source code (software);storage management","software repository data collection;software repository data storage;DataRover system;software engineering project;source code;API authentication;API querying;data transformation;data linkage;graphical front end","","","7","","","","","IEEE","IEEE Conferences"
"On essential configuration complexity: Measuring interactions in highly-configurable systems","J. Meinicke; C. Wong; C. Kästner; T. Thüm; G. Saake","University of Magdeburg, Germany; Carnegie Mellon University, USA; Carnegie Mellon University, USA; TU Braunschweig, Germany; University of Magdeburg, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","483","494","Quality assurance for highly-configurable systems is challenging due to the exponentially growing configuration space. Interactions among multiple options can lead to surprising behaviors, bugs, and security vulnerabilities. Analyzing all configurations systematically might be possible though if most options do not interact or interactions follow specific patterns that can be exploited by analysis tools. To better understand interactions in practice, we analyze program traces to characterize and identify where interactions occur on control flow and data. To this end, we developed a dynamic analysis for Java based on variability-aware execution and monitor executions of multiple small to medium-sized programs. We find that the essential configuration complexity of these programs is indeed much lower than the combinatorial explosion of the configuration space indicates. However, we also discover that the interaction characteristics that allow scalable and complete analyses are more nuanced than what is exploited by existing state-of-the-art quality assurance strategies.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582784","Feature Interaction;Configurable Software;Variability-Aware Execution","Meteorology;Complexity theory;Quality assurance;Testing;Extraterrestrial measurements;Computer bugs;Java","Java;program diagnostics;software quality","configuration complexity;highly-configurable system;quality assurance;program trace analysis;dynamic analysis;Java;variability-aware execution;execution monitoring","","","70","","","","","IEEE","IEEE Conferences"
"Privacy preserving via interval covering based subclass division and manifold learning based bi-directional obfuscation for effort estimation","F. Qi; X. Jing; X. Zhu; F. Wu; L. Cheng","State Key Laboratory of Software Engineering, School of Computer, Wuhan University, China; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, China; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, China; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, China; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","75","86","When a company lacks local data in hand, engineers can build an effort model for the effort estimation of a new project by utilizing the training data shared by other companies. However, one of the most important obstacles for data sharing is the privacy concerns of software development organizations. In software engineering, most of existing privacy-preserving works mainly focus on the defect prediction, or debugging and testing, yet the privacy-preserving data sharing problem has not been well studied in effort estimation. In this paper, we aim to provide data owners with an effective approach of privatizing their data before release. We firstly design an Interval Covering based Subclass Division (ICSD) strategy. ICSD can divide the target data into several subclasses by digging a new attribute (i.e., class label) from the effort data. And the obtained class label is beneficial to maintaining the distribution of the target data after obfuscation. Then, we propose a manifold learning based bi-directional data obfuscation (MLBDO) algorithm, which uses two nearest neighbors, which are selected respectively from the previous and next subclasses by utilizing the manifold learning based nearest neighbor selector, as the disturbances to obfuscate the target sample. We call the entire approach as ICSD&MLBDO. Experimental results on seven public effort datasets show that: 1) ICSD&MLBDO can guarantee the privacy and maintain the utility of obfuscated data. 2) ICSD&MLBDO can achieve better privacy and utility than the compared privacy-preserving methods.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582747","Effort estimation;Privacy-preserving;Locality preserving projection;Subclass division","Decision support systems;Data privacy;Servers;Radio frequency","data handling;data privacy;estimation theory;learning (artificial intelligence)","interval covering based subclass division;ICSD strategy;manifold learning based bidirectional obfuscation;MLBDO algorithm;effort estimation;training data utilization;software development organization privacy;software engineering;privacy-preserving data sharing problem;data privatization;effort data digging;class label;target data distribution;nearest neighbor selection;manifold learning based nearest neighbor selector;target sample obfuscation;ICSD&MLBDO;public effort datasets","","","66","","","","","IEEE","IEEE Conferences"
"Too much automation? The bellwether effect and its implications for transfer learning","R. Krishna; T. Menzies; W. Fu","Computer Science, North Carolina State University, USA; Computer Science, North Carolina State University, USA; Computer Science, North Carolina State University, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","122","131","“Transfer learning”: is the process of translating quality predictors learned in one data set to another. Transfer learning has been the subject of much recent research. In practice, that research means changing models all the time as transfer learners continually exchange new models to the current project. This paper offers a very simple “bellwether” transfer learner. Given N data sets, we find which one produces the best predictions on all the others. This “bellwether” data set is then used for all subsequent predictions (or, until such time as its predictions start failing-at which point it is wise to seek another bellwether). Bellwethers are interesting since they are very simple to find (just wrap a for-loop around standard data miners). Also, they simplify the task of making general policies in SE since as long as one bellwether remains useful, stable conclusions for N data sets can be achieved just by reasoning over that bellwether. From this, we conclude (1) this bellwether method is a useful (and very simple) transfer learning method; (2) “bellwethers” are a baseline method against which future transfer learners should be compared; (3) sometimes, when building increasingly complex automatic methods, researchers should pause and compare their supposedly more sophisticated method against simpler alternatives.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582751","Defect Prediction;Data Mining;Transfer learning","Software;Learning systems;Testing;Manuals;Buildings;Predictive models;Complexity theory","data mining;learning (artificial intelligence);software quality","bellwether effect;transfer learning;software quality predictor;data mining","","","50","","","","","IEEE","IEEE Conferences"
"ProcessPAIR: A tool for automated performance analysis and improvement recommendation in software development","M. Raza; J. P. Faria","INESC TEC/University of Porto - Faculty of Engineering, Rua Dr. Roberto Frias, s/n, 4200-465 Porto Portugal; INESC TEC/University of Porto - Faculty of Engineering, Rua Dr. Roberto Frias, s/n, 4200-465 Porto Portugal","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","798","803","High-maturity software development processes can generate significant amounts of data that can be periodically analyzed to identify performance problems, determine their root causes and devise improvement actions. However, conducting that analysis manually is challenging because of the potentially large amount of data to analyze and the effort and expertise required. In this paper, we present ProcessPAIR, a novel tool designed to help developers analyze their performance data with less effort, by automatically identifying and ranking performance problems and potential root causes, so that subsequent manual analysis for the identification of deeper causes and improvement actions can be properly focused. The analysis is based on performance models defined manually by process experts and calibrated automatically from the performance data of many developers. We also show how ProcessPAIR was successfully applied for the Personal Software Process (PSP). A video about ProcessPAIR is available in https://youtu.be/dEk3fhhkduo.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582818","software process;performance analysis;improvement recommendation","Calibration;Unified modeling language;Sensitivity;Software;Performance analysis;Statistical distributions;Estimation","data analysis;software performance evaluation;software process improvement;software tools","ProcessPAIR;software tool;performance analysis;improvement recommendation;software development;data analysis;personal software process;PSP","","","14","","","","","IEEE","IEEE Conferences"
"SuperMod: Tool support for collaborative filtered model-driven software product line engineering","F. Schwäger; B. Westfechtel","Applied Computer Science, University of Bayreuth, 95440 Bayreuth, Germany; Applied Computer Science, University of Bayreuth, 95440 Bayreuth, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","822","827","The increase in productivity implied by model-driven software product line engineering is weakened by the complexity exposed to the user having to manage a multi-variant model. Recently, a new paradigm has emerged: filtered software product line engineering transfers the established check-out/modify/commit workflow from version control to variability management, allowing to iteratively develop the multi-variant model in a single-variant view. This paper demonstrates SuperMod, a tool that supports collaborative filtered model-driven product line engineering, implemented for and with the Eclipse Modeling Framework. Concerning variability management, the tool offers capabilities for editing feature models and specifying feature configurations, both being well-known formalisms in product line engineering. Furthermore, collaborative editing of product lines is provided through distributed version control. The accompanying video shows that SuperMod seamlessly integrates into existing tool landscapes, reduces the complexity of multi-variant editing, automates a large part of variability management, and ensures consistency. A tool demonstration video is available here: http://youtu.be/5XOk3x5kjFc.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582822","Model-driven software engineering;software product line engineering;version control;filtered editing","Unified modeling language;Software product lines;Collaboration;Control systems;Computational modeling;Software;Metadata","collaborative filtering;software product lines","SuperMod tool support;collaborative filtering;model-driven software product line engineering;check-out-modify-commit workflow;version control;variability management;Eclipse modeling framework;distributed version control","","","22","","","","","IEEE","IEEE Conferences"
"Goal-conflict detection based on temporal satisfiability checking","R. Degiovanni; N. Ricci; D. Alrajeh; P. Castro; N. Aguirre","Departamento de Computación, Universidad Nacional de Río Cuarto and CONICET, Argentina; Departamento de Computación, Universidad Nacional de Río Cuarto and CONICET, Argentina; Department of Computing, Imperial College London, UK; Departamento de Computación, Universidad Nacional de Río Cuarto and CONICET, Argentina; Departamento de Computación, Universidad Nacional de Río Cuarto and CONICET, Argentina","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","507","518","Goal-oriented requirements engineering approaches propose capturing how a system should behave through the specification of high-level goals, from which requirements can then be systematically derived. Goals may however admit subtle situations that make them diverge, i.e., not be satisfiable as a whole under specific circumstances feasible within the domain, called boundary conditions. While previous work allows one to identify boundary conditions for conflicting goals written in LTL, it does so through a pattern-based approach, that supports a limited set of patterns, and only produces pre-determined formulations of boundary conditions. We present a novel automated approach to compute boundary conditions for general classes of conflicting goals expressed in LTL, using a tableaux-based LTL satisfiability procedure. A tableau for an LTL formula is a finite representation of all its satisfying models, which we process to produce boundary conditions that violate the formula, indicating divergence situations. We show that our technique can automatically produce boundary conditions that are more general than those obtainable through existing previous pattern-based approaches, and can also generate boundary conditions for goals that are not captured by these patterns.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582786","Goal Conflicts;Satisfiability Checking;Tableaux Method","Boundary conditions;Software;Cost accounting;Requirements engineering;Computational modeling;Methane;Standards","computability;formal specification;pattern recognition;temporal logic","goal-conflict detection;temporal satisfiability checking;goal-oriented requirements engineering;boundary conditions;pattern-based approach;tableaux-based LTL satisfiability;finite representation","","","47","","","","","IEEE","IEEE Conferences"
"Symbolic execution of complex program driven by machine learning based constraint solving","X. Li; Y. Liang; H. Qian; Y. Hu; L. Bu; Y. Yu; X. Chen; X. Li","State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, P.R. China","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","554","559","Symbolic execution is a widely-used program analysis technique. It collects and solves path conditions to guide the program traversing. However, due to the limitation of the current constraint solvers, it is difficult to apply symbolic execution on programs with complex path conditions, like nonlinear constraints and function calls. In this paper, we propose a new symbolic execution tool MLB to handle such problem. Instead of relying on the classical constraint solving, in MLB, the feasibility problems of the path conditions are transformed into optimization problems, by minimizing some dissatisfaction degree. The optimization problems are then handled by the underlying optimization solver through machine learning guided sampling and validation. MLB is implemented on the basis of Symbolic PathFinder and encodes not only the simple linear path conditions, but also nonlinear arithmetic operations, and even black-box function calls of library methods, into symbolic path conditions. Experiment results show that MLB can achieve much better coverage on complex real-world programs.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582790","Symbolic Execution;Machine Learning;Complicated Path Condition;Constraint Solving","Optimization;Libraries;Engines;Machine learning algorithms;Java;Transforms;Algorithm design and analysis","arithmetic;constraint handling;learning (artificial intelligence);optimisation;program diagnostics","complex program;machine learning;constraint solving;program analysis;constraint solvers;complex path conditions;nonlinear constraints;symbolic execution tool;MLB;optimization problems;dissatisfaction degree;optimization solver;symbolic PathFinder;linear path conditions;nonlinear arithmetic operations;black-box function calls;library methods;symbolic path conditions","","","26","","","","","IEEE","IEEE Conferences"
"Automatically recommending code reviewers based on their expertise: An empirical comparison","C. Hannebauer; M. Patalas; S. Stünkelt; V. Gruhn","paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Germany; paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Germany; paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Germany; paluno - The Ruhr Institute for Software Technology, University of Duisburg-Essen, Germany","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","99","110","Code reviews are an essential part of quality assurance in Free, Libre, and Open Source Software (FLOSS) projects. However, finding a suitable reviewer can be difficult, and delayed or forgotten reviews are the consequence. Automating reviewer selection with suitable algorithms can mitigate this problem. We compare empirically six algorithms based on modification expertise and two algorithms based on review expertise on four major FLOSS projects. Our results indicate that the algorithms based on review expertise yield better recommendations than those based on modification expertise. The algorithm Weighted Review Count (WRC) recommends at least one out of five reviewers correctly in 69 % to 75 % of all cases, which is one of the best results achieved in the comparison.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582749","Code reviewer recommendation;code reviews;expertise metrics;issue tracker;open source;patches;recommendation system","Measurement;Prediction algorithms;Software;Software algorithms;Algorithm design and analysis;History;Machine learning algorithms","project management;public domain software;software quality","code reviewer automatic recommendation;quality assurance;free, libre, and open source software projects;FLOSS projects;reviewer selection automation;modification expertise;review expertise;weighted review count;WRC","","","57","","","","","IEEE","IEEE Conferences"
"Visualization of combinatorial models and test plans","R. Tzoref-Brill; P. Wojciak; S. Maoz","School of Computer Science, Tel Aviv University and IBM Research, Israel; IBM Systems, USA; School of Computer Science, Tel Aviv University, Israel","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","144","154","Combinatorial test design (CTD) is an effective and widely used test design technique. CTD provides automatic test plan generation, but it requires a manual definition of the test space in the form of a combinatorial model. One challenge for successful application of CTD in practice relates to this manual model definition and maintenance process. Another challenge relates to the comprehension and use of the test plan generated by CTD for prioritization purposes. In this work we introduce the use of visualizations as a means to address these challenges. We apply three different forms of visualization, matrices, graphs, and treemaps, to visualize the relationships between the different elements of the model, and to visualize the strength of each test in the test plan and the relationships between the different tests in terms of combinatorial coverage. We evaluate our visualizations via a user survey with 19 CTD practitioners, as well as via two industrial projects in which our visualization was used and allowed test designers to get vital insight into their models and into the coverage provided through CTD generated test plans.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582753","Combinatorial Testing;Software Visualization","Visualization;Data visualization;Atmospheric modeling;Manuals;Computational modeling;Testing;Image color analysis","program testing;program visualisation","combinatorial models visualization;test plans visualization;combinatorial test design;automatic test plan generation;matrices;graphs;treemaps;combinatorial coverage;software visualization;CTD generated test plans","","","25","","","","","IEEE","IEEE Conferences"
"ASE 2019 Organization","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","26","27","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2019.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952202","","","","","","","","","","","","IEEE","IEEE Conferences"
"ASE 2015 Organization","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xvii","xvii","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2015.5","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371982","","","","","","","","","","","","IEEE","IEEE Conferences"
"ASE Steering Committee and ASE Fellows","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xxii","xxii","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2015.7","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371987","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Chairs","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","20","25","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ASE.2019.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952558","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Committees and Reviewers","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","28","33","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2019.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952425","","","","","","","","","","","","IEEE","IEEE Conferences"
"Steering Committee","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","34","34","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2019.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952537","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and Supporters","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","35","35","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","10.1109/ASE.2019.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952508","","","","","","","","","","","","IEEE","IEEE Conferences"
"Doctoral Symposium and Tool Demonstrations Committees","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xxi","xxi","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2015.115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371986","","","","","","","","","","","","IEEE","IEEE Conferences"
"Organization Committee","","","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","vii","xii","Provides a listing of current committee members and society officers. The conference also offers a note of thanks and lists its reviewers.","","","10.1109/ASE.2017.8115608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115608","","","","","","","","","","","","IEEE","IEEE Conferences"
"Silver sponsors","","","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","xiii","xiii","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","10.1109/ASE.2017.8115609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115609","","","","","","","","","","","","IEEE","IEEE Conferences"
"Publisher's Information","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","910","910","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2015.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372091","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Chairs","","","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","iii","viii","Presents the welcome message from the conference proceedings.","","","10.1109/ASE.2013.6693057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693057","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Chairs","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xv","xvi","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ASE.2015.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371981","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Committee","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xviii","xviii","Provides a listing of current committee members and society officers.","","","10.1109/ASE.2015.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371983","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the chairs","","","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","iii","xi","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ASE.2017.8115607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115607","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Copyright notice]","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","4","4","Presents the copyright information for the conference. May include reprint permission information.","","","10.1109/ASE.2019.00003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952247","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page i]","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1","1","Presents the title page of the proceedings record.","","","10.1109/ASE.2019.00001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952307","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii]","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","3","3","Presents the title page of the proceedings record.","","","10.1109/ASE.2019.00002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952325","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author Index","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","1289","1296","Presents an index of the authors whose articles are published in the conference proceedings record.","","","10.1109/ASE.2019.00165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952195","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2019","","","5","19","Presents the table of contents/splash page of the proceedings record.","","","10.1109/ASE.2019.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952268","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","v","xiv","Presents the table of contents/splash page of the proceedings record.","","","10.1109/ASE.2015.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371980","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii]","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","iii","iii","Presents the title page of the proceedings record.","","","10.1109/ASE.2015.2","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371978","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Front matter]","","","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","i","ii","Conference proceedings front matter may contain various advertisements, welcome messages, committee or program information, and other miscellaneous conference information. This may in some cases also include the cover art, table of contents, copyright statements, title-page or half title-pages, blank pages, venue maps or other general information relating to the conference that was part of the original conference proceedings.","","","10.1109/ASE.2013.6693055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693055","","","","","","","","","","","","IEEE","IEEE Conferences"
"Expert Review Panel","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xix","xix","The conference offers a note of thanks and lists its reviewers.","","","10.1109/ASE.2015.111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371984","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Front matter]","","","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1","2","Conference proceedings front matter may contain various advertisements, welcome messages, committee or program information, and other miscellaneous conference information. This may in some cases also include the cover art, table of contents, copyright statements, title-page or half title-pages, blank pages, venue maps or other general information relating to the conference that was part of the original conference proceedings.","","","10.1109/ASE.2017.8115604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115604","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","906","909","Presents an index of the authors whose articles are published in the conference proceedings record.","","","10.1109/ASE.2015.97","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372090","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Copyright notice]","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","iv","iv","Presents the copyright information for the conference. May include reprint permission information.","","","10.1109/ASE.2015.3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371979","","","","","","","","","","","","IEEE","IEEE Conferences"
"Contents","","","2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2013","","","1","6","The following topics are dealt with: concurrency; dynamic analysis; testing and verification; evolution; generation and synthesis; recommendations; security; debugging; resources; specification mining; models and complexity; software analysis; adaptation and transformation; and models and requirements.","","","10.1109/ASE.2013.6693056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693056","","","concurrency control;data mining;program debugging;program testing;security of data;software engineering","automated software engineering;software concurrency;dynamic analysis;software testing;software verification;software evolution;software generation;software synthesis;software security;software debugging;software resources;specification mining;software models;software complexity;software analysis","","","","","","","","IEEE","IEEE Conferences"
"Additional reviewers","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xx","xx","The conference offers a note of thanks and lists its reviewers.","","","10.1109/ASE.2015.112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371985","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and supporters","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","xxvi","xxvi","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","10.1109/ASE.2015.114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371989","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index","","","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","1034","1036","Presents an index of the authors whose articles are published in the conference proceedings record.","","","10.1109/ASE.2017.8115605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115605","","","","","","","","","","","","IEEE","IEEE Conferences"
"Contents","","","2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2017","","","xiv","xx","The following topics are dealt with: test generation; developer practice and behavior; documentation; formal verification; security of data; mobile development; binary analysis; program comprehension; reliability and bugs; source code analysis; symbolic execution; program repair; recommender systems; concurrency; program synthesis; and data visualization.","","","10.1109/ASE.2017.8115606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115606","","","concurrency (computers);data visualisation;formal verification;mobile computing;program debugging;program diagnostics;program testing;recommender systems;security of data;software reliability;source code (software);symbol manipulation;system documentation","test generation;developer practice;developer behavior;documentation;formal verification;security of data;mobile development;binary analysis;program comprehension;bugs;reliability;source code analysis;symbolic execution;program repair;recommender systems;concurrency;program synthesis;data visualization","","","","","","","","IEEE","IEEE Conferences"
"[Title page i]","","","2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2015","","","i","i","The following topics are dealt with: automated development support; formal verification; specification mining; search-based software testing; concurrency bugs; concurrency analysis; automatic test generation; mobile applications; program repair; program synthesis; software performance; product lines; configurable software systems; defect prediction; debugging; concurrent programming; parallel programming; program analysis; program translations; software evolution; data mining and tool demonstrations.","","","10.1109/ASE.2015.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7371977","","","concurrency control;data mining;formal specification;mobile computing;parallel programming;program debugging;program diagnostics;program testing;program verification;software maintenance;software product lines","tool demonstrations;data mining;software evolution;program translations;program analysis;parallel programming;concurrent programming;debugging;defect prediction;configurable software systems;product lines;software performance;program synthesis;program repair;mobile applications;automatic test generation;concurrency analysis;concurrency bugs;search-based software testing;specification mining;formal verification;automated development support","","","","","","","","IEEE","IEEE Conferences"
"[Front matter]","","","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","i","xviii","Conference proceedings front matter may contain various advertisements, welcome messages, committee or program information, and other miscellaneous conference information. This may in some cases also include the cover art, table of contents, copyright statements, title-page or half title-pages, blank pages, venue maps or other general information relating to the conference that was part of the original conference proceedings.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582736","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index","","","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","","2016","","","900","901","Presents an index of the authors whose articles are published in the conference proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582837","","","","","","","","","","","","IEEE","IEEE Conferences"
