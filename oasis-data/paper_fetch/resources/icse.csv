"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,"Reference Count","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Statistical Errors in Software Engineering Experiments: A Preliminary Literature Review","R. P. Reyes Ch.; O. Dieste; E. R. Fonseca C.; N. Juristo","Univ. Politec. de Madrid, Madrid, Spain; Univ. Politec. de Madrid, Madrid, Spain; NA; Univ. Politec. de Madrid, Madrid, Spain","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1195","1206","Background: Statistical concepts and techniques are often applied incorrectly, even in mature disciplines such as medicine or psychology. Surprisingly, there are very few works that study statistical problems in software engineering (SE). Aim: Assess the existence of statistical errors in SE experiments. Method: Compile the most common statistical errors in experimental disciplines. Survey experiments published in ICSE to assess whether errors occur in high quality SE publications. Results: The same errors as identified in others disciplines were found in ICSE experiments, where 30 of the reviewed papers included several error types such as: a) missing statistical hypotheses, b) missing sample size calculation, c) failure to assess statistical test assumptions, and d) uncorrected multiple testing. This rather large error rate is greater for research papers where experiments are confined to the validation section. The origin of the errors can be traced back to: a) researchers not having sufficient statistical training, and b) a profusion of exploratory research. Conclusions: This paper provides preliminary evidence that SE research suffers from the same statistical problems as other experimental disciplines. However, the SE community appears to be unaware of any shortcomings in its experiments, whereas other disciplines work hard to avoid these threats. Further research is necessary to find the underlying causes and set up corrective measures, but there are some potentially effective actions and are a priori easy to implement: a) improve the statistical training of SE researchers, and b) enforce quality assessment and reporting guidelines in SE publications.","","","10.1145/3180155.3180161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453201","Literature review;Survey;Prevalence;Statistical errors","Software engineering;Bibliographies;Training;Guidelines;Error analysis;Back","psychology;research and development;software engineering;statistical testing","software engineering experiments;SE experiments;high quality SE publications;ICSE experiments;statistical hypotheses;statistical test assumptions;SE community;SE researchers;quality assessment;statistical errors;statistical training;SE research","","","","","","","","IEEE","IEEE Conferences"
"3rd FME Workshop on Formal Methods in Software Engineering (FormaliSE 2015)","S. Gnesi; N. Plat","NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","977","978","Despite their significant advantages, formal methods are not widely used in industrial software development. Following the successful workshops we organized at ICSE 2103 in San Francisco, and ICSE 2014 in Hyderabad, we organize a third edition of the FormaliSE workshop with the main goal to promote the integration between the formal methods and the software engineering communities.","","","10.1109/ICSE.2015.313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203136","Formal methods;Software engineering","Software;Conferences;Software engineering;Security;Committees;Industries;Collaboration","","","","","","","","","","IEEE","IEEE Conferences"
"A Novel Neural Source Code Representation Based on Abstract Syntax Tree","J. Zhang; X. Wang; H. Zhang; H. Sun; K. Wang; X. Liu","Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China; Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China; The University of Newcastle, Australia; Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China; Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China; Beihang University, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","783","794","Exploiting machine learning techniques for analyzing programs has attracted much attention. One key problem is how to represent code fragments well for follow-up analysis. Traditional information retrieval based methods often treat programs as natural language texts, which could miss important semantic information of source code. Recently, state-of-the-art studies demonstrate that abstract syntax tree (AST) based neural models can better represent source code. However, the sizes of ASTs are usually large and the existing models are prone to the long-term dependency problem. In this paper, we propose a novel AST-based Neural Network (ASTNN) for source code representation. Unlike existing models that work on entire ASTs, ASTNN splits each large AST into a sequence of small statement trees, and encodes the statement trees to vectors by capturing the lexical and syntactical knowledge of statements. Based on the sequence of statement vectors, a bidirectional RNN model is used to leverage the naturalness of statements and finally produce the vector representation of a code fragment. We have applied our neural network based source code representation method to two common program comprehension tasks: source code classification and code clone detection. Experimental results on the two tasks indicate that our model is superior to state-of-the-art approaches.","","","10.1109/ICSE.2019.00086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812062","Abstract Syntax Tree, source code representation, neural network, code classification, code clone detection","Syntactics;Cloning;Semantics;Neural networks;Task analysis;Binary trees;Natural languages","information retrieval;learning (artificial intelligence);natural language processing;program diagnostics;recurrent neural nets;text analysis;tree data structures","abstract syntax tree;code fragment;natural language texts;ASTNN;statement trees;statement vectors;bidirectional RNN model;vector representation;source code representation method;source code classification;code clone detection;program analysis;program comprehension tasks;AST-based Neural Network;neural source code representation;information retrieval;machine learning","","1","66","","","","","IEEE","IEEE Conferences"
"Balancing Soundness and Efficiency for Practical Testing of Configurable Systems","S. Souto; M. D'Amorim; R. Gheyi","State Univ. of Paraiba, Para√≠ba, Brazil; Fed. Univ. of Pernambuco, Recife, Brazil; Fed. Univ. of Campina Grande, Campina Grande, Brazil","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","632","642","Testing configurable systems is important and challenging due to the enormous space of configurations where errors can hide. Existing approaches to test these systems are often costly or unreliable. This paper proposes S-SPLat, a technique that combines heuristic sampling with symbolic search to obtain both breadth and depth in the exploration of the configuration space. S-SPLat builds on SPLat, our previously developed technique, that explores all reachable configurations from tests. In contrast to its predecessor, S-SPLat sacrifices soundness in favor of efficiency. We evaluated our technique on eight software product lines of various sizes and on a large configurable system - GCC. Considering the results for GCC, S-SPLat was able to reproduce all five bugs that we previously found in a previous study with SPLat but much faster and it was able to find two new bugs in a recent release of GCC. Results suggest that it is preferable to use a combination of simple heuristics to drive the symbolic search as opposed to a single heuristic. S-SPLat and our experimental infrastructure are publicly available.","","","10.1109/ICSE.2017.64","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985700","sampling;testing;configuration","Testing;Computer bugs;Software product lines;Complexity theory;Reliability;Space exploration","program testing;software product lines","configurable system testing;S-SPLat technique;heuristic sampling;symbolic search;configuration space;software product lines;GCC","","1","52","","","","","IEEE","IEEE Conferences"
"Stochastic Optimization of Program Obfuscation","H. Liu; C. Sun; Z. Su; Y. Jiang; M. Gu; J. Sun","Sch. of Software, Tsinghua Univ., Beijing, China; Univ. of California, Davis, Davis, CA, USA; Univ. of California, Davis, Davis, CA, USA; Sch. of Software, Tsinghua Univ., Beijing, China; Sch. of Software, Tsinghua Univ., Beijing, China; Sch. of Software, Tsinghua Univ., Beijing, China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","221","231","Program obfuscation is a common practice in software development to obscure source code or binary code, in order to prevent humans from understanding the purpose or logic of software. It protects intellectual property and deters malicious attacks. While tremendous efforts have been devoted to the development of various obfuscation techniques, we have relatively little knowledge on how to most effectively use them together. The biggest challenge lies in identifying the most effective combination of obfuscation techniques. This paper presents a unified framework to optimize program obfuscation. Given an input program P and a set T of obfuscation transformations, our technique can automatically identify a sequence seq = „Äàt1, t2, ..., tn„Äâ (‚àÄi ‚àà [1, n]. ti ‚àà T), such that applying ti in order on P yields the optimal obfuscation performance. We model the process of searching for seq as a mathematical optimization problem. The key technical contributions of this paper are: (1) an obscurity language model to assess obfuscation effectiveness/optimality, and (2) a guided stochastic algorithm based on Markov chain Monte Carlo methods to search for the optimal solution seq. We have realized the framework in a tool Closure* for JavaScript, and evaluated it on 25 most starred JavaScript projects on GitHub (19K lines of code). Our machinery study shows that Closure* outperforms the well-known Google Closure Compiler by defending 26% of the attacks initiated by JSNice. Our human study also reveals that Closure* is practical and can reduce the human attack success rate by 30%.","","","10.1109/ICSE.2017.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985664","program obfuscation;obscurity language model;markov chain monte carlo methods","Optimization;Mathematical model;Reactive power;Markov processes;Google;Lenses;Software","Java;Markov processes;Monte Carlo methods;software engineering","stochastic optimization;program obfuscation;software development;source code;binary code;mathematical optimization problem;guided stochastic algorithm;obscurity language model;Markov chain Monte Carlo methods;JavaScript","","2","41","","","","","IEEE","IEEE Conferences"
"Search-Based Energy Testing of Android","R. Jabbarvand; J. Lin; S. Malek","University of California, Irvine; University of California, Irvine; University of California, Irvine","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1119","1130","The utility of a smartphone is limited by its battery capacity and the ability of its hardware and software to efficiently use the device's battery. To properly characterize the energy consumption of an app and identify energy defects, it is critical that apps are properly tested, i.e., analyzed dynamically to assess the app's energy properties. However, currently there is a lack of testing tools for evaluating the energy properties of apps. We present COBWEB, a search-based energy testing technique for Android. By leveraging a set of novel models, representing both the functional behavior of an app as well as the contextual conditions affecting the app's energy behavior, COBWEB generates a test suite that can effectively find energy defects. Our experimental results using real-world apps demonstrate not only its ability to effectively and efficiently test energy behavior of apps, but also its superiority over prior techniques by finding a wider and more diverse set of energy defects.","","","10.1109/ICSE.2019.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812097","Energy Testing;Android;Software Testing","Testing;Hardware;Global Positioning System;Graphical user interfaces;Smart phones;Receivers;Batteries","Android (operating system);mobile computing;program testing;search problems;smart phones","battery capacity;energy consumption;energy defects;energy properties;search-based energy testing technique;test suite;energy behavior;Android;COBWEB","","1","69","","","","","IEEE","IEEE Conferences"
"Syntactic and Semantic Differencing for Combinatorial Models of Test Designs","R. Tzoref-Brill; S. Maoz","Sch. of Comput. Sci., Tel Aviv Univ., Tel Aviv, Israel; Sch. of Comput. Sci., Tel Aviv Univ., Tel Aviv, Israel","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","621","631","Combinatorial test design (CTD) is an effective test design technique, considered to be a testing best practice. CTD provides automatic test plan generation, but it requires a manual definition of the test space in the form of a combinatorial model. As the system under test evolves, e.g., due to iterative development processes and bug fixing, so does the test space, and thus, in the context of CTD, evolution translates into frequent manual model definition updates. Manually reasoning about the differences between versions of real-world models following such updates is infeasible due to their complexity and size. Moreover, representing the differences is challenging. In this work, we propose a first syntactic and semantic differencing technique for combinatorial models of test designs. We define a concise and canonical representation for differences between two models, and suggest a scalable algorithm for automatically computing and presenting it. We use our differencing technique to analyze the evolution of 42 real-world industrial models, demonstrating its applicability and scalability. Further, a user study with 16 CTD practitioners shows that comprehension of differences between real-world combinatorial model versions is challenging and that our differencing tool significantly improves the performance of less experienced practitioners. The analysis and user study provide evidence for the potential usefulness of our differencing approach. Our work advances the state-of-the-art in CTD with better capabilities for change comprehension and management.","","","10.1109/ICSE.2017.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985699","","Computational modeling;Semantics;Tools;Syntactics;Analytical models;Data models;Binary decision diagrams","program testing","combinatorial test design;automatic test plan generation;CTD practitioners","","2","38","","","","","IEEE","IEEE Conferences"
"A Test-Suite Diagnosability Metric for Spectrum-Based Fault Localization Approaches","A. Perez; R. Abreu; A. van Deursen","HASLab, Univ. of Porto, Porto, Portugal; HASLab, Univ. of Porto, Porto, Portugal; Delft Univ. of Technol., Delft, Netherlands","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","654","664","Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines, branches, paths) covered by the suite, but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric, called DDU, aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability, i.e., the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites, so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. Our experiments show that optimizing a test suite with respect to DDU yields a 34% gain in spectrum-based fault localization report accuracy when compared to the standard branch-coverage metric.","","","10.1109/ICSE.2017.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985702","Testing;Coverage;Diagnosability","Cognition;Density measurement;Software;Computer bugs;Gain measurement;Measurement uncertainty","error detection;fault diagnosis;program debugging;program testing","test-suite diagnosability metric;spectrum-based fault localization techniques;fault isolation;DDU;error detection mechanisms;bugs;branch-coverage metric;density-diversity-uniqueness","","6","39","","","","","IEEE","IEEE Conferences"
"Statically Checking Web API Requests in JavaScript","E. Wittern; A. T. T. Ying; Y. Zheng; J. Dolby; J. A. Laredo","IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","244","254","Many JavaScript applications perform HTTP requests to web APIs, relying on the request URL, HTTP method, and request data to be constructed correctly by string operations. Traditional compile-time error checking, such as calling a non-existent method in Java, are not available for checking whether such requests comply with the requirements of a web API. In this paper, we propose an approach to statically check web API requests in JavaScript. Our approach first extracts a request's URL string, HTTP method, and the corresponding request data using an inter-procedural string analysis, and then checks whether the request conforms to given web API specifications. We evaluated our approach by checking whether web API requests in JavaScript files mined from GitHub are consistent or inconsistent with publicly available API specifications. From the 6575 requests in scope, our approach determined whether the request's URL and HTTP method was consistent or inconsistent with web API specifications with a precision of 96.0%. Our approach also correctly determined whether extracted request data was consistent or inconsistent with the data requirements with a precision of 87.9% for payload data and 99.9% for query data. In a systematic analysis of the inconsistent cases, we found that many of them were due to errors in the client code. The here proposed checker can be integrated with code editors or with continuous integration tools to warn programmers about code containing potentially erroneous requests.","","","10.1109/ICSE.2017.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985666","Static analysis;JavaScript;Web APIs","Uniform resource locators;Data mining;Reactive power;Payloads;Tools;Media;Writing","application program interfaces;Java;program diagnostics","Web API requests;JavaScript;HTTP requests;compile-time error checking;URL string;interprocedural string analysis;GitHub","","7","31","","","","","IEEE","IEEE Conferences"
"Repairing Event Race Errors by Controlling Nondeterminism","C. Q. Adamsen; A. M√∏ller; R. Karim; M. Sridharan; F. Tip; K. Sen","Aarhus Univ., Aarhus, Denmark; Aarhus Univ., Aarhus, Denmark; Samsung Res. America, Mountain View, CA, USA; Samsung Res. America, Mountain View, CA, USA; Northeastern Univ., Boston, MA, USA; EECS Dept., UC Berkeley, Berkeley, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","289","299","Modern web applications are written in an event-driven style, in which event handlers execute asynchronously in response to user or system events. The nondeterminism arising from this programming style can lead to pernicious errors. Recent work focuses on detecting event races and classifying them as harmful or harmless. However, since modifying the source code to prevent harmful races can be a difficult and error-prone task, it may be preferable to steer away from the bad executions. In this paper, we present a technique for automated repair of event race errors in JavaScript web applications. Our approach relies on an event controller that restricts event handler scheduling in the browser according to a specified repair policy, by intercepting and carefully postponing or discarding selected events. We have implemented the technique in a tool called EventRaceCommander, which relies entirely on source code instrumentation, and evaluated it by repairing more than 100 event race errors that occur in the web applications from the largest 20 of the Fortune 500 companies. Our results show that application-independent repair policies usually suffice to repair event race errors without excessive negative impact on performance or user experience, though application-specific repair policies that target specific event races are sometimes desirable.","","","10.1109/ICSE.2017.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985670","JavaScript;event-driven programming;automated repair","Maintenance engineering;Thumb;Tools;Browsers;Instruments;Programming;Schedules","high level languages;Internet;object-oriented programming;online front-ends;software maintenance","event race error repair;JavaScript Web applications;event handler scheduling;browser;EventRaceCommander;source code instrumentation;application-independent repair policies;application-specific repair policies","","2","34","","","","","IEEE","IEEE Conferences"
"Automatically Generating Precise Oracles from Structured Natural Language Specifications","M. Motwani; Y. Brun","University of Massachusetts Amherst; University of Massachusetts Amherst","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","188","199","Software specifications often use natural language to describe the desired behavior, but such specifications are difficult to verify automatically. We present Swami, an automated technique that extracts test oracles and generates executable tests from structured natural language specifications. Swami focuses on exceptional behavior and boundary conditions that often cause field failures but that developers often fail to manually write tests for. Evaluated on the official JavaScript specification (ECMA-262), 98.4% of the tests Swami generated were precise to the specification. Using Swami to augment developer-written test suites improved coverage and identified 1 previously unknown defect and 15 missing JavaScript features in Rhino, 1 previously unknown defect in Node.js, and 18 semantic ambiguities in the ECMA-262 specification.","","","10.1109/ICSE.2019.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812070","oracle;test oracle;test generation;natural language specification","Natural languages;Documentation;Lenses;Software;Boundary conditions;Semantics;Prototypes","formal specification;Java;natural language processing;program testing","structured natural language specifications;developer-written test suites;ECMA-262 specification;software specifications;test oracles;Swami technique;JavaScript features;JavaScript specification","","","80","","","","","IEEE","IEEE Conferences"
"Code Defenders: Crowdsourcing Effective Tests and Subtle Mutants with a Mutation Testing Game","J. M. Rojas; T. D. White; B. S. Clegg; G. Fraser","Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK; Dept. of Comput. Sci., Univ. of Sheffield, Sheffield, UK","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","677","688","Writing good software tests is difficult and not every developer's favorite occupation. Mutation testing aims to help by seeding artificial faults (mutants) that good tests should identify, and test generation tools help by providing automatically generated tests. However, mutation tools tend to produce huge numbers of mutants, many of which are trivial, redundant, or semantically equivalent to the original program, automated test generation tools tend to produce tests that achieve good code coverage, but are otherwise weak and have no clear purpose. In this paper, we present an approach based on gamification and crowdsourcing to produce better software tests and mutants: The Code Defenders web-based game lets teams of players compete over a program, where attackers try to create subtle mutants, which the defenders try to counter by writing strong tests. Experiments in controlled and crowdsourced scenarios reveal that writing tests as part of the game is more enjoyable, and that playing Code Defenders results in stronger test suites and mutants than those produced by automated tools.","","","10.1109/ICSE.2017.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985704","gamification;crowdsourcing;software testing;mutation testing","Games;Tools;Testing;Crowdsourcing;Writing;Software;Computer bugs","computer games;crowdsourcing;Internet;program testing","Code Defenders;mutation testing game;gamification;crowdsourcing;software tests;Web-based game","","2","53","","","","","IEEE","IEEE Conferences"
"Leveraging Artifact Trees to Evolve and Reuse Safety Cases","A. Agrawal; S. Khoshmanesh; M. Vierhauser; M. Rahimi; J. Cleland-Huang; R. Lutz","University of Notre Dame; Iowa State University; University of Notre Dame; Northern Illinois University; University of Notre Dame; Iowa State University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1222","1233","Safety Assurance Cases (SACs) are increasingly used to guide and evaluate the safety of software-intensive systems. They are used to construct a hierarchically organized set of claims, arguments, and evidence in order to provide a structured argument that a system is safe for use. However, as the system evolves and grows in size, a SAC can be difficult to maintain. In this paper we utilize design science to develop a novel solution for identifying areas of a SAC that are affected by changes to the system. Moreover, we generate actionable recommendations for updating the SAC, including its underlying artifacts and trace links, in order to evolve an existing safety case for use in a new version of the system. Our approach, Safety Artifact Forest Analysis (SAFA), leverages traceability to automatically compare software artifacts from a previously approved or certified version with a new version of the system. We identify, visualize, and explain changes in a Delta Tree. We evaluate our approach using the Dronology system for monitoring and coordinating the actions of cooperating, small Unmanned Aerial Vehicles. Results from a user study show that SAFA helped users to identify changes that potentially impacted system safety and provided information that could be used to help maintain and evolve a SAC.","","","10.1109/ICSE.2019.00124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812137","Change Impact, Safety Assurance Cases, Evolution, Traceability","Vegetation;Hazards;Monitoring;Thermostats;Computer science;Forestry","safety-critical software;software reliability;trees (mathematics)","artifact trees;software-intensive systems;structured argument;trace links;software artifacts;safety assurance cases;dronology system;safety artifact forest analysis","","","63","","","","","IEEE","IEEE Conferences"
"BugSwarm: Mining and Continuously Growing a Dataset of Reproducible Failures and Fixes","D. A. Tomassi; N. Dmeiri; Y. Wang; A. Bhowmick; Y. Liu; P. T. Devanbu; B. Vasilescu; C. Rubio-Gonz√°lez","University of California, Davis; University of California, Davis; University of California, Davis; University of California, Davis; University of California, Davis; University of California, Davis; Carnegie Mellon University; University of California, Davis","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","339","349","Fault-detection, localization, and repair methods are vital to software quality; but it is difficult to evaluate their generality, applicability, and current effectiveness. Large, diverse, realistic datasets of durably-reproducible faults and fixes are vital to good experimental evaluation of approaches to software quality, but they are difficult and expensive to assemble and keep current. Modern continuous-integration (CI) approaches, like TRAVIS-CI, which are widely used, fully configurable, and executed within custom-built containers, promise a path toward much larger defect datasets. If we can identify and archive failing and subsequent passing runs, the containers will provide a substantial assurance of durable future reproducibility of build and test. Several obstacles, however, must be overcome to make this a practical reality. We describe BUGSWARM, a toolset that navigates these obstacles to enable the creation of a scalable, diverse, realistic, continuously growing set of durably reproducible failing and passing versions of real-world, open-source systems. The BUGSWARM toolkit has already gathered 3,091 fail-pass pairs, in Java and Python, all packaged within fully reproducible containers. Furthermore, the toolkit can be run periodically to detect fail-pass activities, thus growing the dataset continually.","","","10.1109/ICSE.2019.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812141","Bug Database;Reproducibility;Software Testing;Program Analysis;Experiment Infrastructure","Containers;Tools;Maintenance engineering;History;Software;Libraries;Currencies","data mining;Java;program debugging;program testing;Python;software fault tolerance;software maintenance;software quality","reproducible failures;fault-detection;repair methods;software quality;realistic datasets;durably-reproducible faults;TRAVIS-CI;BUGSWARM toolkit;fail-pass pairs;fully reproducible containers;fail-pass activities;continuous-integration approach;mining;fault localization;Java;Python","","1","32","","","","","IEEE","IEEE Conferences"
"Efficient Detection of Thread Safety Violations via Coverage-Guided Generation of Concurrent Tests","A. Choudhary; S. Lu; M. Pradel","Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany; Dept. of Comput. Sci., Univ. of Chicago, Chicago, IL, USA; Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","266","277","As writing concurrent programs is challenging, developers often rely on thread-safe classes, which encapsulate most synchronization issues. Testing such classes is crucial to ensure the correctness of concurrent programs. An effective approach to uncover otherwise missed concurrency bugs is to automatically generate concurrent tests. Existing approaches either create tests randomly, which is inefficient, build on a computationally expensive analysis of potential concurrency bugs exposed by sequential tests, or focus on exposing a particular kind of concurrency bugs, such as atomicity violations. This paper presents CovCon, a coverage-guided approach to generate concurrent tests. The key idea is to measure how often pairs of methods have already been executed concurrently and to focus the test generation on infrequently or not at all covered pairs of methods. The approach is independent of any particular bug pattern, allowing it to find arbitrary concurrency bugs, and is computationally inexpensive, allowing it to generate many tests in short time. We apply CovCon to 18 thread-safe Java classes, and it detects concurrency bugs in 17 of them. Compared to five state of the art approaches, CovCon detects more bugs than any other approach while requiring less time. Specifically, our approach finds bugs faster in 38 of 47 cases, with speedups of at least 4x for 22 of 47 cases.","","","10.1109/ICSE.2017.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985668","test generation;coverage;concurrency","Instruction sets;Computer bugs;Concurrent computing;Testing;Synchronization;Schedules","concurrency (computers);Java;program debugging;program testing;synchronisation","thread safety violation detection;coverage-guided generation;concurrent tests;concurrent program writing;synchronization;missed concurrency bugs;sequential tests;CovCon;bug pattern;thread-safe Java classes;test generation","","6","67","","","","","IEEE","IEEE Conferences"
"A SEALANT for Inter-App Security Holes in Android","Y. K. Lee; J. Y. Bang; G. Safi; A. Shahbazian; Y. Zhao; N. Medvidovic","Comput. Sci. Dept., Univ. of Southern California, Los Angeles, CA, USA; Kakao Corp., Seongnam, South Korea; Comput. Sci. Dept., Univ. of Southern California, Los Angeles, CA, USA; Comput. Sci. Dept., Univ. of Southern California, Los Angeles, CA, USA; Comput. Sci. Dept., Univ. of Southern California, Los Angeles, CA, USA; Comput. Sci. Dept., Univ. of Southern California, Los Angeles, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","312","323","Android's communication model has a major security weakness: malicious apps can manipulate other apps into performing unintended operations and can steal end-user data, while appearing ordinary and harmless. This paper presents SEALANT, a technique that combines static analysis of app code, which infers vulnerable communication channels, with runtime monitoring of inter-app communication through those channels, which helps to prevent attacks. SEALANT's extensive evaluation demonstrates that (1) it detects and blocks inter-app attacks with high accuracy in a corpus of over 1,100 real-world apps, (2) it suffers from fewer false alarms than existing techniques in several representative scenarios, (3) its performance overhead is negligible, and (4) end-users do not find it challenging to adopt.","","","10.1109/ICSE.2017.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985672","Android;Security;Inter-app vulnerability","Sealing materials;Androids;Humanoid robots;Runtime;Security;Monitoring;Focusing","Android (operating system);program diagnostics;security of data","SEALANT technique;inter-app security holes;Android communication model;static analysis;app code;vulnerable communication channels;inter-app communication runtime monitoring","","8","95","","","","","IEEE","IEEE Conferences"
"Mining Software Defects: Should We Consider Affected Releases?","S. Yatish; J. Jiarpakdee; P. Thongtanunam; C. Tantithamthavorn","The University of Adelaide; Monash University; The University of Melbourne; Monash University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","654","665","With the rise of the Mining Software Repositories (MSR) field, defect datasets extracted from software repositories play a foundational role in many empirical studies related to software quality. At the core of defect data preparation is the identification of post-release defects. Prior studies leverage many heuristics (e.g., keywords and issue IDs) to identify post-release defects. However, such the heuristic approach is based on several assumptions, which pose common threats to the validity of many studies. In this paper, we set out to investigate the nature of the difference of defect datasets generated by the heuristic approach and the realistic approach that leverages the earliest affected release that is realistically estimated by a software development team for a given defect. In addition, we investigate the impact of defect identification approaches on the predictive accuracy and the ranking of defective modules that are produced by defect models. Through a case study of defect datasets of 32 releases, we find that that the heuristic approach has a large impact on both defect count datasets and binary defect datasets. Surprisingly, we find that the heuristic approach has a minimal impact on defect count models, suggesting that future work should not be too concerned about defect count models that are constructed using heuristic defect datasets. On the other hand, using defect datasets generated by the realistic approach lead to an improvement in the predictive accuracy of defect classification models.","","","10.1109/ICSE.2019.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811982","Mining Software Repositories;Empirical Software Engineering;Software Quality;Defect Prediction Models","Predictive models;Object oriented modeling;Software quality;Feature extraction;Data mining;Control systems","data mining;pattern classification;software maintenance;software quality","defect count models;defect classification models;software quality;defect data preparation;post-release defects;software development team;software repositories;defect identification;software defect mining","","","76","","","","","IEEE","IEEE Conferences"
"LEOPARD: Identifying Vulnerable Code for Vulnerability Assessment Through Program Metrics","X. Du; B. Chen; Y. Li; J. Guo; Y. Zhou; Y. Liu; Y. Jiang","Nanyang Technological University, Singapore; Fudan University, China; Nanyang Technological University, Singapore; Tsinghua University, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Tsinghua University, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","60","71","Identifying potentially vulnerable locations in a code base is critical as a pre-step for effective vulnerability assessment; i.e., it can greatly help security experts put their time and effort to where it is needed most. Metric-based and pattern-based methods have been presented for identifying vulnerable code. The former relies on machine learning and cannot work well due to the severe imbalance between non-vulnerable and vulnerable code or lack of features to characterize vulnerabilities. The latter needs the prior knowledge of known vulnerabilities and can only identify similar but not new types of vulnerabilities. In this paper, we propose and implement a generic, lightweight and extensible framework, LEOPARD, to identify potentially vulnerable functions through program metrics. LEOPARD requires no prior knowledge about known vulnerabilities. It has two steps by combining two sets of systematically derived metrics. First, it uses complexity metrics to group the functions in a target application into a set of bins. Then, it uses vulnerability metrics to rank the functions in each bin and identifies the top ones as potentially vulnerable. Our experimental results on 11 real-world projects have demonstrated that, LEOPARD can cover 74.0% of vulnerable functions by identifying 20% of functions as vulnerable and outperform machine learning-based and static analysis-based techniques. We further propose three applications of LEOPARD for manual code review and fuzzing, through which we discovered 22 new bugs in real applications like PHP, radare2 and FFmpeg, and eight of them are new vulnerabilities.","","","10.1109/ICSE.2019.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812029","Program Metric, Vulnerability, Fuzzing","Measurement;Complexity theory;Security;Computer bugs;Fuzzing;Machine learning;Manuals","learning (artificial intelligence);program diagnostics;security of data;software metrics","pattern-based methods;LEOPARD;program metrics;systematically derived metrics;complexity metrics;vulnerability metrics;manual code review;vulnerability assessment;metric-based method;vulnerable code identification;machine learning-based technique","","","82","","","","","IEEE","IEEE Conferences"
"On Learning Meaningful Code Changes Via Neural Machine Translation","M. Tufano; J. Pantiuchina; C. Watson; G. Bavota; D. Poshyvanyk","The College of William and Mary; Universit√† della Svizzera italiana (USI); The College of William and Mary; Universit√† della Svizzera italiana (USI); The College of William and Mary","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","25","36","Recent years have seen the rise of Deep Learning (DL) techniques applied to source code. Researchers have exploited DL to automate several development and maintenance tasks, such as writing commit messages, generating comments and detecting vulnerabilities among others. One of the long lasting dreams of applying DL to source code is the possibility to automate non-trivial coding activities. While some steps in this direction have been taken (e.g., learning how to fix bugs), there is still a glaring lack of empirical evidence on the types of code changes that can be learned and automatically applied by DL. Our goal is to make this first important step by quantitatively and qualitatively investigating the ability of a Neural Machine Translation (NMT) model to learn how to automatically apply code changes implemented by developers during pull requests. We train and experiment with the NMT model on a set of 236k pairs of code components before and after the implementation of the changes provided in the pull requests. We show that, when applied in a narrow enough context (i.e., small/medium-sized pairs of methods before/after the pull request changes), NMT can automatically replicate the changes implemented by developers during pull requests in up to 36% of the cases. Moreover, our qualitative analysis shows that the model is capable of learning and replicating a wide variety of meaningful code changes, especially refactorings and bug-fixing activities. Our results pave the way for novel research in the area of DL on code, such as the automatic learning and applications of refactoring.","","","10.1109/ICSE.2019.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811910","Neural-Machine Translation;Empirical Study","Vocabulary;Crawlers;Computer bugs;Java;Data mining;Software engineering;Task analysis","language translation;learning (artificial intelligence);program debugging;program testing;public domain software;software maintenance;statistical analysis","pull requests;pull request changes;bug-fixing activities;source code;maintenance tasks;nontrivial coding activities;NMT model;code components;code changes;vulnerabilities detection;neural machine translation model;qualitative analysis","","","67","","","","","IEEE","IEEE Conferences"
"FastLane: Test Minimization for Rapidly Deployed Large-Scale Online Services","A. A. Philip; R. Bhagwan; R. Kumar; C. S. Maddila; N. Nagppan","Microsoft Research, India; Microsoft Research, India; Microsoft Research, India; Microsoft Research, India; Microsoft Research, Redmond","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","408","418","Today, we depend on numerous large-scale services for basic operations such as email. These services, built on the basis of Continuous Integration/Continuous Deployment (CI/CD) processes, are extremely dynamic: developers continuously commit code and introduce new features, functionality and fixes. Hundreds of commits may enter the code-base in a single day. Therefore one of the most time-critical, yet resource-intensive tasks towards ensuring code-quality is effectively testing such large code-bases. This paper presents FastLane, a system that performs data-driven test minimization. FastLane uses light-weight machine-learning models built upon a rich history of test and commit logs to predict test outcomes. Tests for which we predict outcomes need not be explicitly run, thereby saving us precious test-time and resources. Our evaluation on a large-scale email and collaboration platform service shows that our techniques can save 18.04%, i.e., almost a fifth of test-time while obtaining a test outcome accuracy of 99.99%.","","","10.1109/ICSE.2019.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812033","test prioritization;commit risk;machine learning","Testing;Correlation;Minimization;Predictive models;Complexity theory;Prediction algorithms;Machine learning","electronic mail;groupware;Internet;learning (artificial intelligence);program testing;software quality","FastLane;rapidly deployed large-scale online services;code-base;resource-intensive tasks;code-quality;light-weight machine-learning models;large-scale email;collaboration platform service;time-critical tasks;data-driven test minimization;continuous integration-continuous deployment processes;CI-CD processes;commit logs","","","39","","","","","IEEE","IEEE Conferences"
"DLFinder: Characterizing and Detecting Duplicate Logging Code Smells","Z. Li; T. Chen; J. Yang; W. Shang","Concordia University, Canada; Concordia University, Canada; Concordia University, Canada; Concordia University, Canada","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","152","163","Developers rely on software logs for a wide variety of tasks, such as debugging, testing, program comprehension, verification, and performance analysis. Despite the importance of logs, prior studies show that there is no industrial standard on how to write logging statements. Recent research on logs often only considers the appropriateness of a log as an individual item (e.g., one single logging statement); while logs are typically analyzed in tandem. In this paper, we focus on studying duplicate logging statements, which are logging statements that have the same static text message. Such duplications in the text message are potential indications of logging code smells, which may affect developers' understanding of the dynamic view of the system. We manually studied over 3K duplicate logging statements and their surrounding code in four large-scale open source systems: Hadoop, CloudStack, ElasticSearch, and Cassandra. We uncovered five patterns of duplicate logging code smells. For each instance of the code smell, we further manually identify the problematic (i.e., require fixes) and justifiable (i.e., do not require fixes) cases. Then, we contact developers in order to verify our manual study result. We integrated our manual study result and developers' feedback into our automated static analysis tool, DLFinder, which automatically detects problematic duplicate logging code smells. We evaluated DLFinder on the four manually studied systems and two additional systems: Camel and Wicket. In total, combining the results of DLFinder and our manual analysis, we reported 82 problematic code smell instances to developers and all of them have been fixed.","","","10.1109/ICSE.2019.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811945","log;code smell;duplicate log;static analysis;empirical study","Manuals;Static analysis;Cloud computing;Debugging;Tools;Semantics;Java","cloud computing;data handling;parallel processing;program debugging;program diagnostics;public domain software","DLFinder;duplicate logging code smells;software logs;single logging statement;duplicate logging statements;problematic duplicate logging code;static text message;dynamic view;open source systems;Hadoop;CloudStack;ElasticSearch;Cassandra;developers feedback","","1","54","","","","","IEEE","IEEE Conferences"
"FLOSS Participants' Perceptions About Gender and Inclusiveness: A Survey","A. Lee; J. C. Carver","The University of Alabama, United States of America; The University of Alabama, United States of America","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","677","687","Background: While FLOSS projects espouse openness and acceptance for all, in practice, female contributors often face discriminatory barriers to contribution. Aims: In this paper, we examine the extent to which these problems still exist. We also study male and female contributors' perceptions of other contributors. Method: We surveyed participants from 15 FLOSS projects, asking a series of open-ended, closed-ended, and behavioral scale questions to gather information about the issue of gender in FLOSS projects. Results: Though many of those we surveyed expressed a positive sentiment towards females who participate in FLOSS projects, some were still strongly against their inclusion. Often, the respondents who were against inclusiveness also believed their own sentiments were the prevailing belief in the community, contrary to our findings. Others did not see the purpose of attempting to be inclusive, expressing the sentiment that a discussion of gender has no place in FLOSS. Conclusions: FLOSS projects have started to move forwards in terms of gender acceptance. However, there is still a need for more progress in the inclusion of gender-diverse contributors.","","","10.1109/ICSE.2019.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812068","FLOSS;gender;survey;Open Source","Computer science;Software;Face;Data mining;Software engineering;Cognition;IEEE Fellows","gender issues;public domain software;sentiment analysis;social aspects of automation","gender-diverse contributors;inclusiveness;female contributors;FLOSS projects;gender acceptance;FLOSS participant perceptions;positive sentiment;male contributor perceptions;female contributor perceptions","","","27","","","","","IEEE","IEEE Conferences"
"Class Imbalance Evolution and Verification Latency in Just-in-Time Software Defect Prediction","G. G. Cabral; L. L. Minku; E. Shihab; S. Mujahid","University of Birmingham (UK) and Federal Rural University of Pernambuco (Brazil); University of Birmingham (UK); Concordia University (Canada); Concordia University (Canada)","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","666","676","Just-in-Time Software Defect Prediction (JIT-SDP) is an SDP approach that makes defect predictions at the software change level. Most existing JIT-SDP work assumes that the characteristics of the problem remain the same over time. However, JIT-SDP may suffer from class imbalance evolution. Specifically, the imbalance status of the problem (i.e., how much underrepresented the defect-inducing changes are) may be intensified or reduced over time. If occurring, this could render existing JIT-SDP approaches unsuitable, including those that re-build classifiers over time using only recent data. This work thus provides the first investigation of whether class imbalance evolution poses a threat to JIT-SDP. This investigation is performed in a realistic scenario by taking into account verification latency -- the often overlooked fact that labeled training examples arrive with a delay. Based on 10 GitHub projects, we show that JIT-SDP suffers from class imbalance evolution, significantly hindering the predictive performance of existing JIT-SDP approaches. Compared to state-of-the-art class imbalance evolution learning approaches, the predictive performance of JIT-SDP approaches was up to 97.2% lower in terms of g-mean. Hence, it is essential to tackle class imbalance evolution in JIT-SDP. We then propose a novel class imbalance evolution approach for the specific context of JIT-SDP. While maintaining top ranked g-means, this approach managed to produce up to 63.59% more balanced recalls on the defect-inducing and clean classes than state-of-the-art class imbalance evolution approaches. We thus recommend it to avoid overemphasizing one class over the other in JIT-SDP.","","","10.1109/ICSE.2019.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812072","Software defect prediction;class imbalance;verification latency;online learning;concept drift;ensembles","Software;Training;Machine learning algorithms;Machine learning;Prediction algorithms;Delays","learning (artificial intelligence);pattern classification;safety-critical software;sampling methods;software fault tolerance","SDP approach;predictive performance;class imbalance evolution approach;just-in-time software defect prediction;JIT-SDP approaches;top ranked g-means","","","36","","","","","IEEE","IEEE Conferences"
"Learning to Prioritize Test Programs for Compiler Testing","J. Chen; Y. Bai; D. Hao; Y. Xiong; H. Zhang; B. Xie","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Univ. of Newcastle, Newcastle, NSW, Australia; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","700","711","Compiler testing is a crucial way of guaranteeing the reliability of compilers (and software systems in general). Many techniques have been proposed to facilitate automated compiler testing. These techniques rely on a large number of test programs (which are test inputs of compilers) generated by some test-generation tools (e.g., CSmith). However, these compiler testing techniques have serious efficiency problems as they usually take a long period of time to find compiler bugs. To accelerate compiler testing, it is desirable to prioritize the generated test programs so that the test programs that are more likely to trigger compiler bugs are executed earlier. In this paper, we propose the idea of learning to test, which learns the characteristics of bug-revealing test programs from previous test programs that triggered bugs. Based on the idea of learning to test, we propose LET, an approach to prioritizing test programs for compiler testing acceleration. LET consists of a learning process and a scheduling process. In the learning process, LET identifies a set of features of test programs, trains a capability model to predict the probability of a new test program for triggering compiler bugs and a time model to predict the execution time of a test program. In the scheduling process, LET prioritizes new test programs according to their bug-revealing probabilities in unit time, which is calculated based on the two trained models. Our extensive experiments show that LET significantly accelerates compiler testing. In particular, LET reduces more than 50% of the testing time in 24.64% of the cases, and reduces between 25% and 50% of the testing time in 36.23% of the cases.","","","10.1109/ICSE.2017.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985706","","Computer bugs;Testing;Program processors;Life estimation;Feature extraction;Training;Predictive models","learning (artificial intelligence);program compilers;program testing;scheduling;software reliability","compiler reliability;software systems;automated compiler testing;test-generation tools;compiler bugs;bug-revealing test programs;LET;learning process;scheduling process;time model;bug-revealing probabilities","","2","79","","","","","IEEE","IEEE Conferences"
"Fuzzy Fine-Grained Code-History Analysis","F. Servant; J. A. Jones","NA; Univ. of California, Irvine, Irvine, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","746","757","Existing software-history techniques represent source-code evolution as an absolute and unambiguous mapping of lines of code in prior revisions to lines of code in subsequent revisions. However, the true evolutionary lineage of a line of code is often complex, subjective, and ambiguous. As such, existing techniques are predisposed to, both, overestimate and underestimate true evolution lineage. In this paper, we seek to address these issues by providing a more expressive model of code evolution, the fuzzy history graph, by representing code lineage as a continuous (i.e., fuzzy) metric rather than a discrete (i.e., absolute) one. Using this more descriptive model, we additionally provide a novel multi-revision code-history analysis - fuzzy history slicing. In our experiments over three real-world software systems, we found that the fuzzy history graph provides a tunable balance of precision and recall, and an overall improved accuracy over existing code-evolution models. Furthermore, we found that the use of such a fuzzy model of history provided improved accuracy for code-history analysis tasks.","","","10.1109/ICSE.2017.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985710","software engineering;computer aided software engineering;software maintenance;reasoning about programs","History;Analytical models;Solids;Computer bugs;Measurement;Computational modeling;Cloning","fuzzy set theory;graph theory;program slicing;software maintenance","fuzzy fine-grained code-history analysis;code lineage;novel multirevision code-history analysis;fuzzy history graph;fuzzy history slicing","","1","55","","","","","IEEE","IEEE Conferences"
"Resource-Aware Program Analysis Via Online Abstraction Coarsening","K. Heo; H. Oh; H. Yang","University of Pennsylvania; Korea University; KAIST","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","94","104","We present a new technique for developing a resource-aware program analysis. Such an analysis is aware of constraints on available physical resources, such as memory size, tracks its resource use, and adjusts its behaviors during fixpoint computation in order to meet the constraint and achieve high precision. Our resource-aware analysis adjusts behaviors by coarsening program abstraction, which usually makes the analysis consume less memory and time until completion. It does so multiple times during the analysis, under the direction of what we call a controller. The controller constantly intervenes in the fixpoint computation of the analysis and decides how much the analysis should coarsen the abstraction. We present an algorithm for learning a good controller automatically from benchmark programs. We applied our technique to a static analysis for C programs, where we control the degree of flow-sensitivity to meet a constraint on peak memory consumption. The experimental results with 18 real-world programs show that our algorithm can learn a good controller and the analysis with this controller meets the constraint and utilizes available memory effectively.","","","10.1109/ICSE.2019.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812143","static analysis;resource constraint;learning","Memory management;Static analysis;Reinforcement learning;Task analysis;Software engineering;Benchmark testing;Indexes","C language;program diagnostics;program verification","fixpoint computation;benchmark programs;static analysis;real-world programs;resource-aware program analysis;online abstraction coarsening;program abstraction;C programs;physical resources","","","37","","","","","IEEE","IEEE Conferences"
"LibD: Scalable and Precise Third-Party Library Detection in Android Markets","M. Li; W. Wang; P. Wang; S. Wang; D. Wu; J. Liu; R. Xue; W. Huo","Key Lab. of Network Assessment Technol., Inst. of Inf. Eng., Beijing, China; Key Lab. of Network Assessment Technol., Inst. of Inf. Eng., Beijing, China; Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA; Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA; Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA; Key Lab. of Network Assessment Technol., Inst. of Inf. Eng., Beijing, China; State Key Lab. of Inf. Security, Inst. of Inf. Eng., Beijing, China; Key Lab. of Network Assessment Technol., Inst. of Inf. Eng., Beijing, China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","335","346","With the thriving of the mobile app markets, third-party libraries are pervasively integrated in the Android applications. Third-party libraries provide functionality such as advertisements, location services, and social networking services, making multi-functional app development much more productive. However, the spread of vulnerable or harmful third-party libraries may also hurt the entire mobile ecosystem, leading to various security problems. The Android platform suffers severely from such problems due to the way its ecosystem is constructed and maintained. Therefore, third-party Android library identification has emerged as an important problem which is the basis of many security applications such as repackaging detection and malware analysis. According to our investigation, existing work on Android library detection still requires improvement in many aspects, including accuracy and obfuscation resilience. In response to these limitations, we propose a novel approach to identifying third-party Android libraries. Our method utilizes the internal code dependencies of an Android app to detect and classify library candidates. Different from most previous methods which classify detected library candidates based on similarity comparison, our method is based on feature hashing and can better handle code whose package and method names are obfuscated. Based on this approach, we have developed a prototypical tool called LibD and evaluated it with an update-to-date and large-scale dataset. Our experimental results on 1,427,395 apps show that compared to existing tools, LibD can better handle multi-package third-party libraries in the presence of name-based obfuscation, leading to significantly improved precision without the loss of scalability.","","","10.1109/ICSE.2017.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985674","Android;third-party library;software mining","Libraries;Androids;Humanoid robots;Tools;Mobile communication;Security;Java","Android (operating system);mobile computing;pattern classification;security of data;software libraries;software tools","LibD tool;precise third-party library detection;Android markets;mobile app markets;security problems;mobile ecosystem;third-party Android library identification;malware analysis;repackaging detection;internal code dependencies;library candidate classification;feature hashing;multipackage third-party libraries;name-based obfuscation","","12","46","","","","","IEEE","IEEE Conferences"
"Zero-Overhead Path Prediction with Progressive Symbolic Execution","R. Rutledge; S. Park; H. Khan; A. Orso; M. Prvulovic; A. Zajic","Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","234","245","In previous work, we introduced zero-overhead profiling (ZOP), a technique that leverages the electromagnetic emissions generated by the computer hardware to profile a program without instrumenting it. Although effective, ZOP has several shortcomings: it requires test inputs that achieve extensive code coverage for its training phase; it predicts path profiles instead of complete execution traces; and its predictions can suffer unrecoverable accuracy losses. In this paper, we present zero-overhead path prediction (ZOP-2), an approach that extends ZOP and addresses its limitations. First, ZOP-2 achieves high coverage during training through progressive symbolic execution (PSE)-symbolic execution of increasingly small program fragments. Second, ZOP-2 predicts complete execution traces, rather than path profiles. Finally, ZOP-2 mitigates the problem of path mispredictions by using a stateless approach that can recover from prediction errors. We evaluated our approach on a set of benchmarks with promising results; for the cases considered, (1) ZOP-2 achieved over 90% path prediction accuracy, and (2) PSE covered feasible paths missed by traditional symbolic execution, thus boosting ZOP-2's accuracy.","","","10.1109/ICSE.2019.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812035","symbolic execution;path profiling;tracing","Training;Predictive models;Instruments;Electromagnetics;Benchmark testing;Task analysis;Microsoft Windows","program testing;symbol manipulation","symbolic execution;path prediction accuracy;electromagnetic emissions;computer hardware;extensive code coverage;path mispredictions;progressive symbolic execution;zero-overhead profiling;prediction errors;zero-overhead path prediction;complete execution traces;path profiles","","","49","","","","","IEEE","IEEE Conferences"
"Tool Choice Matters: JavaScript Quality Assurance Tools and Usage Outcomes in GitHub Projects","D. Kavaler; A. Trockman; B. Vasilescu; V. Filkov","UC Davis; University of Evansville; CMU; UC Davis","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","476","487","Quality assurance automation is essential in modern software development. In practice, this automation is supported by a multitude of tools that fit different needs and require developers to make decisions about which tool to choose in a given context. Data and analytics of the pros and cons can inform these decisions. Yet, in most cases, there is a dearth of empirical evidence on the effectiveness of existing practices and tool choices. We propose a general methodology to model the time-dependent effect of automation tool choice on four outcomes of interest: prevalence of issues, code churn, number of pull requests, and number of contributors, all with a multitude of controls. On a large data set of npm JavaScript projects, we extract the adoption events for popular tools in three task classes: linters, dependency managers, and coverage reporters. Using mixed methods approaches, we study the reasons for the adoptions and compare the adoption effects within each class, and sequential tool adoptions across classes. We find that some tools within each group are associated with more beneficial outcomes than others, providing an empirical perspective for the benefits of each. We also find that the order in which some tools are implemented is associated with varying outcomes.","","","10.1109/ICSE.2019.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812106","quality assurance tools;empirical study","Tools;Task analysis;Pipelines;Quality assurance;Automation;Software;Switches","decision making;Internet;Java;program debugging;program diagnostics;program testing;project management;public domain software;quality assurance;software quality","adoption effects;sequential tool adoptions;beneficial outcomes;varying outcomes;tool choice matters;JavaScript quality assurance tools;GitHub projects;quality assurance automation;empirical evidence;time-dependent effect;automation tool choice;data set;npm JavaScript projects;adoption events;task classes;dependency managers;software development","","1","86","","","","","IEEE","IEEE Conferences"
"Investigating the Effects of Gender Bias on GitHub","N. Imtiaz; J. Middleton; J. Chakraborty; N. Robson; G. Bai; E. Murphy-Hill","North Carolina State University; North Carolina State University; North Carolina State University; North Carolina State University; North Carolina State University; Google LLC","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","700","711","Diversity, including gender diversity, is valued by many software development organizations, yet the field remains dominated by men. One reason for this lack of diversity is gender bias. In this paper, we study the effects of that bias by using an existing framework derived from the gender studies literature.We adapt the four main effects proposed in the framework by posing hypotheses about how they might manifest on GitHub,then evaluate those hypotheses quantitatively. While our results how that effects of gender bias are largely invisible on the GitHub platform itself, there are still signals of women concentrating their work in fewer places and being more restrained in communication than men.","","","10.1109/ICSE.2019.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812110","gender bias;software engineering","Software;Software engineering;Companies;Correlation;Encoding;Computer science","gender issues;software development management;software metrics","gender bias;gender diversity;software development organizations;gender studies;GitHub","","","50","","","","","IEEE","IEEE Conferences"
"Training Binary Classifiers as Data Structure Invariants","F. Molina; R. Degiovanni; P. Ponzio; G. Regis; N. Aguirre; M. Frias","CONICET and University of Rio Cuarto, Argentina; SnT, University of Luxembourg, Luxembourg; CONICET and University of Rio Cuarto, Argentina; University of Rio Cuarto, Argentina; CONICET and University of Rio Cuarto, Argentina; CONICET and Buenos Aires Institute of Technology, Argentina","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","759","770","We present a technique to distinguish valid from invalid data structure objects. The technique is based on building an artificial neural network, more precisely a binary classifier, and training it to identify valid and invalid instances of a data structure. The obtained classifier can then be used in place of the data structure's invariant, in order to attempt to identify (in)correct behaviors in programs manipulating the structure. In order to produce the valid objects to train the network, an assumed-correct set of object building routines is randomly executed. Invalid instances are produced by generating values for object fields that ""break"" the collected valid values, i.e., that assign values to object fields that have not been observed as feasible in the assumed-correct executions that led to the collected valid instances. We experimentally assess this approach, over a benchmark of data structures. We show that this learning technique produces classifiers that achieve significantly better accuracy in classifying valid/invalid objects compared to a technique for dynamic invariant detection, and leads to improved bug finding.","","","10.1109/ICSE.2019.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811951","Specification inference;Machine learning;Bug finding","Data structures;Tools;Java;Computer bugs;Software;Neural networks;Test pattern generators","data structures;learning (artificial intelligence);neural nets;pattern classification;program debugging;program testing","data structure invariants;invalid data structure objects;artificial neural network;invalid instances;object building routines;assign values;learning technique;dynamic invariant detection;valid instances;binary classifiers training;bug finding;valid data structure objects","","","43","","","","","IEEE","IEEE Conferences"
"Symbolic Model Extraction for Web Application Verification","I. Bocic; T. Bultan","Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA; Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","724","734","Modern web applications use complex data models and access control rules which lead to data integrity and access control errors. One approach to find such errors is to use formal verification techniques. However, as a first step, most formal verification techniques require extraction of a formal model which is a difficult problem in itself due to dynamic features of modern languages, and it is typically done either manually, or using ad hoc techniques. In this paper, we present a technique called symbolic model extraction for extracting formal data models from web applications. The key ideas of symbolic model extraction are 1) to use the source language interpreter for model extraction, which enables us to handle dynamic features of the language, 2) to use code instrumentation so that execution of each instrumented piece of code returns the formal model that corresponds to that piece of code, 3) to instrument the code dynamically so that the models of methods that are created at runtime can also be extracted, and 4) to execute both sides of branches during instrumented execution so that all program behaviors can be covered in a single instrumented execution. We implemented the symbolic model extraction technique for the Rails framework and used it to extract data and access control models from web applications. Our experiments demonstrate that symbolic model extraction is scalable and extracts formal models that are precise enough to find bugs in real-world applications without reporting too many false positives.","","","10.1109/ICSE.2017.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985708","Formal Verification;Model Extraction;Web Applications","Instruments;Feature extraction;Data models;Data mining;Rails;Runtime;Load modeling","authorisation;data integrity;formal verification","symbolic model extraction technique;program behaviors;source language interpreter;formal verification techniques;access control rules;complex data models;Web application verification","","","31","","","","","IEEE","IEEE Conferences"
"The Evolution of Continuous Experimentation in Software Product Development: From Data to a Data-Driven Organization at Scale","A. Fabijan; P. Dmitriev; H. H. Olsson; J. Bosch","Fac. of Technol. & Soc., Malmo Univ., Malmo, Sweden; Microsoft Anal. & Experimentation, Microsoft, Redmond, WA, USA; Fac. of Technol. & Soc., Malmo Univ., Malmo, Sweden; Dept. of Comput. Sci. & Eng., Chalmers Univ. of Technol., Goteborg, Sweden","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","770","780","Software development companies are increasingly aiming to become data-driven by trying to continuously experiment with the products used by their customers. Although familiar with the competitive edge that the A/B testing technology delivers, they seldom succeed in evolving and adopting the methodology. In this paper, and based on an exhaustive and collaborative case study research in a large software-intense company with highly developed experimentation culture, we present the evolution process of moving from ad-hoc customer data analysis towards continuous controlled experimentation at scale. Our main contribution is the ""Experimentation Evolution Model"" in which we detail three phases of evolution: technical, organizational and business evolution. With our contribution, we aim to provide guidance to practitioners on how to develop and scale continuous experimentation in software organizations with the purpose of becoming data-driven at scale.","","","10.1109/ICSE.2017.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985712","A/B testing;continuous experimentation;data science;customer feedback;continuous product innovation;Experimentation Evolution Model;product value;Experiment Owner","Software engineering","organisational aspects;product development;software engineering","continuous experimentation;software product development;data-driven organization;A/B testing technology;software-intense company;ad-hoc customer data analysis;experimentation evolution model;business evolution;organizational evolution;technical evolution;software organizations","","12","43","","","","","IEEE","IEEE Conferences"
"Adaptive Unpacking of Android Apps","L. Xue; X. Luo; L. Yu; S. Wang; D. Wu","Dept. of Comput., Hong Kong Polytech. Univ., Hong Kong, China; Dept. of Comput., Hong Kong Polytech. Univ., Hong Kong, China; Dept. of Comput., Hong Kong Polytech. Univ., Hong Kong, China; Dept. of Comput., Hong Kong Polytech. Univ., Hong Kong, China; Coll. of Inf. Sci. & Technol, Pennsylvania State Univ., University Park, PA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","358","369","More and more app developers use the packing services (or packers) to prevent attackers from reverse engineering and modifying the executable (or Dex files) of their apps. At the same time, malware authors also use the packers to hide the malicious component and evade the signature-based detection. Although there are a few recent studies on unpacking Android apps, it has been shown that the evolving packers can easily circumvent them because they are not adaptive to the changes of packers. In this paper, we propose a novel adaptive approach and develop a new system, named PackerGrind, to unpack Android apps. We also evaluate PackerGrind with real packed apps, and the results show that PackerGrind can successfully reveal the packers' protection mechanisms and recover the Dex files with low overhead, showing that our approach can effectively handle the evolution of packers.","","","10.1109/ICSE.2017.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985676","Dynamic Analysis;App Unpacking","Androids;Humanoid robots;Monitoring;Subspace constraints;Data collection;Runtime;Loading","Android (operating system);invasive software;reverse engineering","adaptive unpacking;Android apps;signature-based detection;reverse engineering;PackerGrind;malware authors","","12","61","","","","","IEEE","IEEE Conferences"
"Latent Patterns in Activities: A Field Study of How Developers Manage Context","S. Chattopadhyay; N. Nelson; Y. Ramirez Gonzalez; A. Amelia Leon; R. Pandita; A. Sarma","Oregon State University; Oregon State University; Oregon State University; Oregon State University; Phase Change Software; Oregon State University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","373","383","In order to build efficient tools that support complex programming tasks, it is imperative that we understand how developers program. We know that developers create a context around their programming task by gathering relevant information. We also know that developers decompose their tasks recursively into smaller units. However, important gaps exist in our knowledge about: (1) the role that context plays in supporting smaller units of tasks, (2) the relationship that exists among these smaller units, and (3) how context flows across them. The goal of this research is to gain a better understanding of how developers structure their tasks and manage context through a field study of ten professional developers in an industrial setting. Our analysis reveals that developers decompose their tasks into smaller units with distinct goals, that specific patterns exist in how they sequence these smaller units, and that developers may maintain context between those smaller units with related goals.","","","10.1109/ICSE.2019.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811986","context, task decomposition, field study","Task analysis;Software;Encoding;Tools;Java;Programming profession","formal specification;software development management;software quality","programming task;professional developers;complex programming tasks;latent patterns","","","34","","","","","IEEE","IEEE Conferences"
"Learning Syntactic Program Transformations from Examples","R. Rolim; G. Soares; L. D'Antoni; O. Polozov; S. Gulwani; R. Gheyi; R. Suzuki; B. Hartmann","UFCG, Brazil; UFCG, Brazil; Univ. of Wisconsin - Madison, Madison, WI, USA; Univ. of Washington, Seattle, WA, USA; Microsoft, Redmond, WA, USA; UFCG, Brazil; Univ. of Colorado Boulder, Boulder, CO, USA; UC Berkeley, Berkeley, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","404","415","Automatic program transformation tools can be valuable for programmers to help them with refactoring tasks, and for Computer Science students in the form of tutoring systems that suggest repairs to programming assignments. However, manually creating catalogs of transformations is complex and time-consuming. In this paper, we present REFAZER, a technique for automatically learning program transformations. REFAZER builds on the observation that code edits performed by developers can be used as input-output examples for learning program transformations. Example edits may share the same structure but involve different variables and subexpressions, which must be generalized in a transformation at the right level of abstraction. To learn transformations, REFAZER leverages state-of-the-art programming-by-example methodology using the following key components: (a) a novel domain-specific language (DSL) for describing program transformations, (b) domain-specific deductive algorithms for efficiently synthesizing transformations in the DSL, and (c) functions for ranking the synthesized transformations. We instantiate and evaluate REFAZER in two domains. First, given examples of code edits used by students to fix incorrect programming assignment submissions, we learn program transformations that can fix other students' submissions with similar faults. In our evaluation conducted on 4 programming tasks performed by 720 students, our technique helped to fix incorrect submissions for 87% of the students. In the second domain, we use repetitive code edits applied by developers to the same project to synthesize a program transformation that applies these edits to other locations in the code. In our evaluation conducted on 56 scenarios of repetitive edits taken from three large C# open-source projects, REFAZER learns the intended program transformation in 84% of the cases using only 2.9 examples on average.","","","10.1109/ICSE.2017.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985680","Program transformation;program synthesis;tutoring systems;refactoring","DSL;Programming profession;Tools;C# languages;Pattern matching;Open source software","automatic programming;program processors","syntactic program transformations learning;REFAZER;programming-by-example methodology;domain-specific language;domain-specific deductive algorithms;DSL;code edits;C# open-source projects","","10","50","","","","","IEEE","IEEE Conferences"
"Why Does Code Review Work for Open Source Software Communities?","A. Alami; M. Leavitt Cohn; A. WƒÖsowski","IT University of Copenhagen; IT University of Copenhagen, Denmark; IT University of Copenhagen, Denmark","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1073","1083","Open source software communities have demonstrated that they can produce high quality results. The overall success of peer code review, commonly used in open source projects, has likely contributed strongly to this success. Code review is an emotionally loaded practice, with public exposure of reputation and ample opportunities for conflict. We set off to ask why code review works for open source communities, despite this inherent challenge. We interviewed 21 open source contributors from four communities and participated in meetings of ROS community devoted to implementation of the code review process. It appears that the hacker ethic is a key reason behind the success of code review in FOSS communities. It is built around the ethic of passion and the ethic of caring. Furthermore, we observed that tasks of code review are performed with strong intrinsic motivation, supported by many non-material extrinsic motivation mechanisms, such as desire to learn, to grow reputation, or to improve one's positioning on the job market. In the paper, we describe the study design, analyze the collected data and formulate 20 proposals for how what we know about hacker ethics and human and social aspects of code review, could be exploited to improve the effectiveness of the practice in software projects.","","","10.1109/ICSE.2019.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812037","Open Source, Code Review, Motivation","Interviews;Software;Standards;Ethics;Guidelines;Robot kinematics","human factors;public domain software;software engineering","open source projects;code review process;code review work;open source software communities;peer code review;open source contributors;ROS community;FOSS communities;nonmaterial extrinsic motivation mechanisms","","","46","","","","","IEEE","IEEE Conferences"
"The Seven Sins: Security Smells in Infrastructure as Code Scripts","A. Rahman; C. Parnin; L. Williams","North Carolina State University, USA; North Carolina State University, USA; North Carolina State University, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","164","175","Practitioners use infrastructure as code (IaC) scripts to provision servers and development environments. While developing IaC scripts, practitioners may inadvertently introduce security smells. Security smells are recurring coding patterns that are indicative of security weakness and can potentially lead to security breaches. The goal of this paper is to help practitioners avoid insecure coding practices while developing infrastructure as code (IaC) scripts through an empirical study of security smells in IaC scripts. We apply qualitative analysis on 1,726 IaC scripts to identify seven security smells. Next, we implement and validate a static analysis tool called Security Linter for Infrastructure as Code scripts (SLIC) to identify the occurrence of each smell in 15,232 IaC scripts collected from 293 open source repositories. We identify 21,201 occurrences of security smells that include 1,326 occurrences of hard-coded passwords. We submitted bug reports for 1,000 randomly-selected security smell occurrences. We obtain 212 responses to these bug reports, of which 148 occurrences were accepted by the development teams to be fixed. We observe security smells can have a long lifetime, e.g., a hard-coded secret can persist for as long as 98 months, with a median lifetime of 20 months.","","","10.1109/ICSE.2019.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812041","devops, devsecops, empirical study, infrastructure as code, puppet, security, smell, static analysis","Password;Encoding;Tools;Software;Servers;Static analysis","program debugging;program diagnostics;security of data","hard-coded passwords;security smells;hard-coded secret;security weakness;security breaches;IaC scripts;security linter tool;security linter for infrastructure as code scripts","","6","56","","","","","IEEE","IEEE Conferences"
"IconIntent: Automatic Identification of Sensitive UI Widgets Based on Icon Classification for Android Apps","X. Xiao; X. Wang; Z. Cao; H. Wang; P. Gao","Case Western Reserve University; The University of Texas at San Antonio; Case Western Reserve University; Case Western Reserve University; Princeton University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","257","268","Many mobile applications (i.e., apps) include UI widgets to use or collect users' sensitive data. Thus, to identify suspicious sensitive data usage such as UI-permission mismatch, it is crucial to understand the intentions of UI widgets. However, many UI widgets leverage icons of specific shapes (object icons) and icons embedded with text (text icons) to express their intentions, posing challenges for existing detection techniques that analyze only textual data to identify sensitive UI widgets. In this work, we propose a novel app analysis framework, ICONINTENT, that synergistically combines program analysis and icon classification to identify sensitive UI widgets in Android apps. ICONINTENT automatically associates UI widgets and icons via static analysis on app's UI layout files and code, and then adapts computer vision techniques to classify the associated icons into eight categories of sensitive data. Our evaluations of ICONINTENT on 150 apps from Google Play show that ICONINTENT can detect 248 sensitive UI widgets in 97 apps, achieving a precision of 82.4%. When combined with SUPOR, the state-of-the-art sensitive UI widget identification technique based on text analysis, SUPOR +ICONINTENT can detect 487 sensitive UI widgets (101.2% improvement over SUPOR only), and reduces suspicious permissions to be inspected by 50.7% (129.4% improvement over SUPOR only).","","","10.1109/ICSE.2019.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812108","Mobile Security;Program Analysis;Computer Vision;Icon Recognition","Layout;Image color analysis;Optical character recognition software;Static analysis;Global Positioning System;Feature extraction;Shape","Android (operating system);computer vision;graphical user interfaces;image classification;mobile computing;program diagnostics;text analysis;user interfaces","icon classification;android apps;suspicious sensitive data usage;UI widget identification technique;sensitive UI widgets;ICONINTENT;SUPOR;suspicious permissions;Google Play;mobile applications;user sensitive data;textual data;computer vision techniques","","1","45","","","","","IEEE","IEEE Conferences"
"Detecting Atomicity Violations for Event-Driven Node.js Applications","X. Chang; W. Dou; Y. Gao; J. Wang; J. Wei; T. Huang","State Key Lab of Computer Sciences; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","631","642","Node.js has been widely-used as an event-driven server-side architecture. To improve performance, a task in a Node.js application is usually divided into a group of events, which are non-deterministically scheduled by Node.js. Developers may assume that the group of events (named atomic event group) should be atomically processed, without interruption. However, the atomicity of an atomic event group is not guaranteed by Node.js, and thus other events may interrupt the execution of the atomic event group, break down the atomicity and cause unexpected results. Existing approaches mainly focus on event race among two events, and cannot detect high-level atomicity violations among a group of events. In this paper, we propose NodeAV, which can predictively detect atomicity violations in Node.js applications based on an execution trace. Based on happens-before relations among events in an execution trace, we automatically identify a pair of events that should be atomically processed, and use predefined atomicity violation patterns to detect atomicity violations. We have evaluated NodeAV on real-world Node.js applications. The experimental results show that NodeAV can effectively detect atomicity violations in these Node.js applications.","","","10.1109/ICSE.2019.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811949","Node.js;event-driven architecture;atomicity violation;happens-before","Task analysis;Programming;Instruction sets;Computer architecture;Message systems;Concurrent computing;Computer bugs","Java;program testing;scheduling","event-driven server-side architecture;Node.js application;atomic event group;event race;atomicity violation patterns;event-driven Node.js applications;NodeAV","","","48","","","","","IEEE","IEEE Conferences"
"Dynamic Slicing for Android","T. Azim; A. Alavi; I. Neamtiu; R. Gupta","University of California, Riverside; University of California, Riverside; New Jersey Institute of Technology; University of California, Riverside","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1154","1164","Dynamic program slicing is useful for a variety of tasks, from testing to debugging to security. Prior slicing approaches have targeted traditional desktop/server platforms, rather than mobile platforms such as Android. Slicing mobile, event-based systems is challenging due to their asynchronous callback construction and the IPC (interprocess communication)- heavy, sensor-driven, timing-sensitive nature of the platform. To address these problems, we introduce AndroidSlicer1, the first slicing approach for Android. AndroidSlicer combines a novel asynchronous slicing approach for modeling data and control dependences in the presence of callbacks with lightweight and precise instrumentation; this allows slicing for apps running on actual phones, and without requiring the app's source code. Our slicer is capable of handling a wide array of inputs that Android supports without adding any noticeable overhead. Experiments on 60 apps from Google Play show that AndroidSlicer is effective (reducing the number of instructions to be examined to 0.3% of executed instructions) and efficient (app instrumentation and post-processing combined takes 31 seconds); all while imposing a runtime overhead of just 4%. We present three applications of AndroidSlicer that are particularly relevant in the mobile domain: (1) finding and tracking input parts responsible for an error/crash, (2) fault localization, i.e., finding the instructions responsible for an error/crash, and (3) reducing the regression test suite. Experiments with these applications on an additional set of 18 popular apps indicate that AndroidSlicer is effective for Android testing and debugging.","","","10.1109/ICSE.2019.00118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811953","Mobile apps, Android, Dynamic analysis","Smart phones;Registers;Computer crashes;Testing;Runtime;Debugging;Pins","Android (operating system);mobile computing;program debugging;program slicing;program testing","timing-sensitive nature;AndroidSlicer1;modeling data;control dependences;lightweight instrumentation;precise instrumentation;executed instructions;mobile domain;tracking input parts;regression test suite;Android testing;debugging;dynamic program slicing;mobile platforms;mobile event-based systems;asynchronous callback construction;IPC;interprocess communication;asynchronous slicing approach","","","32","","","","","IEEE","IEEE Conferences"
"The Product Backlog","T. Sedano; P. Ralph; C. P√©raire","Carnegie Mellon University, Silicon Valley Campus; University of Auckland; Carnegie Mellon University, Silicon Valley Campus","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","200","211","Context: One of the most common artifacts in contemporary software projects is a product backlog comprising user stories, bugs, chores or other work items. However, little research has investigated how the backlog is generated or the precise role it plays in a project. Objective: The purpose of this paper is to determine what is a product backlog, what is its role, and how does it emerge? Method: Following Constructivist Grounded Theory, we conducted a two-year, five-month participant-observation study of eight software development projects at Pivotal, a large, international software company. We interviewed 56 software engineers, product designers, and product managers.We conducted a survey of 27 product designers. We alternated between analysis and theoretical sampling until achieving theoretical saturation. Results: We observed 13 practices and 6 obstacles related to product backlog generation. Limitations: Grounded Theory does not support statistical generalization. While the proposed theory of product backlogs appears widely applicable, organizations with different software development cultures may use different practices. Conclusion: The product backlog is simultaneously a model of work to be done and a boundary object that helps bridge the gap between the processes of generating user stories and realizing them in working code. It emerges from sensemaking (the team making sense of the project context) and coevolution (a cognitive process where the team simultaneously refines its understanding of the problematic context and fledgling solution concepts).","","","10.1109/ICSE.2019.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812076","Product-backlog;dual-track-agile;scrum;lean;extreme-programming;user-stories;design-thinking;user-centered-design;feature-engineering","Software;Interviews;Programming;Companies;Buildings;Stakeholders;Data collection","project management","software development projects;product backlog generation;puser stories;software development cultures;constructivist grounded theory","","","58","","","","","IEEE","IEEE Conferences"
"How Do Developers Fix Cross-Project Correlated Bugs? A Case Study on the GitHub Scientific Python Ecosystem","W. Ma; L. Chen; X. Zhang; Y. Zhou; B. Xu","State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China; State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China; State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","381","392","GitHub, a popular social-software-development platform, has fostered a variety of software ecosystems where projects depend on one another and practitioners interact with each other. Projects within an ecosystem often have complex inter-dependencies that impose new challenges in bug reporting and fixing. In this paper, we conduct an empirical study on cross-project correlated bugs, i.e., causally related bugs reported to different projects, focusing on two aspects: 1) how developers track the root causes across projects, and 2) how the downstream developers coordinate to deal with upstream bugs. Through manual inspection of bug reports collected from the scientific Python ecosystem and an online survey with developers, this study reveals the common practices of developers and the various factors in fixing cross-project bugs. These findings provide implications for future software bug analysis in the scope of ecosystem, as well as shed light on the requirements of issue trackers for such bugs.","","","10.1109/ICSE.2017.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985678","GitHub ecosystems;cross-project correlated bugs;root causes tracking;coordinate","Computer bugs;Ecosystems;Software;Collaboration;Maintenance engineering;Tools;Software engineering","configuration management;object-oriented languages;program debugging;project management;software development management","cross-project correlated bugs;GitHub scientific Python ecosystem;upstream bugs;bug reports","","9","39","","","","","IEEE","IEEE Conferences"
"DeepPerf: Performance Prediction for Configurable Software with Deep Sparse Neural Network","H. Ha; H. Zhang","The University of Newcastle, Australia; The University of Newcastle, Australia","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1095","1106","Many software systems provide users with a set of configuration options and different configurations may lead to different runtime performance of the system. As the combination of configurations could be exponential, it is difficult to exhaustively deploy and measure system performance under all possible configurations. Recently, several learning methods have been proposed to build a performance prediction model based on performance data collected from a small sample of configurations, and then use the model to predict system performance under a new configuration. In this paper, we propose a novel approach to model highly configurable software system using a deep feedforward neural network (FNN) combined with a sparsity regularization technique, e.g. the L1 regularization. Besides, we also design a practical search strategy for automatically tuning the network hyperparameters efficiently. Our method, called DeepPerf, can predict performance values of highly configurable software systems with binary and/or numeric configuration options at much higher prediction accuracy with less training data than the state-of-the art approaches. Experimental results on eleven public real-world datasets confirm the effectiveness of our approach.","","","10.1109/ICSE.2019.00113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811988","software performance prediction, deep sparse feedforward neural network, highly configurable systems, sparsity regularization","Software systems;Predictive models;Software performance;Tuning;System performance;Biological neural networks;Data models","feedforward neural nets;learning (artificial intelligence)","deep feedforward neural network;network hyperparameters;performance values;binary configuration options;numeric configuration options;deep sparse neural network;system performance;performance prediction model;performance data;configurable software system;configurable software systems;runtime performance","","3","55","","","","","IEEE","IEEE Conferences"
"Heuristically Matching Solution Spaces of Arithmetic Formulas to Efficiently Reuse Solutions","A. Aquino; G. Denaro; M. Pezz√®","Univ. della Svizzera Italiana, Lugano, Switzerland; Univ. of Milano-Bicocca, Milan, Italy; Univ. della Svizzera Italiana, Lugano, Switzerland","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","427","437","Many symbolic program analysis techniques rely on SMT solvers to verify properties of programs. Despite the remarkable progress made in the development of such tools, SMT solvers still represent a main bottleneck to the scalability of these techniques. Recent approaches tackle this bottleneck by reusing solutions of formulas that recur during program analysis, thus reducing the number of queries to SMT solvers. Current approaches only reuse solutions across formulas that are equivalent to, contained in or implied by other formulas, as identified through a set of predefined rules, and cannot reuse solutions across formulas that differ in their structure, even if they share some potentially reusable solutions. In this paper, we propose a novel approach that can reuse solutions across formulas that share at least one solution, regardless of their structural resemblance. Our approach exploits a novel heuristic to efficiently identify solutions computed for previously solved formulas and most likely shared by new formulas. The results of an empirical evaluation of our approach on two different logics show that our approach can identify on average more reuse opportunities and is markedly faster than competing approaches.","","","10.1109/ICSE.2017.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985682","SMT-based program analysis;symbolic execution;SMT solvers;solution reuse","Scalability;Terminology;Heuristic algorithms;Software engineering;Tools;Operating systems;Mission critical systems","computability;program diagnostics","heuristically matching solution spaces;arithmetic formulas;symbolic program analysis techniques;SMT solvers;structural resemblance","","1","19","","","","","IEEE","IEEE Conferences"
"Developer Reading Behavior While Summarizing Java Methods: Size and Context Matters","N. J. Abid; B. Sharif; N. Dragan; H. Alrasheed; J. I. Maletic","Taibah University, Saudi Arabia; University of Nebraska - Lincoln, USA; Kent State University, USA; King Saud University, Saudi Arabia; Kent State University, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","384","395","An eye-tracking study of 18 developers reading and summarizing Java methods is presented. The developers provide a written summary for methods assigned to them. In total, 63 methods are used from five different systems. Previous studies on this topic use only short methods presented in isolation usually as images. In contrast, this work presents the study in the Eclipse IDE allowing access to all the source code in the system. The developer can navigate via scrolling and switching files while writing the summary. New eye-tracking infrastructure allows for this improvement in the study environment. Data collected includes eye gazes on source code, written summaries, and time to complete each summary. Unlike prior work that concluded developers focus on the signature the most, these results indicate that they tend to focus on the method body more than the signature. Moreover, both experts and novices tend to revisit control flow terms rather than reading them for a long period. They also spend a significant amount of gaze time and have higher gaze visits when they read call terms. Experts tend to revisit the body of the method significantly more frequently than its signature as the size of the method increases. Moreover, experts tend to write their summaries from source code lines that they read the most.","","","10.1109/ICSE.2019.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812039","source code summarization;eye tracking;program comprehension;empirical study","Java;Gaze tracking;Task analysis;Natural languages;Software engineering;Switches","gaze tracking;human factors;Java","Java methods;written summary;gaze time;source code lines;eye gazes;eye tracking infrastructure;developer reading behavior;Eclipse IDE;control flow","","2","48","","","","","IEEE","IEEE Conferences"
"SafeCheck: Safety Enhancement of Java Unsafe API","S. Huang; J. Guo; S. Li; X. Li; Y. Qi; K. Chow; J. Huang","Department of Computer Science, Texas A&M University; Alibaba Group, China; Alibaba Group, China; Alibaba Group, US.; Alibaba Group, US.; Alibaba Group, China; Department of Computer Science, Texas A&M University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","889","899","Java is a safe programming language by providing bytecode verification and enforcing memory protection. For instance, programmers cannot directly access the memory but have to use object references. Yet, the Java runtime provides an Unsafe API as a backdoor for the developers to access the low- level system code. Whereas the Unsafe API is designed to be used by the Java core library, a growing community of third-party libraries use it to achieve high performance. The Unsafe API is powerful, but dangerous, which leads to data corruption, resource leaks and difficult-to-diagnose JVM crash if used improperly. In this work, we study the Unsafe crash patterns and propose a memory checker to enforce memory safety, thus avoiding the JVM crash caused by the misuse of the Unsafe API at the bytecode level. We evaluate our technique on real crash cases from the openJDK bug system and real-world applications from AJDK. Our tool reduces the efforts from several days to a few minutes for the developers to diagnose the Unsafe related crashes. We also evaluate the runtime overhead of our tool on projects using intensive Unsafe operations, and the result shows that our tool causes a negligible perturbation to the execution of the applications.","","","10.1109/ICSE.2019.00095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811920","Java Unsafe API;Dynamic Analysis;Bytecode;Memoey Safety","Java;Safety;Tools;Computer bugs;Runtime;Libraries","application program interfaces;Java;program debugging;security of data;storage management","memory safety;bytecode verification;Java runtime;low- level system code;Java core library;memory checker;memory protection;safety enhancement;Java unsafe API;programming language;unsafe crash patterns;openJDK bug system;JVM crash","","","28","","","","","IEEE","IEEE Conferences"
"StoryDroid: Automated Generation of Storyboard for Android Apps","S. Chen; L. Fan; C. Chen; T. Su; W. Li; Y. Liu; L. Xu","East China Normal University, China; East China Normal University, China; Monash University, Australia; Nanyang Technological University, Singapore; New York University Shanghai, China; Nanyang Technological University, Singapore; New York University Shanghai, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","596","607","Mobile apps are now ubiquitous. Before developing a new app, the development team usually endeavors painstaking efforts to review many existing apps with similar purposes. The review process is crucial in the sense that it reduces market risks and provides inspiration for app development. However, manual exploration of hundreds of existing apps by different roles (e.g., product manager, UI/UX designer, developer) in a development team can be ineffective. For example, it is difficult to completely explore all the functionalities of the app in a short period of time. Inspired by the conception of storyboard in movie production, we propose a system, StoryDroid, to automatically generate the storyboard for Android apps, and assist different roles to review apps efficiently. Specifically, StoryDroid extracts the activity transition graph and leverages static analysis techniques to render UI pages to visualize the storyboard with the rendered pages. The mapping relations between UI pages and the corresponding implementation code (e.g., layout code, activity code, and method hierarchy) are also provided to users. Our comprehensive experiments unveil that StoryDroid is effective and indeed useful to assist app development. The outputs of StoryDroid enable several potential applications, such as the recommendation of UI design and layout code.","","","10.1109/ICSE.2019.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812043","Android app;Storyboard;Competitive analysis;App review","Layout;Google;User interfaces;Semantics;Motion pictures;Production;Visualization","Android (operating system);graphical user interfaces;mobile computing;program diagnostics","storyboard;Android apps;mobile apps;StoryDroid;activity transition graph;UI pages;automated generation;static analysis techniques","","2","70","","","","","IEEE","IEEE Conferences"
"Exposing Library API Misuses Via Mutation Analysis","M. Wen; Y. Liu; R. Wu; X. Xie; S. Cheung; Z. Su","The Hong Kong University of Science and Technology, Hong Kong, China; Shenzhen Key Laboratory of Computational Intelligence Southern University of Science and Technology, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, China; Sun Yat-sen University; The Hong Kong University of Science and Technology, Hong Kong, China; ETH Zurich, Switzerland & UC Davis, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","866","877","Misuses of library APIs are pervasive and often lead to software crashes and vulnerability issues. Various static analysis tools have been proposed to detect library API misuses. They often involve mining frequent patterns from a large number of correct API usage examples, which can be hard to obtain in practice. They also suffer from low precision due to an over-simplified assumption that a deviation from frequent usage patterns indicates a misuse. We make two observations on the discovery of API misuse patterns. First, API misuses can be represented as mutants of the corresponding correct usages. Second, whether a mutant will introduce a misuse can be validated via executing it against a test suite and analyzing the execution information. Based on these observations, we propose MutApi, the first approach to discovering API misuse patterns via mutation analysis. To effectively mimic API misuses based on correct usages, we first design eight effective mutation operators inspired by the common characteristics of API misuses. MutApi generates mutants by applying these mutation operators on a set of client projects and collects mutant-killing tests as well as the associated stack traces. Misuse patterns are discovered from the killed mutants that are prioritized according to their likelihood of causing API misuses based on the collected information. We applied MutApi on 16 client projects with respect to 73 popular Java APIs. The results show that MutApi is able to discover substantial API misuse patterns with a high precision of 0.78. It also achieves a recall of $0.49$ on the MuBench benchmark, which outperforms the state-of-the-art techniques.","","","10.1109/ICSE.2019.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812114","Mutation Analysis;Library API Misuse","Libraries;Computer bugs;Java;Software;Tools;Detectors","application program interfaces;data mining;Java;program diagnostics;program testing;security of data","substantial API misuse patterns;library API misuses;mutation analysis;frequent usage patterns;Java API;static analysis tools;MutApi;mutant-killing tests;frequent pattern mining","","","60","","","","","IEEE","IEEE Conferences"
"Semantically Enhanced Software Traceability Using Deep Learning Techniques","J. Guo; J. Cheng; J. Cleland-Huang","Univ. of Notre Dame, Notre Dame, IN, USA; Univ. of Notre Dame, Notre Dame, IN, USA; Univ. of Notre Dame, Notre Dame, IN, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","3","14","In most safety-critical domains the need for traceability is prescribed by certifying bodies. Trace links are generally created among requirements, design, source code, test cases and other artifacts, however, creating such links manually is time consuming and error prone. Automated solutions use information retrieval and machine learning techniques to generate trace links, however, current techniques fail to understand semantics of the software artifacts or to integrate domain knowledge into the tracing process and therefore tend to deliver imprecise and inaccurate results. In this paper, we present a solution that uses deep learning to incorporate requirements artifact semantics and domain knowledge into the tracing solution. We propose a tracing network architecture that utilizes Word Embedding and Recurrent Neural Network (RNN) models to generate trace links. Word embedding learns word vectors that represent knowledge of the domain corpus and RNN uses these word vectors to learn the sentence semantics of requirements artifacts. We trained 360 different configurations of the tracing network using existing trace links in the Positive Train Control domain and identified the Bidirectional Gated Recurrent Unit (BI-GRU) as the best model for the tracing task. BI-GRU significantly out-performed state-of-the-art tracing methods including the Vector Space Model and Latent Semantic Indexing.","","","10.1109/ICSE.2017.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985645","Traceability;Deep Learning;Recurrent Neural Network;Semantic Representation","Semantics;Machine learning;Recurrent neural networks;Standards;Training;Natural language processing;Software","information retrieval;knowledge representation;learning (artificial intelligence);program diagnostics;program testing;programming language semantics;recurrent neural nets;safety-critical software;source code (software);vectors","semantically enhanced software traceability;deep learning techniques;safety-critical domains;source code;test cases;information retrieval technique;machine learning technique;trace link generation;requirements artifact semantics;domain knowledge;tracing network architecture;word embedding model;recurrent neural network model;word vectors;knowledge representation;domain corpus;sentence semantics;requirements artifacts;positive train control domain;bidirectional gated recurrent unit;BI-GRU;vector space model;latent semantic indexing","","28","70","","","","","IEEE","IEEE Conferences"
"A System Identification Based Oracle for Control-CPS Software Fault Localization","Z. He; Y. Chen; E. Huang; Q. Wang; Y. Pei; H. Yuan","The Hong Kong Polytechnic University, Hong Kong SAR of China; The Hong Kong Polytechnic University, Hong Kong SAR of China; The Hong Kong Polytechnic University, Hong Kong SAR of China; The Hong Kong Polytechnic University, Hong Kong SAR of China; The Hong Kong Polytechnic University, Hong Kong SAR of China; The Chinese University of Hong Kong, Hong Kong SAR of China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","116","127","Control-CPS software fault localization (SFL, aka bug localization) is of critical importance as bugs may cause major failures, even injuries/deaths. To locate the bugs in control-CPSs, SFL tools often demand many labeled (""correct""/""incorrect"") source code execution traces as inputs. To label the correctness of these traces, we must judge the corresponding control-CPS physical trajectories' correctness. However, unlike discrete outputs, the boundaries between correct and incorrect physical trajectories are often vague. The mechanism (aka oracle) to judge the physical trajectories' correctness thus becomes a major challenge. So far, the ad hoc practice of ``human oracles'' is still widely used, whose qualities heavily depend on the human experts' expertise and availability. This paper proposes an oracle based on the well adopted autoregressive system identification (AR-SI). With proven success for controlling black-box physical systems, AR-SI is adapted by us to identify the buggy control-CPS as a black-box. We use this identification result as an oracle to judge the control-CPS's behaviors, and propose a methodology to prepare traces for control-CPS debugging. Comprehensive evaluations on classic control-CPSs with injected real-life and artificial bugs show that our proposed approach significantly outperforms the human oracle approach in SFL accuracy (recall) and latency, and in oracle false positive/negative rates. Our approach also helps discover a new real-life bug in a consumer-grade control-CPS.","","","10.1109/ICSE.2019.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811955","Oracle;Cyber-Physical System;Debug;Testing","Trajectory;Computer bugs;Tools;Software;Emulation;Debugging","autoregressive processes;cyber-physical systems;program debugging;software fault tolerance;software tools;source code (software)","buggy control-CPS;control-CPS debugging;control-CPS software fault localization;aka bug localization;aka oracle;human oracles;autoregressive system identification;black-box physical systems;consumer-grade control;SFL tools;source code execution;AR-SI","","","101","","","","","IEEE","IEEE Conferences"
"Detecting Incorrect Build Rules","N. Licker; A. Rice","University of Cambridge; University of Cambridge","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1234","1244","Automated build systems are routinely used by software engineers to minimize the number of objects that need to be recompiled after incremental changes to the source files of a project. In order to achieve efficient and correct builds, developers must provide the build tools with dependency information between the files and modules of a project, usually expressed in a macro language specific to each build tool. In order to guarantee correctness, the authors of these tools are responsible for enumerating all the files whose contents an output depends on. Unfortunately, this is a tedious process and not all dependencies are captured in practice, which leads to incorrect builds. We automatically uncover such missing dependencies through a novel method that we call build fuzzing. The correctness of build definitions is verified by modifying files in a project, triggering incremental builds and comparing the set of changed files to the set of expected changes. These sets are determined using a dependency graph inferred by tracing the system calls executed during a clean build. We evaluate our method by exhaustively testing build rules of open-source projects, uncovering issues leading to race conditions and faulty builds in 31 of them. We provide a discussion of the bugs we detect, identifying anti-patterns in the use of the macro languages. We fix some of the issues in projects where the features of build systems allow a clean solution.","","","10.1109/ICSE.2019.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812082","build tools;exhaustive testing;verification","Tools;Generators;Computer bugs;Linux;C++ languages;Open source software;Kernel","graph theory;program debugging;program testing;public domain software;software quality","build definitions;changed files;dependency graph;open-source projects;software engineers;dependency information","","1","25","","","","","IEEE","IEEE Conferences"
"Unsupervised Software-Specific Morphological Forms Inference from Informal Discussions","C. Chen; Z. Xing; X. Wang","Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Res. Sch. of Comput. Sci., Australian Nat. Univ., Canberra, ACT, Australia; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","450","461","Informal discussions on social platforms (e.g., Stack Overflow) accumulates a large body of programming knowledge in natural language text. Natural language process (NLP) techniques can be exploited to harvest this knowledge base for software engineering tasks. To make an effective use of NLP techniques, consistent vocabulary is essential. Unfortunately, the same concepts are often intentionally or accidentally mentioned in many different morphological forms in informal discussions, such as abbreviations, synonyms and misspellings. Existing techniques to deal with such morphological forms are either designed for general English or predominantly rely on domain-specific lexical rules. A thesaurus of software-specific terms and commonly-used morphological forms is desirable for normalizing software engineering text, but very difficult to build manually. In this work, we propose an automatic approach to build such a thesaurus. Our approach identifies software-specific terms by contrasting software-specific and general corpuses, and infers morphological forms of software-specific terms by combining distributed word semantics, domain-specific lexical rules and transformations, and graph analysis of morphological relations. We evaluate the coverage and accuracy of the resulting thesaurus against community-curated lists of software-specific terms, abbreviations and synonyms. We also manually examine the correctness of the identified abbreviations and synonyms in our thesaurus. We demonstrate the usefulness of our thesaurus in a case study of normalizing questions from Stack Overflow and CodeProject.","","","10.1109/ICSE.2017.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985684","abbreviation;synonym;morphological form;word embedding;Stack Overflow","Software engineering;Encyclopedias;Electronic publishing;Internet;Thesauri;Dictionaries","natural language processing;software engineering;text analysis;thesauri","unsupervised software-specific morphological forms inference;informal discussions;natural language process;software engineering tasks;NLP techniques;software-specific terms;thesaurus;domain-specific lexical rules","","4","60","","","","","IEEE","IEEE Conferences"
"ActionNet: Vision-Based Workflow Action Recognition From Programming Screencasts","D. Zhao; Z. Xing; C. Chen; X. Xia; G. Li","Australian National University; Australian National University; Monash University; Monash University; Shanghai Jiao Tong University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","350","361","Programming screencasts have two important applications in software engineering context: study developer behaviors, information needs and disseminate software engineering knowledge. Although programming screencasts are easy to produce, they are not easy to analyze or index due to the image nature of the data. Existing techniques extract only content from screencasts, but ignore workflow actions by which developers accomplish programming tasks. This significantly limits the effective use of programming screencasts in downstream applications. In this paper, we are the first to present a novel technique for recognizing workflow actions in programming screencasts. Our technique exploits image differencing and Convolutional Neural Network (CNN) to analyze the correspondence and change of consecutive frames, based on which nine classes of frequent developer actions can be recognized from programming screencasts. Using programming screencasts from Youtube, we evaluate different configurations of our CNN model and the performance of our technique for developer action recognition across developers, working environments and programming languages. Using screencasts of developers' real work, we demonstrate the usefulness of our technique in a practical application for actionaware extraction of key-code frames in developers' work.","","","10.1109/ICSE.2019.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811922","Programming Screencast;Action Recognition;Deep learning","Programming;Microsoft Windows;Feature extraction;Software engineering;Tutorials;Mice","convolutional neural nets;feature extraction;image recognition;software engineering","programming screencasts;vision-based workflow action recognition;ActionNet;image differencing;convolutional neural network;CNN model;programming languages;software engineering;developer behaviors","","1","69","","","","","IEEE","IEEE Conferences"
"Hunting for Bugs in Code Coverage Tools via Randomized Differential Testing","Y. Yang; Y. Zhou; H. Sun; Z. Su; Z. Zuo; L. Xu; B. Xu","Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Unaffiliated; ETH Zurich, Switzerland; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China; Nanjing University, Nanjing, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","488","499","Reliable code coverage tools are critically important as it is heavily used to facilitate many quality assurance activities, such as software testing, fuzzing, and debugging. However, little attention has been devoted to assessing the reliability of code coverage tools. In this study, we propose a randomized differential testing approach to hunting for bugs in the most widely used C code coverage tools. Specifically, by generating random input programs, our approach seeks for inconsistencies in code coverage reports produced by different code coverage tools, and then identifies inconsistencies as potential code coverage bugs. To effectively report code coverage bugs, we addressed three specific challenges: (1) How to filter out duplicate test programs as many of them triggering the same bugs in code coverage tools; (2) how to automatically reduce large test programs to much smaller ones that have the same properties; and (3) how to determine which code coverage tools have bugs? The extensive evaluations validate the effectiveness of our approach, resulting in 42 and 28 confirmed/fixed bugs for gcov and llvm-cov, respectively. This case study indicates that code coverage tools are not as reliable as it might have been envisaged. It not only demonstrates the effectiveness of our approach, but also highlights the need to continue improving the reliability of code coverage tools. This work opens up a new direction in code coverage validation which calls for more attention in this area.","","","10.1109/ICSE.2019.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812045","Code Coverage;Differential Testing;Coverage Tools;Bug Detection.","Computer bugs;Tools;Software;Reliability;Fuzzing;Debugging","program debugging;program testing;software tools","random input programs;C code coverage tools;randomized differential testing;code coverage validation;potential code coverage bugs;code coverage reports;reliable code coverage tools","","2","60","","","","","IEEE","IEEE Conferences"
"When Code Completion Fails: A Case Study on Real-World Completions","V. J. Hellendoorn; S. Proksch; H. C. Gall; A. Bacchelli","UC Davis; University of Zurich; University of Zurich; University of Zurich","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","960","970","Code completion is commonly used by software developers and is integrated into all major IDE's. Good completion tools can not only save time and effort but may also help avoid incorrect API usage. Many proposed completion tools have shown promising results on synthetic benchmarks, but these benchmarks make no claims about the realism of the completions they test. This lack of grounding in real-world data could hinder our scientific understanding of developer needs and of the efficacy of completion models. This paper presents a case study on 15,000 code completions that were applied by 66 real developers, which we study and contrast with artificial completions to inform future research and tools in this area. We find that synthetic benchmarks misrepresent many aspects of real-world completions; tested completion tools were far less accurate on real-world data. Worse, on the few completions that consumed most of the developers' time, prediction accuracy was less than 20% -- an effect that is invisible in synthetic benchmarks. Our findings have ramifications for future benchmarks, tool design and real-world efficacy: Benchmarks must account for completions that developers use most, such as intra-project APIs; models should be designed to be amenable to intra-project data; and real-world developer trials are essential to quantifying performance on the least predictable completions, which are both most time-consuming and far more typical than artificial data suggests. We publicly release our preprint [https://doi.org/10.5281/zenodo.2565673] and replication data and materials [https://doi.org/10.5281/zenodo.2562249].","","","10.1109/ICSE.2019.00101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812116","Code completion;Benchmark;Language models","Tools;Benchmark testing;Data models;Context modeling;Syntactics;Vocabulary;Training","data handling;program testing;software engineering;software tools","code completion;real-world completions;software developers;synthetic benchmarks;real-world data;completion models;artificial completions;tested completion tools;tool design;real-world efficacy;real-world developer trials;predictable completions","","1","29","","","","","IEEE","IEEE Conferences"
"Analyzing APIs Documentation and Code to Detect Directive Defects","Y. Zhou; R. Gu; T. Chen; Z. Huang; S. Panichella; H. Gall","Coll. of Comput. Sci., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing, China; Coll. of Comput. Sci., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing, China; Dept. of Comput. Sci., Middlesex Univ., London, UK; Coll. of Comput. Sci., Nanjing Univ. of Aeronaut. & Astronaut., Nanjing, China; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","27","37","Application Programming Interface (API) documents represent one of the most important references for API users. However, it is frequently reported that the documentation is inconsistent with the source code and deviates from the API itself. Such inconsistencies in the documents inevitably confuse the API users hampering considerably their API comprehension and the quality of software built from such APIs. In this paper, we propose an automated approach to detect defects of API documents by leveraging techniques from program comprehension and natural language processing. Particularly, we focus on the directives of the API documents which are related to parameter constraints and exception throwing declarations. A first-order logic based constraint solver is employed to detect such defects based on the obtained analysis results. We evaluate our approach on parts of well documented JDK 1.8 APIs. Experiment results show that, out of around 2000 API usage constraints, our approach can detect 1158 defective document directives, with a precision rate of 81.6%, and a recall rate of 82.0%, which demonstrates its practical feasibility.","","","10.1109/ICSE.2017.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985647","API documentation;static analysis;natural language processing","Documentation;Natural language processing;Null value;Software;Data mining;Feature extraction;Computer science","application program interfaces;formal logic;natural language processing;program diagnostics;software maintenance;software quality;system documentation","API documentation analysis;directive defect detection;API code analysis;application programming interface documents;API comprehension;software quality;natural language processing;program comprehension;first-order logic based constraint solver;parameter constraints;exception throwing declarations;JDK 1.8 API;API usage constraints;defective document directives;precision rate;recall rate","","14","41","","","","","IEEE","IEEE Conferences"
"Deep Differential Testing of JVM Implementations","Y. Chen; T. Su; Z. Su","Shanghai Jiao Tong University; Nanyang Technological University; ETH Zurich/University of California, Davis","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1257","1268","The Java Virtual Machine (JVM) is the cornerstone of the widely-used Java platform. Thus, it is critical to ensure the reliability and robustness of popular JVM implementations. However, little research exists on validating production JVMs. One notable effort is classfuzz, which mutates Java bytecode syntactically to stress-test different JVMs. It is shown that classfuzz mainly produces illegal bytecode files and uncovers defects in JVMs' startup processes. It remains a challenge to effectively test JVMs' bytecode verifiers and execution engines to expose deeper bugs. This paper tackles this challenge by introducing classming, a novel, effective approach to performing deep, differential JVM testing. The key of classming is a technique, live bytecode mutation, to generate, from a seed bytecode file f, likely valid, executable (live) bytecode files: (1) capture the seed f's live bytecode, the sequence of its executed bytecode instructions; (2) repeatedly manipulate the control- and data-flow in f's live bytecode to generate semantically different mutants; and (3) selectively accept the generated mutants to steer the mutation process toward live, diverse mutants. The generated mutants are then employed to differentially test JVMs. We have evaluated classming on mainstream JVM implementations, including OpenJDK's HotSpot and IBM's J9, by mutating the DaCapo benchmarks. Our results show that classming is very effective in uncovering deep JVM differences. More than 1,800 of the generated classes exposed JVM differences, and more than 30 triggered JVM crashes. We analyzed and reported the JVM runtime differences and crashes, of which 14 have already been confirmed/fixed, including a highly critical security vulnerability in J9 that allowed untrusted code to disable the security manager and elevate its privileges (CVE-2017-1376).","","","10.1109/ICSE.2019.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811957","Differential JVM testing;live bytecode mutation;semantically different mutants","Monitoring;Testing;Java;Engines;Security;Computer crashes;Runtime","Java;program testing;program verification;security of data;source code (software);virtual machines","Java Virtual Machine;Java platform;classfuzz;classming;differential JVM testing;live bytecode mutation;mutation process;deep JVM differences;JVM crashes;bytecode instructions;deep differential testing;OpenJDK HotSpot;IBM J9;DaCapo benchmarks;deeper bugs","","","49","","","","","IEEE","IEEE Conferences"
"Characterizing and Detecting Anti-Patterns in the Logging Code","B. Chen; Z. M. Jiang","AnaLytics & Evaluation (SCALE) Lab., York Univ., Toronto, ON, Canada; AnaLytics & Evaluation (SCALE) Lab., York Univ., Toronto, ON, Canada","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","71","81","Snippets of logging code are output statements (e.g., LOG.info or System.out.println) that developers insert into a software system. Although more logging code can provide more execution context of the system's behavior during runtime, it is undesirable to instrument the system with too much logging code due to maintenance overhead. Furthermore, excessive logging may cause unexpected side-effects like performance slow-down or high disk I/O bandwidth. Recent studies show that there are no well-defined coding guidelines for performing effective logging. Previous research on the logging code mainly tackles the problems of where-to-log and what-to-log. There are very few works trying to address the problem of how-to-log (developing and maintaining high-quality logging code). In this paper, we study the problem of how-to-log by characterizing and detecting the anti-patterns in the logging code. As the majority of the logging code is evolved together with the feature code, the remaining set of logging code changes usually contains the fixes to the anti-patterns. We have manually examined 352 pairs of independently changed logging code snippets from three well-maintenance open source systems: ActiveMQ, Hadoop and Maven. Our analysis has resulted in six different anti-patterns in the logging code. To demonstrate the value of our findings, we have encoded these anti-patterns into a static code analysis tool, LCAnalyzer. Case studies show that LCAnalyzer has an average recall of 95% and precision of 60% and can be used to automatically detect previously unknown anti-patterns in the source code. To gather feedback, we have filed 64 representative instances of the logging code anti-patterns from the most recent releases of ten open source software systems. Among them, 46 instances (72%) have already been accepted by their developers.","","","10.1109/ICSE.2017.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985651","anti-patterns;logging code;logging practices;empirical studies;software maintenance","Tools;Open source software;Software systems;Runtime;Computer crashes;Data mining","data handling;parallel processing;program diagnostics;public domain software;software maintenance;source code (software)","anti-pattern detection;anti-pattern characterization;system behavior;maintenance overhead;high disk I/O bandwidth;logging code snippets;ActiveMQ;Hadoop;Maven;static code analysis tool;LCAnalyzer;source code;open source software systems;how-to-log problem","","12","47","","","","","IEEE","IEEE Conferences"
"RESTler: Stateful REST API Fuzzing","V. Atlidakis; P. Godefroid; M. Polishchuk","Columbia University; Microsoft Research; Microsoft Research","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","748","758","This paper introduces RESTler, the first stateful REST API fuzzer. RESTler analyzes the API specification of a cloud service and generates sequences of requests that automatically test the service through its API. RESTler generates test sequences by (1) inferring producer-consumer dependencies among request types declared in the specification (e.g., inferring that ""a request B should be executed after request A"" because B takes as an input a resource-id x produced by A) and by (2) analyzing dynamic feedback from responses observed during prior test executions in order to generate new tests (e.g., learning that ""a request C after a request sequence A;B is refused by the service"" and therefore avoiding this combination in the future). We present experimental results showing that these two techniques are necessary to thoroughly exercise a service under test while pruning the large search space of possible request sequences. We used RESTler to test GitLab, an open-source Git service, as well as several Microsoft Azure and Office365 cloud services. RESTler found 28 bugs in GitLab and several bugs in each of the Azure and Office365 cloud services tested so far. These bugs have been confirmed and fixed by the service owners.","","","10.1109/ICSE.2019.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811961","REST API;Fuzzing;cloud services;fuzzer;testing;bug finding","Computer bugs;Tools;Fuzzing;Dictionaries;Open source software;Test pattern generators","application program interfaces;cloud computing;fuzzy set theory;program debugging;program testing","prior test executions;request C;test GitLab;open-source Git service;Office365 cloud services;service owners;stateful REST API fuzzing;stateful REST API fuzzer;RESTler analyzes;API specification;cloud service;test sequences;request types;request B;request sequences;Microsoft Azure cloud services;bugs","","1","43","","","","","IEEE","IEEE Conferences"
"Supporting Analysts by Dynamic Extraction and Classification of Requirements-Related Knowledge","Z. Shakeri Hossein Abad; V. Gervasi; D. Zowghi; B. H. Far","University of Calgary, Canada; University of Pisa, Italy; University of Technology Sydney, Australia; University of Calgary, Canada","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","442","453","In many software development projects, analysts are required to deal with systems' requirements from unfamiliar domains. Familiarity with the domain is necessary in order to get full leverage from interaction with stakeholders and for extracting relevant information from the existing project documents. Accurate and timely extraction and classification of requirements knowledge support analysts in this challenging scenario. Our approach is to mine real-time interaction records and project documents for the relevant phrasal units about the requirements related topics being discussed during elicitation. We propose to use both generative and discriminating methods. To extract the relevant terms, we leverage the flexibility and power of Weighted Finite State Transducers (WFSTs) in dynamic modelling of natural language processing tasks. We used an extended version of Support Vector Machines (SVMs) with variable-sized feature vectors to efficiently and dynamically extract and classify requirements-related knowledge from the existing documents. To evaluate the performance of our approach intuitively and quantitatively, we used edit distance and precision/recall metrics. We show in three case studies that the snippets extracted by our method are intuitively relevant and reasonably accurate. Furthermore, we found that statistical and linguistic parameters such as smoothing methods, and words contiguity and order features can impact the performance of both extraction and classification tasks.","","","10.1109/ICSE.2019.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812084","Requirements elicitation;Natural Language Processing;Requirements classification;Weighted Finite State Transducer;Dynamic language models;Information extraction","Feature extraction;Transducers;Stakeholders;Data mining;Real-time systems;Task analysis;Support vector machines","computational linguistics;feature extraction;information retrieval;natural language processing;pattern classification;project management;software development management;support vector machines;text analysis","natural language processing tasks;variable-sized feature vectors;requirements-related knowledge;software development projects;weighted finite state transducers;support vector machines;requirements knowledge;phrasal units;project documents;edit distance;precision/recall metrics;extraction tasks;classification tasks","","","80","","","","","IEEE","IEEE Conferences"
"Travioli: A Dynamic Analysis for Detecting Data-Structure Traversals","R. Padhye; K. Sen","EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA; EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","473","483","Traversal is one of the most fundamental operations on data structures, in which an algorithm systematically visits some or all of the data items of a data structure. We propose a dynamic analysis technique, called Travioli, for detecting data-structure traversals. We introduce the concept of acyclic execution contexts, which enables precise detection of traversals of arrays and linked data structures such as lists and trees in the presence of both loops and recursion. We describe how the information reported by Travioli can be used for visualizing data-structure traversals, manually generating performance regression tests, and for discovering performance bugs caused by redundant traversals. We evaluate Travioli on five real-world JavaScript programs. In our experiments, Travioli produced fewer than 4% false positives. We were able to construct performance tests for 93.75% of the reported true traversals. Travioli also found two asymptotic performance bugs in widely used JavaScript frameworks D3 and express.","","","10.1109/ICSE.2017.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985686","","Reactive power;Arrays;Computer bugs;Lenses;Data visualization;Performance analysis","data structures;Java;system monitoring","dynamic analysis;data-structure traversals;acyclic execution contexts;real-world JavaScript programs;Travioli;regression tests;performance bugs","","1","32","","","","","IEEE","IEEE Conferences"
"Machine-Learning-Guided Selectively Unsound Static Analysis","K. Heo; H. Oh; K. Yi","Seoul Nat. Univ., Seoul, South Korea; Korea Univ., Seoul, South Korea; Seoul Nat. Univ., Seoul, South Korea","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","519","529","We present a machine-learning-based technique for selectively applying unsoundness in static analysis. Existing bug-finding static analyzers are unsound in order to be precise and scalable in practice. However, they are uniformly unsound and hence at the risk of missing a large amount of real bugs. By being sound, we can improve the detectability of the analyzer but it often suffers from a large number of false alarms. Our approach aims to strike a balance between these two approaches by selectively allowing unsoundness only when it is likely to reduce false alarms, while retaining true alarms. We use an anomaly-detection technique to learn such harmless unsoundness. We implemented our technique in two static analyzers for full C. One is for a taint analysis for detecting format-string vulnerabilities, and the other is for an interval analysis for buffer-overflow detection. The experimental results show that our approach significantly improves the recall of the original unsound analysis without sacrificing the precision.","","","10.1109/ICSE.2017.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985690","Static Analysis;Machine Learning;Bug-finding","Computer bugs;Libraries;Benchmark testing;Tools;Software engineering;Scalability;Support vector machines","learning (artificial intelligence);program diagnostics","machine-learning-guided selectively unsound static Analysis;bug-finding static analyzers;anomaly-detection technique;taint analysis;interval analysis;buffer-overflow detection","","2","24","","","","","IEEE","IEEE Conferences"
"Adversarial Sample Detection for Deep Neural Network through Model Mutation Testing","J. Wang; G. Dong; J. Sun; X. Wang; P. Zhang","Shenzhen University, China; Singapore University of Technology and Design, Singapore; Zhejiang University, China; Singapore University of Technology and Design, Singapore; Zhejiang University, China; Zhejiang University, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1245","1256","Deep neural networks (DNN) have been shown to be useful in a wide range of applications. However, they are also known to be vulnerable to adversarial samples. By transforming a normal sample with some carefully crafted human imperceptible perturbations, even highly accurate DNN make wrong decisions. Multiple defense mechanisms have been proposed which aim to hinder the generation of such adversarial samples. However, a recent work show that most of them are ineffective. In this work, we propose an alternative approach to detect adversarial samples at runtime. Our main observation is that adversarial samples are much more sensitive than normal samples if we impose random mutations on the DNN. We thus first propose a measure of 'sensitivity' and show empirically that normal samples and adversarial samples have distinguishable sensitivity. We then integrate statistical hypothesis testing and model mutation testing to check whether an input sample is likely to be normal or adversarial at runtime by measuring its sensitivity. We evaluated our approach on the MNIST and CIFAR10 datasets. The results show that our approach detects adversarial samples generated by state-of-the-art attacking methods efficiently and accurately.","","","10.1109/ICSE.2019.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812047","adversarial sample;detection;deep neural network;mutation testing;sensitivity","Testing;Perturbation methods;Sensitivity;Runtime;Training;Biological neural networks","learning (artificial intelligence);neural nets;program testing;security of data;software fault tolerance;statistical analysis","adversarial sample detection;deep neural network;adversarial samples;normal sample;input sample;model mutation testing;DNN;MNIST dataset;CIFAR10 dataset;sensitivity measure","","3","56","","","","","IEEE","IEEE Conferences"
"FOCUS: A Recommender System for Mining API Function Calls and Usage Patterns","P. T. Nguyen; J. Di Rocco; D. Di Ruscio; L. Ochoa; T. Degueule; M. Di Penta","Universit√† degli Studi dell'Aquila, Italy; Universit√† degli Studi dell'Aquila, Italy; Universit√† degli Studi dell'Aquila, Italy; Centrum Wiskunde & Informatica, Netherlands; Centrum Wiskunde & Informatica, Netherlands; Universit√† degli Studi del Sannio, Italy","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1050","1060","Software developers interact with APIs on a daily basis and, therefore, often face the need to learn how to use new APIs suitable for their purposes. Previous work has shown that recommending usage patterns to developers facilitates the learning process. Current approaches to usage pattern recommendation, however, still suffer from high redundancy and poor run-time performance. In this paper, we reformulate the problem of usage pattern recommendation in terms of a collaborative-filtering recommender system. We present a new tool, FOCUS, which mines open-source project repositories to recommend API method invocations and usage patterns by analyzing how APIs are used in projects similar to the current project. We evaluate FOCUS on a large number of Java projects extracted from GitHub and Maven Central and find that it outperforms the state-of-the-art approach PAM with regards to success rate, accuracy, and execution time. Results indicate the suitability of context-aware collaborative-filtering recommender systems to provide API usage patterns.","","","10.1109/ICSE.2019.00109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812051","recommender system;api mining;api usage pattern;api recommendation","Recommender systems;Collaboration;Java;Libraries;Documentation;Data mining;Tools","application program interfaces;collaborative filtering;data mining;Java;public domain software;recommender systems;software libraries;ubiquitous computing","API function calls;software developers interact;learning process;usage pattern recommendation;open-source project repositories;API method invocations;API usage patterns;collaborative-filtering recommender system;Maven Central;GitHub;Java projects;FOCUS","","2","45","","","","","IEEE","IEEE Conferences"
"Why Do Episodic Volunteers Stay in FLOSS Communities?","A. Barcomb; K. Stol; D. Riehle; B. Fitzgerald","Lero - University of Limerick, Ireland; Friedrich-Alexander-Universit√§t Erlangen-N√ºrnberg, Germany; Lero - University College Cork, Ireland; Friedrich-Alexander-Universit√§t Erlangen-N√ºrnberg, Germany; Lero - University of Limerick, Ireland","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","948","959","Successful Free/Libre and Open Source Software (FLOSS) projects incorporate both habitual and infrequent, or episodic, contributors. Using the concept of episodic volunteering (EV) from the general volunteering literature, we derive a model consisting of five key constructs that we hypothesize affect episodic volunteers' retention in FLOSS communities. To evaluate the model we conducted a survey with over 100 FLOSS episodic volunteers. We observe that three of our model constructs (social norms, satisfaction and community commitment) are all positively associated with volunteers' intention to remain, while the two other constructs (psychological sense of community and contributor benefit motivations) are not. Furthermore, exploratory clustering on unobserved heterogeneity suggests that there are four distinct categories of volunteers: satisfied, classic, social and obligated. Based on our findings, we offer suggestions for projects to incorporate and manage episodic volunteers, so as to better leverage this type of contributors and potentially improve projects' sustainability.","","","10.1109/ICSE.2019.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811892","community management;episodic volunteering;open source software;volunteer management","Psychology;Analytical models;Sustainable development;Open source software;Computer science;Face","public domain software;software development management;software quality","FLOSS communities;habitual contributors;episodic contributors;episodic volunteering;general volunteering literature;community commitment;FLOSS episodic volunteers;free-libre and open source software","","1","88","","","","","IEEE","IEEE Conferences"
"Detecting User Story Information in Developer-Client Conversations to Generate Extractive Summaries","P. Rodeghero; S. Jiang; A. Armaly; C. McMillan","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA; Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA; Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA; Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","49","59","User stories are descriptions of functionality that a software user needs. They play an important role in determining which software requirements and bug fixes should be handled and in what order. Developers elicit user stories through meetings with customers. But user story elicitation is complex, and involves many passes to accommodate shifting and unclear customer needs. The result is that developers must take detailed notes during meetings or risk missing important information. Ideally, developers would be freed of the need to take notes themselves, and instead speak naturally with their customers. This paper is a step towards that ideal. We present a technique for automatically extracting information relevant to user stories from recorded conversations between customers and developers. We perform a qualitative study to demonstrate that user story information exists in these conversations in a sufficient quantity to extract automatically. From this, we found that roughly 10.2% of these conversations contained user story information. Then, we test our technique in a quantitative study to determine the degree to which our technique can extract user story information. In our experiment, our process obtained about 70.8% precision and 18.3% recall on the information.","","","10.1109/ICSE.2017.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985649","developer communication;user story generation;software engineering;productivity;transcripts","Data mining;Software;Computer bugs;Electronic mail;Software algorithms;Software engineering;Algorithm design and analysis","software engineering","user story information detection;developer-client conversations;extractive summaries;software functionality","","6","39","","","","","IEEE","IEEE Conferences"
"Supporting Software Developers with a Holistic Recommender System","L. Ponzanelli; S. Scalabrino; G. Bavota; A. Mocci; R. Oliveto; M. Di Penta; M. Lanza","Univ. della Svizzera Italiana, Lugano, Switzerland; Univ. of Molise, Italy; Univ. della Svizzera Italiana, Lugano, Switzerland; Univ. della Svizzera Italiana, Lugano, Switzerland; Univ. of Molise, Italy; Univ. of Sannio, Benevento, Italy; Univ. della Svizzera Italiana, Lugano, Switzerland","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","94","105","The promise of recommender systems is to provide intelligent support to developers during their programming tasks. Such support ranges from suggesting program entities to taking into account pertinent Q&A pages. However, current recommender systems limit the context analysis to change history and developers' activities in the IDE, without considering what a developer has already consulted or perused, e.g., by performing searches from the Web browser. Given the faceted nature of many programming tasks, and the incompleteness of the information provided by a single artifact, several heterogeneous resources are required to obtain the broader picture needed by a developer to accomplish a task. We present Libra, a holistic recommender system. It supports the process of searching and navigating the information needed by constructing a holistic meta-information model of the resources perused by a developer, analyzing their semantic relationships, and augmenting the web browser with a dedicated interactive navigation chart. The quantitative and qualitative evaluation of Libra provides evidence that a holistic analysis of a developer's information context can indeed offer comprehensive and contextualized support to information navigation and retrieval during software development.","","","10.1109/ICSE.2017.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985653","Mining unstructured data;Recommender systems","Browsers;Uniform resource locators;Recommender systems;Navigation;Web search;User interfaces;Web pages","information analysis;information retrieval;interactive programming;online front-ends;recommender systems;software engineering","software developers;holistic recommender system;intelligent support;programming tasks;program entities;pertinent Q&A pages;heterogeneous resources;Libra;information search;information navigation;holistic meta-information model;Web browser;interactive navigation chart;information context analysis;information retrieval;software development","","8","56","","","","","IEEE","IEEE Conferences"
"Distilling Neural Representations of Data Structure Manipulation using fMRI and fNIRS","Y. Huang; X. Liu; R. Krueger; T. Santander; X. Hu; K. Leach; W. Weimer","Univeristy of Michigan; Univeristy of Michigan; University of Michigan; University of California, Santa Barbara; Univeristy of Michigan; University of Michigan; University of Michigan","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","396","407","Data structures permeate many aspects of software engineering, but their associated human cognitive processes are not thoroughly understood. We leverage medical imaging and insights from the psychological notion of spatial ability to decode the neural representations of several fundamental data structures and their manipulations. In a human study involving 76 participants, we examine list, array, tree, and mental rotation tasks using both functional near-infrared spectroscopy (fNIRS) and functional magnetic resonance imaging (fMRI). We find a nuanced relationship: data structure and spatial operations use the same focal regions of the brain but to different degrees. They are related but distinct neural tasks. In addition, more difficult computer science problems induce higher cognitive load than do problems of pure spatial reasoning. Finally, while fNIRS is less expensive and more permissive, there are some computing-relevant brain regions that only fMRI can reach.","","","10.1109/ICSE.2019.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812086","medical imaging;data structures;spatial ability","Functional magnetic resonance imaging;Data structures;Task analysis;Software engineering;Biomedical imaging;Neuroimaging;Brain","biomedical MRI;biomedical optical imaging;brain;cognition;data structures;infrared spectroscopy;medical image processing;neurophysiology;psychology;spatial reasoning","computing-relevant brain regions;pure spatial reasoning;higher cognitive load;difficult computer science problems;distinct neural tasks;spatial operations;functional magnetic resonance imaging;near-infrared spectroscopy;mental rotation tasks;tree;human study;manipulations;fundamental data structures;spatial ability;psychological notion;leverage medical imaging;associated human cognitive processes;software engineering;fNIRS;fMRI;data structure manipulation;neural representations","","","92","","","","","IEEE","IEEE Conferences"
"Glacier: Transitive Class Immutability for Java","M. Coblenz; W. Nelson; J. Aldrich; B. Myers; J. Sunshine","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; Hampton Univ., Hampton, VA, USA; Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","496","506","Though immutability has been long-proposed as a way to prevent bugs in software, little is known about how to make immutability support in programming languages effective for software engineers. We designed a new formalism that extends Java to support transitive class immutability, the form of immutability for which there is the strongest empirical support, and implemented that formalism in a tool called Glacier. We applied Glacier successfully to two real-world systems. We also compared Glacier to Java's final in a user study of twenty participants. We found that even after being given instructions on how to express immutability with final, participants who used final were unable to express immutability correctly, whereas almost all participants who used Glacier succeeded. We also asked participants to make specific changes to immutable classes and found that participants who used final all incorrectly mutated immutable state, whereas almost all of the participants who used Glacier succeeded. Glacier represents a promising approach to enforcing immutability in Java and provides a model for enforcement in other languages.","","","10.1109/ICSE.2017.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985688","immutability;programming language usability;empirical studies of programmers","Java;Computer bugs;Runtime;Usability;Tools","Java;program debugging;software tools","Glacier tool;Java;transitive class immutability;software bugs prevention;programming languages","","7","27","","","","","IEEE","IEEE Conferences"
"Adaptive Coverage and Operational Profile-Based Testing for Reliability Improvement","A. Bertolino; B. Miranda; R. Pietrantuono; S. Russo","ISTI, Pisa, Italy; ISTI, Pisa, Italy; Univ. degli Studi di Napoli Federico II, Naples, Italy; Univ. degli Studi di Napoli Federico II, Naples, Italy","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","541","551","We introduce covrel, an adaptive software testing approach based on the combined use of operational profile and coverage spectrum, with the ultimate goal of improving the delivered reliability of the program under test. Operational profile-based testing is a black-box technique that selects test cases having the largest impact on failure probability in operation, as such, it is considered well suited when reliability is a major concern. Program spectrum is a characterization of a program's behavior in terms of the code entities (e.g., branches, statements, functions) that are covered as the program executes. The driving idea of covrel is to complement operational profile information with white-box coverage measures based on count spectra, so as to dynamically select the most effective test cases for reliability improvement. In particular, we bias operational profile-based test selection towards those entities covered less frequently. We assess the approach by experiments with 18 versions from 4 subjects commonly used in software testing research, comparing results with traditional operational and coverage testing. Results show that exploiting operational and coverage data in a combined adaptive way actually pays in terms of reliability improvement, with covrel overcoming conventional operational testing in more than 80% of the cases.","","","10.1109/ICSE.2017.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985692","Testing;Reliability;Operational profile;Program count spectrum;Operational coverage;Test case selection","Software reliability;Resource management;Software testing;Reliability engineering;Optimization","probability;program testing;software reliability","adaptive coverage testing;operational profile-based testing;reliability improvement;adaptive software testing approach;operational profile;coverage spectrum;program-under-test;black-box technique;failure probability;program spectrum;program behavior;code entities;white-box coverage measures;count spectra;operational profile-based test selection;operational data;coverage data;covrel","","1","36","","","","","IEEE","IEEE Conferences"
"Distance-Based Sampling of Software Configuration Spaces","C. Kaltenecker; A. Grebhahn; N. Siegmund; J. Guo; S. Apel","University of Passau; University of Passau; University of Weimar; Alibaba Group; University of Passau","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1084","1094","Configurable software systems provide a multitude of configuration options to adjust and optimize their functional and non-functional properties. For instance, to find the fastest configuration for a given setting, a brute-force strategy measures the performance of all configurations, which is typically intractable. Addressing this challenge, state-of-the-art strategies rely on machine learning, analyzing only a few configurations (i.e., a sample set) to predict the performance of other configurations. However, to obtain accurate performance predictions, a representative sample set of configurations is required. Addressing this task, different sampling strategies have been proposed, which come with different advantages (e.g., covering the configuration space systematically) and disadvantages (e.g., the need to enumerate all configurations). In our experiments, we found that most sampling strategies do not achieve a good coverage of the configuration space with respect to covering relevant performance values. That is, they miss important configurations with distinct performance behavior. Based on this observation, we devise a new sampling strategy, called distance-based sampling, that is based on a distance metric and a probability distribution to spread the configurations of the sample set according to a given probability distribution across the configuration space. This way, we cover different kinds of interactions among configuration options in the sample set. To demonstrate the merits of distance-based sampling, we compare it to state-of-the-art sampling strategies, such as t-wise sampling, on 10 real-world configurable software systems. Our results show that distance-based sampling leads to more accurate performance models for medium to large sample sets.","","","10.1109/ICSE.2019.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812049","Distance Based Sampling;Configuration Sampling;Configurable Systems;Performance Modeling","Software systems;Sociology;Statistics;Probability distribution;Task analysis;Performance evaluation","learning (artificial intelligence);sampling methods;software maintenance;software performance evaluation;statistical distributions","sampling strategy;configuration options;t-wise sampling;real-world configurable software systems;software configuration;brute-force strategy;representative sample set;distance-based sampling;sampling strategies;software configuration space;probability distribution","","3","36","","","","","IEEE","IEEE Conferences"
"DifFuzz: Differential Fuzzing for Side-Channel Analysis","S. Nilizadeh; Y. Noller; C. S. Pasareanu","University of Texas at Arlington; Humboldt-Universit√§t zu Berlin; Carnegie Mellon University Silicon Valley, NASA Ames Research Center","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","176","187","Side-channel attacks allow an adversary to uncover secret program data by observing the behavior of a program with respect to a resource, such as execution time, consumed memory or response size. Side-channel vulnerabilities are difficult to reason about as they involve analyzing the correlations between resource usage over multiple program paths. We present DifFuzz, a fuzzing-based approach for detecting side-channel vulnerabilities related to time and space. DifFuzz automatically detects these vulnerabilities by analyzing two versions of the program and using resource-guided heuristics to find inputs that maximize the difference in resource consumption between secret-dependent paths. The methodology of DifFuzz is general and can be applied to programs written in any language. For this paper, we present an implementation that targets analysis of Java programs, and uses and extends the Kelinci and AFL fuzzers. We evaluate DifFuzz on a large number of Java programs and demonstrate that it can reveal unknown side-channel vulnerabilities in popular applications. We also show that DifFuzz compares favorably against Blazer and Themis, two state-of-the-art analysis tools for finding side-channels in Java programs.","","","10.1109/ICSE.2019.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812124","vulnerability detection;side-channel;dynamic analysis;fuzzing","Fuzzing;Java;Tools;Time factors;Instruments;Correlation;Performance analysis","cryptography;Java;program diagnostics;security of data","DifFuzz;differential fuzzing;side-channel analysis;side-channel attacks;secret program data;execution time;resource usage;fuzzing-based approach;resource consumption;secret-dependent paths;Java programs;unknown side-channel vulnerabilities;resource-guided heuristics","","","42","","","","","IEEE","IEEE Conferences"
"Machine Learning-Based Detection of Open Source License Exceptions","C. Vendome; M. Linares-V√°squez; G. Bavota; M. Di Penta; D. German; D. Poshyvanyk","Coll. of William & Mary, Williamsburg, VA, USA; Univ. de los Andes, Bogota, Colombia; Univ. della Svizzera Italiana, Lugano, Switzerland; Univ. of Sannio, Benevento, Italy; Univ. of Victoria, Victoria, BC, Canada; Coll. of William & Mary, Williamsburg, VA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","118","129","From a legal perspective, software licenses govern the redistribution, reuse, and modification of software as both source and binary code. Free and Open Source Software (FOSS) licenses vary in the degree to which they are permissive or restrictive in allowing redistribution or modification under licenses different from the original one(s). In certain cases, developers may modify the license by appending to it an exception to specifically allow reuse or modification under a particular condition. These exceptions are an important factor to consider for license compliance analysis since they modify the standard (and widely understood) terms of the original license. In this work, we first perform a large-scale empirical study on the change history of over 51K FOSS systems aimed at quantitatively investigating the prevalence of known license exceptions and identifying new ones. Subsequently, we performed a study on the detection of license exceptions by relying on machine learning. We evaluated the license exception classification with four different supervised learners and sensitivity analysis. Finally, we present a categorization of license exceptions and explain their implications.","","","10.1109/ICSE.2017.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985655","Software Licenses;Empirical Studies;Classifiers","Software engineering","learning (artificial intelligence);pattern classification;public domain software;software reusability;source code (software)","sensitivity analysis;supervised learners;license exception classification;license compliance analysis;FOSS licenses;free and open source software;source code;binary code;software reuse;software redistribution;software modification;software licenses;open source license exceptions;machine learning-based detection","","3","49","","","","","IEEE","IEEE Conferences"
"Investigating the Impact of Multiple Dependency Structures on Software Defects","D. Cui; T. Liu; Y. Cai; Q. Zheng; Q. Feng; W. Jin; J. Guo; Y. Qu","Xi‚Äôan Jiaotong University, China; Xi‚Äôan Jiaotong University, China; Drexel University, United States; Xi'an Jiaotong University, China; Drexel University, United States; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","584","595","Over the past decades, numerous approaches were proposed to help practitioner to predict or locate defective files. These techniques often use syntactic dependency, history co-change relation, or semantic similarity. The problem is that, it remains unclear whether these different dependency relations will present similar accuracy in terms of defect prediction and localization. In this paper, we present our systematic investigation of this question from the perspective of software architecture. Considering files involved in each dependency type as an individual design space, we model such a design space using one DRSpace. We derived 3 DRSpaces for each of the 117 Apache open source projects, with 643,079 revision commits and 101,364 bug reports in total, and calculated their interactions with defective files. The experiment results are surprising: the three dependency types present significantly different architectural views, and their interactions with defective files are also drastically different. Intuitively, they play completely different roles when used for defect prediction/localization. The good news is that the combination of these structures has the potential to improve the accuracy of defect prediction/localization. In summary, our work provides a new perspective regarding to which type(s) of relations should be used for the task of defect prediction/localization. These quantitative and qualitative results also advance our knowledge of the relationship between software quality and architectural views formed using different dependency types.","","","10.1109/ICSE.2019.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812092","Software Structure;Software Maintenance;Software Quality","History;Syntactics;Semantics;Software;Computer bugs;Reverse engineering;Prediction algorithms","program debugging;public domain software;software architecture;software maintenance;software quality","dependency type;DRSpace;defective files;software quality;multiple dependency structures;software defects;syntactic dependency;history co-change relation;semantic similarity;software architecture;design space;Apache open source projects;dependency relations","","","35","","","","","IEEE","IEEE Conferences"
"PEoPL: Projectional Editing of Product Lines","B. Behringer; J. Palz; T. Berger","Univ. of Luxembourg, Luxembourg City, Luxembourg; htw saar, Germany; Univ. of Gothenburg, Gothenburg, Sweden","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","563","574","The features of a software product line - a portfolio of system variants - can be realized using various implementation techniques (a. k. a., variability mechanisms). Each technique represents the software artifacts of features differently, typically classified into annotative (e.g., C preprocessor) and modular representations (e.g., feature modules), each with distinct advantages and disadvantages. Annotative representations are easy to realize, but annotations clutter source code and hinder program comprehension. Modular representations support comprehension, but are difficult to realize. Most importantly, to engineer feature artifacts, developers need to choose one representation and adhere to it for evolving and maintaining the same artifacts. We present PEoPL, an approach to combine the advantages of annotative and modular representations. When engineering a feature artifact, developers can choose the most-suited representation and even use different representations in parallel. PEoPL relies on separating a product line into an internal and external representation, the latter by providing editable projections used by the developers. We contribute a programming-language-independent internal representation of variability, five editable projections reflecting different variability representations, a supporting IDE, and a tailoring of PEoPL to Java. We evaluate PEoPL's expressiveness, scalability, and flexibility in eight Java-based product lines, finding that all can be realized, that projections are feasible, and that variant computation is fast (<;45ms on average for our largest subject Berkeley DB).","","","10.1109/ICSE.2017.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985694","","Latches;Java;Switches;Visualization;Bars;Software;Clutter","Java;software product lines","PEoPL;projectional editing of product lines;software product line;software artifacts;modular representations;programming-language-independent internal representation;Java-based product lines","","2","65","","","","","IEEE","IEEE Conferences"
"Interactive Production Performance Feedback in the IDE","J. Cito; P. Leitner; M. Rinard; H. C. Gall","MIT; Chalmers and University of Gothenburg; MIT; University of Zurich","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","971","981","Because of differences between development and production environments, many software performance problems are detected only after software enters production. We present PerformanceHat, a new system that uses profiling information from production executions to develop a global performance model suitable for integration into interactive development environments. PerformanceHat's ability to incrementally update this global model as the software is changed in the development environment enables it to deliver near real-time predictions of performance consequences reflecting the impact on the production environment. We implement PerformanceHat as an Eclipse plugin and evaluate it in a controlled experiment with 20 professional software developers implementing several software maintenance tasks using our approach and a representative baseline (Kibana). Our results indicate that developers using PerformanceHat were significantly faster in (1) detecting the performance problem, and (2) finding the root-cause of the problem. These results provide encouraging evidence that our approach helps developers detect, prevent, and debug production performance problems during development before the problem manifests in production.","","","10.1109/ICSE.2019.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811928","software performance engineering, IDE, user study","Monitoring;Software;Runtime;Tools;Data models;Task analysis","program debugging;programming environments;software maintenance;software performance evaluation","interactive production performance feedback;production environment;software performance problems;production executions;global performance model;interactive development environments;development environment;software maintenance tasks;performance problem;debug production performance problems;PerformanceHat;Eclipse plugin;software maintenance","","","33","","","","","IEEE","IEEE Conferences"
"A Neural Model for Generating Natural Language Summaries of Program Subroutines","A. LeClair; S. Jiang; C. McMillan","University of Notre Dame; Eastern Michigan University; University of Notre Dame","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","795","806","Source code summarization -- creating natural language descriptions of source code behavior -- is a rapidly-growing research topic with applications to automatic documentation generation, program comprehension, and software maintenance. Traditional techniques relied on heuristics and templates built manually by human experts. Recently, data-driven approaches based on neural machine translation have largely overtaken template-based systems. But nearly all of these techniques rely almost entirely on programs having good internal documentation; without clear identifier names, the models fail to create good summaries. In this paper, we present a neural model that combines words from code with code structure from an AST. Unlike previous approaches, our model processes each data source as a separate input, which allows the model to learn code structure independent of the text in code. This process helps our approach provide coherent summaries in many cases even when zero internal documentation is provided. We evaluate our technique with a dataset we created from 2.1m Java methods. We find improvement over two baseline techniques from SE literature and one from NLP literature.","","","10.1109/ICSE.2019.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811932","automatic documentation generation;source code summarization;code comment generation","Algorithms;Documentation;Natural languages;Java;Software engineering;Standards;Task analysis","language translation;natural language processing;neural nets;software engineering;source code (software);system documentation","neural machine translation;neural model;program subroutines;source code summarization;natural language descriptions;natural language summaries;data-driven approaches;software maintenance;program comprehension;automatic documentation generation;source code behavior","","1","60","","","","","IEEE","IEEE Conferences"
"Becoming Agile: A Grounded Theory of Agile Transitions in Practice","R. Hoda; J. Noble","Dept. of Electr. & Comput. Eng., Univ. of Auckland, Auckland, New Zealand; Sch. of Eng. & Comput. Sci., Victoria Univ. of Wellington, Wellington, New Zealand","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","141","151","Agile adoption is typically understood as a one-off organizational process involving a staged selection of agile development practices. This view of agility fails to explain the differences in the pace and effectiveness of individual teams transitioning to agile development. Based on a Grounded Theory study of 31 agile practitioners drawn from 18 teams across five countries, we present a grounded theory of becoming agile as a network of on-going transitions across five dimensions: software development practices, team practices, management approach, reflective practices, and culture. The unique position of a software team through this network, and their pace of progress along the five dimensions, explains why individual agile teams present distinct manifestations of agility and unique transition experiences. The theory expands the current understanding of agility as a holistic and complex network of on-going multidimensional transitions, and will help software teams, their managers, and organizations better navigate their individual agile journeys.","","","10.1109/ICSE.2017.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985657","agile software development;transition;selforganizing;teams;management;culture;theory;grounded theory","Software;Interviews;Telecommunications;Banking;Encoding;Finance","cultural aspects;software development management;software prototyping;team working","agile development practices;grounded theory;software development practices;team practices;management approach;reflective practices;culture;software team","","6","44","","","","","IEEE","IEEE Conferences"
"Understanding the Impressions, Motivations, and Barriers of One Time Code Contributors to FLOSS Projects: A Survey","A. Lee; J. C. Carver; A. Bosu","Comput. Sci. Dept., Univ. of Alabama, Tuscaloosa, AL, USA; Comput. Sci. Dept., Univ. of Alabama, Tuscaloosa, AL, USA; Dept. of Comput. Sci., Southern Illinois Univ., Carbondale, IL, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","187","197","Successful Free/Libre Open Source Software (FLOSS) projects must attract and retain high-quality talent. Researchers have invested considerable effort in the study of core and peripheral FLOSS developers. To this point, one critical subset of developers that have not been studied are One-Time code Contributors (OTC) - those that have had exactly one patch accepted. To understand why OTCs have not contributed another patch and provide guidance to FLOSS projects on retaining OTCs, this study seeks to understand the impressions, motivations, and barriers experienced by OTCs. We conducted an online survey of OTCs from 23 popular FLOSS projects. Based on the 184 responses received, we observed that OTCs generally have positive impressions of their FLOSS project and are driven by a variety of motivations. Most OTCs primarily made contributions to fix bugs that impeded their work and did not plan on becoming long term contributors. Furthermore, OTCs encounter a number of barriers that prevent them from continuing to contribute to the project. Based on our findings, there are some concrete actions FLOSS projects can take to increase the chances of converting OTCs into long-term contributors.","","","10.1109/ICSE.2017.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985661","FLOSS;Open source;OSS;Newcomers;One Time Contributors;Survey;Qualitative Research","Computer bugs;Electronic mail;Encoding;Computer science;Open source software;Concrete;Tools","project management;public domain software;software engineering","one time code contributors;FLOSS projects;free-Libre open source software project;OTC","","7","31","","","","","IEEE","IEEE Conferences"
"Statistical Algorithmic Profiling for Randomized Approximate Programs","K. Joshi; V. Fernando; S. Misailovic","University of Illinois at Urbana-Champaign, USA; University of Illinois at Urbana-Champaign, USA; University of Illinois at Urbana-Champaign, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","608","618","Many modern applications require low-latency processing of large data sets, often by using approximate algorithms that trade accuracy of the results for faster execution or reduced memory consumption. Although the algorithms provide probabilistic accuracy and performance guarantees, a software developer who implements these algorithms has little support from existing tools. Standard profilers do not consider accuracy of the computation and do not check whether the outputs of these programs satisfy their accuracy specifications. We present AXPROF, an algorithmic profiling framework for analyzing randomized approximate programs. The developer provides the accuracy specification as a formula in a mathematical notation, using probability or expected value predicates. AXPROF automatically generates statistical reasoning code. It first constructs the empirical models of accuracy, time, and memory consumption. It then selects and runs appropriate statistical tests that can, with high confidence, determine if the implementation satisfies the specification. We used AXPROF to profile 15 approximate applications from three domains - data analytics, numerical linear algebra, and approximate computing. AXPROF was effective in finding bugs and identifying various performance optimizations. In particular, we discovered five previously unknown bugs in the implementations of the algorithms and created fixes, guided by AXPROF.","","","10.1109/ICSE.2019.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811971","profiler;randomized algorithms","Approximation algorithms;Computer bugs;Software algorithms;Hash functions;Probabilistic logic;Heuristic algorithms;Memory management","approximation theory;data analysis;linear algebra;optimisation;probability;program verification;randomised algorithms;statistical testing","AXPROF;statistical reasoning code;memory consumption;approximate computing;statistical algorithmic profiling;randomized approximate programs;low-latency processing;data sets;approximate algorithms;probabilistic accuracy;software developer;statistical tests;data analytics;bugs finding;performance optimizations;linear algebra;mathematical notation","","","67","","","","","IEEE","IEEE Conferences"
"A General Framework for Dynamic Stub Injection","M. Christakis; P. Emmisberger; P. Godefroid; P. M√ºller","Microsoft Res., Redmond, WA, USA; Dept. of Comput. Sci., ETH Zurich, Z√ºrich, Switzerland; Microsoft Res., Redmond, WA, USA; Dept. of Comput. Sci., ETH Zurich, Z√ºrich, Switzerland","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","586","596","Stub testing is a standard technique to simulate the behavior of dependencies of an application under test such as the file system. Even though existing frameworks automate the actual stub injection, testers typically have to implement manually where and when to inject stubs, in addition to the stub behavior. This paper presents a novel framework that reduces this effort. The framework provides a domain specific language to describe stub injection strategies and stub behaviors via declarative rules, as well as a tool that automatically injects stubs dynamically into binary code according to these rules. Both the domain specific language and the injection are language independent, which enables the reuse of stubs and injection strategies across applications. We implemented this framework for both unmanaged (assembly) and managed (.NET) code and used it to perform fault injection for twelve large applications, which revealed numerous crashes and bugs in error handling code. We also show how to prioritize the analysis of test failures based on a comparison of the effectiveness of stub injection rules across applications.","","","10.1109/ICSE.2017.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985696","","Instruments;DSL;Computer bugs;Testing;Runtime;Debugging","binary codes;program diagnostics;program testing;specification languages","stub testing;fault injection;binary code;declarative rules;stub injection strategies;domain specific language","","1","26","","","","","IEEE","IEEE Conferences"
"Multifaceted Automated Analyses for Variability-Intensive Embedded Systems","S. Lazreg; M. Cordy; P. Collet; P. Heymans; S. Mosser","Visteon Electronics, Universit√© C√¥te d'Azur, CNRS, I3S, France; SnT, University of Luxembourg; Universit√© C√¥te d'Azur, CNRS, I3S, France; University of Namur; Universit√© C√¥te d'Azur, CNRS, I3S, France","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","854","865","Embedded systems, like those found in the automotive domain, must comply with stringent functional and non-functional requirements. To fulfil these requirements, engineers are confronted with a plethora of design alternatives both at the software and hardware level, out of which they must select the optimal solution wrt. possibly-antagonistic quality attributes (e.g. cost of manufacturing vs. speed of execution). We propose a model-driven framework to assist engineers in this choice. It captures high-level specifications of the system in the form of variable dataflows and configurable hardware platforms. A mapping algorithm then derives the design space, i.e. the set of compatible pairs of application and platform variants, and a variability-aware executable model, which encodes the functional and non-functional behaviour of all viable system variants. Novel verification algorithms then pinpoint the optimal system variants efficiently. The benefits of our approach are evaluated through a real-world case study from the automotive industry.","","","10.1109/ICSE.2019.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812057","Embedded system design engineering;variability modeling;model checking;non functional property;multi objective optimization","Task analysis;Random access memory;Hardware;Graphics processing units;Rendering (computer graphics);Manufacturing","embedded systems;formal specification;program verification","possibly-antagonistic quality;model-driven framework;high-level specifications;variable dataflows;configurable hardware platforms;mapping algorithm;design space;variability-aware executable model;optimal system;automotive industry;multifaceted automated analyses;variability-intensive embedded systems;automotive domain;nonfunctional requirements;hardware level;verification algorithms","","1","81","","","","","IEEE","IEEE Conferences"
"Type Migration in Ultra-Large-Scale Codebases","A. Ketkar; A. Mesbah; D. Mazinanian; D. Dig; E. Aftandilian","Oregon State University, U.S.A.; University of British Columbia, Canada; University of British Columbia, Canada; Oregon State University, U.S.A.; Google Inc., U.S.A.","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1142","1153","Type migration is a refactoring activity in which an existing type is replaced with another one throughout the source code. Manually performing type migration is tedious as programmers need to find all instances of the type to be migrated, along with its dependencies that propagate over assignment operations, method hierarchies, and subtypes. Existing automated approaches for type migration are not adequate for ultra-large-codebases - they perform an intensive whole-program analysis that does not scale. If we could represent the type structure of the program as graphs, then we could employ a MAPREDUCE parallel and distributed process that scales to hundreds of millions of LOC. We implemented this approach as an IDE-independent tool called T2R, which integrates with most build systems. We evaluated T2R's accuracy, usefulness and scalability on seven open source projects and one proprietary codebase of 300M LOC. T2R generated 130 type migration patches, of which the original developers accepted 98%.","","","10.1109/ICSE.2019.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812061","Refactoring;Type Migration;MapReduce","Java;Google;Open source software;Tools;Scalability;Task analysis;Complexity theory","data mining;parallel processing;program diagnostics;public domain software;software maintenance","ultra-large-scale codebases;type migration patches;refactoring activity;whole-program analysis;MAPREDUCE parallel and distributed process;IDE-independent tool;T2R tool","","1","47","","","","","IEEE","IEEE Conferences"
"PIVOT: Learning API-Device Correlations to Facilitate Android Compatibility Issue Detection","L. Wei; Y. Liu; S. Cheung","The Hong Kong University of Science and Technology, Hong Kong, China; Southern University of Science and Technology, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, Chine","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","878","888","The heavily fragmented Android ecosystem has induced various compatibility issues in Android apps. The search space for such fragmentation-induced compatibility issues (FIC issues) is huge, comprising three dimensions: device models, Android OS versions, and Android APIs. FIC issues, especially those arising from device models, evolve quickly with the frequent release of new device models to the market. As a result, an automated technique is desired to maintain timely knowledge of such FIC issues, which are mostly undocumented. In this paper, we propose such a technique, PIVOT, that automatically learns API-device correlations of FIC issues from existing Android apps. PIVOT extracts and prioritizes API-device correlations from a given corpus of Android apps. We evaluated PIVOT with popular Android apps on Google Play. Evaluation results show that PIVOT can effectively prioritize valid API-device correlations for app corpora collected at different time. Leveraging the knowledge in the learned API-device correlations, we further conducted a case study and successfully uncovered ten previously-undetected FIC issues in open-source Android apps.","","","10.1109/ICSE.2019.00094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811898","Android fragmentation, compatibility, static analysis, learning","Correlation;Biological system modeling;Cameras;Ecosystems;Testing;Google;Open source software","Android (operating system);application program interfaces;learning (artificial intelligence);mobile computing;smart phones","PIVOT;heavily fragmented Android ecosystem;fragmentation-induced compatibility issues;device models;Android OS versions;Android APIs;popular Android apps;valid API-device correlations;learned API-device correlations;open-source Android apps;Android compatibility issue detection","","","63","","","","","IEEE","IEEE Conferences"
"Could I Have a Stack Trace to Examine the Dependency Conflict Issue?","Y. Wang; M. Wen; R. Wu; Z. Liu; S. H. Tan; Z. Zhu; H. Yu; S. Cheung","Northeastern University; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; Northeastern University; Southern University of Science and Technology; Northeastern University; Northeastern University; The Hong Kong University of Science and Technology","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","572","583","Intensive use of libraries in Java projects brings potential risk of dependency conflicts, which occur when a project directly or indirectly depends on multiple versions of the same library or class. When this happens, JVM loads one version and shadows the others. Runtime exceptions can occur when methods in the shadowed versions are referenced. Although project management tools such as Maven are able to give warnings of potential dependency conflicts when a project is built, developers often ask for crashing stack traces before examining these warnings. It motivates us to develop Riddle, an automated approach that generates tests and collects crashing stack traces for projects subject to risk of dependency conflicts. Riddle, built on top of Asm and Evosuite, combines condition mutation, search strategies and condition restoration. We applied Riddle on 19 real-world Java projects with duplicate libraries or classes. We reported 20 identified dependency conflicts including their induced crashing stack traces and the details of generated tests. Among them, 15 conflicts were confirmed by developers as real issues, and 10 were readily fixed. The evaluation results demonstrate the effectiveness and usefulness of Riddle.","","","10.1109/ICSE.2019.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812128","test generation;third party-library;mutation","Libraries;Runtime;Java;Computer crashes;Tools;Test pattern generators;Static analysis","Java;program debugging;program testing;project management;public domain software;system recovery","stack trace;Riddle;real-world Java;induced crashing stack traces;dependency conflict issue;Java projects;runtime exceptions;shadowed versions;project management tools;dependency conflicts;condition mutation;search strategies;condition restoration","","","105","","","","","IEEE","IEEE Conferences"
"Practical GUI Testing of Android Applications Via Model Abstraction and Refinement","T. Gu; C. Sun; X. Ma; C. Cao; C. Xu; Y. Yao; Q. Zhang; J. Lu; Z. Su","University of California, Davis, United States; University of California, Davis, United States; Nanjing University, China; Nanjing University, China; Nanjing University, China; Nanjing University, China; Georgia Institute of Technology, United States; Nanjing University, China; University of California, Davis, United States and ETH Zurich, Switzerland","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","269","280","This paper introduces a new, fully automated modelbased approach for effective testing of Android apps. Different from existing model-based approaches that guide testing with a static GUI model (i.e., the model does not evolve its abstraction during testing, and is thus often imprecise), our approach dynamically optimizes the model by leveraging the runtime information during testing. This capability of model evolution significantly improves model precision, and thus dramatically enhances the testing effectiveness compared to existing approaches, which our evaluation confirms.We have realized our technique in a practical tool, APE. On 15 large, widely-used apps from the Google Play Store, APE outperforms the state-of-the-art Android GUI testing tools in terms of both testing coverage and the number of detected unique crashes. To further demonstrate APE's effectiveness and usability, we conduct another evaluation of APE on 1,316 popular apps, where it found 537 unique crashes. Out of the 38 reported crashes, 13 have been fixed and 5 have been confirmed.","","","10.1109/ICSE.2019.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812132","GUI testing;mobile app testing;CEGAR","Graphical user interfaces;Testing;Tools;Computer crashes;Google;Indexes;Runtime","Android (operating system);graphical user interfaces;mobile computing;program testing","Android apps;static GUI model;testing effectiveness;APE;Android applications;GUI testing;Android GUI testing tools","","1","54","","","","","IEEE","IEEE Conferences"
"Classifying Developers into Core and Peripheral: An Empirical Study on Count and Network Metrics","M. Joblin; S. Apel; C. Hunsen; W. Mauerer","Siemens AG, Erlangen, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; OTH Regensburg Munich, Siemens AG, Munich, Germany","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","164","174","Knowledge about the roles developers play in a software project is crucial to understanding the project's collaborative dynamics. In practice, developers are often classified according to the dichotomy of core and peripheral roles. Typically, count-based operationalizations, which rely on simple counts of individual developer activities (e.g., number of commits), are used for this purpose, but there is concern regarding their validity and ability to elicit meaningful insights. To shed light on this issue, we investigate whether count-based operationalizations of developer roles produce consistent results, and we validate them with respect to developers' perceptions by surveying 166 developers. Improving over the state of the art, we propose a relational perspective on developer roles, using fine-grained developer networks modeling the organizational structure, and by examining developer roles in terms of developers' positions and stability within the developer network. In a study of 10 substantial open-source projects, we found that the primary difference between the count-based and our proposed network-based core-peripheral operationalizations is that the network-based ones agree more with developer perception than count-based ones. Furthermore, we demonstrate that a relational perspective can reveal further meaningful insights, such as that core developers exhibit high positional stability, upper positions in the hierarchy, and high levels of coordination with other core developers, which confirms assumptions of previous work.","","","10.1109/ICSE.2017.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985659","Developer roles;developer networks;classification;mining software repositories","Measurement;Collaboration;Stability analysis;Open source software;Systems architecture;Computer bugs","software engineering","software project;count-based operationalizations;fine-grained developer network;open-source projects;network-based core-peripheral operationalizations","","9","34","","","","","IEEE","IEEE Conferences"
"A Guided Genetic Algorithm for Automated Crash Reproduction","M. Soltani; A. Panichella; A. van Deursen","Delft Univ. of Technol., Delft, Netherlands; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; Delft Univ. of Technol., Delft, Netherlands","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","209","220","To reduce the effort developers have to make for crash debugging, researchers have proposed several solutions for automatic failure reproduction. Recent advances proposed the use of symbolic execution, mutation analysis, and directed model checking as underling techniques for post-failure analysis of crash stack traces. However, existing approaches still cannot reproduce many real-world crashes due to such limitations as environment dependencies, path explosion, and time complexity. To address these challenges, we present EvoCrash, a post-failure approach which uses a novel Guided Genetic Algorithm (GGA) to cope with the large search space characterizing real-world software programs. Our empirical study on three open-source systems shows that EvoCrash can replicate 41 (82%) of real-world crashes, 34 (89%) of which are useful reproductions for debugging purposes, outperforming the state-of-the-art in crash replication.","","","10.1109/ICSE.2017.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985663","Search-Based Software Testing;Genetic Algorithms;Automated Crash Reproduction","Tools;Genetic algorithms;Software;Model checking;Computer bugs;Debugging","genetic algorithms;program debugging","guided genetic algorithm;automated crash reproduction;crash debugging;automatic failure reproduction;EvoCrash;post-failure approach;GGA","","6","40","","","","","IEEE","IEEE Conferences"
"Evaluating and Improving Fault Localization","S. Pearson; J. Campos; R. Just; G. Fraser; R. Abreu; M. D. Ernst; D. Pang; B. Keller","Univ. of Washington, St. Louis, MO, USA; Univ. of Sheffield, Sheffield, UK; Univ. of Massachusetts, Amherst, MA, USA; Univ. of Sheffield, Sheffield, UK; Palo Alto Res. Center, Palo Alto, CA, USA; Univ. of Washington, St. Louis, MO, USA; Univ. of Washington, St. Louis, MO, USA; Univ. of Washington, St. Louis, MO, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","609","620","Most fault localization techniques take as input a faulty program, and produce as output a ranked list of suspicious code locations at which the program may be defective. When researchers propose a new fault localization technique, they typically evaluate it on programs with known faults. The technique is scored based on where in its output list the defective code appears. This enables the comparison of multiple fault localization techniques to determine which one is better. Previous research has evaluated fault localization techniques using artificial faults, generated either by mutation tools or manually. In other words, previous research has determined which fault localization techniques are best at finding artificial faults. However, it is not known which fault localization techniques are best at finding real faults. It is not obvious that the answer is the same, given previous work showing that artificial faults have both similarities to and differences from real faults. We performed a replication study to evaluate 10 claims in the literature that compared fault localization techniques (from the spectrum-based and mutation-based families). We used 2995 artificial faults in 6 real-world programs. Our results support 7 of the previous claims as statistically significant, but only 3 as having non-negligible effect sizes. Then, we evaluated the same 10 claims, using 310 real faults from the 6 programs. Every previous result was refuted or was statistically and practically insignificant. Our experiments show that artificial faults are not useful for predicting which fault localization techniques perform best on real faults. In light of these results, we identified a design space that includes many previously-studied fault localization techniques as well as hundreds of new techniques. We experimentally determined which factors in the design space are most important, using an overall set of 395 real faults. Then, we extended this design space with new techniques. Several of our novel techniques outperform all existing techniques, notably in terms of ranking defective code in the top-5 or top-10 reports.","","","10.1109/ICSE.2017.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985698","","Maintenance engineering;Tools;Debugging;Java;Computer bugs;Focusing;Manuals","program testing;source code (software)","fault localization techniques;faulty program;suspicious code locations;defective code;replication study;spectrum-based families;mutation-based families;design space","","35","50","","","","","IEEE","IEEE Conferences"
"Analysis and Detection of Information Types of Open Source Software Issue Discussions","D. Arya; W. Wang; J. L. C. Guo; J. Cheng","McGill University; McGill University; McGill University; Polytechnique Montreal","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","454","464","Most modern Issue Tracking Systems (ITSs) for open source software (OSS) projects allow users to add comments to issues. Over time, these comments accumulate into discussion threads embedded with rich information about the software project, which can potentially satisfy the diverse needs of OSS stakeholders. However, discovering and retrieving relevant information from the discussion threads is a challenging task, especially when the discussions are lengthy and the number of issues in ITSs are vast. In this paper, we address this challenge by identifying the information types presented in OSS issue discussions. Through qualitative content analysis of 15 complex issue threads across three projects hosted on GitHub, we uncovered 16 information types and created a labeled corpus containing 4656 sentences. Our investigation of supervised, automated classification techniques indicated that, when prior knowledge about the issue is available, Random Forest can effectively detect most sentence types using conversational features such as the sentence length and its position. When classifying sentences from new issues, Logistic Regression can yield satisfactory performance using textual features for certain information types, while falling short on others. Our work represents a nontrivial first step towards tools and techniques for identifying and obtaining the rich information recorded in the ITSs to support various software engineering activities and to satisfy the diverse needs of OSS stakeholders.","","","10.1109/ICSE.2019.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811936","collaborative software engineering;issue tracking system;issue discussion analysis","Stakeholders;Message systems;Software engineering;Computer bugs;Task analysis;Open source software","learning (artificial intelligence);pattern classification;project management;public domain software;regression analysis;software development management","ITSs;open source software projects;software project;OSS stakeholders;OSS issue discussions;qualitative content analysis;sentence types;software engineering activities;information types;open source software issue discussions;random forest;logistic regression","","","29","","","","","IEEE","IEEE Conferences"
"Natural Software Revisited","M. Rahman; D. Palani; P. C. Rigby","Concordia University; Concordia University; Concordia University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","37","48","Recent works have concluded that software code is more repetitive and predictable, i.e. more natural, than English texts. On re-examination, we find that much of the apparent ""naturalness"" of source code is due to the presence of language specific syntax, especially separators, such as semi-colons and brackets. For example, separators account for 44% of all tokens in our Java corpus. When we follow the NLP practices of eliminating punctuation (e.g., separators) and stopwords (e.g., keywords), we find that code is still repetitive and predictable, but to a lesser degree than previously thought. We suggest that SyntaxTokens be filtered to reduce noise in code recommenders. Unlike the code written for a particular project, API code usage is similar across projects: a file is opened and closed in the same manner regardless of domain. When we restrict our n-grams to those contained in the Java API, we find that API usages are highly repetitive. Since API calls are common across programs, researchers have made reliable statistical models to recommend sophisticated API call sequences. Sequential n-gram models were developed for natural languages. Code is usually represented by an AST which contains control and data flow, making n-grams models a poor representation of code. Comparing n-grams to statistical graph representations of the same codebase, we find that graphs are more repetitive and contain higherlevel patterns than n-grams. We suggest that future work focus on statistical code graphs models that accurately capture complex coding patterns. Our replication package makes our scripts and data available to future researchers[1].","","","10.1109/ICSE.2019.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811940","Basic Science;Entropy;Language Models;Statistical Code Graphs;StackOverflow","Java;Mathematical model;Syntactics;Particle separators;Programming;Python","application program interfaces;graph theory;Java;natural language processing;source code (software);statistical analysis;text analysis","natural software;software code;English texts;re-examination;apparent naturalness;source code;language specific syntax;separators;brackets;Java corpus;NLP practices;code recommenders;API code usage;Java API;API usages;sophisticated API call sequences;sequential n-gram models;natural languages;statistical graph representations;statistical code graphs models;complex coding patterns","","2","58","","","","","IEEE","IEEE Conferences"
"Automatic Text Input Generation for Mobile Testing","P. Liu; X. Zhang; M. Pistoia; Y. Zheng; M. Marques; L. Zeng","IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; Purdue Univ., West Lafayette, IN, USA; IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA; Purdue Univ., West Lafayette, IN, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","643","653","Many designs have been proposed to improve the automated mobile testing. Despite these improvements, providing appropriate text inputs remains a prominent obstacle, which hinders the large-scale adoption of automated testing approaches. The key challenge is how to automatically produce the most relevant text in a use case context. For example, a valid website address should be entered in the address bar of a mobile browser app to continue the testing of the app, a singer's name should be entered in the search bar of a music recommendation app. Without the proper text inputs, the testing would get stuck. We propose a novel deep learning based approach to address the challenge, which reduces the problem to a minimization problem. Another challenge is how to make the approach generally applicable to both the trained apps and the untrained apps. We leverage the Word2Vec model to address the challenge. We have built our approaches as a tool and evaluated it with 50 iOS mobile apps including Firefox and Wikipedia. The results show that our approach significantly outperforms existing automatic text input generation methods.","","","10.1109/ICSE.2017.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985701","","Testing;Mobile communication;Neurons;Biological neural networks;Predictive models;Training;Context modeling","learning (artificial intelligence);mobile computing;program testing;text analysis","Wikipedia;Firefox;iOS mobile apps;Word2Vec model;minimization problem;deep learning based approach;music recommendation app;mobile browser app;Web site address;automated mobile testing;automatic text input generation method","","7","37","","","","","IEEE","IEEE Conferences"
"Learning to Spot and Refactor Inconsistent Method Names","K. Liu; D. Kim; T. F. Bissyand√©; T. Kim; K. Kim; A. Koyuncu; S. Kim; Y. Le Traon","Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Department of Software Engineering, Chonbuk National University, South Korea; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg; Department of Software Engineering, Chonbuk National University, South Korea; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1","12","To ensure code readability and facilitate software maintenance, program methods must be named properly. In particular, method names must be consistent with the corresponding method implementations. Debugging method names remains an important topic in the literature, where various approaches analyze commonalities among method names in a large dataset to detect inconsistent method names and suggest better ones. We note that the state-of-the-art does not analyze the implemented code itself to assess consistency. We thus propose a novel automated approach to debugging method names based on the analysis of consistency between method names and method code. The approach leverages deep feature representation techniques adapted to the nature of each artifact. Experimental results on over 2.1 million Java methods show that we can achieve up to 15 percentage points improvement over the state-of-the-art, establishing a record performance of 67.9% F1- measure in identifying inconsistent method names. We further demonstrate that our approach yields up to 25% accuracy in suggesting full names, while the state-of-the-art lags far behind at 1.1% accuracy. Finally, we report on our success in fixing 66 inconsistent method names in a live study on projects in the wild.","","","10.1109/ICSE.2019.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812134","Code refactoring, inconsistent method names, deep neural networks, code embedding","Feature extraction;Semantics;Neural networks;Training;Computational modeling;Debugging;Software","Java;program debugging;software maintenance","refactor inconsistent method names;program methods;debugging method names;method code;Java methods;code readability;software maintenance","","4","86","","","","","IEEE","IEEE Conferences"
"ZenIDS: Introspective Intrusion Detection for PHP Applications","B. Hawkins; B. Demsky","Univ. of California, Irvine, Irvine, CA, USA; Univ. of California, Irvine, Irvine, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","232","243","Since its first appearance more than 20 years ago, PHP has steadily increased in popularity, and has become the foundation of the Internet's most popular content management systems (CMS). Of the world's 1 million most visited websites, nearly half use a CMS, and WordPress alone claims 25% market share of all websites. While their easy-to-use templates and components have greatly simplified the work of developing high quality websites, it comes at the cost of software vulnerabilities that are inevitable in such large and rapidly evolving frameworks. Intrusion Detection Systems (IDS) are often used to protect Internet-facing applications, but conventional techniques struggle to keep up with the fast pace of development in today's web applications. Rapid changes to application interfaces increase the workload of maintaining an IDS whitelist, yet the broad attack surface of a web application makes for a similarly verbose blacklist. We developed ZenIDS to dynamically learn the trusted execution paths of an application during a short online training period and report execution anomalies as potential intrusions. We implement ZenIDS as a PHP extension supported by 8 hooks instrumented in the PHP interpreter. Our experiments demonstrate its effectiveness monitoring live web traffic for one year to 3 large PHP applications, detecting malicious requests with a false positive rate of less than .01% after training on fewer than 4,000 requests. ZenIDS excludes the vast majority of deployed PHP code from the whitelist because it is never used for valid requests-yet could potentially be exploited by a remote adversary. We observe 5% performance overhead (or less) for our applications vs. an optimized vanilla LAMP stack.","","","10.1109/ICSE.2017.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985665","","Training;Monitoring;Authentication;Intrusion detection;Internet;Content management","authoring languages;security of data;system monitoring","PHP applications;ZENIDS;PHP extension;PHP interpreter;malicious requests detection;live Web traffic monitoring;vanilla LAMP stack;introspective intrusion detection;intrusion detection systems","","","54","","","","","IEEE","IEEE Conferences"
"VFix: Value-Flow-Guided Precise Program Repair for Null Pointer Dereferences","X. Xu; Y. Sui; H. Yan; J. Xue","University of New South Wales, Australia; University of Technology Sydney, Australia; University of New South Wales, Australia; University of New South Wales, Australia","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","512","523","Automated Program Repair (APR) faces a key challenge in efficiently generating correct patches from a potentially infinite solution space. Existing approaches, which attempt to reason about the entire solution space, can be ineffective (by often producing no plausible patches at all) and imprecise (by often producing plausible but incorrect patches). We present VFIX, a new value-flow-guided APR approach, to fix null pointer exception (NPE) bugs by considering a substantially reduced solution space in order to greatly increase the number of correct patches generated. By reasoning about the data and control dependences in the program, VFIX can identify bug-relevant repair statements more accurately and generate more correct repairs than before. VFIX outperforms a set of 8 state-of-the-art APR tools in fixing the NPE bugs in Defects4j in terms of both precision (by correctly fixing 3 times as many bugs as the most precise one and 50% more than all the bugs correctly fixed by these 8 tools altogether) and efficiency (by producing a correct patch in minutes instead of hours).","","","10.1109/ICSE.2019.00063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812101","program repair, static analysis, null dereference","Maintenance engineering;Computer bugs;Tools;Aerospace electronics;Software;Australia","program debugging;program diagnostics;software maintenance","VFix;value-flow-guided precise program repair;null pointer dereferences;value-flow-guided APR approach;null pointer exception bugs;bug-relevant repair statements;NPE bugs;automated program repair","","1","92","","","","","IEEE","IEEE Conferences"
"View-Centric Performance Optimization for Database-Backed Web Applications","J. Yang; C. Yan; C. Wan; S. Lu; A. Cheung","University of Chicago, USA; University of Washington, USA; University of Chicago, USA; University of Chicago, USA; University of Washington, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","994","1004","Web developers face the stringent task of designing informative web pages while keeping the page-load time low. This task has become increasingly challenging as most web contents are now generated by processing ever-growing amount of user data stored in back-end databases. It is difficult for developers to understand the cost of generating every web-page element, not to mention explore and pick the web design with the best trade-off between performance and functionality. In this paper, we present Panorama, a view-centric and database-aware development environment for web developers. Using database-aware program analysis and novel IDE design, Panorama provides developers with intuitive information about the cost and the performance-enhancing opportunities behind every HTML element, as well as suggesting various global code refactorings that enable developers to easily explore a wide spectrum of performance and functionality trade-offs.","","","10.1109/ICSE.2019.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811938","database backed web applications;ORM framework;view centric","Databases;Rails;Web pages;Data processing;Tools;Servers;Task analysis","database management systems;hypermedia markup languages;program diagnostics;Web design","view-centric performance optimization;page-load time;back-end databases;database-aware development environment;database-aware program analysis;performance-enhancing opportunities;database-backed Web applications;Web design;Web-page element;informative Web pages","","2","43","","","","","IEEE","IEEE Conferences"
"ReCDroid: Automatically Reproducing Android Application Crashes from Bug Reports","Y. Zhao; T. Yu; T. Su; Y. Liu; W. Zheng; J. Zhang; W. G.J. Halfond","University of Kentucky; University of Kentucky; Nanyang Technological University; Nanyang Technological University; Northwestern Polytechnical University; Northwestern Polytechnical University; University of Southern California","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","128","139","The large demand of mobile devices creates significant concerns about the quality of mobile applications (apps). Developers heavily rely on bug reports in issue tracking systems to reproduce failures (e.g., crashes). However, the process of crash reproduction is often manually done by developers, making the resolution of bugs inefficient, especially that bug reports are often written in natural language. To improve the productivity of developers in resolving bug reports, in this paper, we introduce a novel approach, called ReCDroid, that can automatically reproduce crashes from bug reports for Android apps. ReCDroid uses a combination of natural language processing (NLP) and dynamic GUI exploration to synthesize event sequences with the goal of reproducing the reported crash. We have evaluated ReCDroid on 51 original bug reports from 33 Android apps. The results show that ReCDroid successfully reproduced 33 crashes (63.5% success rate) directly from the textual description of bug reports. A user study involving 12 participants demonstrates that ReCDroid can improve the productivity of developers when resolving crash bug reports.","","","10.1109/ICSE.2019.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811942","Bug reproduction;Android;Natural language processing","Computer bugs;Graphical user interfaces;Data mining;Natural language processing;Google","graphical user interfaces;mobile computing;natural language processing;program debugging;smart phones;software maintenance","reported crash;ReCDroid;bug reports;crash bug reports;Android application crash;Android apps;natural language processing;dynamic GUI exploration","","","57","","","","","IEEE","IEEE Conferences"
"Automated Transplantation and Differential Testing for Clones","T. Zhang; M. Kim","Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","665","676","Code clones are common in software. When applying similar edits to clones, developers often find it difficult to examine the runtime behavior of clones. The problem is exacerbated when some clones are tested, while their counterparts are not. To reuse tests for similar but not identical clones, Grafter transplants one clone to its counterpart by (1) identifying variations in identifier names, types, and method call targets, (2) resolving compilation errors caused by such variations through code transformation, and (3) inserting stub code to transfer input data and intermediate output values for examination. To help developers examine behavioral differences between clones, Grafter supports fine-grained differential testing at both the test outcome level and the intermediate program state level. In our evaluation on three open source projects, Grafter successfully reuses tests in 94% of clone pairs without inducing build errors, demonstrating its automated code transplantation capability. To examine the robustness of G RAFTER, we systematically inject faults using a mutation testing tool, Major, and detect behavioral differences induced by seeded faults. Compared with a static cloning bug finder, Grafter detects 31% more mutants using the test-level comparison and almost 2X more using the state-level comparison. This result indicates that Grafter should effectively complement static cloning bug finders.","","","10.1109/ICSE.2017.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985703","Test Reuse;Code Transplantation;Differential Testing;Code Clones","Cloning;Computer bugs;Testing;Runtime;Software;Safety;Java","program diagnostics;program testing;public domain software;software reusability","automated transplantation testing;automated differential testing;code clones;runtime behavior;Grafter;variation identification;identifier names;targets;compilation errors;code transformation;stub code insertion;input data transfer;intermediate output value transfer;test outcome level;intermediate program state level;open source projects;test reuse;clone pairs;mutation testing tool;Major;fault injection;behavioral differences detection;test-level comparison;state-level comparison;static cloning bug finders","","5","52","","","","","IEEE","IEEE Conferences"
"Parallel Refinement for Multi-Threaded Program Verification","L. Yin; W. Dong; W. Liu; J. Wang","National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","643","653","Program verification is one of the most important methods to ensuring the correctness of concurrent programs. However, due to the path explosion problem, concurrent program verification is usually time consuming, which hinders its scalability to industrial programs. Parallel processing is a mainstream technique to deal with those problems which require mass computing. Hence, designing parallel algorithms to improve the performance of concurrent program verification is highly desired. This paper focuses on parallelization of the abstraction refinement technique, one of the most efficient techniques for concurrent program verification. We present a parallel refinement framework which employs multiple engines to refine the abstraction in parallel. Different from existing work which parallelizes the search process, our method achieves the effect of parallelization by refinement constraint and learnt clause sharing, so that the number of required iterations can be significantly reduced. We have implemented this framework on the scheduling constraint based abstraction refinement method, one of the best methods for concurrent program verification. Experiments on SV-COMP 2018 show the encouraging results of our method. For those complex programs requiring a large number of iterations, our method can obtain a linear reduction of the iteration number and significantly improve the verification performance.","","","10.1109/ICSE.2019.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812136","Concurrent Program;Abstraction Refinement;Scheduling Constraint;Parallel Verification","Engines;Concurrent computing;Programming;Encoding;Instruction sets;Software engineering;Job shop scheduling","iterative methods;multi-threading;parallel algorithms;program diagnostics;program verification;scheduling","parallel processing;parallel algorithms;concurrent program verification;abstraction refinement technique;parallel refinement framework;scheduling constraint based abstraction refinement method;complex programs;multithreaded program;concurrent programs","","","39","","","","","IEEE","IEEE Conferences"
"On Cross-Stack Configuration Errors","M. Sayagh; N. Kerzazi; B. Adams","NA; NA; NA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","255","265","Today's web applications are deployed on powerful software stacks such as MEAN (JavaScript) or LAMP (PHP), which consist of multiple layers such as an operating system, web server, database, execution engine and application framework, each of which provide resources to the layer just above it. These powerful software stacks unfortunately are plagued by so-called cross-stack configuration errors (CsCEs), where a higher layer in the stack suddenly starts to behave incorrectly or even crash due to incorrect configuration choices in lower layers. Due to differences in programming languages and lack of explicit links between configuration options of different layers, sysadmins and developers have a hard time identifying the cause of a CsCE, which is why this paper (1) performs a qualitative analysis of 1,082 configuration errors to understand the impact, effort and complexity of dealing with CsCEs, then (2) proposes a modular approach that plugs existing source code analysis (slicing) techniques, in order to recommend the culprit configuration option. Empirical evaluation of this approach on 36 real CsCEs of the top 3 LAMP stack layers shows that our approach reports the misconfigured option with an average rank of 2.18 for 32 of the CsCEs, and takes only few minutes, making it practically useful.","","","10.1109/ICSE.2017.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985667","Software Configuration;Software Stack;Qualitative Study;Multi-layer Systems;Empirical Study;Slicing;PHP","Databases;Web servers;Testing;Debugging;Operating systems","Internet;program slicing;source code (software)","Web applications;software stacks;cross-stack configuration errors;programming languages;CsCE;qualitative analysis;configuration errors;source code analysis;source code slicing;culprit configuration option;LAMP stack layers","","4","53","","","","","IEEE","IEEE Conferences"
"Supporting the Statistical Analysis of Variability Models","R. Heradio; D. Fernandez-Amoros; C. Mayr-Dorn; A. Egyed","Universidad Nacional de Educacion a Distancia, Spain; Universidad Nacional de Educacion a Distancia, Spain; Johannes Kepler University, Austria; Johannes Kepler University, Austria","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","843","853","Variability models are broadly used to specify the configurable features of highly customizable software. In practice, they can be large, defining thousands of features with their dependencies and conflicts. In such cases, visualization techniques and automated analysis support are crucial for understanding the models. This paper contributes to this line of research by presenting a novel, probabilistic foundation for statistical reasoning about variability models. Our approach not only provides a new way to visualize, describe and interpret variability models, but it also supports the improvement of additional state-of-the-art methods for software product lines; for instance, providing exact computations where only approximations were available before, and increasing the sensitivity of existing analysis operations for variability models. We demonstrate the benefits of our approach using real case studies with up to 17,365 features, and written in two different languages (KConfig and feature models).","","","10.1109/ICSE.2019.00091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811977","Variability modeling;feature modeling;software product lines;software visualization;binary decision diagrams","Visualization;Computational modeling;Analytical models;Software;Cognition;Feature extraction;Complexity theory","data visualisation;probability;public domain software;software product lines;software reusability;statistical analysis","statistical analysis;variability models;automated analysis support;visualization techniques;software product lines;feature model language;KConfig language","","","41","","","","","IEEE","IEEE Conferences"
"Making Malory Behave Maliciously: Targeted Fuzzing of Android Execution Environments","S. Rasthofer; S. Arzt; S. Triller; M. Pradel","Fraunhofer SIT, Tech. Univ. Darmstadt, Darmstadt, Germany; Fraunhofer SIT, Tech. Univ. Darmstadt, Darmstadt, Germany; Fraunhofer SIT, Germany; Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","300","311","Android applications, or apps, provide useful features to end-users, but many apps also contain malicious behavior. Modern malware makes understanding such behavior challenging by behaving maliciously only under particular conditions. For example, a malware app may check whether it runs on a real device and not an emulator, in a particular country, and alongside a specific target app, such as a vulnerable banking app. To observe the malicious behavior, a security analyst must find out and emulate all these app-specific constraints. This paper presents FuzzDroid, a framework for automatically generating an Android execution environment where an app exposes its malicious behavior. The key idea is to combine an extensible set of static and dynamic analyses through a search-based algorithm that steers the app toward a configurable target location. On recent malware, the approach reaches the target location in 75% of the apps. In total, we reach 240 code locations within an average time of only one minute. To reach these code locations, FuzzDroid generates 106 different environments, too many for a human analyst to create manually.","","","10.1109/ICSE.2017.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985671","","Malware;Smart phones;Heuristic algorithms;Algorithm design and analysis;Mobile communication;Security;Instruments","invasive software;smart phones","malory;Android execution environment targeted fuzzing;Android applications;malicious behavior;malware;security analyst;app-specific constraints;FuzzDroid;static analysis;dynamic analysis;search-based algorithm;code locations","","9","44","","","","","IEEE","IEEE Conferences"
"Gigahorse: Thorough, Declarative Decompilation of Smart Contracts","N. Grech; L. Brent; B. Scholz; Y. Smaragdakis","University of Athens, Greece and University of Malta, Malta; The University of Sydney, Australia; The University of Sydney, Australia; University of Athens, Greece","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1176","1186","The rise of smart contracts - autonomous applications running on blockchains - has led to a growing number of threats, necessitating sophisticated program analysis. However, smart contracts, which transact valuable tokens and cryptocurrencies, are compiled to very low-level bytecode. This bytecode is the ultimate semantics and means of enforcement of the contract. We present the Gigahorse toolchain. At its core is a reverse compiler (i.e., a decompiler) that decompiles smart contracts from Ethereum Virtual Machine (EVM) bytecode into a highlevel 3-address code representation. The new intermediate representation of smart contracts makes implicit data- and control-flow dependencies of the EVM bytecode explicit. Decompilation obviates the need for a contract's source and allows the analysis of both new and deployed contracts. Gigahorse advances the state of the art on several fronts. It gives the highest analysis precision and completeness among decompilers for Ethereum smart contracts - e.g., Gigahorse can decompile over 99.98% of deployed contracts, compared to 88% for the recently-published Vandal decompiler and under 50% for the state-of-the-practice Porosity decompiler. Importantly, Gigahorse offers a full-featured toolchain for further analyses (and a ‚Äúbatteries included‚Äù approach, with multiple clients already implemented), together with the highest performance and scalability. Key to these improvements is Gigahorse's use of a declarative, logic-based specification, which allows high-level insights to inform low-level decompilation.","","","10.1109/ICSE.2019.00120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811905","Ethereum;Blockchain;Decompilation;Program Analysis;Security","Smart contracts;Blockchain;Virtual machining;Task analysis;Java;Security","contracts;cryptocurrencies;distributed databases;formal specification;program compilers;program diagnostics;virtual machines","Gigahorse;low-level decompilation;program analysis;blockchain;logic-based specification;cryptocurrencies;Ethereum virtual machine bytecode;EVM bytecode;Porosity decompiler;Vandal decompiler;Ethereum smart contracts","","","36","","","","","IEEE","IEEE Conferences"
"Analyzing and Supporting Adaptation of Online Code Examples","T. Zhang; D. Yang; C. Lopes; M. Kim","University of California, Los Angeles; University of California, Irvine; University of California, Irvine; University of California, Los Angeles","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","316","327","Developers often resort to online Q&A forums such as Stack Overflow (SO) for filling their programming needs. Although code examples on those forums are good starting points, they are often incomplete and inadequate for developers' local program contexts; adaptation of those examples is necessary to integrate them to production code. As a consequence, the process of adapting online code examples is done over and over again, by multiple developers independently. Our work extensively studies these adaptations and variations, serving as the basis for a tool that helps integrate these online code examples in a target context in an interactive manner. We perform a large-scale empirical study about the nature and extent of adaptations and variations of SO snippets. We construct a comprehensive dataset linking SO posts to GitHub counterparts based on clone detection, time stamp analysis, and explicit URL references. We then qualitatively inspect 400 SO examples and their GitHub counterparts and develop a taxonomy of 24 adaptation types. Using this taxonomy, we build an automated adaptation analysis technique on top of GumTree to classify the entire dataset into these types. We build a Chrome extension called ExampleStack that automatically lifts an adaptation-aware template from each SO example and its GitHub counterparts to identify hot spots where most changes happen. A user study with sixteen programmers shows that seeing the commonalities and variations in similar GitHub counterparts increases their confidence about the given SO example, and helps them grasp a more comprehensive view about how to reuse the example differently and avoid common pitfalls.","","","10.1109/ICSE.2019.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812028","online code examples;code adaptation","Cloning;Taxonomy;Java;Tools;Programming;Software engineering;Production","data mining;program debugging;program diagnostics;software maintenance","automated adaptation analysis technique;adaptation-aware template;production code;online Q&A forums;SO snippets;clone detection;time stamp analysis;explicit URL references;Chrome extension;ExampleStack","","","68","","","","","IEEE","IEEE Conferences"
"Graph-Based Mining of In-the-Wild, Fine-Grained, Semantic Code Change Patterns","H. A. Nguyen; T. N. Nguyen; D. Dig; S. Nguyen; H. Tran; M. Hilton","Iowa State University, USA; University of Texas at Dallas, USA; Oregon State University; University of Texas at Dallas, USA; University of Texas at Dallas, USA; Carnegie Mellon University, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","819","830","Prior research exploited the repetitiveness of code changes to enable several tasks such as code completion, bug-fix recommendation, library adaption, etc. These and other novel applications require accurate detection of semantic changes, but the state-of-the-art methods are limited to algorithms that detect specific kinds of changes at the syntactic level. Existing algorithms relying on syntactic similarity have lower accuracy, and cannot effectively detect semantic change patterns. We introduce a novel graph-based mining approach, CPatMiner, to detect previously unknown repetitive changes in the wild, by mining fine-grained semantic code change patterns from a large number of repositories. To overcome unique challenges such as detecting meaningful change patterns and scaling to large repositories, we rely on fine-grained change graphs to capture program dependencies. We evaluate CPatMiner by mining change patterns in a diverse corpus of 5,000+ open-source projects from GitHub across a population of 170,000+ developers. We use three complementary methods. First, we sent the mined patterns to 108 open-source developers. We found that 70% of respondents recognized those patterns as their meaningful frequent changes. Moreover, 79% of respondents even named the patterns, and 44% wanted future IDEs to automate such repetitive changes. We found that the mined change patterns belong to various development activities: adaptive (9%), perfective (20%), corrective (35%) and preventive (36%, including refactorings). Second, we compared our tool with the state-of-the-art, AST-based technique, and reported that it detects 2.1x more meaningful patterns. Third, we use CPatMiner to search for patterns in a corpus of 88 GitHub projects with longer histories consisting of 164M SLOCs. It constructed 322K fine-grained change graphs containing 3M nodes, and detected 17K instances of change patterns from which we provide unique insights on the practice of change patterns among individuals and teams. We found that a large percentage (75%) of the change patterns from individual developers are commonly shared with others, and this holds true for teams. Moreover, we found that the patterns are not intermittent but spread widely over time. Thus, we call for a community-based change pattern database to provide important resources in novel applications.","","","10.1109/ICSE.2019.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812071","Semantic Change Pattern Mining, Graph Mining","Semantics;Tools;Data mining;Syntactics;Computer science;Task analysis;Open source software","data mining;graph theory;program diagnostics;software engineering","fine-grained semantic code change patterns;fine-grained change;mined change patterns;community-based change pattern database;graph-based mining;code changes;semantic change patterns;GitHub projects;AST-based technique","","1","48","","","","","IEEE","IEEE Conferences"
"Optimizing Test Placement for Module-Level Regression Testing","A. Shi; S. Thummalapenta; S. K. Lahiri; N. Bjorner; J. Czerwonka","Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Microsoft Corp., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Corp., Redmond, WA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","689","699","Modern build systems help increase developer productivity by performing incremental building and testing. These build systems view a software project as a group of interdependent modules and perform regression test selection at the module level. However, many large software projects have imprecise dependency graphs that lead to wasteful test executions. If a test belongs to a module that has more dependencies than the actual dependencies of the test, then it is executed unnecessarily whenever a code change impacts those additional dependencies. In this paper, we formulate the problem of wasteful test executions due to suboptimal placement of tests in modules. We propose a greedy algorithm to reduce the number of test executions by suggesting test movements while considering historical build information and actual dependencies of tests. We have implemented our technique, called TestOptimizer, on top of CloudBuild, the build system developed within Microsoft over the last few years. We have evaluated the technique on five large proprietary projects. Our results show that the suggested test movements can lead to a reduction of 21.66 million test executions (17.09%) across all our subject projects. We received encouraging feedback from the developers of these projects; they accepted and intend to implement ‚âà80% of our reported suggestions.","","","10.1109/ICSE.2017.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985705","regression test selection;module-level regression testing;build system","Software;Testing;Buildings;Greedy algorithms;Metadata;Productivity;Google","greedy algorithms;program testing;regression analysis","test placement optimization;module-level regression testing;software project;dependency graphs;greedy algorithm;TestOptimizer;CloudBuild","","2","24","","","","","IEEE","IEEE Conferences"
"RClassify: Classifying Race Conditions in Web Applications via Deterministic Replay","L. Zhang; C. Wang","Virginia Tech., Blacksburg, VA, USA; Univ. of Southern California, Los Angeles, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","278","288","Race conditions are common in web applications but are difficult to diagnose and repair. Although there exist tools for detecting races in web applications, they all report a large number of false positives. That is, the races they report are either bogus, meaning they can never occur in practice, or benign, meaning they do not lead to erroneous behaviors. Since manually diagnosing them is tedious and error prone, reporting these race warnings to developers would be counter-productive. We propose a platform-agnostic, deterministic replay-based method for identifying not only the real but also the truly harmful race conditions. It relies on executing each pair of racing events in two different orders and assessing their impact on the program state: we say a race is harmful only if (1) both of the two executions arefeasible and (2) they lead to different program states. We have evaluated our evidence-based classification method on a large set of real websites from Fortune-500 companies and demonstrated that it significantly outperforms all state-of-the-art techniques.","","","10.1109/ICSE.2017.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985669","Race condition;web application;JavaScript;deterministic replay;program repair","Tools;HTML;Browsers;Companies;Robustness;Benchmark testing;Standards","Internet;pattern classification","RClassify;race condition classification;Web applications;platform-agnostic deterministic replay-based method;program state;evidence-based classification method;Web sites","","2","33","","","","","IEEE","IEEE Conferences"
"An Efficient, Robust, and Scalable Approach for Analyzing Interacting Android Apps","Y. Tsutano; S. Bachala; W. Srisa-An; G. Rothermel; J. Dinh","Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","324","334","When multiple apps on an Android platform interact, faults and security vulnerabilities can occur. Software engineers need to be able to analyze interacting apps to detect such problems. Current approaches for performing such analyses, however, do not scale to the numbers of apps that may need to be considered, and thus, are impractical for application to real-world scenarios. In this paper, we introduce JITANA, a program analysis framework designed to analyze multiple Android apps simultaneously. By using a classloader-based approach instead of a compiler-based approach such as SOOT, JITANA is able to simultaneously analyze large numbers of interacting apps, perform on-demand analysis of large libraries, and effectively analyze dynamically generated code. Empirical studies of JITANA show that it is substantially more efficient than a state-of-the-art approach, and that it can effectively and efficiently analyze complex apps including Facebook, Pokemon Go, and Pandora that the state-of-the-art approach cannot handle.","","","10.1109/ICSE.2017.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985673","Android;program analysis;inter-app communication","Androids;Humanoid robots;Tools;Security;Java;Libraries;Robustness","Android (operating system);mobile computing;program compilers","Android Apps;JITANA;program analysis;classloader-based approach;SOOT;Facebook;Pokemon Go;Pandora","","3","33","","","","","IEEE","IEEE Conferences"
"Mimic: UI Compatibility Testing System for Android Apps","T. Ki; C. M. Park; K. Dantu; S. Y. Ko; L. Ziarek","University at Buffalo, The State University of New York; University at Buffalo, The State University of New York; University at Buffalo, The State University of New York; University at Buffalo, The State University of New York; University at Buffalo, The State University of New York","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","246","256","This paper proposes Mimic, an automated UI compatibility testing system for Android apps. Mimic is designed specifically for comparing the UI behavior of an app across different devices, different Android versions, and different app versions. This design choice stems from a common problem that Android developers and researchers face-how to test whether or not an app behaves consistently across different environments or internal changes. Mimic allows Android app developers to easily perform backward and forward compatibility testing for their apps. It also enables a clear comparison between a stable version of app and a newer version of app. In doing so, Mimic allows multiple testing strategies to be used, such as randomized or sequential testing. Finally, Mimic programming model allows such tests to be scripted with much less developer effort than other comparable systems. Additionally, Mimic allows parallel testing with multiple testing devices and thereby speeds up testing time. To demonstrate these capabilities, we perform extensive tests for each of the scenarios described above. Our results show that Mimic is effective in detecting forward and backward compatibility issues, and verify runtime behavior of apps. Our evaluation also shows that Mimic significantly reduces the development burden for developers.","","","10.1109/ICSE.2019.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811983","Mobile apps;UI compatibility testing;Parallel testing;Programming model","Testing;Programming;Performance evaluation;Runtime;Libraries;Instruments;Google","Android (operating system);mobile computing;program testing;user interfaces","Android apps;Mimic programming model;parallel testing;multiple testing devices;UI compatibility testing system","","1","37","","","","","IEEE","IEEE Conferences"
"Test-Driven Code Review: An Empirical Study","D. Spadini; F. Palomba; T. Baum; S. Hanenberg; M. Bruntink; A. Bacchelli","Delft University of Technology / SIG; University of Zurich; Leibniz Universitat Hannover; Paluno, University of Duisburg-Essen; Software Improvement Group; University of Zurich","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1061","1072","Test-Driven Code Review (TDR) is a code review practice in which a reviewer inspects a patch by examining the changed test code before the changed production code. Although this practice has been mentioned positively by practitioners in informal literature and interviews, there is no systematic knowledge of its effects, prevalence, problems, and advantages. In this paper, we aim at empirically understanding whether this practice has an effect on code review effectiveness and how developers' perceive TDR. We conduct (i) a controlled experiment with 93 developers that perform more than 150 reviews, and (ii) 9 semi-structured interviews and a survey with 103 respondents to gather information on how TDR is perceived. Key results from the experiment show that developers adopting TDR find the same proportion of defects in production code, but more in test code, at the expenses of fewer maintainability issues in production code. Furthermore, we found that most developers prefer to review production code as they deem it more critical and tests should follow from it. Moreover, general poor test code quality and no tool support hinder the adoption of TDR. Public preprint: [https: //doi.org/10.5281/zenodo.2551217], data and materials: [https:// doi.org/10.5281/zenodo.2553139].","","","10.1109/ICSE.2019.00110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811911","MSR;code review;TDR;software testing","Production;Tools;Software;Inspection;Interviews;Computer bugs;Graphical user interfaces","program testing;software development management;software quality","test-driven code review;TDR;code review effectiveness;critical tests;production code;semistructured interviews;test code quality","","1","56","","","","","IEEE","IEEE Conferences"
"Recovering Variable Names for Minified Code with Usage Contexts","H. Tran; N. Tran; S. Nguyen; H. Nguyen; T. N. Nguyen","University of Texas at Dallas, USA; University of Texas at Dallas, USA; University of Texas at Dallas, USA; Iowa State University, USA; University of Texas at Dallas, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1165","1175","To avoid the exposure of original source code in a Web application, the variable names in JS code deployed in the wild are often replaced by short, meaningless names, thus making the code extremely difficult to manually understand and analysis. This paper presents JSNeat, an information retrieval (IR)-based approach to recover the variable names in minified JS code. JSNeat follows a data-driven approach to recover names by searching for them in a large corpus of open-source JS code. We use three types of contexts to match a variable in given minified code against the corpus including the context of the properties and roles of the variable, the context of that variable and relations with other variables under recovery, and the context of the task of the function to which the variable contributes. We performed several empirical experiments to evaluate JSNeat on the dataset of more than 322K JS files with 1M functions, and 3.5M variables with 176K unique variable names. We found that JSNeat achieves a high accuracy of 69.1%, which is the relative improvements of 66.1% and 43% over two state-of-the-art approaches JSNice and JSNaughty, respectively. The time to recover for a file or a variable with JSNeat is twice as fast as with JSNice and 4x as fast as with JNaughty, respectively.","","","10.1109/ICSE.2019.00119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812034","Minified JS Code, Variable Name Recovery, Naturalness of Code, Usage Contexts.","Task analysis;Reactive power;Information retrieval;Tools;Databases;Static VAr compensators;Computer science","authoring languages;information retrieval;Internet;Java;public domain software;source code (software)","usage contexts;JSNeat;information retrieval-based approach;minified JS code;open-source JS code;variable relations;variable contributes;data-driven approach;Web application;variable names;minified code;source code","","1","21","","","","","IEEE","IEEE Conferences"
"SLF: Fuzzing without Valid Seed Inputs","W. You; X. Liu; S. Ma; D. Perry; X. Zhang; B. Liang","Purdue University; Zhejiang University; Purdue University; Purdue University; Purdue University; Renmin University of China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","712","723","Fuzzing is an important technique to detect software bugs and vulnerabilities. It works by mutating a small set of seed inputs to generate a large number of new inputs. Fuzzers' performance often substantially degrades when valid seed inputs are not available. Although existing techniques such as symbolic execution can generate seed inputs from scratch, they have various limitations hindering their applications in real-world complex software. In this paper, we propose a novel fuzzing technique that features the capability of generating valid seed inputs. It piggy-backs on AFL to identify input validity checks and the input fields that have impact on such checks. It further classifies these checks according to their relations to the input. Such classes include arithmetic relation, object offset, data structure length and so on. A multi-goal search algorithm is developed to apply class-specific mutations in order to satisfy inter-dependent checks all together. We evaluate our technique on 20 popular benchmark programs collected from other fuzzing projects and the Google fuzzer test suite, and compare it with existing fuzzers AFL and AFLFast, symbolic execution engines KLEE and S2E, and a hybrid tool Driller that combines fuzzing with symbolic execution. The results show that our technique is highly effective and efficient, out-performing the other tools.","","","10.1109/ICSE.2019.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812105","fuzzing;seed inputs","Fuzzing;Software;Engines;Indexes;Tools;Libraries;Computer science","fuzzy set theory;program debugging;program testing","valid seed inputs;novel fuzzing technique;input validity checks;software bugs detection;software vulnerabilities;Google fuzzer test suite;multigoal search algorithm","","","57","","","","","IEEE","IEEE Conferences"
"Guiding Deep Learning System Testing Using Surprise Adequacy","J. Kim; R. Feldt; S. Yoo","KAIST, Republic of Korea; Chalmers University and Blekinge Inst. of Technology, Sweden; KAIST, Republic of Korea","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1039","1049","Deep Learning (DL) systems are rapidly being adopted in safety and security critical domains, urgently calling for ways to test their correctness and robustness. Testing of DL systems has traditionally relied on manual collection and labelling of data. Recently, a number of coverage criteria based on neuron activation values have been proposed. These criteria essentially count the number of neurons whose activation during the execution of a DL system satisfied certain properties, such as being above predefined thresholds. However, existing coverage criteria are not sufficiently fine grained to capture subtle behaviours exhibited by DL systems. Moreover, evaluations have focused on showing correlation between adversarial examples and proposed criteria rather than evaluating and guiding their use for actual testing of DL systems. We propose a novel test adequacy criterion for testing of DL systems, called Surprise Adequacy for Deep Learning Systems (SADL), which is based on the behaviour of DL systems with respect to their training data. We measure the surprise of an input as the difference in DL system's behaviour between the input and the training data (i.e., what was learnt during training), and subsequently develop this as an adequacy criterion: a good test input should be sufficiently but not overtly surprising compared to training data. Empirical evaluation using a range of DL systems from simple image classifiers to autonomous driving car platforms shows that systematic sampling of inputs based on their surprise can improve classification accuracy of DL systems against adversarial examples by up to 77.5% via retraining.","","","10.1109/ICSE.2019.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812069","Test Adequacy;Coverage Criteria;Deep Learning Systems","Neurons;Testing;Training;Training data;Deep learning;Autonomous vehicles;Density measurement","image classification;learning (artificial intelligence);program testing","DL system;training data;test adequacy criterion;deep learning system testing;Surprise Adequacy for Deep Learning Systems;autonomous driving car platforms;systematic sampling;coverage criteria","","4","44","","","","","IEEE","IEEE Conferences"
"Grey-Box Concolic Testing on Binary Code","J. Choi; J. Jang; C. Han; S. K. Cha","KAIST, Republic of Korea; Samsung Research, Republic of Korea; Naver Labs, Republic of Korea; KAIST, Republic of Korea","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","736","747","We present grey-box concolic testing, a novel path-based test case generation method that combines the best of both white-box and grey-box fuzzing. At a high level, our technique systematically explores execution paths of a program under test as in white-box fuzzing, a.k.a. concolic testing, while not giving up the simplicity of grey-box fuzzing: it only uses a lightweight instrumentation, and it does not rely on an SMT solver. We implemented our technique in a system called Eclipser, and compared it to the state-of-the-art grey-box fuzzers (including AFLFast, LAF-intel, Steelix, and VUzzer) as well as a symbolic executor (KLEE). In our experiments, we achieved higher code coverage and found more bugs than the other tools.","","","10.1109/ICSE.2019.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811950","software testing;concolic testing;fuzzing","Fuzzing;Computer bugs;Instruments;Binary codes;Tools;Security","binary codes;program debugging;program testing","grey-box concolic testing;grey-box fuzzing;white-box fuzzing;grey-box fuzzers;path-based test case generation method;binary code","","","63","","","","","IEEE","IEEE Conferences"
"A Framework for Checking Regression Test Selection Tools","C. Zhu; O. Legunsen; A. Shi; M. Gligoric","The University of Texas at Austin; University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign; The University of Texas at Austin","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","430","441","Regression test selection (RTS) reduces regression testing costs by re-running only tests that can change behavior due to code changes. Researchers and large software organizations recently developed and adopted several RTS tools to deal with the rapidly growing costs of regression testing. As RTS tools gain adoption, it becomes critical to check that they are correct and efficient. Unfortunately, checking RTS tools currently relies solely on limited tests that RTS tool developers manually write. We present RTSCheck, the first framework for checking RTS tools. RTSCheck feeds evolving programs (i.e., sequences of program revisions) to an RTS tool and checks the output against rules inspired by existing RTS test suites. Violations of these rules are likely due to deviations from expected RTS tool behavior, and indicative of bugs in the tool. RTSCheck uses three components to obtain evolving programs: (1) AutoEP automatically generates evolving programs and corresponding tests, (2) DefectsEP uses buggy and fixed program revisions from bug databases, and (3) EvoEP uses sequences of program revisions from actual open-source projects' histories. We used RTSCheck to check three recently developed RTS tools for Java: Clover, Ekstazi, and STARTS. RTSCheck discovered 27 bugs in these three tools.","","","10.1109/ICSE.2019.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812073","regression test selection;program generation;evolution;checking software tools","Tools;Computer bugs;Testing;Safety;Java;Software;Feeds","Java;program debugging;program testing;software tools","program revisions;RTSCheck;checking regression test selection tools;regression testing costs;RTS tool developers;expected RTS tool behavior;RTS test suites;EvoEP;open-source project histories;Java;Clover;Ekstazi;STARTS","","","80","","","","","IEEE","IEEE Conferences"
"What Causes My Test Alarm? Automatic Cause Analysis for Test Alarms in System and Integration Testing","H. Jiang; X. Li; Z. Yang; J. Xuan","Sch. of Software, Dalian Univ. of Technol., Dalian, China; Sch. of Software, Dalian Univ. of Technol., Dalian, China; Western Michigan Univ., Kalamazoo, MI, USA; State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","712","723","Driven by new software development processes and testing in clouds, system and integration testing nowadays tends to produce enormous number of alarms. Such test alarms lay an almost unbearable burden on software testing engineers who have to manually analyze the causes of these alarms. The causes are critical because they decide which stakeholders are responsible to fix the bugs detected during the testing. In this paper, we present a novel approach that aims to relieve the burden by automating the procedure. Our approach, called Cause Analysis Model, exploits information retrieval techniques to efficiently infer test alarm causes based on test logs. We have developed a prototype and evaluated our tool on two industrial datasets with more than 14,000 test alarms. Experiments on the two datasets show that our tool achieves an accuracy of 58.3% and 65.8%, respectively, which outperforms the baseline algorithms by up to 13.3%. Our algorithm is also extremely efficient, spending about 0.1s per cause analysis. Due to the attractive experimental results, our industrial partner, a leading information and communication technology company in the world, has deployed the tool and it achieves an average accuracy of 72% after two months of running, nearly three times more accurate than a previous strategy based on regular expressions.","","","10.1109/ICSE.2017.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985707","software testing;system and integration testing;test alarm analysis;multiclass classification","Software;Computer bugs;Product codes;Instruments;Software testing;Analytical models","information retrieval;program diagnostics;program testing","automatic cause analysis;system and integration testing;test alarms;cause analysis model;information retrieval techniques;test logs;SIT","","7","51","","","","","IEEE","IEEE Conferences"
"To Type or Not to Type: Quantifying Detectable Bugs in JavaScript","Z. Gao; C. Bird; E. T. Barr","Univ. Coll. London, London, UK; Microsoft Res., Redmond, WA, USA; Univ. Coll. London, London, UK","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","758","769","JavaScript is growing explosively and is now used in large mature projects even outside the web domain. JavaScript is also a dynamically typed language for which static type systems, notably Facebook's Flow and Microsoft's TypeScript, have been written. What benefits do these static type systems provide? Leveraging JavaScript project histories, we select a fixed bug and check out the code just prior to the fix. We manually add type annotations to the buggy code and test whether Flow and TypeScript report an error on the buggy code, thereby possibly prompting a developer to fix the bug before its public release. We then report the proportion of bugs on which these type systems reported an error. Evaluating static type systems against public bugs, which have survived testing and review, is conservative: it understates their effectiveness at detecting bugs during private development, not to mention their other benefits such as facilitating code search/completion and serving as documentation. Despite this uneven playing field, our central finding is that both static type systems find an important percentage of public bugs: both Flow 0.30 and TypeScript 2.0 successfully detect 15%!.","","","10.1109/ICSE.2017.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985711","JavaScript;static type systems;Flow;TypeScript;mining software repositories","Computer bugs;History;Software;Surgery;Facebook;Measurement uncertainty;Documentation","Java;program debugging","JavaScript;TypeScript;static type systems;bug detection;Web domain","","5","53","","","","","IEEE","IEEE Conferences"
"Analysis and Testing of Notifications in Android Wear Applications","H. Zhang; A. Rountev","Ohio State Univ., Columbus, OH, USA; Ohio State Univ., Columbus, OH, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","347","357","Android Wear (AW) is Google's platform for developing applications for wearable devices. Our goal is to make a first step toward a foundation for analysis and testing of AW apps. We focus on a core feature of such apps: notifications issued by a handheld device (e.g., a smartphone) and displayed on a wearable device (e.g., a smartwatch). We first define a formal semantics of AW notifications in order to capture the core features and behavior of the notification mechanism. Next, we describe a constraint-based static analysis to build a model of this run-time behavior. We then use this model to develop a novel testing tool for AW apps. The tool contains a testing framework together with components to support AW-specific coverage criteria and to automate the generation of GUI events on the wearable. These contributions advance the state of the art in the increasingly important area of software for wearable devices.","","","10.1109/ICSE.2017.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985675","","Semantics;Testing;Androids;Humanoid robots;Handheld computers;Software;Smart phones","Android (operating system);graphical user interfaces;program diagnostics;program testing;software tools;wearable computers","notification testing;notification analysis;Android wear applications;Google platform;wearable devices;AW apps testing;AW apps analysis;handheld device;constraint-based static analysis;AW-specific coverage criteria;GUI event generation","","8","43","","","","","IEEE","IEEE Conferences"
"Intention-Based Integration of Software Variants","M. Lillack; S. Stanciulescu; W. Hedman; T. Berger; A. WƒÖsowski","Leipzig University, Germany; IT University of Copenhagen, Denmark and Chalmers and University of Gothenburg, Sweden; Chalmers and University of Gothenburg, Sweden; Chalmers and University of Gothenburg, Sweden; IT University of Copenhagen, Denmark","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","831","842","Cloning is a simple way to create new variants of a system. While cheap at first, it increases maintenance cost in the long term. Eventually, the cloned variants need to be integrated into a configurable platform. Such an integration is challenging: it involves merging the usual code improvements between the variants, and also integrating the variable code (features) into the platform. Thus, variant integration differs from traditional soft- ware merging, which does not produce or organize configurable code, but creates a single system that cannot be configured into variants. In practice, variant integration requires fine-grained code edits, performed in an exploratory manner, in multiple iterations. Unfortunately, little tool support exists for integrating cloned variants. In this work, we show that fine-grained code edits needed for integration can be alleviated by a small set of integration intentions-domain-specific actions declared over code snippets controlling the integration. Developers can interactively explore the integration space by declaring (or revoking) intentions on code elements. We contribute the intentions (e.g., 'keep functionality' or 'keep as a configurable feature') and the IDE tool INCLINE, which implements the intentions and five editable views that visualize the integration process and allow declaring intentions producing a configurable integrated platform. In a series of experiments, we evaluated the completeness of the pro- posed intentions, the correctness and performance of INCLINE, and the benefits of using intentions for variant integration. The experiments show that INCLINE can handle complex integration tasks, that views help to navigate the code, and that it consistently reduces mistakes made by developers during variant integration.","","","10.1109/ICSE.2019.00090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811913","software product line;variant integration;clone and own;re engineering variants;code merging;intention based integration","Tools;Merging;Task analysis;Software product lines;Open source software;Maintenance engineering","integrated software;programming environments;software maintenance","fine-grained code edits;integration intentions-domain-specific actions;code snippets;configurable integrated platform;intention-based integration;software variants;configurable platform;variable code;configurable code;IDE tool INCLINE","","","46","","","","","IEEE","IEEE Conferences"
"Rotten Green Tests","J. Delplanque; S. Ducasse; G. Polito; A. P. Black; A. Etien","Univ. Lille, CNRS, France; RMOD - Inria Lille, France; Univ. Lille, CNRS, France; Portland State University, Oregon, USA; Univ. Lille, CNRS, France","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","500","511","Unit tests are a tenant of agile programming methodologies, and are widely used to improve code quality and prevent code regression. A green (passing) test is usually taken as a robust sign that the code under test is valid. However, some green tests contain assertions that are never executed. We call such tests Rotten Green Tests. Rotten Green Tests represent a case worse than a broken test: they report that the code under test is valid, but in fact do not test that validity. We describe an approach to identify rotten green tests by combining simple static and dynamic call-site analyses. Our approach takes into account test helper methods, inherited helpers, and trait compositions, and has been implemented in a tool called DrTest. DrTest reports no false negatives, yet it still reports some false positives due to conditional use or multiple test contexts. Using DrTest we conducted an empirical evaluation of 19,905 real test cases in mature projects of the Pharo ecosystem. The results of the evaluation show that the tool is effective; it detected 294 tests as rotten-green tests that contain assertions that are not executed. Some rotten tests have been ‚Äúsleeping‚Äù in Pharo for at least 5 years.","","","10.1109/ICSE.2019.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812040","","Testing;Software;Java;Tools;Writing;Computer bugs;Software engineering","object-oriented programming;program testing;software prototyping","rotten tests;unit tests;rotten green tests;agile programming methodologies;code quality;code regression;dynamic call-site analysis;static call-site analysis;DrTest;Pharo ecosystem","","","44","","","","","IEEE","IEEE Conferences"
"Reasonably-Most-General Clients for JavaScript Library Analysis","E. K. Kristensen; A. M√∏ller","Aarhus University; Aarhus University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","83","93","A well-known approach to statically analyze libraries without having access to their client code is to model all possible clients abstractly using a most-general client. In dynamic languages, however, a most-general client would be too general: it may interact with the library in ways that are not intended by the library developer and are not realistic in actual clients, resulting in useless analysis results. In this work, we explore the concept of a reasonably-most-general client, in the context of a new static analysis tool REAGENT that aims to detect errors in TypeScript declaration files for JavaScript libraries. By incorporating different variations of reasonably-most-general clients into an existing static analyzer for JavaScript, we use REAGENT to study how different assumptions of client behavior affect the analysis results. We also show how REAGENT is able to find type errors in real-world TypeScript declaration files, and, once the errors have been corrected, to guarantee that no remaining errors exist relative to the selected assumptions.","","","10.1109/ICSE.2019.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812107","program analysis;TypeScript;most general client","Libraries;Tools;Static analysis;Semantics;Contracts;Analytical models;Testing","Java;program diagnostics","client behavior;JavaScript library analysis;client code;library developer;static analysis tool;REAGENT;reasonably-most-general clients","","","29","","","","","IEEE","IEEE Conferences"
"SMOKE: Scalable Path-Sensitive Memory Leak Detection for Millions of Lines of Code","G. Fan; R. Wu; Q. Shi; X. Xiao; J. Zhou; C. Zhang","Hong Kong University of Science and Technology, Hong Kong, China; Hong Kong University of Science and Technology, Hong Kong, China; Hong Kong University of Science and Technology, Hong Kong, China; Sourcebrella Inc., China; Sourcebrella Inc., China; Hong Kong University of Science and Technology, Hong Kong, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","72","82","Detecting memory leak at industrial scale is still not well addressed, in spite of the tremendous effort from both industry and academia in the past decades. Existing work suffers from an unresolved paradox - a highly precise analysis limits its scalability and an imprecise one seriously hurts its precision or recall. In this work, we present SMOKE, a staged approach to resolve this paradox. In the first stage, instead of using a uniform precise analysis for all paths, we use a scalable but imprecise analysis to compute a succinct set of candidate memory leak paths. In the second stage, we leverage a more precise analysis to verify the feasibility of those candidates. The first stage is scalable, due to the design of a new sparse program representation, the use-flow graph (UFG), that models the problem as a polynomial-time state analysis. The second stage analysis is both precise and efficient, due to the smaller number of candidates and the design of a dedicated constraint solver. Experimental results show that SMOKE can finish checking industrial-sized projects, up to 8MLoC, in forty minutes with an average false positive rate of 24.4%. Besides, SMOKE is significantly faster than the state-of-the-art research techniques as well as the industrial tools, with the speedup ranging from 5.2X to 22.8X. In the twenty-nine mature and extensively checked benchmark projects, SMOKE has discovered thirty previously unknown memory leaks which were con?rmed by developers, and one even assigned a CVE ID.","","","10.1109/ICSE.2019.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812075","memory leak, static bug finding, use-flow graph, value-flow graph","Scalability;Leak detection;Benchmark testing;Computer bugs;Complexity theory;Correlation;Tools","data flow analysis;program debugging","SMOKE;sparse program representation;polynomial-time state analysis;path-sensitive memory leak detection;static bug finding;value-flow graph;use-flow graph","","","36","","","","","IEEE","IEEE Conferences"
"UML Diagram Refinement (Focusing on Class-and Use Case Diagrams)","D. Faitelson; S. Tyszberowicz","Software Eng. Dept., Afeka Tel Aviv Acad. Coll. of Eng., Israel; Sch. of Comput. Sci., Acad. Coll. of Tel Aviv-Yaffo, Israel","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","735","745","Large and complicated UML models are not useful, because they are difficult to understand. This problem can be solved by using several diagrams of the same system at different levels of abstraction. Unfortunately, UML does not define an explicit set of rules for ensuring that diagrams at different levels of abstraction are consistent. We define such a set of rules, that we call diagram refinement. Diagram refinement is intuitive, and applicable to several kinds of UML diagrams (mostly to structural diagrams but also to use case diagrams), yet it rests on a solid mathematical basis-the theory of graph homomorphisms. We illustrate its usefulness with a series of examples.","","","10.1109/ICSE.2017.73","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985709","Refinement;UML;Class diagram;Use case diagram;Graph homomorphism;Design patterns","Unified modeling language;Concrete;Lattices;Semantics;Software engineering;Electronic mail;Mathematical model","graph theory;Unified Modeling Language","UML diagram refinement;graph homomorphisms","","3","25","","","","","IEEE","IEEE Conferences"
"Performance Diagnosis for Inefficient Loops","L. Song; S. Lu","NA; NA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","370","380","Writing efficient software is difficult. Design and implementation defects can cause severe performance degradation. Unfortunately, existing performance diagnosis techniques like profilers are still preliminary. They can locate code regions that consume resources, but not the ones that waste resources. In this paper, we first design a root-cause and fix-strategy taxonomy for inefficient loops, one of the most common performance problems in the field. We then design a static-dynamic hybrid analysis tool, LDoctor, to provide accurate performance diagnosis for loops. We further use sampling techniques to lower the run-time overhead without degrading the accuracy or latency of LDoctor diagnosis. Evaluation using real-world performance problems shows that LDoctor can provide better coverage and accuracy than existing techniques, with low overhead.","","","10.1109/ICSE.2017.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985677","performance diagnosis;debugging;loop inefficiency","Tools;Computer bugs;Taxonomy;Software;Redundancy;Anodes;Debugging","program diagnostics;software engineering","software performance degradation;root-cause and fix-strategy taxonomy;LDoctor diagnosis;static-dynamic hybrid analysis tool","","5","37","","","","","IEEE","IEEE Conferences"
"CTRAS: Crowdsourced Test Report Aggregation and Summarization","R. Hao; Y. Feng; J. A. Jones; Y. Li; Z. Chen","State Key Laboratory for Novel Software Technology Nanjing University, China; University of California, Irvine, USA; University of California, Irvine, USA; State Key Laboratory for Novel Software Technology Nanjing University, China; State Key Laboratory for Novel Software Technology Nanjing University, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","900","911","Crowdsourced testing has been widely adopted to improve the quality of various software products. Crowdsourced workers typically perform testing tasks and report their experiences through test reports. While the crowdsourced test reports provide feedbacks from real usage scenarios, inspecting such a large number of reports becomes a time-consuming yet inevitable task. To improve the efficiency of this task, existing widely used issue-tracking systems, such as JIRA, Bugzilla, and Mantis, have provided keyword-search-based methods to assist users in identifying duplicate test reports. However, on mobile devices (such as mobile phones), where the crowdsourced test reports often contain insufficient text descriptions but instead rich screenshots, these text-analysis-based methods become less effective because the data has fundamentally changed. In this paper, instead of focusing on only detecting duplicates based on textual descriptions, we present CTRAS: a novel approach to leveraging duplicates to enrich the content of bug descriptions and improve the efficiency of inspecting these reports. CTRAS is capable of automatically aggregating duplicates based on both textual information and screenshots, and further summarizes the duplicate test reports into a comprehensive and comprehensible report. To validate CTRAS, we conducted quantitative studies using more than 5000 test reports, collected from 12 industrial crowdsourced projects. The experimental results reveal that CTRAS can reach an accuracy of 0.87, on average, regarding automatically detecting duplicate reports, and it outperforms the classic Max-Coverage-based and MMR summarization methods under Jensen Shannon divergence metric. Moreover, we conducted a task-based user study with 30 participants, whose result indicates that CTRAS can save nearly 30% time cost on average without loss of correctness.","","","10.1109/ICSE.2019.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811987","crowdsourced testing;summarization;duplicate bug reports","Testing;Software;Computer bugs;Task analysis;Feature extraction;Mobile handsets;Debugging","information retrieval;natural language processing;program debugging;text analysis","Jensen Shannon divergence metric;industrial crowdsourced projects;comprehensible report;comprehensive report;text-analysis-based methods;duplicate test reports;keyword-search-based methods;crowdsourced test reports;crowdsourced workers;crowdsourced test report aggregation;task-based user study;duplicate reports;CTRAS","","1","45","","","","","IEEE","IEEE Conferences"
"Precise Condition Synthesis for Program Repair","Y. Xiong; J. Wang; R. Yan; J. Zhang; S. Han; G. Huang; L. Zhang","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; SISE, Univ. of Electron. Sci. & Technol. of China, Chengdu, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Microsoft Res., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","416","426","Due to the difficulty of repairing defect, many research efforts have been devoted into automatic defect repair. Given a buggy program that fails some test cases, a typical automatic repair technique tries to modify the program to make all tests pass. However, since the test suites in real world projects are usually insufficient, aiming at passing the test suites often leads to incorrect patches. This problem is known as weak test suites or overfitting. In this paper we aim to produce precise patches, that is, any patch we produce has a relatively high probability to be correct. More concretely, we focus on condition synthesis, which was shown to be able to repair more than half of the defects in existing approaches. Our key insight is threefold. First, it is important to know what variables in a local context should be used in an ""if"" condition, and we propose a sorting method based on the dependency relations between variables. Second, we observe that the API document can be used to guide the repair process, and propose document analysis technique to further filter the variables. Third, it is important to know what predicates should be performed on the set of variables, and we propose to mine a set of frequently used predicates in similar contexts from existing projects. Based on the insight, we develop a novel program repair system, ACS, that could generate precise conditions at faulty locations. Furthermore, given the generated conditions are very precise, we can perform a repair operation that is previously deemed to be too overfitting: directly returning the test oracle to repair the defect. Using our approach, we successfully repaired 18 defects on four projects of Defects4J, which is the largest number of fully automatically repaired defects reported on the dataset so far. More importantly, the precision of our approach in the evaluation is 78.3%, which is significantly higher than previous approaches, which are usually less than 40%.","","","10.1109/ICSE.2017.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985681","","Maintenance engineering;Text analysis;Benchmark testing;Java;Input variables;Software engineering;Software","application program interfaces;document handling;fault location;program testing;software maintenance;sorting","precise condition synthesis;program repair system;automatic defect repair;weak test suites;sorting method;dependency relations;document analysis technique;API document;ACS;faulty locations;repair operation;Defects4J","","28","48","","","","","IEEE","IEEE Conferences"
"Probabilistic Disassembly","K. Miller; Y. Kwon; Y. Sun; Z. Zhang; X. Zhang; Z. Lin","Purdue University, USA; University of Virginia, USA; Purdue University, USA; Purdue University, USA; Purdue University, USA; Ohio State University, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1187","1198","Disassembling stripped binaries is a prominent challenge for binary analysis, due to the interleaving of code segments and data, and the difficulties of resolving control transfer targets of indirect calls and jumps. As a result, most existing disassemblers have both false positives (FP) and false negatives (FN). We observe that uncertainty is inevitable in disassembly due to the information loss during compilation and code generation. Therefore, we propose to model such uncertainty using probabilities and propose a novel disassembly technique, which computes a probability for each address in the code space, indicating its likelihood of being a true positive instruction. The probability is computed from a set of features that are reachable to an address, including control flow and data flow features. Our experiments with more than two thousands binaries show that our technique does not have any FN and has only 3.7% FP. In comparison, a state-of-the-art superset disassembly technique has 85% FP. A rewriter built on our disassembly can generate binaries that are only half of the size of those by superset disassembly and run 3% faster. While many widely-used disassemblers such as IDA and BAP suffer from missing function entries, our experiment also shows that even without any function entry information, our disassembler can still achieve 0 FN and 6.8% FP.","","","10.1109/ICSE.2019.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812038","binary;disassembly;binary rewrite;probabilistic disassembly","Probabilistic logic;Uncertainty;Runtime;Registers;Computer science;Instruments;Aggregates","design for disassembly;probability;program assemblers;program compilers;program diagnostics","disassembling stripped binaries;binary analysis;code segments;control transfer targets;indirect calls;false negatives;code generation;code space;control flow;data flow features;disassembler;probabilistic disassembly;superset disassembly technique;compilation;true positive instruction;probability","","","57","","","","","IEEE","IEEE Conferences"
"How Reliable is the Crowdsourced Knowledge of Security Implementation?","M. Chen; F. Fischer; N. Meng; X. Wang; J. Grossklags","Virginia Tech, United States; Technical University of Munich, Germany; Virginia Tech, United States; University of Texas at San Antonio, United States; Technical University of Munich, Germany","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","536","547","Stack Overflow (SO) is the most popular online Q&A site for developers to share their expertise in solving programming issues. Given multiple answers to a certain question, developers may take the accepted answer, the answer from a person with high reputation, or the one frequently suggested. However, researchers recently observed that SO contains exploitable security vulnerabilities in the suggested code of popular answers, which found their way into security-sensitive high-profile applications that millions of users install every day. This observation inspires us to explore the following questions: How much can we trust the security implementation suggestions on SO? If suggested answers are vulnerable, can developers rely on the community's dynamics to infer the vulnerability and identify a secure counterpart? To answer these highly important questions, we conducted a comprehensive study on security-related SO posts by contrasting secure and insecure advice with the community-given content evaluation. Thereby, we investigated whether SO's gamification approach on incentivizing users is effective in improving security properties of distributed code examples. Moreover, we traced the distribution of duplicated samples over given answers to test whether the community behavior facilitates or prevents propagation of secure and insecure code suggestions within SO. We compiled 953 different groups of similar security-related code examples and labeled their security, identifying 785 secure answer posts and 644 insecure answer posts. Compared with secure suggestions, insecure ones had higher view counts (36,508 vs. 18,713), received a higher score (14 vs. 5), and had significantly more duplicates (3.8 vs. 3.0) on average. 34% of the posts provided by highly reputable so-called trusted users were insecure. Our findings show that based on the distribution of secure and insecure code on SO, users being laymen in security rely on additional advice and guidance. However, the community-given feedback does not allow differentiating secure from insecure choices. The reputation mechanism fails in indicating trustworthy users with respect to security questions, ultimately leaving other users wandering around alone in a software security minefield.","","","10.1109/ICSE.2019.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812042","Stack Overflow, crowdsourced knowledge, social dynamics, security implementation","Security;Cloning;Message systems;Reliability;Encoding;Crowdsourcing;Software","question answering (information retrieval);security of data;Web sites","programming issues;exploitable security vulnerabilities;suggested code;security-sensitive high-profile applications;security implementation suggestions;suggested answers;vulnerability;secure counterpart;secure advice;insecure advice;community-given content evaluation;security properties;distributed code examples;community behavior facilitates;secure code suggestions;insecure code suggestions;similar security-related code examples;community-given feedback;insecure choices;trustworthy users;security questions;software security minefield;crowdsourced knowledge;Stack Overflow;answer posts;online Q&A site;gamification approach","","2","73","","","","","IEEE","IEEE Conferences"
"iSENSE: Completion-Aware Crowdtesting Management","J. Wang; Y. Yang; R. Krishna; T. Menzies; Q. Wang","Institute of Software Chinese Academy of Sciences; Stevens Institute of Technology, USA; North Carolina State University, USA; North Carolina State University, USA; Institute of Software Chinese Academy of Sciences, Beijing, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","912","923","Crowdtesting has become an effective alternative to traditional testing, especially for mobile applications. However, crowdtesting is hard to manage in nature. Given the complexity of mobile applications and unpredictability of distributed crowdtesting processes, it is difficult to estimate (a) remaining number of bugs yet to be detected or (b) required cost to find those bugs. Experience-based decisions may result in ineffective crowdtesting processes, e.g., there is an average of 32% wasteful spending in current crowdtesting practices. This paper aims at exploring automated decision support to effectively manage crowdtesting processes. It proposes an approach named ISENSE which applies incremental sampling technique to process crowdtesting reports arriving in chronological order, organizes them into fixed-size groups as dynamic inputs, and predicts two test completion indicators in an incremental manner. The two indicators are: 1) total number of bugs predicted with Capture-ReCapture model, and 2) required test cost for achieving certain test objectives predicted with AutoRegressive Integrated Moving Average model. The evaluation of ISENSE is conducted on 46,434 reports of 218 crowdtesting tasks from one of the largest crowdtesting platforms in China. Its effectiveness is demonstrated through two application studies for automating crowdtesting management and semi-automation of task closing trade-off analysis. The results show that ISENSE can provide managers with greater awareness of testing progress to achieve cost-effectiveness gains of crowdtesting. Specifically, a median of 100% bugs can be detected with 30% saved cost based on the automated close prediction.","","","10.1109/ICSE.2019.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812109","Crowdtesting;automated close prediction;test completion;crowdtesting management","Computer bugs;Task analysis;Testing;Predictive models;Software;Mobile applications;Data models","autoregressive moving average processes;crowdsourcing;decision support systems;program debugging;program testing","distributed crowdtesting processes;bugs;experience-based decisions;automated decision support;incremental sampling technique;crowdtesting reports;test completion indicators;automating crowdtesting management;cost-effectiveness gains;automated close prediction;iSENSE;completion-aware crowdtesting management;mobile applications;autoregressive integrated moving average model;crowdtesting platforms;crowdtesting tasks","","","68","","","","","IEEE","IEEE Conferences"
"Mining Historical Test Logs to Predict Bugs and Localize Faults in the Test Logs","A. Amar; P. C. Rigby","Concordia University, Canada; Concordia University, Canada","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","140","151","Software testing is an integral part of modern software development. However, test runs can produce thousands of lines of logged output that make it difficult to find the cause of a fault in the logs. This problem is exacerbated by environmental failures that distract from product faults. In this paper we present techniques with the goal of capturing the maximum number of product faults, while flagging the minimum number of log lines for inspection. We observe that the location of a fault in a log should be contained in the lines of a failing test log. In contrast, a passing test log should not contain the lines related to a failure. Lines that occur in both a passing and failing log introduce noise when attempting to find the fault in a failing log. We introduce an approach where we remove the lines that occur in the passing log from the failing log. After removing these lines, we use information retrieval techniques to flag the most probable lines for investigation. We modify TF-IDF to identify the most relevant log lines related to past product failures. We then vectorize the logs and develop an exclusive version of KNN to identify which logs are likely to lead to product faults and which lines are the most probable indication of the failure. Our best approach, LogFaultFlagger finds 89% of the total faults and flags less than 1% of the total failed log lines for inspection. LogFaultFlagger drastically outperforms the previous work CAM. We implemented LogFaultFlagger as a tool at Ericsson where it presents fault prediction summaries to base station testers.","","","10.1109/ICSE.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812113","Testing;Logs;Faults;Industry","Testing;Inspection;Computer bugs;Fault diagnosis;Base stations;Software;Software engineering","data mining;probability;program debugging;program testing;software fault tolerance","mining historical test logs;software testing;logged output;product faults;passing test log;failing log;passing log;relevant log lines;fault prediction summaries;LogFaultFlagger approach;TF-IDF","","1","60","","","","","IEEE","IEEE Conferences"
"Feedback-Based Debugging","Y. Lin; J. Sun; Y. Xue; Y. Liu; J. Dong","Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore; Singapore Univ. of Technol. & Design, Singapore, Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","393","403","Software debugging has long been regarded as a time and effort consuming task. In the process of debugging, developers usually need to manually inspect many program steps to see whether they deviate from their intended behaviors. Given that intended behaviors usually exist nowhere but in human mind, the automation of debugging turns out to be extremely hard, if not impossible. In this work, we propose a feedback-based debugging approach, which (1) builds on light-weight human feedbacks on a buggy program and (2) regards the feedbacks as partial program specification to infer suspicious steps of the buggy execution. Given a buggy program, we record its execution trace and allow developers to provide light-weight feedback on trace steps. Based on the feedbacks, we recommend suspicious steps on the trace. Moreover, our approach can further learn and approximate bug-free paths, which helps reduce required feedbacks to expedite the debugging process. We conduct an experiment to evaluate our approach with simulated feedbacks on 3409 mutated bugs across 3 open source projects. The results show that our feedback-based approach can detect 92.8% of the bugs and 65% of the detected bugs require less than 20 feedbacks. In addition, we implement our proof-of-concept tool, Microbat, and conduct a user study involving 16 participants on 3 debugging tasks. The results show that, compared to the participants using the baseline tool, Whyline, the ones using Microbat can spend on average 55.8% less time to locate the bugs.","","","10.1109/ICSE.2017.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985679","debugging;feedback;slicing;path pattern;approximation","Computer bugs;Debugging;Tools;Reactive power;Inspection;Software debugging;Software engineering","formal specification;program debugging","feedback-based debugging;human feedbacks;buggy program;partial program specification;buggy execution;execution trace;light-weight feedback;Microbat;Whyline","","4","38","","","","","IEEE","IEEE Conferences"
"Exploring API Embedding for API Usages and Applications","T. D. Nguyen; A. T. Nguyen; H. D. Phan; T. N. Nguyen","NA; NA; NA; NA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","438","449","Word2Vec is a class of neural network models that as being trainedfrom a large corpus of texts, they can produce for each unique word acorresponding vector in a continuous space in which linguisticcontexts of words can be observed. In this work, we study thecharacteristics of Word2Vec vectors, called API2VEC or API embeddings, for the API elements within the API sequences in source code. Ourempirical study shows that the close proximity of the API2VEC vectorsfor API elements reflects the similar usage contexts containing thesurrounding APIs of those API elements. Moreover, API2VEC can captureseveral similar semantic relations between API elements in API usagesvia vector offsets. We demonstrate the usefulness of API2VEC vectorsfor API elements in three applications. First, we build a tool thatmines the pairs of API elements that share the same usage relationsamong them. The other applications are in the code migrationdomain. We develop API2API, a tool to automatically learn the APImappings between Java and C# using a characteristic of the API2VECvectors for API elements in the two languages: semantic relationsamong API elements in their usages are observed in the two vectorspaces for the two languages as similar geometric arrangements amongtheir API2VEC vectors. Our empirical evaluation shows that API2APIrelatively improves 22.6% and 40.1% top-1 and top-5 accuracy over astate-of-the-art mining approach for API mappings. Finally, as anotherapplication in code migration, we are able to migrate equivalent APIusages from Java to C# with up to 90.6% recall and 87.2% precision.","","","10.1109/ICSE.2017.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985683","Word2Vec;API embedding;API usages;migration","Java;C# languages;Tools;Semantics;Neural networks;Syntactics","application program interfaces;data mining;geometry;Java;neural nets;source code (software);text analysis;vectors","API embedding;API usages;API applications;Word2Vec vectors;neural network models;text corpus;linguistic words contexts;API2VEC;API elements;API sequences;source code;semantic relations;vector offsets;code migration domain;API mappings;Java;C#;geometric arrangements;code migration","","9","45","","","","","IEEE","IEEE Conferences"
"Automated Reporting of Anti-Patterns and Decay in Continuous Integration","C. Vassallo; S. Proksch; H. C. Gall; M. Di Penta","University of Zurich; University of Zurich; University of Zurich; University of Sannio","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","105","115","Continuous Integration (CI) is a widely-used software engineering practice. The software is continuously built so that changes can be easily integrated and issues such as unmet quality goals or style inconsistencies get detected early. Unfortunately, it is not only hard to introduce CI into an existing project, but it is also challenging to live up to the CI principles when facing tough deadlines or business decisions. Previous work has identified common anti-patterns that reduce the promised benefits of CI. Typically, these anti-patterns slowly creep into a project over time before they are identified. We argue that automated detection can help with early identification and prevent such a process decay. In this work, we further analyze this assumption and survey 124 developers about CI anti-patterns. From the results, we build CI-Odor, a reporting tool for CI processes that detects the existence of four relevant anti-patterns by analyzing regular build logs and repository information. In a study on the 18,474 build logs of 36 popular JAVA projects, we reveal the presence of 3,823 high-severity warnings spread across projects. We validate our reports in a survey among 13 original developers of these projects and through general feedback from 42 developers that confirm the relevance of our reports.","","","10.1109/ICSE.2019.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811921","Continuous Integration, Anti-Pattern, Detection, CI-Smell, CI-Decay","Tools;Pipelines;Detectors;Software;Best practices;Merging;Informatics","Java;program testing;software engineering","continuous integration;software engineering practice;CI principles;common anti-patterns;process decay;CI anti-patterns;Java projects;CI-Odor tool","","2","35","","","","","IEEE","IEEE Conferences"
"Going Farther Together: The Impact of Social Capital on Sustained Participation in Open Source","H. S. Qiu; A. Nolte; A. Brown; A. Serebrenik; B. Vasilescu","Carnegie Mellon University, USA; University of Tartu, Estonia; Bryn Mawr College, USA; Eindhoven University of Technology, Netherlands; Carnegie Mellon University, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","688","699","Sustained participation by contributors in opensource software is critical to the survival of open-source projects and can provide career advancement benefits to individual contributors. However, not all contributors reap the benefits of open-source participation fully, with prior work showing that women are particularly underrepresented and at higher risk of disengagement. While many barriers to participation in open-source have been documented in the literature, relatively little is known about how the social networks that open-source contributors form impact their chances of long-term engagement. In this paper we report on a mixed-methods empirical study of the role of social capital (i.e., the resources people can gain from their social connections) for sustained participation by women and men in open-source GitHub projects. After combining survival analysis on a large, longitudinal data set with insights derived from a user survey, we confirm that while social capital is beneficial for prolonged engagement for both genders, women are at disadvantage in teams lacking diversity in expertise.","","","10.1109/ICSE.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812044","social capital;open source software;gender","Social networking (online);Open source software;Cultural differences;Bonding;Task analysis;Collaboration;Merging","gender issues;project management;public domain software;social aspects of automation;software engineering","open-source software;open-source GitHub projects;sustained participation;social capital;social networks;open-source participation","","5","100","","","","","IEEE","IEEE Conferences"
"Can Latent Topics in Source Code Predict Missing Architectural Tactics?","R. Gopalakrishnan; P. Sharma; M. Mirakhorli; M. Galster","Rochester Inst. of Technol., Rochester, NY, USA; Rochester Inst. of Technol., Rochester, NY, USA; Rochester Inst. of Technol., Rochester, NY, USA; Univ. of Canterbury, Christchurch, New Zealand","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","15","26","Architectural tactics such as heartbeat, resource pooling, and scheduling provide solutions to satisfy reliability, security, performance, and other critical characteristics of a software system. Current design practices advocate rigorous up-front analysis of the system's quality concerns to identify tactics and where in the code they should be used. In this paper, we explore a bottom-up approach to recommend architectural tactics based on latent topics discovered in the source code of projects. We present a recommender system developed by building predictor models which capture relationships between topical concepts in source code and the use of specific architectural tactics in that code. Based on an extensive analysis of over 116,000 open source systems, we identify significant correlations between latent topics in source code and the usage of architectural tactics. We use this information to construct a predictor for generating tactic recommendations. Our approach is validated through a series of experiments which demonstrate the ability to generate package-level tactic recommendations. We provide further validation via two large-scale studies of Apache Hive and Hadoop to illustrate that our recommender system predicts tactics that are actually implemented by developers in later releases.","","","10.1109/ICSE.2017.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985646","Architectural design and implementation;tactic recommender;emergent design","Recommender systems;Inference algorithms;Training;Machine learning algorithms;Security;Software reliability","public domain software;recommender systems;software architecture;software quality;software reliability;source code (software)","source code;missing architectural tactics prediction;software system;system quality analysis;bottom-up approach;latent topics;recommender system;predictor models;open source systems;package-level tactic recommendation generation;Apache Hive;Hadoop","","1","58","","","","","IEEE","IEEE Conferences"
"GreenBundle: An Empirical Study on the Energy Impact of Bundled Processing","S. A. Chowdhury; A. Hindle; R. Kazman; T. Shuto; K. Matsui; Y. Kamei","University of Alberta, Canada; University of Alberta, Canada; University of Hawaii, USA; Kyushu University, Japan; Kyushu University, Japan; Kyushu University, Japan","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1107","1118","Energy consumption is a concern in the data-center and at the edge, on mobile devices such as smartphones. Software that consumes too much energy threatens the utility of the end-user's mobile device. Energy consumption is fundamentally a systemic kind of performance and hence it should be addressed at design time via a software architecture that supports it, rather than after release, via some form of refactoring. Unfortunately developers often lack knowledge of what kinds of designs and architectures can help address software energy consumption. In this paper we show that some simple design choices can have significant effects on energy consumption. In particular we examine the Model-View-Controller architectural pattern and demonstrate how converting to Model-View-Presenter with bundling can improve the energy performance of both benchmark systems and real world applications. We show the relationship between energy consumption and bundled and delayed view updates: bundling events in the presenter can often reduce energy consumption by 30%.","","","10.1109/ICSE.2019.00114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811956","software energy consumption, MVP, MVC, software architecture","Energy consumption;Benchmark testing;Computer architecture;Unified modeling language;Observers;Software;Mobile handsets","energy consumption;mobile computing;power aware computing;software architecture;software maintenance","energy impact;software energy consumption;energy performance;model-view-presenter;model-view-controller architectural pattern","","","80","","","","","IEEE","IEEE Conferences"
"Clone Refactoring with Lambda Expressions","N. Tsantalis; D. Mazinanian; S. Rostami","Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada; Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada; Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","60","70","Lambda expressions have been introduced in Java 8 to support functional programming and enable behavior parameterization by passing functions as parameters to methods. The majority of software clones (duplicated code) are known to have behavioral differences (i.e., Type-2 and Type-3 clones). However, to the best of our knowledge, there is no previous work to investigate the utility of Lambda expressions for parameterizing such behavioral differences in clones. In this paper, we propose a technique that examines the applicability of Lambda expressions for the refactoring of clones with behavioral differences. Moreover, we empirically investigate the applicability and characteristics of the Lambda expressions introduced to refactor a large dataset of clones. Our findings show that Lambda expressions enable the refactoring of a significant portion of clones that could not be refactored by any other means.","","","10.1109/ICSE.2017.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985650","Refactoring;Code duplication;Lambda expressions","Cloning;Data mining;Java;Europe;Testing;Open source software","functional programming;Java;lambda calculus;software maintenance","clone refactoring;lambda expressions;Java 8;functional programming;behavior parameterization;software clones;duplicated code;behavioral differences;Type-2 clones;Type-3 clones","","9","41","","","","","IEEE","IEEE Conferences"
"Detection and Repair of Architectural Inconsistencies in Java","N. Ghorbani; J. Garcia; S. Malek","University of California, Irvine; University of California, Irvine; University of California, Irvine","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","560","571","Java is one of the most widely used programming languages. However, the absence of explicit support for architectural constructs, such as software components, in the programming language itself has prevented software developers from achieving the many benefits that come with architecture-based development. To address this issue, Java 9 has introduced the Java Platform Module System (JPMS), resulting in the first instance of encapsulation of modules with rich software architectural interfaces added to a mainstream programming language. The primary goal of JPMS is to construct and maintain large applications efficiently-as well as improve the encapsulation, security, and maintainability of Java applications in general and the JDK itself. A challenge, however, is that module declarations do not necessarily reflect actual usage of modules in an application, allowing developers to mistakenly specify inconsistent dependencies among the modules. In this paper, we formally define 8 inconsistent modular dependencies that may arise in Java-9 applications. We also present DARCY, an approach that leverages these definitions and static program analyses to automatically (1) detect the specified inconsistent dependencies within Java applications and (2) repair those identified inconsistencies. The results of our experiments, conducted over 38 open-source Java-9 applications, indicate that architectural inconsistencies are widespread and demonstrate the benefits of DARCY in automated detection and repair of these inconsistencies.","","","10.1109/ICSE.2019.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812079","Java Platform Module System;Architectural Inconsistencies;Static Program Analysis;Software Architecture;Module;Detection;Repair;Security;Maintainability;Encapsulation;Software Bloat;Java","Java;Computer architecture;Software;Bars;Encapsulation;Security;Maintenance engineering","Java;object-oriented programming;program diagnostics;software architecture;software maintenance;software prototyping;systems analysis","encapsulation;mainstream programming language;JPMS;Java applications;module declarations;static program analyses;identified inconsistencies;architectural inconsistencies;automated detection;repair;architectural constructs;software components;software developers;architecture-based development;Java Platform Module System;programming languages;open-source Java-9 applications;inconsistent modular dependencies;software architectural interfaces;DARCY","","1","74","","","","","IEEE","IEEE Conferences"
"Pattern-Based Mining of Opinions in Q&A Websites","B. Lin; F. Zampetti; G. Bavota; M. Di Penta; M. Lanza","Universit√† della Svizzera italiana (USI); University of Sannio; Universit√† della Svizzera italiana (USI); University of Sannio; Universit√† della Svizzera italiana (USI)","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","548","559","Informal documentation contained in resources such as Q&A websites (e.g., Stack Overflow) is a precious resource for developers, who can find there examples on how to use certain APIs, as well as opinions about pros and cons of such APIs. Automatically identifying and classifying such opinions can alleviate developers' burden in performing manual searches, and can be used to recommend APIs that are good from some points of view (e.g., performance), or highlight those less ideal from other perspectives (e.g., compatibility). We propose POME (Pattern-based Opinion MinEr), an approach that leverages natural language parsing and pattern-matching to classify Stack Overflow sentences referring to APIs according to seven aspects (e.g., performance, usability), and to determine their polarity (positive vs negative). The patterns have been inferred by manually analyzing 4,346 sentences from Stack Overflow linked to a total of 30 APIs. We evaluated POME by (i) comparing the pattern-matching approach with machine learners leveraging the patterns themselves as well as n-grams extracted from Stack Overflow posts; (ii) assessing the ability of POME to detect the polarity of sentences, as compared to sentiment-analysis tools; (iii) comparing POME with the state-of-the-art Stack Overflow opinion mining approach, Opiner, through a study involving 24 human evaluators. Our study shows that POME exhibits a higher precision than a state-of-the-art technique (Opiner), in terms of both opinion aspect identification and polarity assessment.","","","10.1109/ICSE.2019.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811960","opinion mining;Stack Overflow;sentiment analysis;aspect detection","Sentiment analysis;Tools;Documentation;Data mining;Software engineering;Software;Databases","application program interfaces;data mining;natural language processing;pattern classification;Web sites","POME;opinion aspect identification;polarity assessment;informal documentation;Q&A websites;natural language parsing;Stack Overflow sentences;pattern-based opinion miner;stack overflow opinion mining approach;pattern-based mining;stack overflow posts;APIs;pattern-matching approach","","","47","","","","","IEEE","IEEE Conferences"
"Graph Embedding Based Familial Analysis of Android Malware using Unsupervised Learning","M. Fan; X. Luo; J. Liu; M. Wang; C. Nong; Q. Zheng; T. Liu","Xi'an Jiaotong University, China; The Hong Kong Polytechnic University, China; Xi'an Jiaotong University; Southeast University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","771","782","The rapid growth of Android malware has posed severe security threats to smartphone users. On the basis of the familial trait of Android malware observed by previous work, the familial analysis is a promising way to help analysts better focus on the commonalities of malware samples within the same families, thus reducing the analytical workload and accelerating malware analysis. The majority of existing approaches rely on supervised learning and face three main challenges, i.e., low accuracy, low efficiency, and the lack of labeled dataset. To address these challenges, we first construct a fine-grained behavior model by abstracting the program semantics into a set of subgraphs. Then, we propose SRA, a novel feature that depicts the similarity relationships between the Structural Roles of sensitive API call nodes in subgraphs. An SRA is obtained based on graph embedding techniques and represented as a vector, thus we can effectively reduce the high complexity of graph matching. After that, instead of training a classifier with labeled samples, we construct malware link network based on SRAs and apply community detection algorithms on it to group the unlabeled samples into groups. We implement these ideas in a system called GefDroid that performs Graph embedding based familial analysis of AnDroid malware using unsupervised learning. Moreover, we conduct extensive experiments to evaluate GefDroid on three datasets with ground truth. The results show that GefDroid can achieve high agreements (0.707-0.883 in term of NMI) between the clustering results and the ground truth. Furthermore, GefDroid requires only linear run-time overhead and takes around 8.6s to analyze a sample on average, which is considerably faster than the previous work.","","","10.1109/ICSE.2019.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812083","Android malware;graph embedding;familial analysis;unsupervised learning","Malware;Unsupervised learning;Semantics;Detection algorithms;Security;Feature extraction;Face","application program interfaces;graph theory;invasive software;learning (artificial intelligence);pattern classification;pattern clustering;smart phones;unsupervised learning","familial analysis;unsupervised learning;analytical workload;supervised learning;graph embedding techniques;malware link network;Android malware;SRA;similarity relationships;GefDroid","","","61","","","","","IEEE","IEEE Conferences"
"SPAIN: Security Patch Analysis for Binaries towards Understanding the Pain and Pills","Z. Xu; B. Chen; M. Chandramohan; Y. Liu; F. Song","Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Inf. Sci. & Technol., Shanghai Tech Univ., China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","462","472","Software vulnerability is one of the major threats to software security. Once discovered, vulnerabilities are often fixed by applying security patches. In that sense, security patches carry valuable information about vulnerabilities, which could be used to discover, understand and fix (similar) vulnerabilities. However, most existing patch analysis approaches work at the source code level, while binary-level patch analysis often heavily relies on a lot of human efforts and expertise. Even worse, some vulnerabilities may be secretly patched without applying CVE numbers, or only the patched binary programs are available while the patches are not publicly released. These practices greatly hinder patch analysis and vulnerability analysis. In this paper, we propose a scalable binary-level patch analysis framework, named SPAIN, which can automatically identify security patches and summarize patch patterns and their corresponding vulnerability patterns. Specifically, given the original and patched versions of a binary program, we locate the patched functions and identify the changed traces (i.e., a sequence of basic blocks) that may contain security or non-security patches. Then we identify security patches through a semantic analysis of these traces and summarize the patterns through a taint analysis on the patched functions. The summarized patterns can be used to search similar patches or vulnerabilities in binary programs. Our experimental results on several real-world projects have shown that: i) SPAIN identified security patches with high accuracy and high scalability, ii) SPAIN summarized 5 patch patterns and their corresponding vulnerability patterns for 5 vulnerability types, and iii) SPAIN discovered security patches that were not documented, and discovered 3 zero-day vulnerabilities.","","","10.1109/ICSE.2017.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985685","","Security;Semantics;Software;Tools;Scalability;Registers;Portable document format","security of data;software engineering","SPAIN;security patch analysis;software vulnerability;software security;scalable binary-level patch analysis framework;binary programs","","9","44","","","","","IEEE","IEEE Conferences"
"Superion: Grammar-Aware Greybox Fuzzing","J. Wang; B. Chen; L. Wei; Y. Liu","Nanyang Technological University, Singapore; Fudan University, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","724","735","In recent years, coverage-based greybox fuzzing has proven itself to be one of the most effective techniques for finding security bugs in practice. Particularly, American Fuzzy Lop (AFL for short) is deemed to be a great success in fuzzing relatively simple test inputs. Unfortunately, when it meets structured test inputs such as XML and JavaScript, those grammar-blind trimming and mutation strategies in AFL hinder the effectiveness and efficiency. To this end, we propose a grammar-aware coverage-based greybox fuzzing approach to fuzz programs that process structured inputs. Given the grammar (which is often publicly available) of test inputs, we introduce a grammar-aware trimming strategy to trim test inputs at the tree level using the abstract syntax trees (ASTs) of parsed test inputs. Further, we introduce two grammar-aware mutation strategies (i.e., enhanced dictionary-based mutation and tree-based mutation). Specifically, tree-based mutation works via replacing subtrees using the ASTs of parsed test inputs. Equipped with grammar-awareness, our approach can carry the fuzzing exploration into width and depth. We implemented our approach as an extension to AFL, named Superion; and evaluated the effectiveness of Superion using large- scale programs (i.e., an XML engine libplist and three JavaScript engines WebKit, Jerryscript and ChakraCore). Our results have demonstrated that Superion can improve the code coverage (i.e., 16.7% and 8.8% in line and function coverage) and bug-finding capability (i.e., 34 new bugs, among which we discovered 22 new vulnerabilities with 19 CVEs assigned and 3.2K USD bug bounty rewards received) over AFL and jsfunfuzz.","","","10.1109/ICSE.2019.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811923","Greybox Fuzzing, Structured Inputs, ASTs","Fuzzing;Grammar;Computer bugs;XML;Syntactics;Engines;Instruments","grammars;grey systems;program compilers;program debugging;program testing;security of data;trees (mathematics)","abstract syntax trees;tree-based mutation;AFL;Superion;grammar-blind trimming mutation strategies;grammar-aware coverage-based greybox fuzzing approach;American fuzzy lop;security bugs;XML;JavaScript;ASTs;parsed test","","1","73","","","","","IEEE","IEEE Conferences"
"Do Developers Discover New Tools On The Toilet?","E. Murphy-Hill; E. K. Smith; C. Sadowski; C. Jaspan; C. Winter; M. Jorde; A. Knight; A. Trenk; S. Gross","Google, LLC; Bloomberg; Google, LLC; Google, LLC; Waymo; Google, LLC; Google, LLC; Google, LLC; Google, LLC","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","465","475","Maintaining awareness of useful tools is a substantial challenge for developers. Physical newsletters are a simple technique to inform developers about tools. In this paper, we evaluate such a technique, called Testing on the Toilet, by performing a mixed-methods case study. We first quantitatively evaluate how effective this technique is by applying statistical causal inference over six years of data about tools used by thousands of developers. We then qualitatively contextualize these results by interviewing and surveying 382 developers, from authors to editors to readers. We found that the technique was generally effective at increasing software development tool use, although the increase varied depending on factors such as the breadth of applicability of the tool, the extent to which the tool has reached saturation, and the memorability of the tool name.","","","10.1109/ICSE.2019.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812046","software engineering;diffusion of innovations","Tools;Software;Google;Testing;Software engineering;Advertising;Productivity","program testing;software development management;software tools;statistical analysis","physical newsletters;statistical causal inference;tool name;software development tool;testing on the toilet","","1","43","","","","","IEEE","IEEE Conferences"
"How Practitioners Perceive Coding Proficiency","X. Xia; Z. Wan; P. S. Kochhar; D. Lo","Faculty of Information Technology, Monash University; College of Computer Science and Technology, Zhejiang University; Microsoft, Canada; School of Information Systems, Singapore Management University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","924","935","Coding proficiency is essential to software practitioners. Unfortunately, our understanding on coding proficiency often translates to vague stereotypes, e.g., ""able to write good code"". The lack of specificity hinders employers from measuring a software engineer's coding proficiency, and software engineers from improving their coding proficiency skills. This raises an important question: what skills matter to improve one's coding proficiency. To answer this question, we perform an empirical study by surveying 340 software practitioners from 33 countries across 5 continents. We first identify 38 coding proficiency skills grouped into nine categories by interviewing 15 developers from three companies. We then ask our survey respondents to rate the level of importance for these skills, and provide rationales of their ratings. Our study highlights a total of 21 important skills that receive an average rating of 4.0 and above (important and very important), along with rationales given by proponents and dissenters. We discuss implications of our findings to researchers, educators, and practitioners.","","","10.1109/ICSE.2019.00098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812050","practitioners;coding proficiency","Encoding;Software;Interviews;Companies;Computer bugs;Computer languages;Programming","project management;software development management","software practitioners;coding proficiency skills;coding proficiency;software engineers","","","49","","","","","IEEE","IEEE Conferences"
"An Unsupervised Approach for Discovering Relevant Tutorial Fragments for APIs","H. Jiang; J. Zhang; Z. Ren; T. Zhang","Sch. of Software, Dalian Univ. of Technol., Dalian, China; Sch. of Software, Dalian Univ. of Technol., Dalian, China; Sch. of Software, Dalian Univ. of Technol., Dalian, China; Coll. of Comput. Sci. & Technol., Harbin Eng. Univ., Harbin, China","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","38","48","Developers increasingly rely on API tutorials to facilitate software development. However, it remains a challenging task for them to discover relevant API tutorial fragments explaining unfamiliar APIs. Existing supervised approaches suffer from the heavy burden of manually preparing corpus-specific annotated data and features. In this study, we propose a novel unsupervised approach, namely Fragment Recommender for APIs with PageRank and Topic model (FRAPT). FRAPT can well address two main challenges lying in the task and effectively determine relevant tutorial fragments for APIs. In FRAPT, a Fragment Parser is proposed to identify APIs in tutorial fragments and replace ambiguous pronouns and variables with related ontologies and API names, so as to address the pronoun and variable resolution challenge. Then, a Fragment Filter employs a set of non-explanatory detection rules to remove non-explanatory fragments, thus address the non-explanatory fragment identification challenge. Finally, two correlation scores are achieved and aggregated to determine relevant fragments for APIs, by applying both topic model and PageRank algorithm to the retained fragments. Extensive experiments over two publicly open tutorial corpora show that, FRAPT improves the state-of-the-art approach by 8.77% and 12.32% respectively in terms of F-Measure. The effectiveness of key components of FRAPT is also validated.","","","10.1109/ICSE.2017.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985648","Application Programming Interface;PageRank Algorithm;Topic Model;Unsupervised Approaches","Tutorials;Correlation;Ontologies;Programming;Manuals;Software;Filtering algorithms","application program interfaces;computer aided instruction;computer science education;grammars;recommender systems;unsupervised learning","API tutorials;unsupervised approach;Fragment Recommender for APIs with PageRank and Topic model;FRAPT;fragment parser;fragment filter;nonexplanatory fragment identification;variable resolution challenge;pronoun challenge;F-Measure;application programming interfaces","","8","41","","","","","IEEE","IEEE Conferences"
"Automated Refactoring of Legacy Java Software to Default Methods","R. Khatchadourian; H. Masuhara","City Univ. of New York, New York, NY, USA; Tokyo Inst. of Technol., Tokyo, Japan","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","82","93","Java 8 default methods, which allow interfaces to contain (instance) method implementations, are useful for the skeletal implementation software design pattern. However, it is not easy to transform existing software to exploit default methods as it requires analyzing complex type hierarchies, resolving multiple implementation inheritance issues, reconciling differences between class and interface methods, and analyzing tie-breakers (dispatch precedence) with overriding class methods to preserve type-correctness and confirm semantics preservation. In this paper, we present an efficient, fully-automated, type constraint-based refactoring approach that assists developers in taking advantage of enhanced interfaces for their legacy Java software. The approach features an extensive rule set that covers various corner-cases where default methods cannot be used. To demonstrate applicability, we implemented our approach as an Eclipse plug-in and applied it to 19 real-world Java projects, as well as submitted pull requests to popular GitHub repositories. The indication is that it is useful in migrating skeletal implementation methods to interfaces as default methods, sheds light onto the pattern's usage, and provides insight to language designers on how this new construct applies to existing software.","","","10.1109/ICSE.2017.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985652","refactoring;java;interfaces;default methods","Java;Software;Semantics;Concrete;Face;Printing;Syntactics","Java;software maintenance","automated refactoring;legacy Java software;software design pattern;fully-automated type constraint-based refactoring approach;Eclipse plug-in;GitHub repositories","","5","42","","","","","IEEE","IEEE Conferences"
"Easy Modelling and Verification of Unpredictable and Preemptive Interrupt-Driven Systems","M. Pan; S. Chen; Y. Pei; T. Zhang; X. Li","Nanjing University, China; Nanjing University, China; The Hong Kong Polytechnic University, China; Nanjing University, China; Nanjing University, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","212","222","The widespread real-time and embedded systems are mostly interrupt-driven because their heavy interaction with the environment is often initiated by interrupts. With the interrupt arrival being unpredictable and the interrupt handling being preemptive, a large number of possible system behaviours are generated, which makes the correctness assurance of such systems difficult and costly. Model checking is considered to be one of the effective methods for exhausting behavioural state space for correctness. However, existing modelling approaches for interrupt-driven systems are based on either calculus or automata theory, and have a steep learning curve. To address this problem, we propose a new modelling language called interrupt sequence diagram (ISD). By extending the popular UML sequence diagram notations, the ISD supports the modelling of interrupts' essential features visually and concisely. We also propose an automata-based semantics for ISD, based on which ISD can be transformed to a subset of hybrid automata so as to leverage the abundant off-the-shelf checkers. Experiments on examples from both real-world and existing literature were conducted, and the results demonstrate our approach's usability and effectiveness.","","","10.1109/ICSE.2019.00037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812085","Interrupt-driven systems, Sequence diagrams, System modelling, Model checking","Unified modeling language;Satellites;Task analysis;Semantics;Automata;Usability;Testing","automata theory;embedded systems;formal verification;interrupts;Unified Modeling Language","interrupt-driven systems;embedded systems;interrupt arrival;interrupt handling;model checking;behavioural state space;modelling language;interrupt sequence diagram;ISD;UML sequence diagram notations;hybrid automata","","","40","","","","","IEEE","IEEE Conferences"
"ProEva: Runtime Proactive Performance Evaluation Based on Continuous-Time Markov Chains","G. Su; T. Chen; Y. Feng; D. S. Rosenblum","Sch. of Comput. & Inf. Technol., Univ. of Wollongong, Wollongong, NSW, Australia; Dept. of Comput. Sci., Middlesex Univ., London, UK; Fac. of Eng. & Inf. Technol, Univ. of Technol. Sydney, Sydney, NSW, Australia; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","484","495","Software systems, especially service-based software systems, need to guarantee runtime performance. If their performance is degraded, some reconfiguration countermeasures should be taken. However, there is usually some latency before the countermeasures take effect. It is thus important not only to monitor the current system status passively but also to predict its future performance proactively. Continuous-time Markov chains (CTMCs) are suitable models to analyze time-bounded performance metrics (e.g., how likely a performance degradation may occur within some future period). One challenge to harness CTMCs is the measurement of model parameters (i.e., transition rates) in CTMCs at runtime. As these parameters may be updated by the system or environment frequently, it is difficult for the model builder to provide precise parameter values. In this paper, we present a framework called ProEva, which extends the conventional technique of time-bounded CTMC model checking by admitting imprecise, interval-valued estimates for transition rates. The core method of ProEva computes asymptotic expressions and bounds for the imprecise model checking output. We also present an evaluation of accuracy and computational overhead for ProEva.","","","10.1109/ICSE.2017.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985687","continuous-time Markov chain;imprecise parameters;performance;Quality-of-Service","Software engineering","formal verification;Markov processes;software performance evaluation","ProEva;runtime proactive performance evaluation;continuous-time Markov chains;service-based software systems;time-bounded CTMC model checking","","2","37","","","","","IEEE","IEEE Conferences"
"How Good Is a Security Policy against Real Breaches? A HIPAA Case Study","√ñ. Kafali; J. Jones; M. Petruso; L. Williams; M. P. Singh","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Coll. of Arts & Sci., Elon Univ., Elon, NC, USA; Dept. of Comput. Sci., Appalachian State Univ., Boone, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","530","540","Policy design is an important part of software development. As security breaches increase in variety, designing a security policy that addresses all potential breaches becomes a nontrivial task. A complete security policy would specify rules to prevent breaches. Systematically determining which, if any, policy clause has been violated by a reported breach is a means for identifying gaps in a policy. Our research goal is to help analysts measure the gaps between security policies and reported breaches by developing a systematic process based on semantic reasoning. We propose SEMAVER, a framework for determining coverage of breaches by policies via comparison of individual policy clauses and breach descriptions. We represent a security policy as a set of norms. Norms (commitments, authorizations, and prohibitions) describe expected behaviors of users, and formalize who is accountable to whom and for what. A breach corresponds to a norm violation. We develop a semantic similarity metric for pairwise comparison between the norm that represents a policy clause and the norm that has been violated by a reported breach. We use the US Health Insurance Portability and Accountability Act (HIPAA) as a case study. Our investigation of a subset of the breaches reported by the US Department of Health and Human Services (HHS) reveals the gaps between HIPAA and reported breaches, leading to a coverage of 65%. Additionally, our classification of the 1,577 HHS breaches shows that 44% of the breaches are accidental misuses and 56% are malicious misuses. We find that HIPAA's gaps regarding accidental misuses are significantly larger than its gaps regarding malicious misuses.","","","10.1109/ICSE.2017.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985691","Security and privacy breaches;social norms;breach ontology;semantic similarity","Ontologies;Security;Semantics;Medical services;Cognition;Measurement;Taxonomy","inference mechanisms;security of data;software engineering","HIPAA;security policies;security breaches;semantic reasoning;SEMAVER;norm violation;semantic similarity metric;US Health Insurance Portability and Accountability Act;US Department of Health and Human Services;HHS;accidental misuses;malicious misuses;software development","","1","41","","","","","IEEE","IEEE Conferences"
"Safe Automated Refactoring for Intelligent Parallelization of Java 8 Streams","R. Khatchadourian; Y. Tang; M. Bagherzadeh; S. Ahmed","City University of New York (CUNY) Hunter College; City University of New York (CUNY) Graduate Center; Oakland University; Oakland University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","619","630","Streaming APIs are becoming more pervasive in mainstream Object-Oriented programming languages. For example, the Stream API introduced in Java 8 allows for functional-like, MapReduce-style operations in processing both finite and infinite data structures. However, using this API efficiently involves subtle considerations like determining when it is best for stream operations to run in parallel, when running operations in parallel can be less efficient, and when it is safe to run in parallel due to possible lambda expression side-effects. In this paper, we present an automated refactoring approach that assists developers in writing efficient stream code in a semantics-preserving fashion. The approach, based on a novel data ordering and typestate analysis, consists of preconditions for automatically determining when it is safe and possibly advantageous to convert sequential streams to parallel and unorder or de-parallelize already parallel streams. The approach was implemented as a plug-in to the Eclipse IDE, uses the WALA and SAFE analysis frameworks, and was evaluated on 11 Java projects consisting of ?642K lines of code. We found that 57 of 157 candidate streams (36.31%) were refactorable, and an average speedup of 3.49 on performance tests was observed. The results indicate that the approach is useful in optimizing stream code to their full potential.","","","10.1109/ICSE.2019.00072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811925","refactoring;static analysis;automatic parallelization;typestate analysis;Java 8;streams","Java;Pipelines;Writing;Data structures;Semantics;Image color analysis;Instruction sets","application program interfaces;data structures;Java;software maintenance","semantics-preserving fashion;typestate analysis;sequential streams;parallel streams;optimizing stream code;safe automated refactoring;intelligent parallelization;Java 8;Stream API;MapReduce-style operations;finite data structures;infinite data structures;stream operations;running operations;automated refactoring approach;lambda expression side-effects;stream code;mainstream object-oriented programming languages","","","76","","","","","IEEE","IEEE Conferences"
"Scalable Approaches for Test Suite Reduction","E. Cruciani; B. Miranda; R. Verdecchia; A. Bertolino","Gran Sasso Science Institute; Federal University of Pernambuco: Recife, Pernambuco; Gran Sasso Science Institute & Vrije Universiteit Amsterdam; ISTI ‚Äì Consiglio Nazionale delle Ricerche","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","419","429","Test suite reduction approaches aim at decreasing software regression testing costs by selecting a representative subset from large-size test suites. Most existing techniques are too expensive for handling modern massive systems and moreover depend on artifacts, such as code coverage metrics or specification models, that are not commonly available at large scale. We present a family of novel very efficient approaches for similarity-based test suite reduction that apply algorithms borrowed from the big data domain together with smart heuristics for finding an evenly spread subset of test cases. The approaches are very general since they only use as input the test cases themselves (test source code or command line input). We evaluate four approaches in a version that selects a fixed budget B of test cases, and also in an adequate version that does the reduction guaranteeing some fixed coverage. The results show that the approaches yield a fault detection loss comparable to state-of-the-art techniques, while providing huge gains in terms of efficiency. When applied to a suite of more than 500K real world test cases, the most efficient of the four approaches could select B test cases (for varying B values) in less than 10 seconds.","","","10.1109/ICSE.2019.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812048","Clustering;Random projection;Similarity-based testing;Software testing;Test suite reduction","Testing;Big Data;Software;Measurement;Fault detection;Scalability;Clustering algorithms","Big Data;program testing;set theory","similarity-based test suite reduction;evenly spread subset;test source code;B test cases;scalable approaches;test suite reduction approaches;large-size test suites;modern massive systems;code coverage metrics;big data domain;smart heuristics;command line input","","","36","","","","","IEEE","IEEE Conferences"
"NL2Type: Inferring JavaScript Function Types from Natural Language Information","R. S. Malik; J. Patra; M. Pradel","TU Darmstadt, Germany; TU Darmstadt, Germany; TU Darmstadt, Germany","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","304","315","JavaScript is dynamically typed and hence lacks the type safety of statically typed languages, leading to suboptimal IDE support, difficult to understand APIs, and unexpected runtime behavior. Several gradual type systems have been proposed, e.g., Flow and TypeScript, but they rely on developers to annotate code with types. This paper presents NL2Type, a learning-based approach for predicting likely type signatures of JavaScript functions. The key idea is to exploit natural language information in source code, such as comments, function names, and parameter names, a rich source of knowledge that is typically ignored by type inference algorithms. We formulate the problem of predicting types as a classification problem and train a recurrent, LSTM-based neural model that, after learning from an annotated code base, predicts function types for unannotated code. We evaluate the approach with a corpus of 162,673 JavaScript files from real-world projects. NL2Type predicts types with a precision of 84.1% and a recall of 78.9% when considering only the top-most suggestion, and with a precision of 95.5% and a recall of 89.6% when considering the top-5 suggestions. The approach outperforms both JSNice, a state-of-the-art approach that analyzes implementations of functions instead of natural language information, and DeepTyper, a recent type prediction approach that is also based on deep learning. Beyond predicting types, NL2Type serves as a consistency checker for existing type annotations. We show that it discovers 39 inconsistencies that deserve developer attention (from a manual analysis of 50 warnings), most of which are due to incorrect type annotations.","","","10.1109/ICSE.2019.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811893","JavaScript;deep learning;type inference;comments;identifiers","Natural languages;Data mining;Predictive models;Semantics;Deep learning;Manuals","digital signatures;Java;learning (artificial intelligence);natural language processing;neural nets;pattern classification;program diagnostics;source code (software);type theory","NL2Type;natural language information;type signatures;type inference algorithms;JavaScript function types;statical typed languages;type prediction;source code;LSTM;DeepTyper;deep learning","","2","65","","","","","IEEE","IEEE Conferences"
"Recommending and Localizing Change Requests for Mobile Apps Based on User Reviews","F. Palomba; P. Salza; A. Ciurumelea; S. Panichella; H. Gall; F. Ferrucci; A. De Lucia","Delft Univ. of Technol., Delft, Netherlands; Univ. of Salerno, Fisciano, Italy; Univ. of Zurich, Zurich, Switzerland; Univ. of Zurich, Zurich, Switzerland; Univ. of Zurich, Zurich, Switzerland; Univ. of Salerno, Fisciano, Italy; Univ. of Salerno, Fisciano, Italy","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","106","117","Researchers have proposed several approaches to extract information from user reviews useful for maintaining and evolving mobile apps. However, most of them just perform automatic classification of user reviews according to specific keywords (e.g., bugs, features). Moreover, they do not provide any support for linking user feedback to the source code components to be changed, thus requiring a manual, time-consuming, and error-prone task. In this paper, we introduce CHANGEADVISOR, a novel approach that analyzes the structure, semantics, and sentiments of sentences contained in user reviews to extract useful (user) feedback from maintenance perspectives and recommend to developers changes to software artifacts. It relies on natural language processing and clustering algorithms to group user reviews around similar user needs and suggestions for change. Then, it involves textual based heuristics to determine the code artifacts that need to be maintained according to the recommended software changes. The quantitative and qualitative studies carried out on 44,683 user reviews of 10 open source mobile apps and their original developers showed a high accuracy of CHANGEADVISOR in (i) clustering similar user change requests and (ii) identifying the code components impacted by the suggested changes. Moreover, the obtained results show that ChangeAdvisor is more accurate than a baseline approach for linking user feedback clusters to the source code in terms of both precision (+47%) and recall (+38%).","","","10.1109/ICSE.2017.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985654","Mobile Apps;Mining User Reviews;Natural Language Processing;Impact Analysis","Computer bugs;Mobile communication;Joining processes;Tools;Maintenance engineering;Software;Feature extraction","mobile computing;natural language processing;source code (software)","textual based heuristics;CHANGEADVISOR;user feedback;source code components;mobile apps","","20","63","","","","","IEEE","IEEE Conferences"
"Active Inductive Logic Programming for Code Search","A. Sivaraman; T. Zhang; G. Van den Broeck; M. Kim","University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","292","303","Modern search techniques either cannot efficiently incorporate human feedback to refine search results or cannot express structural or semantic properties of desired code. The key insight of our interactive code search technique ALICE is that user feedback can be actively incorporated to allow users to easily express and refine search queries. We design a query language to model the structure and semantics of code as logic facts. Given a code example with user annotations, ALICE automatically extracts a logic query from code features that are tagged as important. Users can refine the search query by labeling one or more examples as desired (positive) or irrelevant (negative). ALICE then infers a new logic query that separates positive examples from negative examples via active inductive logic programming. Our comprehensive simulation experiment shows that ALICE removes a large number of false positives quickly by actively incorporating user feedback. Its search algorithm is also robust to user labeling mistakes. Our choice of leveraging both positive and negative examples and using nested program structure as an inductive bias is effective in refining search queries. Compared with an existing interactive code search technique, ALICE does not require a user to manually construct a search pattern and yet achieves comparable precision and recall with much fewer search iterations. A case study with real developers shows that ALICE is easy to use and helps express complex code patterns.","","","10.1109/ICSE.2019.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812091","Code Search, Active Learning, Inductive Logic Programming","Labeling;Logic programming;Semantics;Tools;Database languages;Feature extraction;Computer bugs","inductive logic programming;query languages;query processing;search engines","active inductive logic programming;user feedback;user labeling mistakes;search query;search pattern;structural properties;semantic properties;interactive code search technique ALICE;query language;logic facts;user annotations;logic query;code features;search iterations;nested program structure;interactive code search technique","","1","66","","","","","IEEE","IEEE Conferences"
"Challenges for Static Analysis of Java Reflection - Literature Review and Empirical Study","D. Landman; A. Serebrenik; J. J. Vinju","Centrum Wiskunde & Inf., Amsterdam, Netherlands; Centrum Wiskunde & Inf., Amsterdam, Netherlands; Centrum Wiskunde & Inf., Amsterdam, Netherlands","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","507","518","The behavior of software that uses the Java Reflection API is fundamentally hard to predict by analyzing code. Only recent static analysis approaches can resolve reflection under unsound yet pragmatic assumptions. We survey what approaches exist and what their limitations are. We then analyze how real-world Java code uses the Reflection API, and how many Java projects contain code challenging state-of-the-art static analysis. Using a systematic literature review we collected and categorized all known methods of statically approximating reflective Java code. Next to this we constructed a representative corpus of Java systems and collected descriptive statistics of the usage of the Reflection API. We then applied an analysis on the abstract syntax trees of all source code to count code idioms which go beyond the limitation boundaries of static analysis approaches. The resulting data answers the research questions. The corpus, the tool and the results are openly available. We conclude that the need for unsound assumptions to resolve reflection is widely supported. In our corpus, reflection can not be ignored for 78% of the projects. Common challenges for analysis tools such as non-exceptional exceptions, programmatic filtering meta objects, semantics of collections, and dynamic proxies, widely occur in the corpus. For Java software engineers prioritizing on robustness, we list tactics to obtain more easy to analyze reflection code, and for static analysis tool builders we provide a list of opportunities to have significant impact on real Java code.","","","10.1109/ICSE.2017.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985689","Java;Reflection;Static Analysis;Systematic Literature Review;Empirical Study","Java;Tools;Bibliographies;Grammar;Software;Systematics;Semantics","application program interfaces;computational linguistics;Java;program diagnostics;public domain software;software tools;source code (software);trees (mathematics)","static analysis tool;Java Reflection API;literature review;software behavior;real-world Java code analysis;Java projects;reflective Java code;Java systems;collected descriptive statistics;abstract syntax trees;source code;code idioms;nonexceptional exceptions;programmatic filtering meta objects;dynamic proxies;collections semantics;reflection code analysis","","9","80","","","","","IEEE","IEEE Conferences"
"RADAR: A Lightweight Tool for Requirements and Architecture Decision Analysis","S. A. Busari; E. Letier","Dept. of Comput. Sci., Univ. Coll. London, London, UK; Dept. of Comput. Sci., Univ. Coll. London, London, UK","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","552","562","Uncertainty and conflicting stakeholders' objectives make many requirements and architecture decisions particularly hard. Quantitative probabilistic models allow software architects to analyse such decisions using stochastic simulation and multi-objective optimisation, but the difficulty of elaborating the models is an obstacle to the wider adoption of such techniques. To reduce this obstacle, this paper presents a novel modelling language and analysis tool, called RADAR, intended to facilitate requirements and architecture decision analysis. The language has relations to quantitative AND/OR goal models used in requirements engineering and to feature models used in software product lines. However, it simplifies such models to a minimum set of language constructs essential for decision analysis. The paper presents RADAR's modelling language, automated support for decision analysis, and evaluates its application to four real-world examples.","","","10.1109/ICSE.2017.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985693","Decision Analysis;Requirements Engineering;Software Architecture;Goal Modelling;Monte-Carlo Simulation;Multi-Objective Optimisation;Search-Based Software Engineering;Expected Value of Information","Radar;Computer architecture;Analytical models;Mathematical model;Optimization;Decision analysis;Software","software architecture;software product lines;systems analysis","modelling language;RADAR;architecture decision analysis;requirements decision analysis;quantitative AND/OR goal models;requirements engineering;software product lines;Requirements and Architecture Decision Analyser","","2","46","","","","","IEEE","IEEE Conferences"
"Towards Understanding and Reasoning About Android Interoperations","S. Bae; S. Lee; S. Ryu","KAIST; KAIST, South Korea; KAIST, South Korea","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","223","233","Hybrid applications (apps) have become one of the most attractive options for mobile app developers thanks to its support for portability and device-specific features. Android hybrid apps, for example, support portability via JavaScript, device-specific features via Android Java, and seamless interactions between them. However, their interoperation semantics is often under-documented and unintuitive, which makes hybrid apps vulnerable to errors. While recent research has addressed such vulnerabilities, none of them are based on any formal grounds. In this paper, we present the first formal specification of Android interoperability to establish a firm ground for understanding and reasoning about the interoperations. We identify its semantics via extensive testing and thorough inspection of Android source code. We extend an existing multi-language semantics to formally express the key features of hybrid mechanisms, dynamic and indistinguishable interoperability. Based on the extensions, we incrementally define a formal interoperation semantics and disclose its numerous unintuitive and inconsistent behaviors. Moreover, on top of the formal semantics, we devise a lightweight type system that can detect bugs due to the unintuitive inter-language communication. We show that it detects more bugs more efficiently than HybriDroid, the state-of-the-art analyzer of Android hybrid apps, in real-world Android hybrid apps.","","","10.1109/ICSE.2019.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811927","Android hybrid applications, interoperability, multi-language systems, operational semantics, type system","Java;Semantics;Interoperability;Bridges;Computer bugs;Switches;Cognition","Android (operating system);formal specification;Java;mobile computing;open systems","Android interoperations;device-specific features;Android Java;formal specification;Android interoperability;Android source code;dynamic interoperability;formal interoperation semantics;real-world Android hybrid apps;multilanguage semantics","","1","25","","","","","IEEE","IEEE Conferences"
"Software Documentation Issues Unveiled","E. Aghajani; C. Nagy; O. L. Vega-M√°rquez; M. Linares-V√°squez; L. Moreno; G. Bavota; M. Lanza","Software Institute, Universit√† della Svizzera italiana (USI), Switzerland; Software Institute, Universit√† della Svizzera italiana (USI), Switzerland; Universidad de los Andes, Colombia; Universidad de los Andes, Colombia; Colorado State University, USA; Software Institute, Universit√† della Svizzera italiana (USI), Switzerland; Software Institute, Universit√† della Svizzera italiana (USI), Switzerland","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1199","1210","(Good) Software documentation provides developers and users with a description of what a software system does, how it operates, and how it should be used. For example, technical documentation (e.g., an API reference guide) aids developers during evolution/maintenance activities, while a user manual explains how users are to interact with a system. Despite its intrinsic value, the creation and the maintenance of documentation is often neglected, negatively impacting its quality and usefulness, ultimately leading to a generally unfavourable take on documentation. Previous studies investigating documentation issues have been based on surveying developers, which naturally leads to a somewhat biased view of problems affecting documentation. We present a large scale empirical study, where we mined, analyzed, and categorized 878 documentation-related artifacts stemming from four different sources, namely mailing lists, Stack Overflow discussions, issue repositories, and pull requests. The result is a detailed taxonomy of documentation issues from which we infer a series of actionable proposals both for researchers and practitioners.","","","10.1109/ICSE.2019.00122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811931","Documentation, Empirical Study","Documentation;Software;Tools;Maintenance engineering;Taxonomy;Interviews;Information services","application program interfaces;data mining;document handling;software maintenance;system documentation;Web sites","issue repositories;software system;API reference guide;user manual;software documentation issues;documentation-related artifacts;mailing lists;Stack Overflow discussions;pull requests","","","127","","","","","IEEE","IEEE Conferences"
"On Reliability of Patch Correctness Assessment","X. D. Le; L. Bao; D. Lo; X. Xia; S. Li; C. Pasareanu","Carnegie Mellon University; Zhejiang University City College; Singapore Management University; Monash University; Zhejiang University; Carnegie Mellon University and NASA Ames Research Center","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","524","535","Current state-of-the-art automatic software repair (ASR) techniques rely heavily on incomplete specifications, or test suites, to generate repairs. This, however, may cause ASR tools to generate repairs that are incorrect and hard to generalize. To assess patch correctness, researchers have been following two methods separately: (1) Automated annotation, wherein patches are automatically labeled by an independent test suite (ITS) - a patch passing the ITS is regarded as correct or generalizable, and incorrect otherwise, (2) Author annotation, wherein authors of ASR techniques manually annotate the correctness labels of patches generated by their and competing tools. While automated annotation cannot ascertain that a patch is actually correct, author annotation is prone to subjectivity. This concern has caused an on-going debate on the appropriate ways to assess the effectiveness of numerous ASR techniques proposed recently. In this work, we propose to assess reliability of author and automated annotations on patch correctness assessment. We do this by first constructing a gold set of correctness labels for 189 randomly selected patches generated by 8 state-of-the-art ASR techniques through a user study involving 35 professional developers as independent annotators. By measuring inter-rater agreement as a proxy for annotation quality - as commonly done in the literature - we demonstrate that our constructed gold set is on par with other high-quality gold sets. We then compare labels generated by author and automated annotations with this gold set to assess reliability of the patch assessment methodologies. We subsequently report several findings and highlight implications for future studies.","","","10.1109/ICSE.2019.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812054","Automated program repair;empirical study;test case generationn","Maintenance engineering;Tools;Gold;Reliability;Task analysis;Software;Best practices","program testing;software maintenance;software reliability","patch correctness assessment;ASR tools;independent test suite;correctness labels;automated annotations;annotation quality;patch assessment methodologies;automatic software repair techniques;randomly selected patches;ASR techniques;automated annotation;author annotation","","","84","","","","","IEEE","IEEE Conferences"
"How C++ Developers Use Immutability Declarations: An Empirical Study","J. Eyolfson; P. Lam","University of California, Los Angeles, USA; University of Waterloo, Canada","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","362","372","Best practices for developers, as encoded in recent programming language designs, recommend the use of immutability whenever practical. However, there is a lack of empirical evidence about the uptake of this advice. Our goal is to understand the usage of immutability by C++ developers in practice. This work investigates how C++ developers use immutability by analyzing their use of the C++ immutability qualifier, const, and by analyzing the code itself. We answer the following broad questions about const usage: 1) do developers actually write non-trivial (more than 3 methods) immutable classes and immutable methods? 2) do developers label their immutable classes and methods? We analyzed 7 medium-to-large open source projects and collected two sources of empirical data: 1) const annotations by developers, indicating an intent to write immutable code; and 2) the results of a simple static analysis which identified easily const-able methods---those that clearly did not mutate state. We estimate that 5% of non-trivial classes (median) are immutable. We found the vast majority of classes do carry immutability labels on methods: surprisingly, developers const-annotate 46% of methods, and we estimate that at least 51% of methods could be const-annotated. Furthermore, developers missed immutability labels on at least 6% of unannotated methods. We provide an in-depth discussion on how developers use const and the results of our analyses.","","","10.1109/ICSE.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812125","immutability;language design;empirical studies;static analysis","Software engineering","C++ language;program diagnostics;software engineering","immutable code;C++ developers;immutability declarations;immutability qualifier;programming language designs;static analysis","","","18","","","","","IEEE","IEEE Conferences"
"Software Development Waste","T. Sedano; P. Ralph; C. P√©raire","Pivotal, Palo Alto, CA, USA; Univ. of Auckland, Auckland, New Zealand; Electr. & Comput. Eng., Carnegie Mellon Univ., Moffett Field, CA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","130","140","Context: Since software development is a complex socio-technical activity that involves coordinating different disciplines and skill sets, it provides ample opportunities for waste to emerge. Waste is any activity that produces no value for the customer or user. Objective: The purpose of this paper is to identify and describe different types of waste in software development. Method: Following Constructivist Grounded Theory, we conducted a two-year five-month participant-observation study of eight software development projects at Pivotal, a software development consultancy. We also interviewed 33 software engineers, interaction designers, and product managers, and analyzed one year of retrospection topics. We iterated between analysis and theoretical sampling until achieving theoretical saturation. Results: This paper introduces the first empirical waste taxonomy. It identifies nine wastes and explores their causes, underlying tensions, and overall relationship to the waste taxonomy found in Lean Software Development. Limitations: Grounded Theory does not support statistical generalization. While the proposed taxonomy appears widely applicable, organizations with different software development cultures may experience different waste types. Conclusion: Software development projects manifest nine types of waste: building the wrong feature or product, mismanaging the backlog, rework, unnecessarily complex solutions, extraneous cognitive load, psychological distress, waiting/multitasking, knowledge loss, and ineffective communication.","","","10.1109/ICSE.2017.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985656","Software engineering waste;Extreme Programming;Lean Software Development","Software;Interviews;Manufacturing;Taxonomy;Programming;Production systems","software engineering","software development waste;complex socio-technical activity;constructivist grounded theory;software development consultancy;Pivotal;lean software development","","10","30","","","","","IEEE","IEEE Conferences"
"Decoding the Representation of Code in the Brain: An fMRI Study of Code Review and Expertise","B. Floyd; T. Santander; W. Weimer","NA; NA; NA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","175","186","Subjective judgments in software engineering tasks are of critical importance but can be difficult to study with conventional means. Medical imaging techniques hold the promise of relating cognition to physical activities and brain structures. In a controlled experiment involving 29 participants, we examine code comprehension, code review and prose review using functional magnetic resonance imaging. We find that the neural representations of programming languages vs. natural languages are distinct. We can classify which task a participant is undertaking based solely on brain activity (balanced accuracy 79%, p <; 0.001). Further, we find that the same set of brain regions distinguish between code and prose (near-perfect correlation, r = 0.99, p <; 0.001). Finally, we find that task distinctions are modulated by expertise, such that greater skill predicts a less differentiated neural representation (r = -0.44, p = 0.016) indicating that more skilled participants treat code and prose more similarly at a neural activation level.","","","10.1109/ICSE.2017.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985660","medical imaging;code comprehension;prose review","Biomedical imaging;Software engineering;Brain;Software;Computer science;Natural languages;Tools","biomedical MRI;medical image processing;software engineering","fMRI study;software engineering tasks;medical imaging techniques;functional magnetic resonance imaging;code comprehension;code review;prose review;neural representations;programming languages;natural languages","","11","85","","","","","IEEE","IEEE Conferences"
"Redundant Loads: A Software Inefficiency Indicator","P. Su; S. Wen; H. Yang; M. Chabbi; X. Liu","College of William & Mary, USA; College of William & Mary, USA; Beihang University, China; Scalable Machines Research, USA; College of William & Mary, USA","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","982","993","Modern software packages have become increasingly complex with millions of lines of code and references to many external libraries. Redundant operations are a common performance limiter in these code bases. Missed compiler optimization opportunities, inappropriate data structure and algorithm choices, and developers' inattention to performance are some common reasons for the existence of redundant operations. Developers mainly depend on compilers to eliminate redundant operations. However, compilers' static analysis often misses optimization opportunities due to ambiguities and limited analysis scope; automatic optimizations to algorithmic and data structural problems are out of scope. We develop LoadSpy, a whole-program profiler to pinpoint redundant memory load operations, which are often a symptom of many redundant operations. The strength of LoadSpy exists in identifying and quantifying redundant load operations in programs and associating the redundancies with program execution contexts and scopes to focus developers' attention on problematic code. LoadSpy works on fully optimized binaries, adopts various optimization techniques to reduce its overhead, and provides a rich graphic user interface, which make it a complete developer tool. Applying LoadSpy showed that a large fraction of redundant loads is common in modern software packages despite highest levels of automatic compiler optimizations. Guided by LoadSpy, we optimize several well-known benchmarks and real-world applications, yielding significant speedups.","","","10.1109/ICSE.2019.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811970","Whole-program profiling;Software optimization;Performance measurement;Tools","Redundancy;Optimization;Loading;Software;Tools;Monitoring;Registers","application program interfaces;data structures;graphical user interfaces;optimisation;optimising compilers;program debugging;program diagnostics;software libraries","redundant loads;software inefficiency indicator;modern software packages;common performance limiter;missed compiler optimization opportunities;algorithm choices;algorithmic data structural problems;LoadSpy;redundant memory load operations;automatic compiler optimizations;data structure;redundant load operations;graphic user interface","","1","81","","","","","IEEE","IEEE Conferences"
"Global Optimization of Numerical Programs Via Prioritized Stochastic Algebraic Transformations","X. Wang; H. Wang; Z. Su; E. Tang; X. Chen; W. Shen; Z. Chen; L. Wang; X. Zhang; X. Li","Nanjing University, China; Nanjing University, China; ETH Zurich, Switzerland / UC Davis, United States; Nanjing University, China; Nanjing University, China; Nanjing University, China; Nanjing University, China; Nanjing University, China; Nanjing University, China; Nanjing University, China","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1131","1141","Numerical code is often applied in the safety-critical, but resource-limited areas. Hence, it is crucial for it to be correct and efficient, both of which are difficult to ensure. On one hand, accumulated rounding errors in numerical programs can cause system failures. On the other hand, arbitrary/infinite-precision arithmetic, although accurate, is infeasible in practice and especially in resource-limited scenarios because it performs thousands of times slower than floating-point arithmetic. Thus, it has been a significant challenge to obtain high-precision, easy-to-maintain, and efficient numerical code. This paper introduces a novel global optimization framework to tackle this challenge. Using our framework, a developer simply writes the infinite-precision numerical program directly following the problem's mathematical requirement specification. The resulting code is correct and easy-to-maintain, but inefficient. Our framework then optimizes the program in a global fashion (i.e., considering the whole program, rather than individual expressions or statements as in prior work), the key technical difficulty this work solves. To this end, it analyzes the program's numerical value flows across different statements through a symbolic trace extraction algorithm, and generates optimized traces via stochastic algebraic transformations guided by effective rule selection. We first evaluate our technique on numerical benchmarks from the literature; results show that our global optimization achieves significantly higher worst-case accuracy than the state-of-the-art numerical optimization tool. Second, we show that our framework is also effective on benchmarks having complicated program structures, which are challenging for numerical optimization. Finally, we apply our framework on real-world code to successfully detect numerical bugs that have been confirmed by developers.","","","10.1109/ICSE.2019.00116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812093","program optimization;numerical analysis;program transformation","Optimization;Software;Benchmark testing;Tools;Measurement;Computer science;Computer bugs","algebra;optimisation","resource-limited scenarios;floating-point arithmetic;infinite-precision numerical program;resulting code;global fashion;numerical value;optimized traces;numerical benchmarks;program structures;real-world code;numerical bugs;numerical programs;prioritized stochastic algebraic transformations;safety-critical;resource-limited areas;accumulated rounding errors;numerical code;global optimization framework;numerical optimization tool","","","41","","","","","IEEE","IEEE Conferences"
"Do Developers Read Compiler Error Messages?","T. Barik; J. Smith; K. Lubick; E. Holmes; J. Feng; E. Murphy-Hill; C. Parnin","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Psychol., Washington & Lee Univ., Lexington, VA, USA; Dept. of Psychol., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","575","585","In integrated development environments, developers receive compiler error messages through a variety of textual and visual mechanisms, such as popups and wavy red underlines. Although error messages are the primary means of communicating defects to developers, researchers have a limited understanding on how developers actually use these messages to resolve defects. To understand how developers use error messages, we conducted an eye tracking study with 56 participants from undergraduate and graduate software engineering courses at our university. The participants attempted to resolve common, yet problematic defects in a Java code base within the Eclipse development environment. We found that: 1) participants read error messages and the difficulty of reading these messages is comparable to the difficulty of reading source code, 2) difficulty reading error messages significantly predicts participants' task performance, and 3) participants allocate a substantial portion of their total task to reading error messages (13%-25%). The results of our study offer empirical justification for the need to improve compiler error messages for developers.","","","10.1109/ICSE.2017.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985695","compiler errors;eye tracking;integrated development environments;programmer comprehension;reading;visual attention","Gaze tracking;Libraries;Java;Software engineering;Visualization;Google;Navigation","Java;program compilers","compiler error messages;software engineering courses;Java code base;Eclipse development environment;source code","","6","38","","","","","IEEE","IEEE Conferences"
"AdJust: Runtime Mitigation of Resource Abusing Third-Party Online Ads","W. Wang; I. L. Kim; Y. Zheng","University at Buffalo; Purdue University; IBM T.J. Watson Research Center","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1005","1015","Online advertising is the most critical revenue stream for many Internet companies. However, showing ads on websites comes with a price tag. Since website contents and third-party ads are blended together, third-party ads may compete with the publisher contents, delaying or even breaking the rendering of first-party contents. In addition, dynamically including scripts from ad networks all over the world may introduce buggy scripts that slow down page loads and even freeze the browser. The resulting poor usability problems lead to bad user experience and lower profits. The problems caused by such resource abusing ads are originated from two root causes: First, content publishers have no control over third-party ads. Second, publishers cannot differentiate resource consumed by ads from that consumed by their own contents. To address these challenges, we propose an effective technique, AdJust, that allows publishers to specify constraints on events associated with third-party ads (e.g., URL requests, HTML element creations, and timers), so that they can mitigate user experience degradations and enforce consistent ads experience to all users. We report on a series of experiments over the Alexa top 200 news websites. The results point to the efficacy of our proposed techniques: AdJust effectively mitigated degradations that freeze web browsers (on 36 websites), reduced the load time of publisher contents (on 61 websites), prioritized publisher contents (on 166 websites) and ensured consistent rendering orders among top ads (on 68 websites).","","","10.1109/ICSE.2019.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811929","online ads;defective ads;resource abusing;performance degradation","Servers;Runtime;Browsers;Delays;Web pages;Sports;Uniform resource locators","advertising data processing;rendering (computer graphics);Web sites","content publishers;third-party ads;prioritized publisher contents;resource abusing third-party online ads;website contents;first-party contents;AdJust technique;online advertising","","","30","","","","","IEEE","IEEE Conferences"
"9.6 Million Links in Source Code Comments: Purpose, Evolution, and Decay","H. Hata; C. Treude; R. G. Kula; T. Ishio","Nara Institute of Science and Technology, Japan; University of Adelaide, Australia; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1211","1221","Links are an essential feature of the World Wide Web, and source code repositories are no exception. However, despite their many undisputed benefits, links can suffer from decay, insufficient versioning, and lack of bidirectional traceability. In this paper, we investigate the role of links contained in source code comments from these perspectives. We conducted a large-scale study of around 9.6 million links to establish their prevalence, and we used a mixed-methods approach to identify the links' targets, purposes, decay, and evolutionary aspects. We found that links are prevalent in source code repositories, that licenses, software homepages, and specifications are common types of link targets, and that links are often included to provide metadata or attribution. Links are rarely updated, but many link targets evolve. Almost 10% of the links included in source code comments are dead. We then submitted a batch of link-fixing pull requests to open source software repositories, resulting in most of our fixes being merged successfully. Our findings indicate that links in source code comments can indeed be fragile, and our work opens up avenues for future work to address these problems.","","","10.1109/ICSE.2019.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811933","code comment;link decay;knowledge sharing","C++ languages;Java;Licenses;Documentation;Python;Web sites","Internet;public domain software;software maintenance","source code repositories;link targets;source code comments;link-fixing pull requests;source software repositories;World Wide Web;mixed-methods approach","","1","45","","","","","IEEE","IEEE Conferences"
"Symbolic Repairs for GR(1) Specifications","S. Maoz; J. O. Ringert; R. Shalom","Tel Aviv University; University of Leicester; Tel Aviv University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1016","1026","Unrealizability is a major challenge for GR(1), an expressive assume-guarantee fragment of LTL that enables efficient synthesis. Some works attempt to help engineers deal with unrealizability by generating counter-strategies or computing an unrealizable core. Other works propose to repair the unrealizable specification by suggesting repairs in the form of automatically generated assumptions. In this work we present two novel symbolic algorithms for repairing unrealizable GR(1) specifications. The first algorithm infers new assumptions based on the recently introduced JVTS. The second algorithm infers new assumptions directly from the specification. Both algorithms are sound. The first is incomplete but can be used to suggest many different repairs. The second is complete but suggests a single repair. Both are symbolic and therefore efficient. We implemented our work, validated its correctness, and evaluated it on benchmarks from the literature. The evaluation shows the strength of our algorithms, in their ability to suggest repairs and in their performance and scalability compared to previous solutions.","","","10.1109/ICSE.2019.00106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812056","reactive synthesis;repair;GR(1)","Maintenance engineering;Safety;Glass;Cascading style sheets;Benchmark testing;Scalability;Standards","formal specification;maintenance engineering;program debugging","symbolic repairs;counter-strategies;symbolic algorithms;GR1 specification;JVTS","","","37","","","","","IEEE","IEEE Conferences"
"The List is the Process: Reliable Pre-Integration Tracking of Commits on Mailing Lists","R. Ramsauer; D. Lohmann; W. Mauerer","OTH Regensburg; University of Hanover; OTH Regensburg","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","807","818","A considerable corpus of research on software evolution focuses on mining changes in software repositories, but omits their pre-integration history. We present a novel method for tracking this otherwise invisible evolution of software changes on mailing lists by connecting all early revisions of changes to their final version in repositories. Since artefact modifications on mailing lists are communicated by updates to fragments (i.e., patches) only, identifying semantically similar changes is a non-trivial task that our approach solves in a language-independent way. We evaluate our method on high-profile open source software (OSS) projects like the Linux kernel, and validate its high accuracy using an elaborately created ground truth. Our approach can be used to quantify properties of OSS development processes, which is an essential requirement for using OSS in reliable or safety-critical industrial products, where certifiability and conformance to processes are crucial. The high accuracy of our technique allows, to the best of our knowledge, for the first time to quantitatively determine if an open development process effectively aligns with given formal process requirements.","","","10.1109/ICSE.2019.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812060","software engineering;mining software repositories;mailing lists;patches;commits","Postal services;Tools;Linux;Kernel;Electronic mail;Software reliability","data mining;electronic mail;Linux;public domain software;software maintenance","OSS development processes;open development process;mailing lists;software evolution;software repositories;open source software projects;Linux kernel;reliable safety-critical industrial products;formal process requirements","","","41","","","","","IEEE","IEEE Conferences"
"DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets","E. Horton; C. Parnin","North Carolina State University; North Carolina State University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","328","338","Platforms like Stack Overflow and GitHub's gist system promote the sharing of ideas and programming techniques via the distribution of code snippets designed to illustrate particular tasks. Python, a popular and fast-growing programming language, sees heavy use on both sites, with nearly one million questions asked on Stack Overflow and 400 thousand public gists on GitHub. Unfortunately, around 75% of the Python example code shared through these sites cannot be directly executed. When run in a clean environment, over 50% of public Python gists fail due to an import error for a missing library. We present DockerizeMe, a technique for inferring the dependencies needed to execute a Python code snippet without import error. DockerizeMe starts with offline knowledge acquisition of the resources and dependencies for popular Python packages from the Python Package Index (PyPI). It then builds Docker specifications using a graph-based inference procedure. Our inference procedure resolves import errors in 892 out of nearly 3,000 gists from the Gistable dataset for which Gistable's baseline approach could not find and install all dependencies.","","","10.1109/ICSE.2019.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811897","Docker;Configuration Management;Environment Inference;Dependencies;Python","Python;Libraries;Knowledge based systems;Wheels;Task analysis;Indexes;Inference algorithms","graph theory;inference mechanisms;knowledge acquisition;Python;software packages;source code (software)","DockerizeMe;automatic inference;environment dependencies;Stack Overflow;programming techniques;programming language;missing library;Python code snippet;offline knowledge acquisition;graph-based inference procedure;GitHub gist system;Python package index","","1","26","","","","","IEEE","IEEE Conferences"
"Harnessing Evolution for Multi-Hunk Program Repair","S. Saha; R. k. Saha; M. r. Prasad","University of California Santa Barbara; Fujitsu Laboratories of America, Inc.; Fujitsu Laboratories of America, Inc.","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","13","24","Despite significant advances in automatic program repair (APR) techniques over the past decade, practical deployment remains an elusive goal. One of the important challenges in this regard is the general inability of current APR techniques to produce patches that require edits in multiple locations, i.e., multi-hunk patches. In this work, we present a novel APR technique that generalizes single-hunk repair techniques to include an important class of multi-hunk bugs, namely bugs that may require applying a substantially similar patch at a number of locations. We term such sets of repair locations as evolutionary siblings - similar looking code, instantiated in similar contexts, that are expected to undergo similar changes. At the heart of our proposed method is an analysis to accurately identify a set of evolutionary siblings, for a given bug. This analysis leverages three distinct sources of information, namely the test-suite spectrum, a novel code similarity analysis, and the revision history of the project. The discovered siblings are then simultaneously repaired in a similar fashion. We instantiate this technique in a tool called HERCULES and demonstrate that it is able to correctly fix 46 bugs in the Defects4J dataset, the highest of any individual APR technique to date. This includes 15 multi-hunk bugs and overall 11 bugs which have not been fixed by any other technique so far.","","","10.1109/ICSE.2019.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812131","automatic program repair, multi-hunk patches, code similarity","Maintenance engineering;Computer bugs;Cloning;Tools;History;Search problems;Syntactics","program debugging;program testing","multihunk program repair;automatic program repair techniques;multihunk patches;single-hunk repair techniques;repair locations;evolutionary siblings;code similarity analysis;APR technique;HERCULES tool;Defects4J dataset","","","47","","","","","IEEE","IEEE Conferences"
"From Diversity by Numbers to Diversity as Process: Supporting Inclusiveness in Software Development Teams with Brainstorming","A. Filippova; E. Trainer; J. D. Herbsleb","Inst. for Software Res., Carnegie Mellon Univ., Pittsburgh, PA, USA; Inst. for Software Res., Carnegie Mellon Univ., Pittsburgh, PA, USA; Inst. for Software Res., Carnegie Mellon Univ., Pittsburgh, PA, USA","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","152","163","Negative experiences in diverse software development teams have the potential to turn off minority participants from future team-based software development activity. We examine the use of brainstorming as one concrete team processes that may be used to improve the satisfaction of minority developers when working in a group. Situating our study in time-intensive hackathon-like environments where engagement of all team members is particularly crucial, we use a combination of survey and interview data to test our propositions. We find that brainstorming strategies are particularly effective for team members who identify as minorities, and support satisfaction with both the process and outcomes of teamwork through different mechanisms.","","","10.1109/ICSE.2017.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985658","Diversity;hackathons;teamwork;brainstorming;satisfaction;software engineering management","Software;Teamwork;Software engineering;Concrete;Cultural differences;Organizations","software engineering","software development;time-intensive hackathon-like environments;brainstorming","","4","47","","","","","IEEE","IEEE Conferences"
"Socio-Technical Work-Rate Increase Associates With Changes in Work Patterns in Online Projects","F. Sarker; B. Vasilescu; K. Blincoe; V. Filkov","University of California, Davis, United States; Carnegie Mellon University, United States; University of Auckland, New Zealand; University of California, Davis, United States","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","936","947","Software developers work on a variety of tasks ranging from the technical, e.g., writing code, to the social, e.g., participating in issue resolution discussions. The amount of work developers perform per week (their work-rate) also varies and depends on project needs and developer schedules. Prior work has shown that while moderate levels of increased technical work and multitasking lead to higher productivity, beyond a certain threshold, they can lead to lowered performance. Here, we study how increases in the short-term work-rate along both the technical and social dimensions are associated with changes in developers' work patterns, in particular communication sentiment, technical productivity, and social productivity. We surveyed active and prolific developers on GitHub to understand the causes and impacts of increased work-rates. Guided by the responses, we developed regression models to study how communication and committing patterns change with increased work-rates and fit those models to large-scale data gathered from traces left by thousands of GitHub developers. From our survey and models, we find that most developers do experience work-rate-increase-related changes in behavior. Most notably, our models show that there is a sizable effect when developers comment much more than their average: the negative sentiment in their comments increases, suggesting an increased level of stress. Our models also show that committing patterns do not change with increased commenting, and vice versa, suggesting that technical and social activities tend not to be multitasked.","","","10.1109/ICSE.2019.00099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811968","software engineering;work related stress;work patterns;multitasking;socio technical;work rate increase;survey;empirical analysis;regression modeling;GitHub;software developers;open source software;online projects;commits;comments;sentiment;social activities;technical activities;focus switching;recommendations;repositories;issues;pull requests;discussions;teams;collaboration;team members;social coding","Stress;Task analysis;Software;Productivity;Data models;Multitasking;Switches","Internet;project management;regression analysis;software engineering","GitHub developers;technical activities;social activities;work patterns;technical dimensions;social dimensions;technical productivity;social productivity;software developers;socio-technical work-rate increase;online projects;regression models","","","58","","","","","IEEE","IEEE Conferences"
"Search-Driven String Constraint Solving for Vulnerability Detection","J. Thom√©; L. K. Shar; D. Bianculli; L. Briand","SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","198","208","Constraint solving is an essential technique for detecting vulnerabilities in programs, since it can reason about input sanitization and validation operations performed on user inputs. However, real-world programs typically contain complex string operations that challenge vulnerability detection. State-of-the-art string constraint solvers support only a limited set of string operations and fail when they encounter an unsupported one, this leads to limited effectiveness in finding vulnerabilities. In this paper we propose a search-driven constraint solving technique that complements the support for complex string operations provided by any existing string constraint solver. Our technique uses a hybrid constraint solving procedure based on the Ant Colony Optimization meta-heuristic. The idea is to execute it as a fallback mechanism, only when a solver encounters a constraint containing an operation that it does not support. We have implemented the proposed search-driven constraint solving technique in the ACO-Solver tool, which we have evaluated in the context of injection and XSS vulnerability detection for Java Web applications. We have assessed the benefits and costs of combining the proposed technique with two state-of-the-art constraint solvers (Z3-str2 and CVC4). The experimental results, based on a benchmark with 104 constraints derived from nine realistic Web applications, show that our approach, when combined in a state-of-the-art solver, significantly improves the number of detected vulnerabilities (from 4.7% to 71.9% for Z3-str2, from 85.9% to 100.0% for CVC4), and solves several cases on which the solver fails when used stand-alone (46 more solved cases for Z3-str2, and 11 more for CVC4), while still keeping the execution time affordable in practice.","","","10.1109/ICSE.2017.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985662","vulnerability detection;string constraint solving;search-based software engineering","Java;Libraries;Security;Ant colony optimization;Automata;Search problems;Standards","ant colony optimisation;Internet;Java;program verification;search problems","input sanitization;program validation operations;complex string operations;search-driven string constraint solving technique;hybrid constraint solving procedure;ant colony optimization metaheuristic;fallback mechanism;ACO-solver tool;XSS vulnerability detection;Java Web applications","","1","56","","","","","IEEE","IEEE Conferences"
"Towards Automating Precision Studies of Clone Detectors","V. Saini; F. Farmahinifarahani; Y. Lu; D. Yang; P. Martins; H. Sajnani; P. Baldi; C. V. Lopes","University of California Irvine; University of California Irvine; University of California Irvine; University of California Irvine; University of California Irvine; Microsoft, USA; University of California Irvine; University of California Irvine","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","49","59","Current research in clone detection suffers from poor ecosystems for evaluating precision of clone detection tools. Corpora of labeled clones are scarce and incomplete, making evaluation labor intensive and idiosyncratic, and limiting intertool comparison. Precision-assessment tools are simply lacking. We present a semiautomated approach to facilitate precision studies of clone detection tools. The approach merges automatic mechanisms of clone classification with manual validation of clone pairs. We demonstrate that the proposed automatic approach has a very high precision and it significantly reduces the number of clone pairs that need human validation during precision experiments. Moreover, we aggregate the individual effort of multiple teams into a single evolving dataset of labeled clone pairs, creating an important asset for software clone research.","","","10.1109/ICSE.2019.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811972","Precision Evaluation, Clone Detection, Machine learning, Open source labeled datasets","Cloning;Tools;Detectors;Manuals;Inspection;Software;Aggregates","program diagnostics;software maintenance;software management;software tools","clone detection tools;precision-assessment tools;semiautomated approach;clone classification;precision experiments;labeled clone pairs;software clone research;clone detectors;labor intensive evaluation;human validation","","","28","","","","","IEEE","IEEE Conferences"
"CRADLE: Cross-Backend Validation to Detect and Localize Bugs in Deep Learning Libraries","H. V. Pham; T. Lutellier; W. Qi; L. Tan","University of Waterloo; University of Waterloo; University of Science and Technology of China; Purdue University","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1027","1038","Deep learning (DL) systems are widely used in domains including aircraft collision avoidance systems, Alzheimer's disease diagnosis, and autonomous driving cars. Despite the requirement for high reliability, DL systems are difficult to test. Existing DL testing work focuses on testing the DL models, not the implementations (e.g., DL software libraries) of the models. One key challenge of testing DL libraries is the difficulty of knowing the expected output of DL libraries given an input instance. Fortunately, there are multiple implementations of the same DL algorithms in different DL libraries. Thus, we propose CRADLE, a new approach that focuses on finding and localizing bugs in DL software libraries. CRADLE (1) performs cross-implementation inconsistency checking to detect bugs in DL libraries, and (2) leverages anomaly propagation tracking and analysis to localize faulty functions in DL libraries that cause the bugs. We evaluate CRADLE on three libraries (TensorFlow, CNTK, and Theano), 11 datasets (including ImageNet, MNIST, and KGS Go game), and 30 pre-trained models. CRADLE detects 12 bugs and 104 unique inconsistencies, and highlights functions relevant to the causes of inconsistencies for all 104 unique inconsistencies.","","","10.1109/ICSE.2019.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812095","deep learning software testing;cross-implementation testing;bugs detection;software testing","Libraries;Computer bugs;Testing;Training;Atmospheric modeling;Task analysis;Deep learning","learning (artificial intelligence);neural nets;program debugging;software libraries","cross-backend validation;deep learning libraries;deep learning systems;DL software libraries;CRADLE;cross-implementation inconsistency checking;anomaly propagation tracking","","2","75","","","","","IEEE","IEEE Conferences"
"AutoTap: Synthesizing and Repairing Trigger-Action Programs Using LTL Properties","L. Zhang; W. He; J. Martinez; N. Brackenbury; S. Lu; B. Ur","The University of Chicago; The University of Chicago; The University of Chicago; The University of Chicago; The University of Chicago; The University of Chicago","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","281","291","End-user programming, particularly trigger-action programming (TAP), is a popular method of letting users express their intent for how smart devices and cloud services interact. Unfortunately, sometimes it can be challenging for users to correctly express their desires through TAP. This paper presents AutoTap, a system that lets novice users easily specify desired properties for devices and services. AutoTap translates these properties to linear temporal logic (LTL) and both automatically synthesizes property-satisfying TAP rules from scratch and repairs existing TAP rules. We designed AutoTap based on a user study about properties users wish to express. Through a second user study, we show that novice users made significantly fewer mistakes when expressing desired behaviors using AutoTap than using TAP rules. Our experiments show that AutoTap is a simple and effective option for expressive end-user programming.","","","10.1109/ICSE.2019.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811900","End-user programming;Trigger-action programming;Program synthesis;Program repair","Programming;Smart devices;Microsoft Windows;Rain;Maintenance engineering;Safety;Computer bugs","cloud computing;software maintenance;temporal logic","AutoTap;LTL properties;trigger-action programming;smart devices;property-satisfying TAP rules;cloud services;end-user programming;trigger-action programs;linear temporal logic;program repair;program synthesis","","","41","","","","","IEEE","IEEE Conferences"
"An Empirical Study on Mutation, Statement and Branch Coverage Fault Revelation That Avoids the Unreliable Clean Program Assumption","T. T. Chekam; M. Papadakis; Y. Le Traon; M. Harman","Interdiscipl. Centre for Security, Reliability & Trust, Univ. of Luxembourg, Luxembourg City, Luxembourg; Interdiscipl. Centre for Security, Reliability & Trust, Univ. of Luxembourg, Luxembourg City, Luxembourg; Interdiscipl. Centre for Security, Reliability & Trust, Univ. of Luxembourg, Luxembourg City, Luxembourg; Univ. Coll. London, London, UK","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","597","608","Many studies suggest using coverage concepts, such as branch coverage, as the starting point of testing, while others as the most prominent test quality indicator. Yet the relationship between coverage and fault-revelation remains unknown, yielding uncertainty and controversy. Most previous studies rely on the Clean Program Assumption, that a test suite will obtain similar coverage for both faulty and fixed ('clean') program versions. This assumption may appear intuitive, especially for bugs that denote small semantic deviations. However, we present evidence that the Clean Program Assumption does not always hold, thereby raising a critical threat to the validity of previous results. We then conducted a study using a robust experimental methodology that avoids this threat to validity, from which our primary finding is that strong mutation testing has the highest fault revelation of four widely-used criteria. Our findings also revealed that fault revelation starts to increase significantly only once relatively high levels of coverage are attained.","","","10.1109/ICSE.2017.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985697","Mutation testing;test effectiveness;code coverage;real faults;test adequacy","Testing;Java;Correlation;Robustness;Standards;Tools","program testing;software fault tolerance;software quality","branch coverage fault revelation;unreliable clean program assumption avoidance;test quality indicator;semantic deviations;mutation testing","","14","57","","","","","IEEE","IEEE Conferences"
"2nd International Workshop on Rapid Continuous Software Engineering (RCoSE 2015)","M. Tichy; J. Bosch; M. Goedicke; B. Fitzgerald","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","993","994","Continuous software engineering refers to the organizational¬†¬†capability to develop, release and learn from software in very short¬†¬†rapid cycles, typically hours, days or a very small numbers of¬†¬†weeks.¬†¬†This requires not only agile processes in teams but in the¬†¬†complete research and development organization. Additionally, the¬†¬†technology used in the different development phases, like¬†¬†requirements engineering and system integration, must support the¬†¬†quick development cycles. Finally, automatic live experimentation¬†¬†for different system alternatives enables fast gathering of required¬†¬†data for decision making. The workshop, the second in the series¬†¬†after the first one at ICSE 2014, aims to bring the research¬†¬†communities of the aforementioned areas together to exchange¬†¬†challenges, ideas, and solutions to bring software engineering a¬†¬†step further to being a holistic continuous process. The workshop¬†¬†program is based on eight papers selected in the peer-review process¬†¬†and supplemented by interaction and discussions at the workshop. The¬†¬†topics range from agile methods, continuous software engineering¬†¬†practices to specific techniques, like visualization and testing.","","","10.1109/ICSE.2015.343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203144","","Conferences;Software engineering;Software;Companies;Testing","","","","2","8","","","","","IEEE","IEEE Conferences"
"8th International Workshop on Search-Based Software Testing (SBST 2015)","G. Gay; G. Antoniol","NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1001","1002","This paper is a report on the 8th International Workshop on Search-Based Software Testing at the 37th International Conference on Sofrware Engineering (ICSE). Search-Based Software Testing (SBST) is a form of Search-Based Software Engineering (SBSE) that optimizes testing through the use of computational search. SBST is used to generate test data, prioritize test cases, minimize test suites, reduce human oracle cost, verify software models, test service-orientated architectures, construct test suites for interaction testing, and validate real time properties. The objectives of this workshop are to bring together researchers and industrial practitioners from SBST and the wider software engineering community to share experience and provide directions for future research, and to encourage the use of search techniques to combine aspects of testing with other aspects of the software engineering lifecycle.Three full research papers, three short papers, and threeposition papers will be presented in the two-day workshop. Additionally, six development groups have pitted their test generation tools against a common set of programs and benchmarks, and will present their techniques and results. This report will give the background of the workshop and detail the provisional program.","","","10.1109/ICSE.2015.323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203148","","Conferences;Software engineering;Software;Software testing;Search problems;Measurement","","","","1","3","","","","","IEEE","IEEE Conferences"
"1st International Workshop on Software Protection (SPRO 2015)","P. Falcarin; B. Wyseur","NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1013","1014","There are many reasons to protect software: your banking app needs to be protected to prevent fraud; software operating on critical infrastructures needs to be protected against vulnerability discovery; software vendors and service companies need it to protect their business; etc. In the past decade, many techniques to protect software have been presented and broken. Beyond making individual techniques better, the challenge includes to be able to deploy them in practice and be able to evaluate them. This is the objective of SPRO, the first International Workshop on Software Protection: to bring together researchers and industrial practitioners both from software protection and the wider software engineering community to share experience and provide directions for future research, in order to stimulate the use of software engineering techniques in novel aspects of software protection. This first edition of the workshop is held at ICSE 2015 in Florence (Italy) with the aim of creating a community working in this new growing area of security, and to highlight its synergies with different research fields of software engineering, like: formal models, program analysis, reverse engineering, code transformations, empirical evaluation, and software metrics. This paper presents the research themes and challenges of the workshop, describes the workshop organization, and summarizes the research papers.","","","10.1109/ICSE.2015.328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203154","Obfuscation;Virtualization;Information Hiding;security modelling;security metrics","Software protection;Conferences;Software;Software engineering;Security;Analytical models;Reverse engineering","","","","","9","","","","","IEEE","IEEE Conferences"
"5th International Workshop on the Twin Peaks of Requirements and Architecture (TwinPeaks 2015)","M. Galster; M. Mirakhorli","NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1017","1018","The relationships and interdependencies between software requirements and the architectures of software-intensive systems are described in the Twin Peaks model. The fundamental idea of the Twin Peaks model is that Requirements Engineering and Software Architecture should not be treated in isolation. Instead, we need to progressively discover and specify requirements while concurrently exploring alternative architectural solutions. However, bridging the gap between Requirements Engineering and Software Architecture has mainly been discussed independently in the respective communities. Therefore, this ICSE workshop aims at bringing together researchers, practitioners and educators from the Requirements Engineering and Software Architecture fields to jointly explore the strong interdependencies between requirements and architecture. Based on the results from previous editions of the workshop, this edition focuses on agile software development contexts and on exploring lightweight techniques for integrating requirements and architectural thinking.","","","10.1109/ICSE.2015.330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203156","twin peaks;requirements engineering;software architecture;agile","Conferences;Computer architecture;Requirements engineering;Software architecture;Software;Context","","","","","4","","","","","IEEE","IEEE Conferences"
"10th International Workshop on Automation of Software Test (AST 2015)","R. Subramanyan; L. Mariani; D. Hao","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","963","964","This paper is a report on The 10th IEEE/ACMInternational Workshop on Automation of Software Test (AST2015) at the 37th International Conference on Software Engineering(ICSE 2015). It sets a special theme on testing oracles.Keynote speeches and charette discussions are organized aroundthis special theme. 16 full research papers and 2 keynotes willbe presented in the two-day workshop. The report will give thebackground of the workshop and the selection of the specialtheme, and report on the organization of the workshop. Theprovisional program will be presented with a list of the sessionsand papers to be presented at the workshop.","","","10.1109/ICSE.2015.307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203129","Automation of Software Test;Software Testing;Software Tools;Test Oracle","Conferences;Software;Automation;Software testing;Graphical user interfaces;Speech","","","","","","","","","","IEEE","IEEE Conferences"
"4th International Workshop on Games and Software Engineering (GAS 2015)","J. Bishop; K. M. L. Cooper; W. Scacchi; J. Whitehead","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","979","980","We present a summary of the 4th ICSE Workshop on Games and Software Engineering. The full day workshop is planned to include a keynote speaker, game-jam demonstration session, and paper presentations on game software engineering topics related to software engineering education, frameworks for game development and infrastructure, quality assurance, and model-based game development. The accepted papers are overviewed here.","","","10.1109/ICSE.2015.314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203137","Game engineering;software engineering","Games;Software engineering;Conferences;Engines;Education;Quality assurance;Computer architecture","","","","","","","","","","IEEE","IEEE Conferences"
"4th International Workshop on Realizing AI Synergies in Software Engineering (RAISE 2015)","B. Turhan; A. Bener; R. Harrison; A. Miransky; C. Mericli; L. Minku","NA; NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","991","992","This workshop is the fourth in the series and continued to build upon the work carried out at the previous iterations of the International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering, which were held at ICSE in 2012, 2013 and 2014. RAISE 2015 brought together researchers and practitioners from the artificial intelligence (AI) and software engineering (SE) disciplines to build on the interdis- ciplinary synergies that exist and to stimulate further interaction across these disciplines. Mutually beneficial characteristics have appeared in the past few decades and are still evolving due to new challenges and technological advances. Hence, the question that motivates and drives the RAISE Workshop series is: ""Are SE and AI researchers ignoring important insights from AI and SE?"". To pursue this question, RAISE'15 explored not only the application of AI techniques to SE problems but also the application of SE techniques to AI problems. RAISE not only strengthens the AI- and-SE community but also continues to develop a roadmap of strategic research directions for AI and SE.","","","10.1109/ICSE.2015.320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203143","","Artificial intelligence;Conferences;Software engineering;Electronic mail;Software;Computer science;Robots","","","","","","","","","","IEEE","IEEE Conferences"
"3rd International Workshop on Software Engineering for Systems-of-Systems (SESoS 2015)","F. Oquendo; P. Avgeriou; C. E. Cuesta; K. Drira; E. Y. Nakagawa; J. C. Maldonado; A. Zisman","NA; NA; NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1011","1012","Systems-of-Systems (SoS) refer to a new class of software-intensive systems, where their constituent systems work cooperatively in order to fulfill specific missions. Characterized by managerial and operational independence, geographic distribution, evolutionary development, and emergent behavior, SoS bring substantial challenges to the software engineering area. SESoS 2015, held in Florence, Italy, on May 17, 2015, as a joint workshop of the 37th International Conference on Software Engineering (ICSE), provided a forum to exchange ideas and experiences, analyze current research and development issues, discuss promising solutions, and to explore inspiring visions for the future of Software Engineering (SE) for SoS.","","","10.1109/ICSE.2015.327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203153","System-of-Systems;Software Engineering;Ultra-large Scale Systems","Software engineering;Conferences;Electronic mail;Committees;Software;Research and development;Vehicle dynamics","","","","","5","","","","","IEEE","IEEE Conferences"
"1st International Workshop on TEchnical and LEgal aspects of data pRIvacy and Security (TELERISE 2015)","I. Matteucci; P. Mori; M. Petrocchi","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1015","1016","This paper is the report on the 1st International Workshop on TEchnical and LEgal aspects of data pRIvacy and SEcurity (TELERISE 2015) at the 37th International Conference on Software Engineering (ICSE 2015). TELERISE investigates privacy and security issues in data sharing from a technical and legal perspective. Keynote speech as well as selected papers presented at the event fit the topics of the workshop. This report gives the rationale of TELERISE and it provides a provisional program.","","","10.1109/ICSE.2015.329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203155","","Conferences;Law;Security;Data privacy;Privacy;Organizations","","","","","3","","","","","IEEE","IEEE Conferences"
"[Journal First] Model Comprehension for Security Risk Assessment: An Empirical Comparison of Tabular vs. Graphical Representations","K. Labunets; F. Massacci; F. Paci; S. Marczak; F. M. de Oliveira","Delft Univ. of Technol., Delft, Netherlands; Univ. of Trento, Trento, Italy; Univ. of Southampton, Southampton, UK; Pontificia Univ. Catolica do Rio Grande do Sul, Rio Grande, Brazil; Pontificia Univ. Catolica do Rio Grande do Sul, Rio Grande, Brazil","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","395","395","Context: Tabular and graphical representations are used to communicate security risk assessments for IT systems. However, there is no consensus on which type of representation better supports the comprehension of risks (such as the relationships between threats, vulnerabilities and security controls). Vessey's cognitive fit theory predicts that graphs should be better because they capture spatial relationships. Method: We report the results of two studies performed in two countries with 69 and 83 participants respectively, in which we assessed the effectiveness of tabular and graphical representations concerning the extraction of correct information about security risks. Results: Participants who applied tabular risk models gave more precise and complete answers to the comprehension questions when requested to find simple and complex information about threats, vulnerabilities, or other elements of the risk models. Conclusions: Our findings can be explained by Vessey's cognitive fit theory as tabular models implicitly capture elementary linear spatial relationships. Interest for ICSE: It is almost taken for granted in Software Engineering that graphical-, diagram-based models are ""the"" way to go (e.g., the SE Body of Knowledge). This paper provides some experimental-based doubts that this might not always be the case. It will provide an interesting debate that might ripple to traditional requirements and design notations outside security.","","","10.1145/3180155.3182511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453097","Empirical Study;Security Risk Assessment;Risk Modeling;Comprehensibility;Cognitive Fit","Security;Task analysis;Unified modeling language;Software engineering;Risk management;Data mining;Complexity theory","risk analysis;risk management;security of data;software engineering;solid modelling","comprehension questions;Vessey's cognitive fit theory;elementary linear spatial relationships;diagram-based models;security risk assessment;graphical representations;security controls;security risks;tabular risk models;model comprehension;Software Engineering","","","","","","","","IEEE","IEEE Conferences"
"Global-Aware Recommendations for Repairing Violations in Exception Handling","E. A. Barbosa; A. Garcia","Digital Metropolis Inst., UFRN, Natal, Brazil; Inf. Dept., PUC-Rio, Rio de Janeiro, Brazil","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","858","858","This paper presents an extended abstract incorporated as a journalrst paper into the ICSE'18 program.","","","10.1145/3180155.3182539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453159","Exception Handling;Recommender system;Software maintenance","Maintenance engineering;Software engineering;Software maintenance;Java;Tools;Recommender systems","exception handling;object-oriented programming;program diagnostics;recommender systems","global-aware recommendations;repairing violations;journalrst paper;exception handling","","1","","","","","","IEEE","IEEE Conferences"
"Poster: Static Analysis of Concurrent Higher-Order Programs","Q. Stievenart; J. Nicolay; W. De Meuter; C. De Roover","Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium; Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium; Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium; Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","821","822","Few static analyses support concurrent higher-order programs. Tools for detecting concurrency bugs such as deadlocks and race conditions are nonetheless invaluable to developers. Concurrency can be implemented using a variety of models, each supported by different synchronization primitives. Using this poster, we present an approach for analyzing concurrent higher-order programs in a precise manner through abstract interpretation. We instantiate the approach for two static analyses that are capable of detecting deadlocks and race conditions in programs that rely either on compare-and-swap (cas), or on conventional locks for synchronization. We observe few false positives and false negatives on a corpus of small concurrent programs, with better results for the lock-based analyses. We also observe that these programs lead to a smaller state space to be explored by the analyses. Our results show that the choice of synchronization primitives supported by an abstract interpreter has an important impact on the complexity of the static analyses performed with this abstract interpreter.","","","10.1109/ICSE.2015.265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203086","static analysis;abstract interpretation;concurrency;higher-order","System recovery;Concurrent computing;Synchronization;Model checking;Programming;Explosions;Adaptation models","concurrency (computers);program diagnostics;synchronisation","static concurrent higher-order program analysis;concurrency bug detection;synchronization primitives;race conditions;deadlock detection;compare-and-swap;lock-based analysis;abstract interpreter","","","9","","","","","IEEE","IEEE Conferences"
"Poster: Model-based Run-time Variability Resolution for Robotic Applications","L. Gherardi; N. Hochgeschwender","Inst. for Dynamic Syst. & Control, ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., Bonn-Rhein-Sieg Univ., St. Augustin, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","829","830","In this paper we present our ongoing work on Robotics Run-time Adaptation (RRA). RRA is a model-driven approach that addresses robotics runtime adaptation by modeling and resolving run-time variability of robotic applications.","","","10.1109/ICSE.2015.269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203090","Variability Resolution;Runtime Adaptation;Model-based Approach","Adaptation models;Robots;Context;Computer architecture;Context modeling;Engines;Software architecture","robots","model-based run-time variability resolution;robotic applications;robotics run-time adaptation;RRA;model-driven approach","","1","4","","","","","IEEE","IEEE Conferences"
"Workshop on Applications of Human Error Research to Improve Software Engineering (WAHESE 2015)","G. S. Walia; J. C. Caver; G. Bradshaw","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1019","1020","Advances in the psychological understanding of the origins and manifestations of human error have led to tremendous reductions in errors in fields such as medicine, aviation, and nuclear power plants. This workshop is intended to foster a better understanding of software engineering errors and how a psychological perspective can reduce them, improving software quality and reducing maintenance costs. The workshop goal is to develop a body of knowledge that can advance our understanding of the psychological processes (of human reasoning, planning, and problem solving) and how they fail during the software development. Applying human error research to software quality improvement will provide insights to the cognitive aspects of software development. The workshop will include interactive session to discuss common themes of errors in different fields, and structure software error information to detect and prevent software errors during the development.","","","10.1109/ICSE.2015.353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203157","","Conferences;Psychology;Software engineering;Software quality;Taxonomy;Accidents","","","","","15","","","","","IEEE","IEEE Conferences"
"Analysis of Android Inter-App Security Vulnerabilities Using COVERT","A. Sadeghi; H. Bagheri; S. Malek","Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA; Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA; Dept. of Comput. Sci., George Mason Univ., Fairfax, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","725","728","The state-of-the-art in securing mobile software systems are substantially intended to detect and mitigate vulnerabilities in a single app, but fail to identify vulnerabilities that arise due to the interaction of multiple apps, such as collusion attacks and privilege escalation chaining, shown to be quite common in the apps on the market. This paper demonstrates COVERT, a novel approach and accompanying tool-suite that relies on a hybrid static analysis and lightweight formal analysis technique to enable compositional security assessment of complex software. Through static analysis of Android application packages, it extracts relevant security specifications in an analyzable formal specification language, and checks them as a whole for inter-app vulnerabilities. To our knowledge, COVERT is the first formally-precise analysis tool for automated compositional analysis of Android apps. Our study of hundreds of Android apps revealed dozens of inter-app vulnerabilities, many of which were previously unknown.","","","10.1109/ICSE.2015.233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203053","","Androids;Humanoid robots;Security;Analytical models;Smart phones;Metals;Mobile communication","Android (operating system);formal specification;mobile computing;program diagnostics;security of data;specification languages","Android inter-app security vulnerability analysis;COVERT approach;mobile software systems;collusion attacks;privilege escalation chaining;hybrid static analysis;lightweight formal analysis technique;complex software compositional security assessment;Android application package static analysis;formal specification language;formally-precise analysis tool","","16","14","","","","","IEEE","IEEE Conferences"
"Exploration, Analysis, and Manipulation of¬†¬†Source Code Using srcML","J. I. Maletic; M. L. Collard","Dept. of Comput. Sci., Kent State Univ., Kent, OH, USA; Dept. of Comput. Sci., Univ. of Akron, Akron, OH, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","951","952","This technology briefing is intended for those interested in constructing custom software analysis and manipulation tools to support research or commercial applications. srcML (srcML.org) is an infrastructure consisting of an XML representation for C/C++/C#/Java source code along with efficient parsing technology to convert source code to-and-from the srcML format. The briefing describes srcML, the toolkit, and the application of XPath and XSLT to query and modify source code. Additionally, a hands-on tutorial of how to use srcML and XML tools to construct custom analysis and manipulation tools will be conducted.","","","10.1109/ICSE.2015.302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203124","srcML;static program analysis;program transformation;XML","Software;XML;Conferences;Software engineering;Tutorials;Robustness","C++ language;Java;program compilers;program diagnostics;source code (software);XML","source code exploration;srcML;source code analysis;source code manipulation;custom software analysis;manipulation tools;XML representation;C-C++-C#-Java source code;parsing technology;XPath;XSLT;custom analysis","","2","4","","","","","IEEE","IEEE Conferences"
"Poster: MAPP: The Berkeley Model and Algorithm Prototyping Platform","T. Wang; K. Aadithya; B. Wu; J. Roychowdhury","EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA; EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA; EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA; EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","825","826","We describe the Berkeley Model and Algorithm Prototyping Platform (MAPP), designed to facilitate experimentation with numerical algorithms and models. MAPP is written entirely in MATLAB and is available as open source under the GNU GPL.","","","10.1109/ICSE.2015.267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203088","","Mathematical model;Algorithm design and analysis;Integrated circuit modeling;Object oriented modeling;Numerical models;MATLAB;SPICE","graphical user interfaces;public domain software;SPICE","model-and-algorithm prototyping platform;numerical algorithms;MAPP;Matlab;open source software;GNU GPL;SPICE","","1","7","","","","","IEEE","IEEE Conferences"
"Poster: Software Development Risk Management: Using Machine Learning for Generating Risk Prompts","H. R. Joseph","Dept. of Electr. Eng., Indian Inst. of Technol. Madras, Chennai, India","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","833","834","Software risk management is a critical component of software development management. Due to the magnitude of potential losses, risk identification and mitigation early on become paramount. Lists containing hundreds of possible risk prompts are available both in academic literature as well as in practice. Given the large number of risks documented, scanning the lists for risks and pinning down relevant risks, though comprehensive, becomes impractical. In this work, a machine learning algorithm is developed to generate risk prompts, based on software project characteristics and other factors. The work also explores the utility of post-classification tagging of risks.","","","10.1109/ICSE.2015.271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203092","Software risk;software management;machine learning;risk prompts","Software;Taxonomy;Tagging;Neural networks;Machine learning algorithms;Risk management;Distance measurement","identification technology;learning (artificial intelligence);risk management;software development management","software risk management;software development management;machine learning;risk identification;risk mitigation;post-classification tagging","","","10","","","","","IEEE","IEEE Conferences"
"Correctness and Relative Correctness","N. Diallo; W. Ghardallou; A. Mili","New Jersey Inst. of Technol., Newark, NJ, USA; Fac. of Sci. of Tunis, Univ. of Tunis El Manar, Tunis, Tunisia; New Jersey Inst. of Technol., Newark, NJ, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","591","594","In the process of trying to define what is a software fault, we have found that to formally define software faults we need to introduce the concept of relative correctness, i.e. the property of a program to be more-correct than another with respect to a given specification. A feature of a program is a fault (for a given specification)only because there exists an alternative to it that would make the program more-correct with respect to the specification.In this paper, we explore applications of the concept of relative correctness in program testing, program repair, and program design.Specifically, we argue that in many situations of software testing, fault removal and program repair, testing for relative correctness rather than absolute correctness leads to clearer conclusions and better outcomes. Also, we find that designing programs by stepwise correctness-enhancing transformations rather than by stepwise correctness-preserving refinements leads to simpler programs and is more tolerant of designer mistakes.","","","10.1109/ICSE.2015.200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203020","","Maintenance engineering;Software;Semantics;Generators;Software engineering;Software testing","formal specification;program testing;software fault tolerance;software maintenance","relative correctness;software fault;formal specification;program testing;program repair;program design","","3","13","","","","","IEEE","IEEE Conferences"
"Load Testing Large-Scale Software Systems","Z. M. J. Jiang","Dept. of Electr. Eng. & Comput. Sci., York Univ., Toronto, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","955","956","Large-scale software systems (e.g., Amazon and Dropbox) must be load tested to ensure that they can service thousands or millions of concurrent requests every day. In this technical briefing, we will describe the state of research and practices in the area of load testing. We will focus on the techniques used in the three phases of a load test: (1) designing a load test, (2) executing a load test, and (3) analyzing the results of a load test. This technical briefing is targeted at load testing practitioners and software engineering researchers interested in testing and analyzing the behavior of large-scale software systems.","","","10.1109/ICSE.2015.304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203126","load testing;software testing;performance;scalability","Testing;Software systems;Software engineering;Conferences;Computer science;Monitoring","program testing","Dropbox;Amazon;large-scale software system load testing","","","12","","","","","IEEE","IEEE Conferences"
"1st International Workshop on Big Data Software Engineering (BIGDSE 2015)","L. Baresi; T. Menzies; A. Metzger; T. Zimmermann","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","965","966","Big Data is about extracting valuable information from data in order to use it in intelligent ways such as to revolutionize decision-making in businesses, science and society. BIGDSE 2015 discusses the link between Big Data and software engineering and critically looks into issues such as cost-benefit of big data.","","","10.1109/ICSE.2015.308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203130","","Big data;Software engineering;Data mining;Conferences;Software systems;Market research","","","","","2","","","","","IEEE","IEEE Conferences"
"Software Engineering in Ferrari F1","C. Silenzi","Scuderia, Ferrari, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","3","3","Summary form only given. The software and hardware development in Ferrari F1 is characterized by a very short cycle time. Typically during the in-season development, the fixes and new developments need to be addressed in few days, in order to be ready for the following race. At the same time the hardware, like new electronic control units or new devices need to be developed from one year to the other. In this scenario the validation procedures are very critical, because of the need to achieve the same results in a shorter time.","","","10.1109/ICSE.2015.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194555","","Software;Hardware;Software engineering;Conferences;Biographies;Inverters;Batteries","software engineering","software engineering;Ferrari F1;software development;hardware development;in-season development;electronic control units","","1","","","","","","IEEE","IEEE Conferences"
"JRebel.Android: Runtime Class- and Resource Reloading for Android","R. Raudj√§rv; A. R. Gregersen","R&D Dept., Zeroturnaround OU, Tartu, Estonia; R&D Dept., Zeroturnaround OU, Tartu, Estonia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","741","744","Developers writing Android applications suffer from a dreadful redeploy time every time they need to test changes to the source code. While runtime class reloading systems are widely used for the underlying programming language, Java, there is currently no support for reloading code on the Android platform. This paper presents a new tool, JRebel.Android that enables automatic runtime class- and resource reloading capabilities for Android. The target of this paper is the Android developer as well as the researcher for which dynamic updating capabilities on mobile devices can serve as a basic building block within areas such as runtime maintenance or self-adaptive systems. JRebel.Android is able to reload classes in much less than 1 second, saving more than 91% of the total redeploy time for small apps, more than 95% for medium size apps, and even more for larger apps.","","","10.1109/ICSE.2015.337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203057","Class Reloading;Android;Dynamic Software Updating;Resource Reloading","Androids;Humanoid robots;Java;Runtime;Standards;Google;Instruments","Android (operating system);Java;software tools;source code (software)","JRebel.Android tool;runtime class-resource reloading system;source code;programming language;Java;dynamic updating capability;mobile devices;self-adaptive systems;runtime maintenance","","","11","","","","","IEEE","IEEE Conferences"
"Fast and Precise Statistical Code Completion","P. Roos","ETH Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","757","759","The main problem we try to solve is API code completion which is both precise and works in real-time. We describe an efficient implementation of an N-gram language model combined with several smoothing methods and a completion algorithm based on beam search. We show that our system is both fast and precise using a thorough experimental evaluation. With optimal parameters we are able to find completions in milliseconds and the desired completion is in the top 3 suggestions in 89% of the time.","","","10.1109/ICSE.2015.240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203061","Statistical Language Models;Code Completion;Synthesis;APIs","Smoothing methods;Runtime;Computational modeling;Real-time systems;Libraries;Probability;Semantics","application program interfaces;programming languages;statistical analysis","statistical code completion;API code completion;N-gram language model;smoothing methods;completion algorithm;beam search;experimental evaluation","","","16","","","","","IEEE","IEEE Conferences"
"The Art and Science of Analyzing Software Data; Quantitative Methods","T. Menzies; L. Minku; F. Peters","Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Comptuer Sci., Univ. of Birmingham, Birmingham, UK; Lero, Univ. of Limerick, Limerick, Ireland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","959","960","Using the tools of quantitative data science, software engineers that can predict useful information on new projects based on past projects. This tutorial reflects on the state-of-the-art in quantitative reasoning in this important field. This tutorial discusses the following: (a) when local data is scarce, we show how to adapt data from other organizations to local problems; (b) when working with data of dubious quality, we show how to prune spurious information; (c) when data or models seem too complex, we show how to simplify data mining results; (d) when the world changes, and old models need to be updated, we show how to handle those updates; (e) when the effect is too complex for one model, we show to how reason over ensembles.","","","10.1109/ICSE.2015.306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203128","","Software;Software engineering;Computer science;Tutorials;Data mining;Data models;Art","data analysis;data mining;software quality","software data analysis;quantitative methods;quantitative data science tools;software engineers;data mining","","2","4","","","","","IEEE","IEEE Conferences"
"8th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE 2015)","A. Begel; R. Prikladnicki; Y. Dittrich; C. R. B. d. Souza; A. Sarma; S. Athavale","NA; NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","969","970","Software is created for and with a wide range of stakeholders, from customers to management, from value-added providers to customer service personnel. These stakeholders work with teams of software engineers to develop and evolve software systems that support their activities. All of these people and their interactions are central to software development. Thus, it is crucial to investigate the dynamic and frequently changing Cooperative and Human Aspects of Software Engineering (CHASE), both before and after deployment, in order to understand current software practices, processes, and tools. In turn, this enables us to design tools and support mechanisms that improve software creation, software maintenance, and customer communication.Researchers and practitioners have long recognized the need to investigate these aspects, however, their articles are scattered across conferences and communities. This workshop will provide a unified forum for discussing high quality research studies, models, methods, and tools for human and cooperative aspects of software engineering. This will be the 8th in a series of workshops, which continue to be a meeting place for the academic, industrial, and practitioner communities interested in this area, and will give opportunities to present and discuss works-in-progress.","","","10.1109/ICSE.2015.309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203132","Management;Performance;Human Factors","Software;Software engineering;Conferences;Stakeholders;Teamwork;Committees","","","","","","","","","","IEEE","IEEE Conferences"
"Smart Programming Playgrounds","R. Padhye; P. Dhoolia; S. Mani; V. S. Sinha","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","607","610","Modern IDEs contain sophisticated components for inferring missing types, correcting bad syntax and completing partial expressions in code, but they are limited to the context that is explicitly defined in a project's configuration. These tools are ill-suited for quick prototyping of incomplete code snippets, such as those found on the Web in Q&A forums or walk-through tutorials, since such code snippets often assume the availability of external dependencies and may even contain implicit references to an execution environment that provides data or compute services. We propose an architecture for smart programming playgrounds that can facilitate rapid prototyping of incomplete code snippets through a semi-automatic context resolution that involves identifying static dependencies, provisioning external resources on the cloud and injecting resource bindings to handles in the original code fragment. Such a system could be potentially useful in a range of different scenarios, from sharing code snippets on the Web to experimenting with new ideas during traditional software development.","","","10.1109/ICSE.2015.204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203024","playgrounds;code snippets;dependency injection;cloud computing","Context;Databases;Programming;IEEE catalogs;Libraries;Graphical user interfaces;Engines","Internet;programming environments;software architecture;software prototyping","smart programming playgrounds;IDEs;incomplete code snippet prototyping;semiautomatic context resolution;cloud computing;code fragment;software development;integrated development environments","","","12","","","","","IEEE","IEEE Conferences"
"Mining Temporal Properties of Data Invariants","C. Lemieux","Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","751","753","System specifications are important in maintaining program correctness, detecting bugs, understanding systems and guiding test case generation. Often, these specifications are not explicitly written by developers. If we want to use them for analysis, we need to obtain them through other methods; for example, by mining them out of program behavior. Several tools exist to mine data invariants and temporal properties from program traces, but few examine the temporal relationships between data invariants. An example of this kind of relationship would be ""the return value of the method isFull? is false until the field size reaches the value capacity"". We propose a data-temporal property miner, Quarry, which mines Linear Temporal Logic (LTL) relations of arbitrary length and complexity between Daikon-style data invariants. We infer data invariants from systems using Daikon, recompose these data invariants into sequences, and mine temporal properties over these sequences. Our preliminary results suggest that this method may recover important system properties.","","","10.1109/ICSE.2015.238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203059","","Data mining;Software engineering;Conferences;Context;Software;Hardware;Instruments","computational complexity;data mining;program debugging;program verification;temporal logic","temporal property mining;data invariants;system specifications;program correctness;bug detection;test case generation;program behavior;program traces;isFull method;value capacity;data-temporal property miner;Quarry;linear temporal logic relation mining;LTL relation mining;Daikon-style data invariants;Daikon","","2","21","","","","","IEEE","IEEE Conferences"
"Enabling Testing of Android Apps","M. Linares-V√°squez","Coll. of William & Mary, Williamsburg, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","763","765","Existing approaches for automated testing of An- droid apps are designed to achieve different goals and exhibit some pros and cons that should be carefully considered by developers and testers. For instance, random testing (RT) provides a high ratio of infeasible inputs or events, and test cases generated with RT and systematic exploration-based testing (SEBT) are not representative of natural (i.e., real) application usage scenarios. In addition, collecting test scripts for automated testing is expensive. We address limitations of existing tools for GUI-based testing of Android apps in a novel hybrid approach called T+. Our approach is based on a novel framework, which is aimed at generating actionable test cases for different testing goals. The framework also enables GUI-based testing without expensive test scripts collection for the stakeholders.","","","10.1109/ICSE.2015.242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203063","","Testing;Androids;Humanoid robots;Graphical user interfaces;Vocabulary;Software engineering;Systematics","Android (operating system);graphical user interfaces;program testing","testing goal;actionable test case generation;T+ approach;GUI-based testing;automated testing;test script collection;natural application usage scenario;SEBT;systematic exploration-based testing;random testing;Android apps testing","","6","14","","","","","IEEE","IEEE Conferences"
"2nd International Workshop on Context for Software Development (CSD 2015)","K. Blincoe; D. Damian; G. Valetto; J. D. Herbsleb","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","973","974","The goal of this one-day workshop is to bring together researchers interested in techniques and tools that leverage context information that accumulates around development activities. Developers continuously make use of context to make decisions, coordinate their work, understand the purpose behind their tasks, and understand how their tasks fit with the rest of the project. However, there is little research on defining what context is, how we can model it, and how we can use those models to better support software development at large. This workshop brings together scholars interested in identifying, gathering and modelling context information in software development, as well as discussing its applications.","","","10.1109/ICSE.2015.311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203134","","Context;Software;Conferences;Software engineering;Context modeling;Computer science;Committees","","","","","3","","","","","IEEE","IEEE Conferences"
"Code Repurposing as an Assessment Tool","J. Sant","Fac. of Appl. Sci. & Technol., Sheridan Coll., Oakville, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","295","298","Code repurposing is often used for system development and to learn both APIs and techniques. Repurposing code typically requires that you understand the code first. This makes it an excellent candidate as an assessment tool in computer science and software engineering education. This technique might have a special application in combatting plagiarism. This paper discusses experiences using code repurposing as an assessment tool in different courses and with different sections.","","","10.1109/ICSE.2015.158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202975","Assessment;Code Repurposing;Plagiarism Softwaredevelopment;Cloze Testing","Plagiarism;Standards;Software;Programming profession;Education;Joints","computer science education;programming","code repurposing;system development;API;application program interface;code understanding;computer science education;software engineering education;plagiarism","","2","7","","","","","IEEE","IEEE Conferences"
"Qualitative Analysis of Knowledge Transfer in Pair Programming","F. Zieris","Freie Univ. Berlin, Berlin, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","855","858","Knowledge transfer in the context of pair programming is both a desired effect and a necessary precondition. There is no detailed understanding yet of how effective and efficient knowledge transfer in this particular context actually works. My qualitative research is concerned with the analysis of professional software developer's sessions to capture their specific knowledge transfer skill in the form of comprehensible, relevant, and practical patterns.","","","10.1109/ICSE.2015.277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203098","","Programming profession;Knowledge transfer;Software;Software engineering;Context;Propulsion","knowledge management;professional aspects;software prototyping","qualitative analysis;pair programming;professional software developer session analysis;knowledge transfer skill","","1","16","","","","","IEEE","IEEE Conferences"
"Evolution-Aware Monitoring-Oriented Programming","O. Legunsen; D. Marinov; G. Rosu","Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","615","618","Monitoring-Oriented Programming (MOP) helps develop more reliable software by means of monitoring against formal specifications. While MOP showed promising results, all prior research has focused on checking a single version of software. We propose to extend MOP to support multiple software versions and thus be more relevant in the context of rapid software evolution. Our approach, called eMOP, is inspired by regression test selection -- a well studied, evolution-centered technique. The key idea in eMOP is to monitor only the parts of code that changed between versions. We illustrate eMOP by means of a running example, and show the results of preliminary experiments. eMOP opens up a new line of research on MOP -- it can significantly improve usability and performance when applied across multiple versions of software and is complementary to algorithmic MOP advances on a single version.","","","10.1109/ICSE.2015.206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203026","Runtime Verification;Regression Testing;Runtime Monitoring;Monitoring-Oriented Programming","Monitoring;Runtime;Testing;Open source software;Java;Programming","configuration management;formal specification;program testing;program verification;software maintenance;software prototyping;software reliability","evolution-aware monitoring-oriented programming;software reliability;formal specification;software checking;software versions;rapid software evolution;eMOP;regression test selection;evolution-centered technique;code monitoring","","4","23","","","","","IEEE","IEEE Conferences"
"Commit Bubbles","T. Barik; K. Lubick; E. Murphy-Hill","ABB Corp. Res., Raleigh, NC, USA; North Carolina State Univ., Raleigh, NC, USA; North Carolina State Univ., Raleigh, NC, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","631","634","Developers who use version control are expected to produce systematic commit histories that show well-defined steps with logical forward progress. Existing version control tools assume that developers also write code systematically. Unfortunately, the process by which developers write source code is often evolutionary, or as-needed, rather than systematic. Our contribution is a fragment-oriented concept called Commit Bubbles that will allow developers to construct systematic commit histories that adhere to version control best practices with less cognitive effort, and in a way that integrates with their as-needed coding workflows.","","","10.1109/ICSE.2015.210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203030","version control;integrated development environments;software maintenance;software tools","History;Systematics;Context;Encoding;Switches;Best practices;Software","configuration management;software tools;source code (software)","commit bubbles;systematic commit histories;version control tools;source code;fragment-oriented concept;as-needed coding workflows","","3","22","","","","","IEEE","IEEE Conferences"
"Towards Model Driven Architecture and Analysis of System of Systems Access Control","J. El Hachem","LIUPPA Lab., Univ. of PAU & Pays Adour, Mont-de-Marsan, France","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","867","870","Nowadays there is growing awareness of the importance of Systems of Systems (SoS) which are large-scale systems composed of complex systems. SoS possess specific properties when compared with monolithic complex systems, in particular: operational independence, managerial independence, evolutionary development, emergent behavior and geographic distribution. One of the current main challenges is the impact of these properties on SoS security modeling and analysis. In this research proposal, we introduce a new method incorporating a process, a language and a software architectural tool to model, analyze and predict security architectural alternatives of SoS. Thus security will be taken into account as soon as possible in the life cycle of the SoS, making it less expensive.","","","10.1109/ICSE.2015.280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203101","Model Driven Engineering;Maritime Security;Architectural Alternatives;Simulation.","Security;Systems of systems;Unified modeling language;Computer architecture;Medical services;Conferences;Analytical models","authorisation;marine safety;safety-critical software;software architecture;systems engineering","model driven architecture;system-of-systems access control analysis;large-scale systems;complex systems;operational independence;managerial independence;evolutionary development;emergent behavior;geographic distribution;SoS security modeling;SoS security analysis;software architectural tool;SoS life cycle","","3","19","","","","","IEEE","IEEE Conferences"
"Textual Analysis for Code Smell Detection","F. Palomba","Dept. of Manage. & Inf. Technol., Univ. of Salerno, Fisciano, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","769","771","The negative impact of smells on the quality of a software systems has been empirical investigated in several studies. This has recalled the need to have approaches for the identification and the removal of smells. While approaches to remove smells have investigated the use of both structural and conceptual information extracted from source code, approaches to identify smells are based on structural information only. In this paper, we bridge the gap analyzing to what extent conceptual information, extracted using textual analysis techniques, can be used to identify smells in source code. The proposed textual-based approach for detecting smells in source code, coined as TACO (Textual Analysis for Code smell detectiOn), has been instantiated for detecting the Long Method smell and has been evaluated on three Java open source projects. The results indicate that TACO is able to detect between 50% and 77% of the smell instances with a precision ranging between 63% and 67%. In addition, the results show that TACO identifies smells that are not identified by approaches based on solely structural information.","","","10.1109/ICSE.2015.244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203065","","Software engineering;Conferences;Accuracy;Data mining;Software systems;Societies","information retrieval;Java","software systems;structural information;textual analysis techniques;TACO;textual analysis for code smell detection;long method smell;Java open source projects","","7","32","","","","","IEEE","IEEE Conferences"
"7th International Workshop on Modeling in Software Engineering (MiSE 2015)","J. Gray; M. Chechik; V. Kulkarni; R. F. Paige","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","985","986","Models are an important tool in conquering the increasing complexity of modern software systems. Key industries are strategically directing their development environments towards more extensive use of modeling techniques. MiSE 2015 aimed to understand, through critical analysis, the current and future uses of models in the engineering of software-intensive systems. The MiSE workshop series has proven to be an effective forum for discussing modeling techniques from both the MDE and software engineering perspectives. An important goal of this workshop is to foster exchange between these two communities. In 2015 the focus was on considering the current state of tool support and the challenges that need to be addressed to improve the maturity of tools. There was also analysis of successful applications of modeling techniques in specific application domains, with attempts to determine how the participants' experiences can be carried over to other domains.","","","10.1109/ICSE.2015.317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203140","modeling;quality;software tools","Conferences;Analytical models;Software;Adaptation models;Software engineering;Electronic mail","","","","","","","","","","IEEE","IEEE Conferences"
"Optimising Energy Consumption of Design Patterns","A. Noureddine; A. Rajan","Sch. of Inf., Univ. of Edinburgh, Edinburgh, UK; Sch. of Inf., Univ. of Edinburgh, Edinburgh, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","623","626","Software design patterns are widely used in software engineering to enhance productivity and maintainability.However, recent empirical studies revealed the high energy overhead in these patterns. Our vision is to automatically detect and transform design patterns during compilation for better energy efficiency without impacting existing coding practices. In this paper, we propose compiler transformations for two design patterns, Observer and Decorator, and perform an initial evaluation of their energy efficiency.","","","10.1109/ICSE.2015.208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203028","","Observers;Energy consumption;Optimization;Software;Computers;Transforms;Software engineering","power aware computing;program compilers;software maintenance","energy consumption optimisation;software design patterns;software engineering;maintainability;compilation;energy efficiency;coding practices;compiler transformations","","15","20","","","","","IEEE","IEEE Conferences"
"Safe Evolution Patterns for Software Product Lines","N. Dintzner","Software Eng. Res. Group, Delft Univ. of Technol., Delft, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","875","878","Despite a global recognition of the problem, and massive investment from researchers and practitioners, the evolution of complex software systems is still a major challenge for today's architects and developers. In the context of product lines, or highly configurable systems, variability in the implementation and design makes many of the pre-existing challenges even more difficult to tackle. Many approaches and tools have been designed, but developers still miss the tools and methods enabling safe evolution of complex, variable systems. In this paper, we present our research plans toward this goal: making the evolution of software product lines safer. We show, by use of two concrete examples of changes that occurred in Linux, that simple heuristics can be applied to facilitate change comprehension and avoid common mistakes, without relying on heavy tooling. Based on those observations, we present the steps we intend to take to build a framework to regroup and classify changes, run simple checks, and eventually increase the quality of code deliveries affecting the variability model, mapping and implementation of software product lines.","","","10.1109/ICSE.2015.282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203103","Product line;evolution;variability","Linux;Kernel;Frequency modulation;Software product lines;Context;Conferences;Feature extraction","software maintenance;software product lines;software quality","evolution patterns;software product lines;software systems evolution;Linux;change comprehension;code delivery quality;variability model","","","17","","","","","IEEE","IEEE Conferences"
"Understanding Conflicts Arising from Collaborative Development","P. Accioly","Inf. Center, Fed. Univ. of Pernambuco, Recife, Brazil","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","775","777","When working in a collaborative development environment, developers implement tasks separately. Consequently, during the integration process, one might have to deal with conflicting changes. Previous studies indicate that conflicts occur frequently and impair developers' productivity. Such evidence motivates the development of tools that try to tackle this problem. However, despite the existing evidence, there are still many unanswered questions. The goal of this research is to investigate conflict characteristics in practice through empirical studies and use this body of knowledge to improve strategies that support software developers working collaboratively.","","","10.1109/ICSE.2015.246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203067","Collaborative Software Development;Conflicts;Empirical Studies","Collaboration;Software engineering;Syntactics;Crystals;Semantics;Conferences;Productivity","groupware;software engineering","collaborative development;conflict characteristics;software developers","","1","8","","","","","IEEE","IEEE Conferences"
"Post-Dominator Analysis for Precisely Handling Implicit Flows","A. Bichhawat","Saarland Univ., Saarbrucken, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","787","789","Most web applications today use JavaScript for including third-party scripts, advertisements etc., which pose a major security threat in the form of confidentiality and integrity violations. Dynamic information flow control helps address this issue of information stealing. Most of the approaches over-approximate when unstructured control flow comes into picture, thereby raising a lot of false alarms. We utilize the post-dominator analysis technique to determine the context of the program at a given point and prove that this approach is the most precise technique to handle implicit flows.","","","10.1109/ICSE.2015.250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203071","","Security;Context;Conferences;Computer languages;Software engineering;Lattices;Programmable logic arrays","authoring languages;Java;program diagnostics;security of data","JavaScript;security threat;Web applications;integrity violations;confidentiality violations;dynamic information flow control;unstructured control flow;post-dominator analysis technique;implicit flow handling","","","13","","","","","IEEE","IEEE Conferences"
"4th International Workshop on Green and Sustainable Software (GREENS 2015)","M. Morisio; P. Lago; N. Meyer; H. A. M√ºller; G. Scanniello","NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","981","982","Engineering green software-intensive systems is critical in our drive towards a sustainable, smarter planet. The goal of green software engineering is to apply green principles to the design and operation of software-intensive systems. Green and self-greening software systems have tremendous potential to decrease energy consumption. Moreover, enterprise software can and should be re-thought to address sustainability issues using innovative business models, processes, and incentives. Monitoring and measuring the greenness of software is critical towards the notion of sustainable and green software. Demonstrating improvement is paramount for users to achieve and affect change. Thus, the theme of GREENS 2015 is Towards a Green Software Body of Knowledge. The GREENS workshop series brings together researchers and practitioners to discuss both the state-of-the-art and state-of-the-practice in green software, including novel ideas, research challenges, methods, experiences, and tools to support the engineering of sustainable and energy efficient software systems.","","","10.1109/ICSE.2015.315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203138","Green software engineering;green design;key green indicators (KGIs);green monitoring;green adaptation;smart green sensors and actuators;self-greening;energy efficiency;sustainability;green scheduling;green computing;green IT","Green products;Software engineering;Conferences;Industries;Software systems;Energy consumption","","","","","","","","","","IEEE","IEEE Conferences"
"5th International Workshop on Product LinE Approaches in Software Engineering PLE for a Sustainable Society (PLEASE 2015)","J. Rubin; G. Botterweck; A. Pleuss; D. Weiss","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","989","990","This paper summarizes the motivation, objectives, and format of the 5th International Workshop on Product LinE Approaches in Software Engineering (PLEASE15). The main goal of the PLEASE workshop series is to encourage and promote the adoption of Software Product Line Engineering. This year's edition focuses on the link between software product line engineering (SPLE) and new challenges posed by emerging societal trends. Towards this end, we invited reports on (1) opportunities posed by societal challenges for SPLE research and practice and (2) concrete solutions exemplifying application of SPLE techniques to societal challenges.","","","10.1109/ICSE.2015.319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203142","","Conferences;Software product lines;Software;Committees;Electronic mail;Concrete","","","","","5","","","","","IEEE","IEEE Conferences"
"Towards a Practical Security Analysis Methodology","A. v. d. Berghe","NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","883","886","The research community has proposed numerous techniques to perform security-oriented analyses based on a software design model. Such a formal analysis can provide precise security guarantees to the software designer, and facilitate the discovery of subtle flaws. Nevertheless, using such techniques in practice poses a big challenge for the average software designer, due to the narrow scope of each technique, the heterogeneous set of modelling languages that are required, and the analysis results that are often hard to interpret. Within the course of our research, we intend to provide practitioners with an integrated, easy-to-use modelling and analysis environment that enables them to work on a broad range of common security concerns without leaving the software design's level of abstraction.","","","10.1109/ICSE.2015.283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203105","","Unified modeling language;Analytical models;Cryptography;Vocabulary;Software design","security of data;software engineering","security analysis methodology;security-oriented analysis;software design model;formal analysis;security guarantee;modelling languages;software designabstraction level","","","24","","","","","IEEE","IEEE Conferences"
"Code Reviews Do Not Find Bugs. How the Current Code Review Best Practice Slows Us Down","J. Czerwonka; M. Greiler; J. Tilford","Microsoft Corp., Redmond, WA, USA; Microsoft Corp., Redmond, WA, USA; Microsoft Corp., Redmond, WA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","27","28","Because of its many uses and benefits, code reviews are a standard part of the modern software engineering workflow. Since they require involvement of people, code reviewing is often the longest part of the code integration activities. Using experience gained at Microsoft and with support of data, we posit (1) that code reviews often do not find functionality issues that should block a code submission; (2) that effective code reviews should be performed by people with specific set of skills; and (3) that the social aspect of code reviews cannot be ignored. We find that we need to be more sophisticated with our guidelines for the code review workflow. We show how our findings from code reviewing practice influence our code review tools at Microsoft. Finally, we assert that, due to its costs, code reviewing practice is a topic deserving to be better understood, systematized and applied to software engineering workflow with more precision than the best practice currently prescribes.","","","10.1109/ICSE.2015.131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202946","Software engineering workflow;code reviews;code integration","Software engineering;Software;Inspection;Best practices;Standards;Guidelines;Switches","program compilers;program diagnostics;software engineering","code review tools;code review workflow;code submission;Microsoft;code integration;software engineering workflow;code review best practice;bug finding","","15","6","","","","","IEEE","IEEE Conferences"
"Deep Representations for Software Engineering","M. White","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","781","783","Deep learning subsumes algorithms that automatically learn compositional representations. The ability of these models to generalize well has ushered in tremendous advances in many fields. We propose that software engineering (SE) research is a unique opportunity to use these transformative approaches. Our research examines applications of deep architectures such as recurrent neural networks and stacked restricted Boltzmann machines to SE tasks.","","","10.1109/ICSE.2015.248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203069","","Software;Computational modeling;Machine learning;Conferences;Software engineering;Computer architecture;Context","Boltzmann machines;learning (artificial intelligence);recurrent neural nets;software engineering","deep representation;software engineering;deep learning subsumes algorithm;compositional representation learning;transformative approach;deep architecture;recurrent neural networks;stacked restricted Boltzmann machine","","1","45","","","","","IEEE","IEEE Conferences"
"Poster: Static Detection of Configuration-Dependent Bugs in Configurable Software","J. Al-Kofahi; L. Guo; H. V. Nguyen; H. A. Nguyen; T. N. Nguyen","Electr. & Comput. Eng. Dept., Iowa State Univ., Ames, IA, USA; UPMC Univ. Paris 06, Paris, France; Electr. & Comput. Eng. Dept., Iowa State Univ., Ames, IA, USA; Electr. & Comput. Eng. Dept., Iowa State Univ., Ames, IA, USA; Electr. & Comput. Eng. Dept., Iowa State Univ., Ames, IA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","795","796","Configurable software systems enable developers to configure at compile time a single variant of the system to tailor it towards specific environments and features. Although traditional static analysis tools can assist developers in software development and maintenance, they can only run on a concrete configuration of a configurable software system. Thus, it is necessary to derive many configurations so that the configuration-specific parts of the source code can be checked. To avoid this tedious and error-prone process, we propose an approach to automatically derive a set of configurations that cover as many combinations of configuration-specific blocks of code or source files as possible. We represent a C program with CPP directives (e.g., #ifdef) with a CPP control-flow graph (CPP-CFG) in which CPP expressions are condition nodes and #ifdef blocks are statement nodes. We then explore possible paths on CPP-CFG with dynamic symbolic execution and depth-first search algorithms, and correspondingly, producing possible combinations of concrete blocks of C code, on which an existing static analysis tool can run. Our preliminary evaluation on a benchmark of configuration-dependent bugs on Linux shows that our approach can detect more bugs than a state-of-the-art tool.","","","10.1109/ICSE.2015.252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203073","configuration-dependent bugs;configurable software;dynamic symbolic execution","Computer bugs;Concrete;Linux;Heuristic algorithms;Kernel;Software systems","graph theory;program diagnostics;software maintenance;tree searching","static detection;configuration-dependent bugs;configurable software systems;static analysis tools;software development;software maintenance;configuration-specific blocks;C program;CPP directives;CPP control-flow graph;CPP-CFG;dynamic symbolic execution;depth-first search algorithms;Linux","","","4","","","","","IEEE","IEEE Conferences"
"Bootstrapping Mobile App Development","S. Barnett; R. Vasa; J. Grundy","Centre for Comput. & Eng. Software Syst. & Software Innovation Lab., Swinburne Univ. of Technol., Melbourne, VIC, Australia; Centre for Comput. & Eng. Software Syst. & Software Innovation Lab., Swinburne Univ. of Technol., Melbourne, VIC, Australia; Centre for Comput. & Eng. Software Syst. & Software Innovation Lab., Swinburne Univ. of Technol., Melbourne, VIC, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","657","660","Modern IDEs provide limited support for developers when starting a new data-driven mobile app. App developers are currently required to write copious amounts of boilerplate code, scripts, organise complex directories, and author actual functionality. Although this scenario is ripe for automation, current tools are yet to address it adequately. In this paper we present RAPPT, a tool that generates the scaffolding of a mobile app based on a high level description specified in a Domain Specific Language (DSL). We demonstrate the feasibility of our approach by an example case study and feedback from a professional development team. Demo at: https://www.youtube.com/watch?v=ffquVgBYpLM.","","","10.1109/ICSE.2015.216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203036","Model Driven Development;Code Generation;Mobile App Prototyping","Androids;Humanoid robots;Mobile communication;DSL;Motion pictures;Software engineering;Productivity","application program interfaces;mobile computing;specification languages","DSL;domain specific language;RAPPT tool;data-driven mobile app;integrated development environment;IDE;mobile application development","","10","11","","","","","IEEE","IEEE Conferences"
"scvRipper: Video Scraping Tool for Modeling Developers' Behavior Using Interaction Data","L. Bao; J. Li; Z. Xing; X. Wang; B. Zhou","Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","673","676","Screen-capture tool can record a user's interaction with software and application content as a stream of screenshots which is usually stored in certain video format. Researchers have used screen-captured videos to study the programming activities that the developers carry out. In these studies, screen-captured videos had to be manually transcribed to extract software usage and application content data for the study purpose. This paper presents a computer-vision based video scraping tool (called scvRipper) that can automatically transcribe a screen-captured video into time-series interaction data according to the analyst's need. This tool can address the increasing need for automatic behavioral data collection methods in the studies of human aspects of software engineering.","","","10.1109/ICSE.2015.220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203040","Video Scraping;Interaction Data","Software;Visualization;Data mining;Graphical user interfaces;Computational modeling;Instruments","computer vision;user interfaces;video signal processing","scvRipper;developer behavior modelling;interaction data;screen-capture tool;user interaction;screen-captured videos;computer-vision based video scraping tool;time-series interaction data;automatic behavioral data collection methods;software engineering;application content data","","3","16","","","","","IEEE","IEEE Conferences"
"Mining Patterns of Sensitive Data Usage","V. Avdiienko","Software Eng. Dept., Saarland Univ., Saarbrucken, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","891","894","When a user downloads an Android application from a market, she does not know much about its actual behavior. A brief description, a set of screenshots, and the list of permissions, which give a high level intuition of what the application might be doing, are all the user sees before installing and running the application on his device. These elements are not enough to decide whether the application is secure, and for sure they do not indicate whether it might violate the user's privacy by leaking some sensitive data. The goal of my thesis is to employ both static and dynamic taint analyses to gather information on how Android applications use sensitive data. The main hypothesis of this work is that malicious and benign mobile applications differ in how they use sensitive data, and consequently information flow can be used effectively to identify malware.","","","10.1109/ICSE.2015.285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203107","","Androids;Humanoid robots;Data mining;Malware;Software engineering;Medical services","Android (operating system);data mining;data privacy;invasive software;mobile computing;program diagnostics","pattern mining;sensitive data usage pattern;Android application;application security;user privacy;static taint analysis;dynamic taint analysis;mobile applications;malware identification","","1","14","","","","","IEEE","IEEE Conferences"
"A Declarative Foundation for Comprehensive History Querying","R. Stevens","Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","907","910","Researchers in the field of Mining Software Repositories perform studies about the evolution of software projects. To this end, they use the version control system storing the changes made to a single software project. Such studies are concerned with the source code characteristics in one particular revision, the commit data for that revision, how the code evolves over time and what concrete, fine-grained changes were applied to the source code between two revisions. Although tools exist to analyse an individual concern, scripts and manual work is required to combine these tools to perform a single experiment. We present a general-purpose history querying tool named QwalKeko that enables expressing these concerns in a single uniform language, and having them detected in a git repository. We have validated our work by means of replication studies as well as through MSR studies of our own.","","","10.1109/ICSE.2015.289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203111","declarative programming;program querying;history querying;mining software repositories","Software;History;Database languages;Libraries;Programming;Medical services;Java","configuration management;data mining;project management;software maintenance;source code (software)","declarative foundation;comprehensive history querying;software repository mining;software project evolution;version control system;source code characteristics;general-purpose history querying tool;QwalKeko;single uniform language;git repository","","3","19","","","","","IEEE","IEEE Conferences"
"Poster: Interactive and Collaborative Source Code Annotation","R. Suzuki","Univ. of Tokyo, Tokyo, Japan","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","799","800","Software documentation plays an important role in sharing the knowledge behind source code between distributed programmers. Good documentation makes source code easier to understand; on the other hand, developers have to constantly update the documentation whenever the source code changes. Developers will benefit from an automated tool that simplifies keeping documentation up-to-date and facilitates collaborative editing. In this paper, we explore the concept of collaborative code annotation by combining the idea from crowdsourcing. We introduce Cumiki, a web-based collaborative annotation tool that makes it easier for crowds of developers to collaboratively create the up-to-date documentation. This paper describes the user interface, the mechanism, and its implementation, and discusses the possible usage scenarios.","","","10.1109/ICSE.2015.254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203075","","Documentation;Collaboration;Crowdsourcing;Software;Software engineering;User interfaces;Programming","distributed programming;Internet;software tools;source code (software);system documentation","collaborative source code annotation;interactive source code annotation;software documentation;distributed programmers;collaborative editing;crowdsourcing;Web-based collaborative annotation tool;Cumiki tool;user interface","","2","7","","","","","IEEE","IEEE Conferences"
"2nd International Workshop on Requirements Engineering and Testing (RET 2015)","E. Bjarnason; M. Morandini; M. Borg; M. Unterkalmsteiner; M. Felderer; M. Staats","NA; NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","997","998","The RET (Requirements Engineering and Testing) workshop provides a meeting point for researchers and practitioners from the two separate fields of Requirements Engineering (RE) and Testing. The goal is to improve the connection and alignment of these two areas through an exchange of ideas, challenges, practices, experiences and results. The long term aim is to build a community and a body of knowledge within the intersection of RE and Testing. One of the main outputs of the 1st workshop was a collaboratively constructed map of the area of RET showing the topics relevant to RET for these. The 2nd workshop will continue in the same interactive vein and include a keynote, paper presentations with ample time for discussions, and a group exercise. For true impact and relevance this cross-cutting area requires contribution from both RE and Testing, and from both researchers and practitioners. For that reason we welcome a range of paper contributions from short experience papers to full research papers that both clearly cover connections between the two fields.","","","10.1109/ICSE.2015.351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203146","requirements engineering;testing;alignment","Testing;Conferences;Requirements engineering;Software engineering;Software;Industries;Joining processes","","","","1","4","","","","","IEEE","IEEE Conferences"
"2nd International Workshop on Software Engineering Methods in Spreadsheets (SEMS 2015)","F. Hermans; R. F. Paige; P. Sestoft","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1005","1006","Spreadsheets are heavily used in industry, becausethey are easily written and adjusted, using an intuitive visual interface. They often start out as simple tools; however, over time spreadsheets can become increasingly complex, up to the point where they become complicated and inflexible. In many ways, spreadsheet are similar to software: both concern the storage and manipulation of data and the presentation of results to the user. Because of this similarity, many methods and techniques from software engineering can be applied to spreadsheets. The role of SEMS, the International Workshop on Software Engineering Methods in Spreadsheets is to explore the possibilities of applying successful methods from software engineering to spreadsheets. Some, like testing and visualization, have been tried before and can be built upon. For methods that have not yet been tried on spreadsheets, SEMS will serve as a platform for early feedback. The SEMS program included an industrial keynote, ""spreadsheet stories"" (success or failure), short and long research papers,a good mix of industrial and academic researchers, as well as lively discussion and debate.","","","10.1109/ICSE.2015.325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203150","","Conferences;Software engineering;Industries;Committees;Electronic mail;Software;Testing","","","","","","","","","","IEEE","IEEE Conferences"
"The ECCO Tool: Extraction and Composition for Clone-and-Own","S. Fischer; L. Linsbauer; R. E. Lopez-Herrejon; A. Egyed","Johannes Kepler Univ. Linz, Linz, Austria; Johannes Kepler Univ. Linz, Linz, Austria; Johannes Kepler Univ. Linz, Linz, Austria; Johannes Kepler Univ. Linz, Linz, Austria","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","665","668","Software reuse has become mandatory for companies to compete and a wide range of reuse techniques are available today. However, ad hoc practices such as copying existing systems and customizing them to meet customer-specific needs are still pervasive, and are generically called clone-and-own. We have developed a conceptual framework to support this practice named ECCO that stands for Extraction and Composition for Clone-and-Own. In this paper we present our Eclipse-based tool to support this approach. Our tool can automatically locate reusable parts from previously developed products and subsequently compose a new product from a selection of desired features. The tools demonstration video can be found here: http://youtu.be/N6gPekuxU6o.","","","10.1109/ICSE.2015.218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203038","product variants;clone-and-own;reuse;features;feature interactions","Software;Feature extraction;Data mining;Conferences;Software engineering;Systematics;Distance measurement","software product lines","ECCO tool;software reuse;customer-specific needs;extraction-and-composition-for-clone-and-own;Eclipse-based tool;feature selection;software product lines","","12","9","","","","","IEEE","IEEE Conferences"
"Automated Program Repair in an Integrated Development Environment","Y. Pei; C. A. Furia; M. Nordio; B. Meyer","Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","681","684","We present the integration of the AutoFix automated program repair technique into the EiffelStudio Development Environment. AutoFix presents itself like a recommendation system capable of automatically finding bugs and suggesting fixes in the form of source-code patches. Its performance suggests usage scenarios where it runs in the background or during work interruptions, displaying fix suggestions as they become available. This is a contribution towards the vision of semantic Integrated Development Environments, which offer powerful automated functionality within interfaces familiar to developers. A screencast highlighting the main features of AutoFix can be found at: http://youtu.be/Ff2ULiyL-80.","","","10.1109/ICSE.2015.222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203042","","Maintenance engineering;Contracts;Heuristic algorithms;Computer bugs;Testing;Algorithm design and analysis;Semantics","program diagnostics;software maintenance;source code (software)","AutoFix automated program repair technique;EiffelStudio development environment;recommendation system;source-code patches;semantic integrated development environments","","5","12","","","","","IEEE","IEEE Conferences"
"Towards Generation of Software Development Tasks","C. A. Thompson","Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","915","918","The presence of well defined fine-grained sub-tasks is important to the development process: having a fine-grained task context has been shown to allow developers to more efficiently resume work. However, determining how to break a high level task down into sub-tasks is not always straightforward. Sometimes developers lack experience, and at other times, the task definition is not clear enough to afford confident decomposition. In my research I intend to show that by using syntactic mining of past task descriptions and their decomposition, I can provide automatically derived sub-task suggestions to afford more confident task decomposition by developers.","","","10.1109/ICSE.2015.291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203113","","Software;Data mining;Programming;Logic gates;Electronic mail;Stress;Medical services","data mining;software engineering","software development tasks;fine-grained sub-tasks;syntactic mining","","","16","","","","","IEEE","IEEE Conferences"
"Poster: Filtering Code Smells Detection Results","F. Arcelli Fontana; V. Ferme; M. Zanoni","Dept. of Inf., Syst. & Commun., Univ. of Milano-Bicocca, Milan, Italy; Fac. of Inf., Univ. of Lugano (USI), Lugano, Switzerland; Dept. of Inf., Syst. & Commun., Univ. of Milano-Bicocca, Milan, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","803","804","Many tools for code smell detection have been developed, providing often different results. This is due to the informal definition of code smells and to the subjective interpretation of them. Usually, aspects related to the domain, size, and design of the system are not taken into account when detecting and analyzing smells. These aspects can be used to filter out the noise and achieve more relevant results. In this paper, we propose different filters that we have identified for five code smells. We provide two kind of filters, Strong and Weak Filters, that can be integrated as part of a detection approach.","","","10.1109/ICSE.2015.256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203077","","Libraries;Matched filters;Surgery;Couplings;Accuracy;Information filters","software reliability","code smell detection;subjective code smell interpretation;code smell filtering;strong filters;weak filters","","8","3","","","","","IEEE","IEEE Conferences"
"Poster: Automatically Fixing Real-World JavaScript Performance Bugs","M. Selakovic; M. Pradel","Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany; Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","811","812","Programs often suffer from poor performance that can be fixed by relatively simple changes. Currently, developers either manually identify and fix such performance problems, or they rely on compilers to optimize their code. Unfortunately, manually fixing performance bugs is non-trivial, and compilers are limited to a predefined set of optimizations. This paper presents an approach for automatically finding and fixing performance bugs in JavaScript programs. To focus our work on relevant problems, we study 37 real-world performance bug fixes from eleven popular JavaScript projects and identify several recurring fix patterns. Based on the results of the study, we present a static analysis that identifies occurrences of common fix patterns and a fix generation technique that proposes to transform a given program into a more efficient program. Applying the fix generation technique to three libraries with known performance bugs yields fixes that are equal or equivalent to those proposed by the developers, and that lead to speedups between 10% and 25%.","","","10.1109/ICSE.2015.260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203081","","Computer bugs;Reactive power;Optimization;Maintenance engineering;Semantics;Transforms;Libraries","Java;program debugging;program diagnostics","compilers;JavaScript programs;static analysis;common fix patterns;fix generation technique;real-world performance bugs","","2","6","","","","","IEEE","IEEE Conferences"
"1st International Workshop on Software Engineering for Smart Cyber-Physical Systems (SEsCPS 2015)","T. Bures; D. Weyns; M. Klein; R. E. Haber","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1009","1010","Cyber-physical system (CPS) have been recognized as a top-priority in research and development. The innovations sought for CPS demand them to deal effectively with dynamicity of their environment, to be scalable, adaptive, tolerant to threats, etc. -- i.e. they have to be smart. Although approaches in software engineering (SE) exist that individually meet these demands, their synergy to address the challenges of smart CPS (sCPS) in a holistic manner remains an open challenge. The workshop focuses on software engineering challenges for sCPS. The goals are to increase the understanding of problems of SE for sCPS, study foundational principles for engineering sCPS, and identify promising SE solutions for sCPS. Based on these goals, the workshop aims to formulate a research agenda for SE of sCPS.","","","10.1109/ICSE.2015.326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203152","","Conferences;Software engineering;Cyber-physical systems;Software;Adaptation models;Committees;Technological innovation","","","","3","8","","","","","IEEE","IEEE Conferences"
"Supporting Scientific SE Process Improvement","E. S. Mesh","Dept. of Comput. & Inf. Sci., Rochester Inst. of Technol., Rochester, NY, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","923","926","The increasing complexity of scientific software can result in significant impacts on the research itself. In traditional software development projects, teams adopt historical best practices into their development processes to mitigate the risk of such problems. In contrast, the gap that has formed between the traditional and scientific software communities leaves scientists to rely on only their own experience when facing software process improvement (SPI) decisions. Rather than expect scientists to become software engineering (SE) experts or the SE community to learn all of the intricacies involved in scientific software development projects, we seek a middle ground. The Scientific Software Process Improvement Framework (SciSPIF) will allow scientists to self-drive their own SPI efforts while leveraging the collective experiences of their peers and linking their concerns to established SE best practices. This proposal outlines the known challenges of scientific software development, relevant concepts from traditional SE research, and our planned methodology for collecting the data required to construct SciSPIF while staying grounded in the actual goals and concerns of the scientists.","","","10.1109/ICSE.2015.293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203115","software engineering;process improvement;scientific software","Software;Software engineering;Best practices;Conferences;Interviews;Scientific computing;Encoding","natural sciences computing;project management;risk management;software development management;software process improvement","SciSPIF;Scientific Software Process Improvement Framework;scientific software development project;software engineering experts;SPI decision;software process improvement;scientific software community;risk mitigation;software development process;scientific software complexity;scientific SE process improvement","","1","28","","","","","IEEE","IEEE Conferences"
"Poster: Segmentation Based Online Performance Problem Diagnosis","J. Zhou; Z. Chen; J. Wang","Sci. & Technol. on Parallel & Distrib. Process. Lab., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","807","808","Currently, the performance problems of software systems gets more and more attentions. Among various diagnosis methods based on system traces, principal component analysis (PCA) based methods are widely used due to the high accuracy of the diagnosis results and requiring no specific domain knowledge. However, according to our experiments, we have validated several shortcomings existed in PCA-based methods, including requiring traces with a same call sequence, inefficiency when the traces are long, and missing performance problems. To cope with these issues, we introduce a segmentation based online diagnosis method in this poster.","","","10.1109/ICSE.2015.258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203079","performance problem diagnosis;principal component analysis;system trace;software reliability","Principal component analysis;Software systems;Accuracy;Measurement;Monitoring;Computer architecture;Conferences","principal component analysis;program diagnostics;software performance evaluation","online performance problem diagnosis;software systems performance problems;diagnosis methods;system traces;principal component analysis;PCA based methods;segmentation based online diagnosis method","","1","6","","","","","IEEE","IEEE Conferences"
"Poster: Is Carmen Better than George? Testing the Exploratory Tester Using HCI Techniques","A. Borg; C. Porter; M. Micallef","Univ. of Malta, Msida, Malta; Univ. of Malta, Msida, Malta; Univ. of Malta, Msida, Malta","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","815","816","Exploratory software testing is an activity which can be carried out by both untrained and formally trained testers. In this paper, we propose using Human Computer Interaction (HCI) techniques to carry out a study of exploratory testing strategies used by the two groups of testers. This data will be used to make recommendations to companies with regards to the mix of skills and training required for testing teams.","","","10.1109/ICSE.2015.262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203083","Exploratory Testing Strategies;Human-Computer Interaction","Human computer interaction;Software testing;Data collection;Training;Computer bugs;Software","human computer interaction;program testing","HCI techniques;human computer interaction;exploratory software testing","","2","7","","","","","IEEE","IEEE Conferences"
"Free Hugs -- Praising Developers for Their Actions","R. Minelli; A. Mocci; M. Lanza","Fac. of Inf., Univ. of Lugano, Lugano, Switzerland; Fac. of Inf., Univ. of Lugano, Lugano, Switzerland; Fac. of Inf., Univ. of Lugano, Lugano, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","555","558","Developing software is a complex, intrinsically intellectual, and therefore ephemeral activity, also due to the intangible nature of the end product, the source code. There is a thin red line between a productive development session, where a developer actually does something useful and productive, and a session where the developer essentially produces ""fried air"", pieces of code whose quality and usefulness are doubtful at best. We believe that well-thought mechanisms of gamification built on fine-grained interaction information mined from the IDE can crystallize and reward good coding behavior. We present our preliminary experience with the design and implementation of a micro-gamification layer built into an object-oriented IDE, which at the end of each development session not only helps the developer to understand what he actually produced, but also praises him in case the development session was productive. Building on this, we envision an environment where the IDE reflects on the deeds of the developers and by providing a historical view also helps to track and reward long-term growth in terms of development skills, not dissimilar from the mechanics of role-playing games.","","","10.1109/ICSE.2015.342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203011","gamification;ide;interaction data;doctor;window plague","Software;Games;Navigation;Software engineering;Productivity;Programming;User interfaces","object-oriented programming;software engineering;source code (software)","software development;source code;gamification mechanisms;fine-grained interaction information;coding behavior;microgamification layer;object-oriented IDE;role-playing game mechanics;integrated development environment","","2","17","","","","","IEEE","IEEE Conferences"
"MU-MMINT: An IDE for Model Uncertainty","M. Famelis; N. Ben-David; A. Di Sandro; R. Salay; M. Chechik","Univ. of Toronto, Toronto, ON, Canada; Univ. of Toronto, Toronto, ON, Canada; Univ. of Toronto, Toronto, ON, Canada; Univ. of Toronto, Toronto, ON, Canada; Univ. of Toronto, Toronto, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","697","700","Developers have to work with ever-present design-time uncertainty, i.e., Uncertainty about selecting among alternative design decisions. However, existing tools do not support working in the presence of uncertainty, forcing developers to either make provisional, premature decisions, or to avoid using the tools altogether until uncertainty is resolved. In this paper, we present a tool, called MU-MMINT, that allows developers to express their uncertainty within software artifacts and perform a variety of model management tasks such as reasoning, transformation and refinement in an interactive environment. In turn, this allows developers to defer the resolution of uncertainty, thus avoiding having to undo provisional decisions. See the companion video: http://youtu.be/kAWUm-iFatM.","","","10.1109/ICSE.2015.226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203046","","Uncertainty;Unified modeling language;Visualization;Adaptation models;Software;Cognition;Analytical models","software engineering;software tools","MU-MMINT tool;IDE;integrated development environment;model uncertainty;design-time uncertainty;design decisions;software artifacts;model management tasks;reasoning task;transformation task;refinement task","","7","17","","","","","IEEE","IEEE Conferences"
"Ekstazi: Lightweight Test Selection","M. Gligoric; L. Eloussi; D. Marinov","Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","713","716","Regression testing is a crucial, but potentially time-consuming, part of software development. Regression test selection (RTS), which runs only a subset of tests, was proposed over three decades ago as a promising way to speed up regression testing. However, RTS has not been widely adopted in practice. We propose EKSTAZI , a lightweight RTS tool, that can integrate well with testing frameworks and build systems, increasing the chance for adoption. EKSTAZI tracks dynamic dependencies of tests on files and requires no integration with version-control systems. We implemented EKSTAZI for Java+JUnit and Scala+ScalaTest, and evaluated it on 615 revisions of 32 open-source projects (totaling almost 5M LOC). The results show that EKSTAZI reduced the end-to-end testing time by 32% on average compared to executing all tests. EKSTAZI has been adopted for day-to-day use by several Apache developers. The demo video for EKSTAZI can be found at http://www.youtube.com/watch?v=jE8K5_UCP28.","","","10.1109/ICSE.2015.230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203050","","Testing;Java;Instruments;Open source software;Monitoring;Google","Java;program testing;regression analysis;software tools","EKSTAZI;lightweight test selection;regression testing;software development;regression test selection;lightweight RTS tool;dynamic dependency tracking;Java+JUnit;Scala+ScalaTest;open-source projects;Apache developers","","15","20","","","","","IEEE","IEEE Conferences"
"Verification of Android Applications","H. v. d. Merwe","NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","931","934","This study investigates an alternative approach to analyze Android applications using model checking. We develop an extension to Java Path Finder (JPF) called JPF-Android to verify Android applications outside of the Android platform. JPF is a powerful Java model checker and analysis engine that is very effective at detecting corner-case and hard-to-find errors using its fine-grained analysis capabilities. JPF-Android provides a simplified model of the Android application framework on which an Android application can run and it can generate input events or parse an input script containing sequences of input events to drive the execution of the application. JPF-Android traverses all execution paths of the application by simulating these input events and can detect common property violations such as deadlocks and runtime exceptions in Android applications. It also introduces user defined execution specifications called Checklists to verify the flow of application execution.","","","10.1109/ICSE.2015.295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203117","","Androids;Humanoid robots;Java;Libraries;Analytical models;Model checking","Android (operating system);Java;program verification","verification;Android applications;model checking;Java path finder;JPF-Android;Android platform;Java model checker;analysis engine;corner-case errors detection;hard-to-find errors detection;execution paths;property violations;deadlocks;runtime exceptions;Checklists;application execution","","","12","","","","","IEEE","IEEE Conferences"
"Agile Project Management: From Self-Managing Teams to Large-Scale Development","T. Dyb√•; T. Dings√∏yr","SINTEF, Trondheim, Norway; SINTEF, Trondheim, Norway","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","945","946","Agile software development represents a new approach for planning and managing software projects. It puts less emphasis on up-front plans and strict control and relies more on informal collaboration, coordination, and learning. This briefing provides a characterization and definition of agile project management based on extensive studies of large-scale industrial projects. It explains the circumstances behind the change from traditional management with its focus on direct supervision and standardization of work processes, to the newer, agile focus on self-managing teams, including its opportunities and benefits, but also its complexity and challenges. The main focus of the briefing is the four principles of agile project management: minimum critical specification, autonomous teams, redundancy, and feedback and learning. The briefing is intended for researchers, practitioners and educators in software engineering, especially project managers. For researchers, an updated state of the art will be uncovered, and the presentation will be based on current best evidence. For practitioners, principles, processes, and key success factors will be outlined and a successful large-scale case study of agile project management will be presented. For educators, the briefing will provide the basis for developing course material.","","","10.1109/ICSE.2015.299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203121","Software Engineering;Large-Scale;Project Management;Agile Development;Self-Management;Portfolio Management","Software;Project management;Planning;Complexity theory;Uncertainty;Redundancy","project management;software development management;software prototyping","agile project management;self-managing teams;agile software development;software project planning;software projects management;large-scale industrial project development;software engineering","","2","1","","","","","IEEE","IEEE Conferences"
"Poster: ProNat: An Agent-Based System Design for Programming in Spoken Natural Language","S. Weigelt; W. F. Tichy","NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","819","820","The emergence of natural language interfaces has led to first attempts of programming in natural language. We present ProNat, a tool for script-like programming in spoken natural language (SNL). Its agent-based architecture unifies deep natural language understanding (NLU) with modular software design. ProNat focuses on the extraction of processing flows and control structures from spoken utterances. For evaluation we have begun to build a speech corpus. First experiments are conducted in the domain of domestic robotics, but ProNat's architecture makes domain acquisition easy. Test results with spoken utterances in ProNat seem promising, but much work has to be done to achieve deep NLU.","","","10.1109/ICSE.2015.264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203085","programming in natural language;natural language processing;end user programming;ontology;agent-based software design;natural lanuage understanding;robotics","Natural languages;Programming;Speech;Robots;Ontologies;Unified modeling language;Speech recognition","authoring languages;natural language interfaces;programming languages;software agents;software architecture;software tools","agent-based system design;spoken natural language;natural language interfaces;SNL;script-like programming;deep natural language understanding;NLU;modular software design;agent-based architecture;control structures;processing flow extraction;speech corpus;domestic robotics;ProNat architecture;spoken utterances","","7","12","","","","","IEEE","IEEE Conferences"
"CACHECA: A Cache Language Model Based Code Suggestion Tool","C. Franks; Z. Tu; P. Devanbu; V. Hellendoorn","Dept. of Comput. Sci., Univ. of California at Davis, Davis, CA, USA; Dept. of Comput. Sci., Univ. of California at Davis, Davis, CA, USA; Dept. of Comput. Sci., Univ. of California at Davis, Davis, CA, USA; Delft Univ. of Technol., Delft, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","705","708","Nearly every Integrated Development Environment includes a form of code completion. The suggested completions (""suggestions"") are typically based on information available at compile time, such as type signatures and variables in scope. A statistical approach, based on estimated models of code patterns in large code corpora, has been demonstrated to be effective at predicting tokens given a context. In this demo, we present CACHECA, an Eclipse plug in that combines the native suggestions with a statistical suggestion regime. We demonstrate that a combination of the two approaches more than doubles Eclipse's suggestion accuracy. A video demonstration is available at https://www.youtube.com/watch?v=3INk0N3JNtc.","","","10.1109/ICSE.2015.228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203048","","Accuracy;Engines;Context;Context modeling;Java;Computational modeling;Predictive models","programming languages;software tools;source code (software)","CACHECA;Eclipse plugin;cache language model;code suggestion tool;integrated development environment;code completion;statistical approach;code pattern model estimation","","12","8","","","","","IEEE","IEEE Conferences"
"StressCloud: A Tool for Analysing Performance and Energy Consumption of Cloud Applications","F. Chen; J. Grundy; J. Schneider; Y. Yang; Q. He","Sch. of Software & Electr. Eng., Swinburne Univ. of Technol., Melbourne, VIC, Australia; Sch. of Software & Electr. Eng., Swinburne Univ. of Technol., Melbourne, VIC, Australia; Sch. of Software & Electr. Eng., Swinburne Univ. of Technol., Melbourne, VIC, Australia; Sch. of Software & Electr. Eng., Swinburne Univ. of Technol., Melbourne, VIC, Australia; Sch. of Software & Electr. Eng., Swinburne Univ. of Technol., Melbourne, VIC, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","721","724","Finding the best deployment configuration that maximises energy efficiency while guaranteeing system performance of cloud applications is an extremely challenging task. It requires the evaluation of system performance and energy consumption under a wide variety of realistic workloads and deployment configurations. This paper demonstrates StressCloud, an automatic performance and energy consumption analysis tool for cloud applications in real-world cloud environments. StressCloud supports 1) the modelling of realistic cloud application workloads, 2) the automatic generation and running of load tests, and 3) the profiling of system performance and energy consumption.","","","10.1109/ICSE.2015.232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203052","","Computational modeling;Load modeling;Energy consumption;Cloud computing;System performance;Data models;Servers","cloud computing;energy conservation;energy consumption;power aware computing;software performance evaluation;software tools","StressCloud tool;cloud performance analysis;energy efficiency;system performance evaluation;energy consumption analysis tool;real-world cloud environments;load tests","","5","10","","","","","IEEE","IEEE Conferences"
"The Green Lab: Experimentation in Software Energy Efficiency","G. Procaccianti; P. Lago; A. Vetr√≤; D. M. Fern√°ndez; R. Wieringa","Dept. of Comput. Sci., VU Univ., Amsterdam, Netherlands; Dept. of Comput. Sci., VU Univ., Amsterdam, Netherlands; Tech. Univ. Munchen, Munich, Germany; Tech. Univ. Munchen, Munich, Germany; Univ. of Twente, Enschede, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","941","942","Software energy efficiency is a research topic where experimentation is widely adopted. Nevertheless, current studies and research approaches struggle to find generalizable findings that can be used to build a consistent knowledge base for energy-efficient software. To this end, we will discuss how to combine the traditional hypothesis-driven (top-down) approach with a bottom-up discovery approach. In this technical briefing, participants will learn the challenges that characterize the research in software energy efficiency. They will experience the complexity in this field and its implications for experimentation.","","","10.1109/ICSE.2015.297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203119","Energy Efficiency;Software Engineering;Empirical Methods","Software;Energy consumption;Software engineering;Energy measurement;Complexity theory;Software measurement;Conferences","energy conservation;green computing;software engineering","green laboratory;software energy efficiency;hypothesis-driven approach;bottom-up discovery approach","","13","8","","","","","IEEE","IEEE Conferences"
"The Use of Text Retrieval and Natural Language Processing in Software Engineering","V. Arnaoudova; S. Haiduc; A. Marcus; G. Antoniol","Univ. of Texas at Dallas, Richardson, TX, USA; Florida State Univ., Tallahassee, FL, USA; Univ. of Texas at Dallas, Richardson, TX, USA; Polytech. Montreal, Montreal, QC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","949","950","This technical briefing presents the state of the art Text Retrieval and Natural Language Processing techniques used in Software Engineering and discusses their applications in the field.","","","10.1109/ICSE.2015.301","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203123","Text retrieval;natural language processing","Software;Software engineering;Natural language processing;Committees;Conferences;Tutorials;Information retrieval","information retrieval;natural language processing;software engineering;text analysis","text retrieval;software engineering;natural language processing techniques","","2","","","","","","IEEE","IEEE Conferences"
"Poster: Conquering Uncertainty in Java Programming","T. Fukamachi; N. Ubayashi; S. Hosoai; Y. Kamei","Kyushu Univ., Fukuoka, Japan; Kyushu Univ., Fukuoka, Japan; Kyushu Univ., Fukuoka, Japan; Kyushu Univ., Fukuoka, Japan","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","823","824","Uncertainty in programming is one of the challenging issues to be tackled, because it is error-prone for many programmers to temporally avoid uncertain concerns only using simple language constructs such as comments and conditional statements. This paper proposes ucJava, a new Java programming environment for conquering uncertainty. Our environment provides a modular programming style for uncertainty and supports test-driven development taking uncertainty into consideration.","","","10.1109/ICSE.2015.266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203087","","Uncertainty;Java;Programming;Testing;Connectors;Programming environments","Java","Java programming uncertainty;language constructs;conditional statements;comments;ucJava;Java programming environment;modular programming style;test-driven development","","2","7","","","","","IEEE","IEEE Conferences"
"Poster: Tierless Programming in JavaScript","L. Philips; W. De Meuter; C. De Roover","Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium; Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium; Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","831","832","Whereas ""responsive"" web applications already offered a more desktop-like experience, there is an increasing user demand for ""rich"" web applications (RIAs) that offer collaborative and even off-line functionality. Realizing these qualities requires distributing previously centralized application logic and state vertically from the server to a client tier (e.g., for desktop-like and off-line client functionality), and horizontally between instances of the same tier (e.g., for collaborative client functionality and for scaling of resource-starved services). Both bring about the essential complexity of distributing application assets and maintaining their consistency, along with the accidental complexity of reconciling a myriad of heterogenous tier-specific technology. Tierless programming languages enable developing web applications as a single artefact that is automatically split in tier-specific code - resulting in a development process akin to that of a desktop application. This relieves developers of distribution and consistency concerns, as well as the need to align different tier-specific technologies. However, programmers still have to adopt a new and perhaps esoteric language. We therefore advocate developing tierless programs in a general-purpose language instead. In this poster, we introduce our approach to tierless programming in JavaScript. We expand upon our previous work by identifying development challenges arising from this approach that could be resolved through tool support.","","","10.1109/ICSE.2015.270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203091","","Servers;Reactive power;Programming;Prototypes;Libraries;Collaboration;Complexity theory","Internet;Java;programming languages","JavaScript;responsive Web applications;RIA;accidental complexity;tierless programming languages;general-purpose language","","1","8","","","","","IEEE","IEEE Conferences"
"Incorporating Human Intention into Self-Adaptive Systems","S. Huang; P. Miranda","Comput. & Electr. Eng. & Comput. Sci., Florida Atlantic Univ., Boca Raton, FL, USA; Comput. & Electr. Eng. & Comput. Sci., Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","571","574","Self-adaptive systems are fed with contextual information from the environments in which the systems operate,from within themselves, and from the users. Traditional self-adaptive systems research has focused on inputs of systems performance, resources, exception, and error recovery that drive systems' reaction to their environments. The intelligent ability ofthese self-adaptive systems is impoverished without knowledge ofa user's covert attention (thoughts, emotions, feelings). As a result, it is difficult to build effective systems that anticipate and react to users' needs as projected by covert behavior. This paperpresents the preliminary research results on capturing users'intention through neural input, and in reaction, commanding actions from software systems (e.g., load an application) based on human intention. Further, systems can self-adapt and refine their behaviors driven by such human covert behavior. The long-term research goal is to incorporate and synergize human neural input.Thus establishing software systems with a self-adaptive capability to ""feel"" and ""anticipate"" users intentions and put the human in the loop.","","","10.1109/ICSE.2015.196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203015","Brain computer interface (BCI);human computer interface (HCI);neural input;self-adaptive systems;overt and covert behavior;human in the loop","Electroencephalography;Mice;Computers;Digital signal processing;Software systems;Software engineering;Adaptive systems","human computer interaction;software engineering","self-adaptive systems;human intention;contextual information;software systems;human covert behavior;human neural input;human computer interface","","2","21","","","","","IEEE","IEEE Conferences"
"6th International Workshop on Emerging Trends in Software Metrics (WETSoM 2015)","S. Counsell; A. Visaggio; R. Tonelli; E. Tempero","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1021","1022","WETSoM is a gathering of researchers and practitioners to discuss the progress on software metrics knowledge. Motivations for this workshop include the low impact that software metrics have on current software development and the increased interest in research. The goals of this workshop include critically examining the evidence for the effectiveness of existing metrics and identifying new directions for metrics. Evidence for existing metrics includes how the metrics have been used in practice and studies showing their effectiveness. Identifying new directions includes use of new theories, such as complex network theory, on which to base metrics.","","","10.1109/ICSE.2015.347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203158","Software Metrics;Software Quality","Software;Software metrics;Conferences;Software engineering;Market research;Complex networks","","","","","","","","","","IEEE","IEEE Conferences"
"Ariadne: Topology Aware Adaptive Security for Cyber-Physical Systems","C. Tsigkanos; L. Pasquale; C. Ghezzi; B. Nuseibeh","Politec. di Milano, Milan, Italy; Lero - the Irish Software Res. Centre, Limerick, Ireland; Politec. di Milano, Milan, Italy; Lero - the Irish Software Res. Centre, Limerick, Ireland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","729","732","This paper presents Ariadne, a tool for engineering topology aware adaptive security for cyber-physical systems. It allows security software engineers to model security requirements together with the topology of the operational environment. This model is then used at runtime to perform speculative threat analysis to reason about the consequences that topological changes arising from the movement of agents and assets can have on the satisfaction of security requirements. Our tool also identifies an adaptation strategy that applies security controls when necessary to prevent potential security requirements violations.","","","10.1109/ICSE.2015.234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203054","Adaptive Systems;Security;Verification","Security;Topology;Servers;Adaptation models;Runtime;Mobile handsets;Ports (Computers)","security of data;software tools","Ariadne tool;cyber-physical systems;engineering topology aware adaptive security;security software engineers;speculative threat analysis;adaptation strategy","","11","5","","","","","IEEE","IEEE Conferences"
"Reactive Programming: A Walkthrough","G. Salvaneschi; A. Margara; G. Tamburrelli","Tech. Univ. Darmstadt, Darmstadt, Germany; Univ. della Svizzera italiana, Lugano, Switzerland; Vrije Univ., Amsterdam, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","953","954","Over the last few years, Reactive Programming has emerged as the trend to support the development of reactive software through dedicated programming abstractions. Reactive Programming has been increasingly investigated in the programming languages community and it is now gaining the interest of practitioners. Conversely, it has received so far less attention from the software engineering community. This technical briefing bridges this gap through an accurate overview of Reactive Programming, discussing the available frameworks and outlining open research challenges with an emphasis on cross-field research opportunities.","","","10.1109/ICSE.2015.303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203125","","Software engineering;Software;Programming profession;Computer languages;Observers;Graphical user interfaces","programming languages;software engineering","reactive programming;reactive software development;programming abstraction;programming language","","5","11","","","","","IEEE","IEEE Conferences"
"Poster: An Efficient Equivalence Checking Method for Petri Net Based Models of Programs","S. Bandyopadhyay; D. Sarkar; C. Mandal","Indian Inst. of Technol., Kharagpur, Kharagpur, India; Indian Inst. of Technol., Kharagpur, Kharagpur, India; Indian Inst. of Technol., Kharagpur, Kharagpur, India","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","827","828","The initial behavioural specification of any software programs goes through significant optimizing and parallelizing transformations, automated and also human guided, before being mapped to an architecture. Establishing validity of these transformations is crucial to ensure that they preserve the original behaviour. PRES+ model (Petri net based Representation of Embedded Systems) encompassing data processing is used to model parallel behaviours. Being value based with inherent scope of capturing parallelism, PRES+ models depict such data dependencies more directly; accordingly, they are likely to be more convenient as the intermediate representations (IRs) of both the source and the transformed codes for translation validation than strictly sequential variable-based IRs like Finite State Machines with Data path (FSMDs) (which are essentially sequential control flow graphs (CFGs)). In this work, a path based equivalence checking method for PRES+ models is presented.","","","10.1109/ICSE.2015.268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203089","Equivalence checking;PRES+ model;FSMD model","Computational modeling;Petri nets;Data models;Sparks;Benchmark testing;Embedded systems","embedded systems;formal specification;parallel programming;Petri nets;program interpreters;program verification;software architecture;source code (software)","Petri net based models;behavioural specification;software programs;optimizing transformations;parallelizing transformations;architecture;PRES+ model;Petri net based representation of embedded systems;data processing;parallel behaviours;parallelism;data dependencies;intermediate representations;source codes;transformed codes;translation validation;sequential variable-based IR;finite state machines with data path;FSMD;sequential control flow graphs;CFG;path based equivalence checking method","","5","7","","","","","IEEE","IEEE Conferences"
"Poster: Reasoning Based on Imperfect Context Data in Adaptive Security","S. Sartoli; A. S. Namin","Comput. Sci. Dept., Texas Tech Univ., Lubbock, TX, USA; Comput. Sci. Dept., Texas Tech Univ., Lubbock, TX, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","835","836","Enabling software systems to adjust their protection in continuously changing environments with imperfect context information is a grand challenging problem. The issue of uncertain reasoning based on imperfect information has been overlooked in traditional logic programming with classical negation when applied to dynamic systems. This paper sketches a non-monotonic approach based on Answer Set Programming to reason with imperfect context data in adaptive security where there is little or no knowledge about certainty of the actions and events.","","","10.1109/ICSE.2015.272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203093","Adaptive security;imperfect data;non-monotonic logic","Context;Security;Cognition;Adaptation models;Monitoring;Context modeling;Patents","data protection;logic programming;security of data","imperfect context data;adaptive security;software systems;logic programming;dynamic systems;nonmonotonic approach;answer set programming","","4","5","","","","","IEEE","IEEE Conferences"
"VERMEER: A Tool for Tracing and Explaining Faulty C Programs","D. Schwartz-Narbonne; C. Oh; M. Sch√§f; T. Wies","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","737","740","We present VERMEER, a new automated debugging tool for C. VERMEER combines two functionalities: (1) a dynamic tracer that produces a linearized trace from a faulty C program and a given test input; and (2) a static analyzer that explains why the trace fails. The tool works in phases that simplify the input program to a linear trace, which is then analyzed using an automated theorem prover to produce the explanation. The output of each phase is a valid C program. VERMEER is able to produce useful explanations of non trivial traces for real C programs within a few seconds. The tool demo can be found at http://youtu.be/E5lKHNJVerU.","","","10.1109/ICSE.2015.236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203056","","Concrete;Benchmark testing;Debugging;Interpolation;Libraries;Software;Algorithm design and analysis","C language;program debugging;program diagnostics;software tools;theorem proving","VERMEER;faulty C program tracing;automated debugging tool;dynamic tracer;linearized trace;static analyzer;automated theorem prover","","1","16","","","","","IEEE","IEEE Conferences"
"Profiling Kernels Behavior to Improve CPU / GPU Interactions","R. Salgado","Pleiad Lab., Univ. of Chile, Santiago, Chile","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","754","756","Most modern computer and mobile devices have a graphical processing unit (GPU) available for any general purpose computation. GPU supports a programming model that is radically different from traditional sequential programming. As such, programming GPU is known to be hard and error prone, despite the large number of available APIs and dedicated programming languages. In this paper we describe a profiling technique that reports on the interaction between a CPU and GPUs. The resulting execution profile may then reveal anomalies and suboptimal situations, in particular due to an improper memory configuration. Our profiler has been effective at identifying suboptimal memory allocation usage in one image processing application.","","","10.1109/ICSE.2015.239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203060","gpgpu;opencl;memory profiling;profiling","Graphics processing units;Kernel;Programming;Visualization;Central Processing Unit;Computers;Measurement","graphics processing units;storage management","kernel behavior profiling technique;CPU-GPU interactions;mobile devices;graphical processing unit;programming model;improper memory configuration;suboptimal memory allocation usage;image processing application","","","9","","","","","IEEE","IEEE Conferences"
"Big(ger) Data in Software Engineering","M. Nagappan; M. Mirakhorli","Dept. of Software Eng., Rochester Inst. of Technol., Rochester, NY, USA; Dept. of Software Eng., Rochester Inst. of Technol., Rochester, NY, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","957","958","""Big Data"" analytics has become the next hot topic for most companies - from financial institutions to technology companies to service providers. Likewise in software engineering, data collected about the development of software, the operation of the software in the field, and the users feedback on software have been used before. However, collecting and analyzing this information across hundreds of thousands or millions of software projects gives us the unique ability to reason about the ecosystem at large, and software in general. At no time in history has there been easier access to extremely powerful computational resources as it is today, thanks to the advances in cloud computing, both from the technology and business perspectives. In this technical briefing, we will present the state-of-the-art with respect to the research carried out in the area of big data analytics in software engineering research.","","","10.1109/ICSE.2015.305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203127","Big Data;Software Engineering","Software;Software engineering;Big data;Data mining;Companies;Conferences;Ecosystems","Big Data;data analysis;software engineering","Big Data analytics;software engineering;software project","","","2","","","","","IEEE","IEEE Conferences"
"3rd International Workshop on Conducting Empirical Studies in Industry (CESI 2015)","X. Franch; N. H. Madhavji; C. H. C. Duarte","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","967","968","Few would deny today the importance of empirical studies in the field of Software Engineering (SE) and, indeed, an increasing number of studies are being conducted involving the software industry. While literature abounds on empirical procedures, relatively little is known about the dynamics and complexity of conducting empirical studies in the software industry. What are the impediments and how to best handle them? This driver underlies the organisation of the third in a series of workshops, CESI 2015. Apart from structured presentations and discussions from academic and industry participants, this workshop (like predecessor workshops) includes a ""wall of ideas"" session where all participants asynchronously post their ideas on the wall, literally, which are then analysed. As a tangible output, the workshop's discussions will be summarised in a post-workshop report.","","","10.1109/ICSE.2015.345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203131","Empirical studies;software industry","Conferences;Industries;Software;Software engineering;Context;Committees;Australia","","","","","","","","","","IEEE","IEEE Conferences"
"How and When to Transfer Software Engineering Research via Extensions","D. Shepherd; K. Damevski; L. Pollock","ABB Corp. Res., Raleigh, NC, USA; Virginia State Univ., Petersburg, VA, USA; Univ. of Delaware, Newark, DE, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","239","240","It is often reported that there is a large gap between software engineering research and practice, with little transfer from research to practice. While this is true in general, one transfer technique is increasingly breaking down this barrier: extensions to integrated development environments (IDEs). With the proliferation of app stores for IDEs and increasing transfer effort from researchers several research-based extensions have seen significant adoption. In this talk we'll discuss our experience transferring code search research, which currently is in the top 5% of Visual Studio extensions with over 13,000 downloads, as well as other research techniques transferred via extensions such as NCrunch, FindBugs, Code Recommenders, Mylyn, and Instasearch. We'll use the lessons learned from our transfer experience to provide case study evidence as to best practices for successful transfer, supplementing it with the quantitative evidence offered by app store and usage data across the broader set of extensions. The goal of this 30 minute talk is to provide researchers with a realistic view on which research techniques can be transferred to practice as well as concrete steps to execute such a transfer.","","","10.1109/ICSE.2015.152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202968","integrated development environment;technology transfer;plugins;case study","Software engineering;Computer bugs;Electronic mail;Visualization;Testing;Prototypes;Software","software engineering","software engineering research;integrated development environments;IDE;research-based extensions;Visual Studio extensions","","2","14","","","","","IEEE","IEEE Conferences"
"Industry/University Collaboration in Software Engineering Education: Refreshing and Retuning Our Strategies","N. R. Mead","Software Eng. Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","273","275","This panel session will explore strategies for industry/university collaboration in software engineering education. Specific discussion topics will include new strategies for successful industry/university collaboration, exploration of reasons why some of the old strategies no longer work, and regional/geographical differences noted by the international set of panelists. The panel hopes to identify new promising strategies for such collaborations. Specific industry representatives will be invited to attend and participate in the discussion.","","","10.1109/ICSE.2015.156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202972","","Software engineering;Industries;Software;Collaboration;Training;Conferences","computer based training;computer science education;educational institutions;organisational aspects","industry-university collaboration;software engineering education;regional differences;geographical differences","","2","10","","","","","IEEE","IEEE Conferences"
"Understanding the Software Fault Introduction Process","L. Inozemtseva","Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","843","846","Testing and debugging research revolves around faults, yet we have a limited understanding of the processes by which faults are introduced and removed. Previous work in this area has focused on describing faults rather than explaining the introduction and removal processes, meaning that a great deal of testing and debugging research depends on assumptions that have not been empirically validated. We propose a three-phase project to develop an explanatory theory of the fault introduction process and describe how the project will be completed.","","","10.1109/ICSE.2015.274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203095","software faults;testing;debugging","Testing;Debugging;Software engineering;Software;Fault diagnosis;Computer crashes;Medical services","program debugging;program testing;research and development;software fault tolerance","software fault introduction process;debugging research;removal processes;testing research;three-phase project","","","16","","","","","IEEE","IEEE Conferences"
"Dynamic Safety Cases for Through-Life Safety Assurance","E. Denney; G. Pai; I. Habli","SGT / NASA Ames Res. Center, Moffett Field, CA, USA; SGT / NASA Ames Res. Center, Moffett Field, CA, USA; Dept. of Comput. Sci., Univ. of York, York, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","587","590","We describe dynamic safety cases, a novel operationalization of the concept of through-life safety assurance, whose goal is to enable proactive safety management. Using an example from the aviation systems domain, we motivate our approach, its underlying principles, and a lifecycle. We then identify the key elements required to move towards a formalization of the associated framework.","","","10.1109/ICSE.2015.199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203019","Dynamic safety case;Safety assurance;Lifecycle processes;Safety management","Monitoring;Biomedical monitoring;Safety management;Runtime;Cognition;Temperature sensors","safety-critical software","through-life safety assurance;dynamic safety cases;through-life safety assurance concept;proactive safety management;aviation systems domain;safety principles;safety lifecycle","","16","17","","","","","IEEE","IEEE Conferences"
"A Unified Framework for the Comprehension of Software's Time","O. Benomar; H. Sahraoui; P. Poulin","Dept. I.R.O., Univ. de Montreal, Montreal, QC, Canada; Dept. I.R.O., Univ. de Montreal, Montreal, QC, Canada; Dept. I.R.O., Univ. de Montreal, Montreal, QC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","603","606","The dimension of time in software appears in both program execution and software evolution. Much research has been devoted to the understanding of either program execution or software evolution, but these two research communities have developed tools and solutions exclusively in their respective context. In this paper, we claim that a common comprehension framework should apply to the time dimension of software. We formalize this as a meta-model that we instantiate and apply to the two different comprehension problems.","","","10.1109/ICSE.2015.203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203023","","Software;Heating;Visualization;Collaboration;History;Measurement;Context","software maintenance","software time dimension;program execution;software evolution;meta-model;comprehension framework;software maintenance","","","19","","","","","IEEE","IEEE Conferences"
"Mining the Metadata -- and Its Consequences","S. Landau","Worcester Polytech. Inst., Worcester, MA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","4","5","Traditionally metadata, the who, when, where of a phone call, the IP address, time, date of an Internet connection, has been viewed as deserving of less privacy than the contents of the communication. But ubiquitous computing and communication has changed that equation, and such transactional information has become increasingly revelatory. In this talk, I will discuss how metadata is used in all sorts of investigations, from malware to malfeasance. I will also discuss how the ubiquity of metadata must mean a change in our approaches to it.","","","10.1109/ICSE.2015.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194556","","Metadata;Privacy;Security;Surveillance;Data privacy;Law","data mining;data privacy;Internet;invasive software;meta data;ubiquitous computing","metadata mining;phone call;IP address;Internet connection;ubiquitous computing;transactional information;malware;malfeasance;metadata ubiquity","","1","13","","","","","IEEE","IEEE Conferences"
"FormTester: Effective Integration of Model-Based and Manually Specified Test Cases","R. Dixit; C. Lutteroth; G. Weber","Dept. of Comput. Sci., Univ. of Auckland, Auckland, New Zealand; Dept. of Comput. Sci., Univ. of Auckland, Auckland, New Zealand; Dept. of Comput. Sci., Univ. of Auckland, Auckland, New Zealand","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","745","748","Whilst Model Based Testing (MBT) is an improvement over manual test specification, the leap from it to MBT can be hard. Only recently MBT tools for Web applications have emerged that can recover models from existing manually specified test cases. However, there are further requirements for supporting both MBT and manually specified tests. First, we need support for the generation of test initialization procedures. Also, we want to identify areas of the system that are not testable due to defects. We present Form Tester, a new MBT tool addressing these limitations. An evaluation with real Web applications shows that Form Tester helps to reduce the time spent on developing test cases.","","","10.1109/ICSE.2015.237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203058","","Manuals;Testing;Adaptation models;Automation;Software engineering;Computational modeling;Writing","formal specification;program testing","FormTester;model-based test case;manually-specified test case;model-based testing;Web applications;MBT tools;test initialization procedure generation","","","9","","","","","IEEE","IEEE Conferences"
"A Combined Technique of GUI Ripping and Input Perturbation Testing for Android Apps","G. Imparato","Univ. of Naples ‚ÄúFederico II‚Äù, Naples, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","760","762","Mobile applications have become an integral part of the daily lives of millions of users, thus making necessary to ensure their security and reliability. Moreover the increasing number of mobile applications with rich Graphical User Interfaces (GUI) creates a growing need for automated techniques of GUI Testing for mobile applications. In this paper, the GUI Ripping Technique is combined with the Input Perturbation Testing to improve the quality of Android Application Testing. The proposed technique, based on a systematic and automatic exploration of the behavior of Android applications, creates a model of the explored GUI and then uses it to generate the perturbed text inputs. The technique was evaluated on many Android apps and its results were compared with random input tests.","","","10.1109/ICSE.2015.241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203062","Android Application Testing;GUI Ripping;Testing Automation;Input Perturbation Testing","Graphical user interfaces;Testing;Androids;Humanoid robots;Mobile applications;Computer bugs;Software engineering","Android (operating system);graphical user interfaces;mobile computing;program testing;security of data;software quality;software reliability","GUI ripping technique;input perturbation testing;graphical user interfaces;GUI testing automated techniques;mobile applications;Android application testing;perturbed text input generation;random input tests","","5","16","","","","","IEEE","IEEE Conferences"
"1st International Workshop on Complex faUlts and Failures in LargE Software Systems (COUFLESS 2015)","M. Grechanik; J. Alonso; A. P. Nikora","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","971","972","COUFLESS is a one-day workshop that starts with keynote speaker, Prof. Kishor S. Trivedi from Duke University, North Carolina, USA whose talk's title is titled: ""Why Does Software Fail and What Should be Done About It?""¬†¬†¬†A total of 15 papers were submitted to COUFLESS with 53 authors from nine countries and each paper received at least three reviews by the 26 members of the program committee from 11 countries, making it a truly International Workshop. After a long discussion, 11 papers were accepted with the acceptance rate of 73%. Accepted papers address the issues of localizing and debugging complex faults in large-scale software applications.","","","10.1109/ICSE.2015.310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203133","Workshop;Mandelbug;failure;debugging","Conferences;Databases;Debugging;Software systems;Committees","","","","","","","","","","IEEE","IEEE Conferences"
"Scalability Studies on Selective Mutation Testing","J. Zhang","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","851","854","Mutation testing is a test method which is designed to evaluate a test suite's quality. Due to the expensive cost of mutation testing, selective mutation testing was first proposed in 1991 by Mathur, in which a subset of mutants are selected aiming to achieve the same effectiveness as the whole set of mutants in evaluating the quality of test suites. Though selective mutation testing has been widely investigated in recent years, many people still doubt if it can suit well for large programs. Realizing that none of the existing work has systematically studied the scalability of selective mutation testing, I plan to work on the scalability of selective mutation testing through several studies.","","","10.1109/ICSE.2015.276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203097","","Testing;Scalability;Software;Medical services;Predictive models;Java;Measurement","program testing","scalability studies;selective mutation testing","","1","20","","","","","IEEE","IEEE Conferences"
"Capsule-Oriented Programming","H. Rajan","Dept. of Comput. Sci., Iowa State Univ. of Sci. & Technol., Ames, IA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","611","614","‚ÄúExplicit concurrency should be abolished from all higher-level programming languages (i.e. everything except - perhaps- plain machine code.).‚Äù Dijkstra [1] (paraphrased). A promising class of concurrency abstractions replaces explicit concurrency mechanisms with a single linguistic mechanism that combines state and control and uses asynchronous messages for communications, e.g. active objects or actors, but that doesn't remove the hurdle of understanding non-local control transfer. What if the programming model enabled programmers to simply do what they do best, that is, to describe a system in terms of its modular structure and write sequential code to implement the operations of those modules and handles details of concurrency? In a recently sponsored NSF project we are developing such a model that we call capsule-oriented programming and its realization in the Panini project. This model favors modularity over explicit concurrency, encourages concurrency correctness by construction, and exploits modular structure of programs to expose implicit concurrency.","","","10.1109/ICSE.2015.205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203025","Modularity;implicit concurrency;programming model;modular structure;concurrency abstraction;capsules","Concurrent computing;Programming;Java;Synchronization;Global Positioning System;Program processors;Message systems","concurrency (computers);high level languages;software engineering","capsule-oriented programming;higher-level programming languages;concurrency abstractions;explicit concurrency mechanisms;single linguistic mechanism;nonlocal control transfer;sequential code;NSF project;Panini project","","6","33","","","","","IEEE","IEEE Conferences"
"Statistical Learning and Software Mining for Agent Based Simulation of Software Evolution","V. Honsel","Inst. of Comput. Sci., Univ. of Gottingen, Gottingen, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","863","866","In the process of software development it is of high interest for a project manager to gain insights about the ongoing process and possible development trends at several points in time. Substantial factors influencing this process are, e.g., the constellation of the development team, the growth and complexity of the system, and the error-proneness of software entities. For this purpose we build an agent based simulation tool which predicts the future of a project under given circumstances, stored in parameters, which control the simulation process. We estimate these parameters with the help of software mining. Our work exposed the need for a more fine-grained model for the developer behavior. Due to this we create a learning model, which helps us to understand the contribution behavior of developers and, thereby, to determine simulation parameters close to reality. In this paper we present our agent based simulation model for software evolution and describe how methods from statistical learning and data mining serves us to estimate suitable simulation parameters.","","","10.1109/ICSE.2015.279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203100","Software Process Simulation;Hidden Markov Model;Agent Based Modeling;Developer Behavior","Hidden Markov models;Software;Object oriented modeling;Data models;Data mining;Predictive models;Adaptation models","data mining;digital simulation;learning (artificial intelligence);parameter estimation;software agents;software engineering","statistical learning;software mining;agent based simulation tool;software evolution;software development process;parameter estimation","","4","17","","","","","IEEE","IEEE Conferences"
"An Approach to Detect Android Antipatterns","G. Hecht","Inria, Univ. of Lille 1, Lille, France","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","766","768","Mobile applications are becoming complex software systems that must be developed quickly and evolve regularly to fit new user requirements and execution contexts. However, addressing these constraints may result in poor design choices, known as antipatterns, which may degrade software quality and performance. Thus, the automatic detection of antipatterns is an important activity that eases the future maintenance and evolution tasks. Moreover, it helps developers to refactor their applications and thus, to improve their quality. While antipatterns are well-known in object-oriented applications, their study in mobile applications is still in their infancy. In this paper, we presents a tooled approach, called Paprika, to analyze Android applications and to detect object-oriented and Android-specific antipatterns from binaries of applications.","","","10.1109/ICSE.2015.243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203064","","Androids;Humanoid robots;Mobile communication;Java;Software;Measurement;Mobile applications","Android (operating system);mobile computing;software maintenance;software quality","Android antipattern detection;mobile applications;complex software systems;software quality degradation;software performance degradation;antipattern automatic detection;object-oriented applications;Paprika tooled approach;object-oriented detection","","7","22","","","","","IEEE","IEEE Conferences"
"2nd International Workshop on Crowd Sourcing in Software Engineering (CSI-SE 2015)","G. Fraser; T. D. LaToza; L. Mariani","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","975","976","Crowdsourcing is increasingly revolutionizing the ways in which software is engineered. Programmers increasingly crowdsource answering their questions through Q&A sites. Non-programmers may contribute human-intelligence to development projects, by, for example, usability testing software or even play games with a purpose to implicitly construct formal specifications. Crowdfunding helps to democratize decisions about what software to build. Software engineering researchers may even benefit from new opportunities to evaluate their work with real developers by recruiting developers from the crowd. CSI- SE will inform the software engineering community of current techniques and trends in crowdsourcing, discuss the application of crowdsourcing to software engineering to date, and identify new opportunities to apply crowdsourcing to solve software engineering problems.","","","10.1109/ICSE.2015.312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203135","","Crowdsourcing;Software engineering;Conferences;Usability;Testing;Games","","","","","","","","","","IEEE","IEEE Conferences"
"DIETs: Recommender Systems for Mobile API Developers","S. Beyer","Univ. of Klagenfurt, Klagenfurt, Austria","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","859","862","The increasing number of posts related to mobile app development indicates unaddressed problems in the usage of mobile APIs. Arguing that these problems result from in- adequate documentation and shortcomings in the design and implementation of the APIs, the goal of this research is to develop and evaluate two developers' issues elimination tools (DIETs) for mobile API developers to diminish the problems of mobile applications (apps) development.After categorizing the problems, we investigate their causes, by exploring the relationships between the topics and trends of posts on Stack Overflow, the app developers' experience, the API and test code, and its changes. The results of these studies will be used to develop two DIETs that support API developers to improve the documentation, design, and implementation of their APIs.","","","10.1109/ICSE.2015.278","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203099","recommender systems;api;mobile api developers","Mobile communication;Documentation;Smart phones;Androids;Humanoid robots;Software engineering;Data mining","application program interfaces;mobile computing;recommender systems;system documentation","DIET;recommender systems;mobile API developers;mobile app development;developer issues elimination tool;mobile application development;Stack Overflow;app developer experience;test code;system documentation","","","20","","","","","IEEE","IEEE Conferences"
"Combining Mastery Learning with Project-Based Learning in a First Programming Course: An Experience Report","M. Jazayeri","Univ. of Lugano, Lugano, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","315","318","One of the challenges in teaching a first programming course is that in the same course, the students must learn basic programming techniques and high level abstraction abilities, and the application of those techniques and concepts in problem solving and (engineering) design. To confront this challenge, in previous years, we have included a project-based learning phase at the end of our course to encourage the acquisition of high level design and creativity. To address some of the shortcomings of our previous editions, we have recently included a mastery phase to the course. While project-based learning is suitable for teaching high-level skills that require design and creativity and prepare the students for the study of software engineering, mastery-based learning is suitable for concrete skills such as basic programming tasks. Our particular innovation is to allow students into the project phase only if they have demonstrated a minimum predefined competency level in programming. The combination of the two approaches seems to address most of the requirements of a first programming course. We present our motivation for combining the two pedagogical techniques and our experience with the course.","","","10.1109/ICSE.2015.163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202980","first programming course;mastery learning;project-based learning;CS1/CS2;introductory programming;software engineering education","Programming profession;Education;Software engineering;Concrete;Software;Java","computer science education;educational courses;programming;teaching","mastery learning;project-based learning;programming course;basic programming techniques;high level abstraction abilities;high-level skills teaching;programming competency level","","4","10","","","","","IEEE","IEEE Conferences"
"A Unified Approach to Automatic Testing of Architectural Constraints","A. Caracciolo","Software Composition Group, Univ. of Bern, Bern, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","871","874","Architectural decisions are often encoded in the form of constraints and guidelines. Non-functional requirements can be ensured by checking the conformance of the implementation against this kind of invariant. Conformance checking is often a costly and error-prone process that involves the use of multiple tools, differing in effectiveness, complexity and scope of applicability. To reduce the overall effort entailed by this activity, we propose a novel approach that supports verification of human-readable declarative rules through the use of adapted off-the-shelf tools. Our approach consists of a rule specification DSL, called Dicto, and a tool coordination framework, called Probo. The approach has been implemented in a soon to be evaluated prototype.","","","10.1109/ICSE.2015.281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203102","software architecture;conformance checking;architectural constraints","Testing;Software architecture;Software;DSL;Guidelines;Stakeholders;Computer architecture","automatic test software;formal specification;program testing;software architecture","unified approach;automatic architectural constraint testing;architectural decisions;nonfunctional requirements;conformance checking;error-prone process;human-readable declarative rule verification;rule specification DSL;Dicto;tool coordination framework;Probo","","","16","","","","","IEEE","IEEE Conferences"
"The Future of Software Engineering (SEIP Keynote)","G. Booch","IBM Res., Austin, TX, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","3","3","Summary form only given. No matter what future we may envision, it relies on software that has not yet been written. Even now, software-intensive systems have woven themselves into the interstitial spaces of civilization, and we as individuals and as a species have slowly surrendered ourselves to computing. Looking back, we can identify several major and distinct styles whereby we have built such systems. We have come a long way, and even today, we certainly can name a number of best practices for software development that yield systems of quality. However, by no means can we stand still: the nature of the systems we build continues to change, and as they collectively weave themselves into our live, we must attend not only to the technical elements of software development, we must also attend to human needs. In this presentation we will look at the history of software engineering and offer some grand challenges for the future.","","","10.1109/ICSE.2015.128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202943","software engineering;history;future","Software engineering;Software;Weaving;Computer architecture;Conferences;Best practices;History","software engineering","software engineering;software-intensive systems;interstitial civilization spaces;software development","","","","","","","","IEEE","IEEE Conferences"
"A Large Scale Study of License Usage on GitHub","C. Vendome","Coll. of William & Mary, Williamsburg, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","772","774","The open source community relies upon licensing in order to govern the distribution, modification, and reuse of existing code. These licenses evolve to better suit the requirements of the development communities and to cope with unaddressed or new legal issues. In this paper, we report the results of a large empirical study conducted over the change history of 16,221 open source Java projects mined from Git Hub. Our study investigates how licensing usage and adoption changes over a period of ten years. We consider both the distribution of license usage within projects of a rapidly growing forge and the extent that new versions of licenses are introduced in these projects.","","","10.1109/ICSE.2015.245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203066","Software Licenses;Mining Software Repositories;Empirical Studies","Licenses;Software;Conferences;Software engineering;Data mining;Law","Java;law;public domain software;software reusability","license usage;GitHub;open source community;licensing;code distribution;code modification;code reuse;development communities;legal issues;open source Java projects;license distribution","","10","16","","","","","IEEE","IEEE Conferences"
"Automatic Categorization of Software Libraries Using Bytecode","J. Escobar-Avila","Dept. of Comput. Sci., Florida State Univ., Tallahassee, FL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","784","786","Automatic software categorization is the task of assigning categories or tags to software libraries in order to summarize their functionality. Correctly assigning these categories is essential to ensure that relevant libraries can be easily retrieved by developers from large repositories. Current categorization approaches rely on the semantics reflected in the source code, or use supervised machine learning techniques, which require a set of labeled software as a training data. These approaches fail when such information is not available. We propose a novel unsupervised approach for the automatic categorization of Java libraries, which uses the bytecode of a library in order to determine its category. We show that the approach is able to successfully categorize libraries from the Apache Foundation Repository.","","","10.1109/ICSE.2015.249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203070","software categorization;bytecode;clustering;dirichlet process;automatic labeling","Software;Software libraries;Data mining;Accuracy;Conferences;Semantics","Java;software libraries;source code (software);unsupervised learning","automatic software library categorization;bytecode;source code;unsupervised approach;Java libraries;Apache Foundation Repository","","1","11","","","","","IEEE","IEEE Conferences"
"7th International Workshop on Principles of Engineering Service-Oriented and Cloud Systems (PESOS 2015)","M. A. Babar; H. Paik; M. Chetlur; M. Bauer; A. M. Sharifloo","NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","987","988","PESOS has established itself as a forum that brings together software engineering researchers and practitioners working in the areas of service-oriented systems to discuss research challenges, new developments and applications, as well as methods, techniques, experiences, and tools to support engineering, evolution and adaptation of service-oriented systems. The technical advances and growing adoption of Cloud computing is creating new challenges for the PESOS the software services community to explore the approaches to better engineer software systems that are designed, developed, operated and governed in the context of the Cloud. We again attracted high-quality submissions on a diverse set of relevant topics such as better approaches to engineering service-based collaborative systems, Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS) models of cloud computing and associated software quality attributes. PESOS 2015 will continue to be the key forum for collecting case studies and artifacts for educators and researchers in this area.","","","10.1109/ICSE.2015.318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203141","Software engineering;software services;collaborative services;cloud computing;cloud services;SOA;service-oriented architecture;service-oriented systems","Conferences;Collaboration;Software as a service;Cloud computing;Service-oriented architecture","","","","","","","","","","IEEE","IEEE Conferences"
"Mining Software Repositories for Social Norms","H. K. Dam; B. T. R. Savarimuthu; D. Avery; A. Ghose","Univ. of Wollongong, Wollongong, NSW, Australia; Univ. of Otago, Dunedin, New Zealand; Univ. of Wollongong, Wollongong, NSW, Australia; Univ. of Wollongong, Wollongong, NSW, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","627","630","Social norms facilitate coordination and cooperation among individuals, thus enable smoother functioning of social groups such as the highly distributed and diverse open source software development (OSSD) communities. In these communities, norms are mostly implicit and hidden in huge records of human-interaction information such as emails, discussions threads, bug reports, commit messages and even source code. This paper aims to introduce a new line of research on extracting social norms from the rich data available in software repositories. Initial results include a study of coding convention violations in JEdit, Argo UML and Glassfish projects. It also presents a new life-cycle model for norms in OSSD communities and demonstrates how a number of norms extracted from the Python development community follow this life-cycle model.","","","10.1109/ICSE.2015.209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203029","","Encoding;Software;Proposals;Electronic mail;Java;Data mining;Monitoring","data mining;public domain software;software engineering;source code (software)","software repository mining;social norm extraction;open source software development community;OSSD community;human-interaction information;source code;JEdit;Argo UML;Glassfish projects;life-cycle model;Python development community","","4","8","","","","","IEEE","IEEE Conferences"
"Bixie: Finding and Understanding Inconsistent Code","T. McCarthy; P. R√ºmmer; M. Sch√§f","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","645","648","We present Bixie, a tool to detect inconsistencies in Java code. Bixie detectsinconsistent code at a higher precision than previous tools and provides novelfault localization techniques to explain why code is inconsistent. Wedemonstrate the usefulness of Bixie on over one million lines of code, showthat it can detect inconsistencies at a low false alarm rate, and fix a numberof inconsistencies in popular open-source projects. Watch our Demo at http://youtu.be/QpsoUBJMxhk.","","","10.1109/ICSE.2015.213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203033","","Java;Arrays;Benchmark testing;Runtime;Unsolicited electronic mail;Computer bugs;Open source software","Java;program compilers;program diagnostics;software fault tolerance","Bixie;inconsistent code finding;inconsistent code understanding;Java code;fault localization technique;open-source projects","","1","12","","","","","IEEE","IEEE Conferences"
"Strategies for Prioritizing Test Cases Generated Through Model-Based Testing Approaches","J. F. S. Ouriques","NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","879","882","Software testing is expensive and time consuming,especially for complex software. In order to deal with the costof testing, researchers develop Model-Based Testing (MBT). InMBT, test cases are generated automatically and a drawback isa huge generated test suite. Our research aims at studying the Test Case Prioritization problem in MBT context. So far, we already evaluated the influence of the model structure and the characteristics of the test cases that fail. Results suggest that the former does not affect significantly the performance of techniques, however, the latter indeed represents a major impact. Therefore, a worthy information in this context might be an expert who knows the crucial parts of the software, thus we propose the first version of a prioritization technique that considers hints from the expert and the distance notion in order to prioritize test cases. Evaluation and tuning of the technique are ongoing, but preliminary evaluation reveals promising results.","","","10.1109/ICSE.2015.338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203104","","Testing;Context;Unified modeling language;Software;Context modeling;Software engineering;Conferences","program testing","test case generation;model-based testing approach;software testing;MBT;test case prioritization problem;prioritization technique","","2","27","","","","","IEEE","IEEE Conferences"
"Casper: Using Ghosts to Debug Null Deferences with Dynamic Causality Traces","B. Cornu","Univ. of Lille, Lille, France","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","790","791","Fixing software errors requires understanding their root cause. In this paper, we introduce ""causality traces'', they are specially crafted execution traces augmented with the information needed to reconstruct a causal chain from a root cause to an execution error. We propose an approach and a tool, called Casper, for dynamically constructing causality traces for null dereference errors. The core idea of Casper is to inject special values, called ""ghosts"", into the execution stream to construct the causality trace at runtime. We evaluate our contribution by providing and assessing the causality traces of 14 real null dereference bugs collected over six large, popular open-source projects.","","","10.1109/ICSE.2015.251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203072","","Null value;Computer bugs;Debugging;History;Runtime;Open source software;Java","program debugging;software tools","Casper;null deference error debug;dynamic causality traces;software error fixing;execution error;ghosts;open-source projects","","","3","","","","","IEEE","IEEE Conferences"
"4th SEMAT Workshop on General Theory of Software Engineering (GTSE 2015)","P. Ralph; G. Engels; I. Jacobson; M. Goedicke","Univ. of Auckland, Auckland, New Zealand; Univ. of Paderborn, Paderborn, Germany; Ivar Jacobson Int., Verbier, Switzerland; Uni Duisburg-Essen, Paluno, Duisburg-Essen, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","983","984","General theories explain the fundamental phenomena that constitute a research domain. They apply across a domain and often integrate many theories and concepts into a single cohesive view. While general theories are extremely important for education and research coordination, and common in many disciplines (e.g. sociology, criminology, electrical engineering, biology, physics), software engineering lacks a well-accepted general theory. The General Theory of Software Engineering workshop seeks to rectify this situation by promoting theory development in software engineering. The fourth workshop in this series, held in conjunction with the International Conference on Software Engineering, displayed a promising trend toward more theory development papers.","","","10.1109/ICSE.2015.316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203139","Research methodology;process theory;questionnaire;case study;field study","Software engineering;Conferences;Software;Jacobian matrices;Concrete;Complexity theory;Education","software engineering","SEMAT;Software Engineering Method and Theory;General Theory of Software Engineering;GTSE workshop","","","16","","","","","IEEE","IEEE Conferences"
"ViDI: The Visual Design Inspector","Y. Tymchuk; A. Mocci; M. Lanza","REVEAL @ Fac. of Inf., Univ. of Lugano, Lugano, Switzerland; REVEAL @ Fac. of Inf., Univ. of Lugano, Lugano, Switzerland; REVEAL @ Fac. of Inf., Univ. of Lugano, Lugano, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","653","656","We present ViDI (Visual Design Inspector), a novel code review tool which focuses on quality concerns and design inspection as its cornerstones. It leverages visualization techniques to represent the reviewed software and augments the visualization with the results of quality analysis tools. To effectively understand the contribution of a reviewer in terms of the impact of her changes on the overall system quality, ViDI supports the recording and further inspection of reviewing sessions. ViDI is an advanced prototype which we will soon release to the Pharo open-source community.","","","10.1109/ICSE.2015.215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203035","Lugano","Visualization;Inspection;Quality assessment;Software systems;Software engineering;Birds","data visualisation;software quality;software reviews;software tools","ViDI;visual design inspector;code review tool;visualization technique;system quality","","2","11","","","","","IEEE","IEEE Conferences"
"Measuring Software Developers' Perceived Difficulty with Biometric Sensors","S. C. M√ºller","Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","887","890","As a developer works on a change task, he or she might perceive some parts of the task as easy and other parts as being very difficult. Currently, little is known about when a developer experiences different difficulty levels, although being able to assess these difficulty levels would be helpful for many reasons. For instance, a developer's perceived difficulty might be used to determine the likelihood of a bug being introduced into the code or the quality of the code a developer is working with. In psychology, biometric measurements, such as electro-dermal activity or heart rate, have already been extensively used to assess a person's mental state and emotions, but only little research has been conducted to investigate how these sensors can be used in the context of software engineering. In our research we want to take advantage of the insights gained in these psychological studies and investigate whether such biometric sensors can be used to measure developers' perceived difficulty while working on a change task and support them in their work.","","","10.1109/ICSE.2015.284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203106","","Biosensors;Software;Software engineering;Software measurement;Psychology","sensors;software quality","software developer measurement;biometric sensors;code quality;biometric measurements;psychology;electro-dermal activity;heart rate;person mental state assessment;emotion assessment;software engineering","","2","33","","","","","IEEE","IEEE Conferences"
"Poster: Improving Cloud-Based Continuous Integration Environments","A. Gambi; Z. Rostyslav; S. Dustdar","Distrib. Syst. Group, Vienna Univ. of Technol., Vienna, Austria; Distrib. Syst. Group, Vienna Univ. of Technol., Vienna, Austria; Distrib. Syst. Group, Vienna Univ. of Technol., Vienna, Austria","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","797","798","We propose a novel technique for improving the efficiency of cloud-based continuous integration development environments. Our technique identifies repetitive, expensive and time-consuming setup activities that are required to run integration and system tests in the cloud, and consolidates them into preconfigured testing virtual machines such that the overall costs of test execution are minimized. We create such testing machines by reconfiguring and opportunistically snapshotting the virtual machines already registered in the cloud.","","","10.1109/ICSE.2015.253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203074","integration test;test-driven development;snapshot;system tests;linear programming;cost flow;flow constraints","Virtual machining;Software;Servers;Standards;Load modeling;Software testing","cloud computing;virtual machines","of cloud-based continuous integration development environments;preconfigured testing virtual machines;test execution cost;testing machines","","3","6","","","","","IEEE","IEEE Conferences"
"3rd International Workshop on Release Engineering (RELENG 2015)","B. Adams; S. Bellomo; C. Bird; F. Khomh; K. Moir","NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","995","996","Release engineering deals with all activities inbetween regular development and actual usage of asoftware product by the end user, i.e., integration, build, testexecution, packaging and delivery of software. Although re-search on this topic goes back for decades, the increasing heterogeneity and variability of software products along withthe recent trend to reduce the release cycle to days or even hoursstarts to question some of the common beliefs and practicesof the field. For example, a project like Mozilla Firefox releasesevery 6 weeks, generating updates for dozens of existing Fire-fox versions on 5 desktop, 2 mobile and 3 mobile desktopplatforms, each of which for more than 80 locales. In this con-text, the International Workshop on Release Engineering(RELENG) aims to provide a highly interactive forum for re-searchers and practitioners to address the challenges of, findsolutions for and share experiences with release engineering, and to build connections between the various communities.","","","10.1109/ICSE.2015.321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203145","release engineering;integration;build system;test execution;packaging;deployment;continuous delivery","Software;Conferences;Software engineering;Google;Packaging;Testing;Maintenance engineering","","","","","11","","","","","IEEE","IEEE Conferences"
"Source Code Curation on StackOverflow: The Vesperin System","H. Sanchez; J. Whitehead","Comput. Sci. Dept., UC Santa Cruz, Santa Cruz, CA, USA; Comput. Media Dept., UC Santa Cruz, Santa Cruz, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","661","664","The past few years have witnessed the rise of software question and answer sites like StackOverflow, where developers can pose detailed coding questions and receive quality answers. Developers using these sites engage in a complex code foraging process of understanding and adapting the code snippets they encounter. We introduce the notion of source code curation to cover the act of discovering some source code of interest, cleaning and transforming (refining) it, and then presenting it in a meaningful and organized way. In this paper, we present Vesperin, a source code curation system geared towards curating Java code examples on StackOverflow.","","","10.1109/ICSE.2015.217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203037","","Java;Software;Aerospace electronics;Context;Programming;Software engineering","Java;software quality;source code (software)","Java code;complex code foraging process;Vesperin system;StackOverflow;source code curation system","","1","12","","","","","IEEE","IEEE Conferences"
"Search-Based Migration of Model Variants to Software Product Line Architectures","W. K. G. Assun√ß√£o","DINF, Fed. Univ. of Parana, Curitiba, Brazil","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","895","898","Software Product Lines (SPLs) are families of related software systems developed for specific market segments or domains. Commonly, SPLs emerge from sets of existing variants when their individual maintenance becomes infeasible. However, current approaches for SPL migration do not support design models, are partially automated, or do not reflect constraints from SPL domains. To tackle these limitations, the goal of this doctoral research plan is to propose an automated approach to the SPL migration process at the design level. This approach consists of three phases: detection, analysis and transformation. It uses as input the class diagrams and lists of features for each system variant, and relies on search-based algorithms to create a product line architecture that best captures the variability present in the variants. Our expected contribution is to support the adoption of SPL practices in companies that face the scenario of migrating variants to SPLs.","","","10.1109/ICSE.2015.286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203108","Reuse;Migration;Re-engineering;Software Product Line;Search-Based Software Engineering","Software;Feature extraction;Programmable logic arrays;Unified modeling language;Software product lines;Medical services","software architecture;software product lines","product line architecture;search-based algorithm;SPL migration process;SPL architecture;software product line architecture;search-based migration algorithm","","","24","","","","","IEEE","IEEE Conferences"
"An Integrated Multi-Agent-Based Simulation Approach to Support Software Project Management","D. d. M. Baia","NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","911","914","Software projects often do not accomplish what is expected. They fail to comply with the planned schedule, cost more than predicted, or are simply not completed at all owing to issues such as bad planning, a poorly chosen team or an incorrect definition of the tasks to be performed. Although simulation methods and tools have been introduced to alleviate these problems, there is a lack of simulation approaches that integrate software project knowledge, software development processes, project-related situation-awareness, and learning techniques to help project managers to make more informed decisions and hence reach successful conclusions with software projects. In addition, in order to be more proactive, such approaches need to provide simulations based on both static and dynamic situation-awareness data, support (self-)adaptive project planning and execution, and recommend remedial courses of action when real-time project anomalies occur. In this context, this PhD research aims to create an integrated multi-agent-based simulation to support software project management in a more comprehensive way.","","","10.1109/ICSE.2015.290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203112","software project management;multi-agent-based simulation","Software;Data models;Project management;Adaptation models;Planning;Real-time systems;Decision making","learning (artificial intelligence);multi-agent systems;planning;project management;software development management","integrated multiagent-based simulation approach;software project management;software development processes;project-related situation-awareness;learning techniques;static situation-awareness data;dynamic situation-awareness data;self-adaptive project planning","","2","11","","","","","IEEE","IEEE Conferences"
"Poster: Discovering Code Dependencies by Harnessing Developer's Activity","M. Konopka; P. Navrat; M. Bielikova","Fac. of Inf. & Inf. Technol., Slovak Univ. of Technol. in Bratislava, Bratislava, Slovakia; Fac. of Inf. & Inf. Technol., Slovak Univ. of Technol. in Bratislava, Bratislava, Slovakia; Fac. of Inf. & Inf. Technol., Slovak Univ. of Technol. in Bratislava, Bratislava, Slovakia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","801","802","Monitoring software developer's interactions in an integrated development environment is sought for revealing new information about developers and developed software. In this paper we present an approach for identifying potential source code dependencies solely from interaction data. We identify three kinds of potential dependencies and additionally assign them to developer's activity as well, to reveal detailed task-related connections in the source code. Interaction data as a source allow us to identify these candidates for dependencies even for dynamically typed programming languages, or across multiple languages in the source code. After first evaluations and positive results we continue with collecting data in professional environment of Web developers, and evaluating our approach.","","","10.1109/ICSE.2015.255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203076","Source code dependency;interaction data;task context;implicit feedback;dynamic typing","Navigation;Software;Syntactics;Context;Debugging;Maintenance engineering;Computer languages","programming environments;programming languages;software engineering;source code (software);system monitoring","source code dependency discovery;software developer interaction monitoring;integrated development environment;interaction data;programming languages;Web developers","","4","7","","","","","IEEE","IEEE Conferences"
"Poster: Symbolic Execution of MPI Programs","X. Fu; Z. Chen; H. Yu; C. Huang; W. Dong; J. Wang","State Key Lab. of High Performance Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; State Key Lab. of High Performance Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; State Key Lab. of High Performance Comput., Nat. Univ. of Defense Technol., Changsha, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","809","810","MPI is widely used in high performance computing. In this extended abstract, we report our current status of analyzing MPI programs. Our method can provide coverage of both input and non-determinism for MPI programs with mixed blocking and non-blocking operations. In addition, to improve the scalability further, a deadlock-oriented guiding method for symbolic execution is proposed. We have implemented our methods, and the preliminary experimental results are promising.","","","10.1109/ICSE.2015.259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203080","MPI;Symbolic Execution;Synchronous;Asynchronous;Deadlock","System recovery;Scalability;High performance computing;Runtime;Message passing;Standards;Space exploration","application program interfaces;message passing;parallel processing;program diagnostics;software reliability","MPI program symbolic execution;high performance computing;MPI program analysis;deadlock-oriented guiding method","","1","7","","","","","IEEE","IEEE Conferences"
"Second International Workshop on Software Architecture and Metrics (SAM 2015)","I. Ozkaya; R. L. Nord; H. Koziolek; P. Avgeriou","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","999","1000","Software engineers and architects of complex software systems need to balance hard quality attribute requirements while at the same time manage risks and make decisions with a system-wide and long-lasting impact. To achieve these tasks efficiently, they need quantitative information about design-time and run-time system aspects through usable and quick tools. While there is body of work focusing on code quality and metrics, their applicability at the design and architecture level and at scale are inconsistent and not proven. We are interested in exploring whether architecture can assist with better contextualizing existing system and code quality and metrics approaches. Furthermore, we ask whether we need additional architecture-level metrics to make progress and whether something as complex and subtle as software architecture can be quantified. The goal of this workshop is to discuss progress, gather empirical evidence, and identify priorities for a research agenda on architecture and metrics in the software engineering field.","","","10.1109/ICSE.2015.346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203147","Software architecture; metrics; software analytics; technical debt; software quality; software maintenance and evolution; empirical software engineering; qualitative methods","Computer architecture;Conferences;Software architecture;Software;Software measurement","","","","2","6","","","","","IEEE","IEEE Conferences"
"2nd International Workshop on Software Engineering Research and Industrial Practice (SER&IP 2015)","J. Bishop; R. Shukla; F. Shull; S. Sen","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1007","1008","Differing perceptions and expectations are obstaclesto collaboration between software engineering (SE) researchersand practitioners: Researchers often have a view thatpractitioners are reluctant to share real data. Practitionersbelieve that researchers are mostly working on topics which aredivorced from real industrial needs. Researchers believe thatpractitioners are looking for quick fixes. Practitioners have aview that case studies in research do not represent thecomplexities of real projects. Researchers may expect a few yearsto do research on a problem whereas practitioners expect a quicksolution that pays off immediately.Researchers and practitioners need to identify the gaps and todiscover the ways to collaborate to strengthen SE research andindustrial practice (IP). The main purpose of this workshop is tobring together researchers and practitioners to discuss thecurrent state of SE research and IP and to enhance collaborationbetween them. The SER&IP 2015 workshop provided a platformto share success stories of SE research-practice partnerships aswell as to discuss the challenges, through a day-long agenda ofkeynotes, paper presentations and round table discussions.","","","10.1109/ICSE.2015.352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203151","Software engineering research;industrial practice;researchers;practitioners;collaboration;challenges","Conferences;Industries;Software engineering;Collaboration;Software;Business;Australia","","","","","5","","","","","IEEE","IEEE Conferences"
"Extract Package Refactoring in ARIES","F. Palomba; M. Tufano; G. Bavota; R. Oliveto; A. Marcus; D. Poshyvanyk; A. De Lucia","Dept. of Manage. & Inf. Technol., Univ. of Salerno, Salerno, Italy; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Center for Appl. Software Eng., Free Univ. of Bolzano-Bozen, Bolzano, Italy; Dept. of Biosci. & Territory, Univ. of Molise, Campobasso, Italy; Dept. of Comput. Sci., Univ. of Texas, Austin, TX, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Manage. & Inf. Technol., Univ. of Salerno, Salerno, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","669","672","Software evolution often leads to the degradation of software design quality. In Object-Oriented (OO) systems, this often results in packages that are hard to understand and maintain, as they group together heterogeneous classes with unrelated responsibilities. In such cases, state-of-the-art re-modularization tools solve the problem by proposing a new organization of the existing classes into packages. However, as indicated by recent empirical studies, such approaches require changing thousands of lines of code to implement the new recommended modularization. In this demo, we present the implementation of an Extract Package refactoring approach in ARIES (Automated Refactoring In EclipSe), a tool supporting refactoring operations in Eclipse. Unlike state-of-the-art approaches, ARIES automatically identifies and removes single low-cohesive packages from software systems, which represent localized design flaws in the package organization, with the aim to incrementally improve the overall quality of the software modularisation.","","","10.1109/ICSE.2015.219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203039","","Couplings;Measurement;Iterative closest point algorithm;Software engineering;Software systems;Organizations","object-oriented programming;software maintenance;software quality;software tools","extract package refactoring;ARIES tool;software evolution;software design quality degradation;OO systems;object-oriented systems;re-modularization tools;automated refactoring in EclipSe;single low-cohesive packages;software systems;localized design flaws;software modularisation","","2","7","","","","","IEEE","IEEE Conferences"
"FLEXISKETCH TEAM: Collaborative Sketching and Notation Creation on the Fly","D. W√ºest; N. Seyff; M. Glinz","Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","685","688","When software engineers collaborate, they frequently use whiteboards or paper for sketching diagrams. This is fast and flexible, but the resulting diagrams cannot be interpreted by software modeling tools. We present FLEXISKETCH TEAM, a tool solution consisting of a significantly extended version of our previous, single-user FLEXISKETCH tool for Android devices and a new desktop tool. Our solution for collaborative, model-based sketching of free-form diagrams allows users to define and re-use diagramming notations on the fly. Several users can work simultaneously on the same model sketch with multiple tablets. The desktop tool provides a shared view of the drawing canvas which can be projected onto an electronic whiteboard. Preliminary results from an exploratory study show that our tool motivates meeting participants to actively take part in sketching as well as defining ad-hoc notations.","","","10.1109/ICSE.2015.223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203043","","Metamodeling;Libraries;Collaboration;Object oriented modeling;Software;Conferences;Unified modeling language","mobile computing;software engineering;software tools","FLEXISKETCH team;collaborative sketching;software modeling tools;Android devices;desktop tool;single-user FLEXISKETCH tool;collaborative model-based sketching;free-form diagrams;diagramming notation creation on the fly;electronic whiteboard;multiple tablets","","7","19","","","","","IEEE","IEEE Conferences"
"Contributor's Performance, Participation Intentions, Its Influencers and Project Performance","A. Rastogi","Indraprastha Inst. of Inf. Technol., Delhi, India","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","919","922","Software project performance largely depends on the software development team. Studies have shown that interest and activity levels of contributors at any time significantly affect project success measures. This dissertation provides suggestions to enhance contributors' performance and participation intentions to help improve project performance. To do so, we mine historical data in software repositories from a two-pronged approach: 1) To assess contributors' performance to identify strengths and areas of improvement. 2) To measure the influence of factors on contributors' participation and performance, and provide suggestions that help advance contributor's engagement. The methodology used in this study leverage empirical techniques, both quantitative and qualitative, to conduct the analysis. We believe that the insights presented here will help contributors improve their performance. Also, we expect managers and business analysts to benefit from the suggestions to revise factors that negatively influence contributors' engagement and hence improve project performance.","","","10.1109/ICSE.2015.292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203114","Mining Software Repositories;Performance;Participation Intentions;Software Projects","Atmospheric measurements;Particle measurements;Open source software;Data mining;Software measurement;Software engineering","data mining;project management;software development management","participation intentions;project performance;contributor performance;software project performance;software development team;historical data mining;software repository;contributor engagement","","","35","","","","","IEEE","IEEE Conferences"
"Poster: Enhancing Partition Testing through Output Variation","H. Liu; P. Poon; T. Y. Chen","RMIT Univ., Melbourne, VIC, Australia; Hong Kong Polytech. Univ., Hong Kong, China; Swinburne Univ. of Technol., Hawthorn, VIC, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","805","806","A major test case generation approach is to divide the input domain into disjoint partitions, from which test cases can be selected. However, we observe that in some traditional approaches to partition testing, the same partition may be associated with different output scenarios. Such an observation implies that the partitioning of the input domain may not be precise enough for effective software fault detection. To solve this problem, partition testing should be fine-tuned to additionally use the information of output scenarios in test case generation, such that these test cases are more fine-grained not only with respect to the input partitions but also from the perspective of output scenarios.","","","10.1109/ICSE.2015.257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203078","partition testing;choice relation framework;output scenario","Testing;Software;Concrete;Conferences;Software engineering;Fault detection;Indexes","fault diagnosis;program testing;software fault tolerance","partition testing;test case generation approach;disjoint partitions;output variation;software fault detection;input domain partitioning","","","5","","","","","IEEE","IEEE Conferences"
"Poster: Dynamic Analysis Using JavaScript Proxies","L. Christophe; C. De Roover; W. De Meuter","Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium; Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium; Software Languages Lab., Vrije Univ. Brussel, Brussels, Belgium","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","813","814","JavaScript has become a popular programming language. However, its highly dynamic nature encumbers static analysis for quality assurance purposes. Only dynamic techniques such as concolic testing seem to cope. Often, these involve an instrumentation phase in which source code is extended with analysis-specific concerns. The corresponding implementations represent a duplication of engineering efforts. To facilitate developing dynamic analyses for JavaScript, we introduce Aran; a general-purpose JavaScript instrumenter that takes advantage of proxies, a recent addition to the JavaScript reflection APIs.","","","10.1109/ICSE.2015.261","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203082","Dynamic Analysis;JavaScript;Harmony Proxy;Instrumentation;ECMAScript6","Instruments;Performance analysis;Testing;Shadow mapping;Runtime;Browsers","authoring languages;Java;program diagnostics;program testing;quality assurance;software quality;source code (software)","JavaScript proxies;dynamic program analysis;programming language;quality assurance;static program analysis;concolic testing;source code;instrumentation phase;Aran general-purpose JavaScript instrumenter;JavaScript reflection APIs","","1","9","","","","","IEEE","IEEE Conferences"
"SE4HPCS'15: The 2015 International Workshop on Software Engineering for High Performance Computing in Science","J. C. Carver; N. Chue Hong; P. Ciancarini","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1003","1004","HPC software is developed and used in a wide variety of scientific domains including nuclear physics, computational chemistry, crash simulation, satellite data processing, fluid dynamics, climate modeling, bioinformatics, and vehicle development. The increase in the importance of this software motivates the need to identify and understand appropriate software engineering (SE) practices for HPC architectures. Because of the variety of the scientific domains addressed using HPC, existing SE tools and techniques developed for the business/IT community are often not efficient or effective. Appropriate SE solutions must account for the salient characteristics of the HPC, research oriented development environment. This situation creates a need for members of the SE community to interact with members of the scientific and HPC communities to address this need. This workshop facilitates that collaboration by bringing together members of the SE, the scientific, and the HPC communities to share perspectives and present findings relevant to research, practice, and education. A significant portion of the workshop is devoted to focused interaction among the participants with the goal of generating a research agenda to improve tools, techniques, and experimental methods regarding SE for HPC science.","","","10.1109/ICSE.2015.324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203149","Software Engineering;Computational Science;Computational Engineering;High Performance Computing","Software;Conferences;Software engineering;Computer architecture;Scientific computing;Computational modeling;High performance computing","","","","","7","","","","","IEEE","IEEE Conferences"
"Varis: IDE Support for Embedded Client Code in PHP Web Applications","H. V. Nguyen; C. K√§stner; T. N. Nguyen","ECpE Dept., Iowa State Univ., Ames, IA, USA; Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA; ECpE Dept., Iowa State Univ., Ames, IA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","693","696","In software development, IDE services are used to assist developers in programming tasks. In dynamic web applications, however, since the client-side code is embedded in the server-side program as string literals, providing IDE services for such embedded code is challenging. We introduce Varis, a tool that provides services on the embedded client-side code. We perform symbolic execution on a PHP program to approximate its output and parse it into a VarDOM that compactly represents all its DOM variations. Using the VarDOM, we implement various types of IDE services for embedded client code including syntax highlighting, code completion, and 'find declaration'.","","","10.1109/ICSE.2015.225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203045","IDE services;embedded code;web applications","HTML;Syntactics;Cascading style sheets;Servers;Presses;Approximation methods","embedded systems;Internet;programming environments","Varis tool;IDE support services;embedded client-side code;PHP Web applications;software development;programming tasks;server-side program;symbolic execution;VarDOM;editor services","","3","10","","","","","IEEE","IEEE Conferences"
"Software Requirements Patterns - A State of the Art and the Practice","X. Franch","Group of Software & Service Eng. (GESSI), Univ. Politec. de Catalunya (UPC-BarcelonaTech), Barcelona, Spain","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","943","944","Software requirement patterns are an increasingly popular approach to knowledge reuse in the requirements engineering phase. Several research proposals have been formulated in the last years, and this technical briefing presents them. Beyond that, a report on the current adoption of these proposals (or any other ad-hoc approach) in industry is presented. This state of the practice will show that the need to pave the road to successful adoption still persists.","","","10.1109/ICSE.2015.298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203120","Software Requirements Patterns;Requirements Engineering;Patterns;Requirements Reuse;Knowledge Engineering;Empirical Study;Literature Review;Survey","Software;Requirements engineering;Software engineering;Bibliographies;Systematics;Proposals;Industries","formal specification;formal verification;object-oriented programming;systems analysis","software requirement patterns;knowledge reuse;requirements engineering","","1","16","","","","","IEEE","IEEE Conferences"
"Poster: VIBeS, Transition System Mutation Made Easy","X. Devroey; G. Perrouin; P. Schobbens; P. Heymans","PReCISE Res. Center, Univ. of Namur, Namur, Belgium; PReCISE Res. Center, Univ. of Namur, Namur, Belgium; PReCISE Res. Center, Univ. of Namur, Namur, Belgium; PReCISE Res. Center, Univ. of Namur, Namur, Belgium","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","817","818","Mutation testing is an established technique used to evaluate the quality of a set of test cases. As model-based testing took momentum, mutation techniques were lifted to the model level. However, as for code mutation analysis, assessing test cases on a large set of mutants can be costly. In this paper, we introduce the Variability-Intensive Behavioural teSting (VIBeS) framework. Relying on Featured Transition Systems (FTSs), we represent all possible mutants in a single model constrained by a feature model for mutant (in)activation. This allow to assess all mutants in a single test case execution. We present VIBeS implementation steps and the DSL we defined to ease model-based mutation analysis.","","","10.1109/ICSE.2015.263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203084","Model-Based Mutation Testing;Featured Transition Systems;VIBeS","Testing;Analytical models;Computational modeling;DSL;Java;Adaptation models;Load modeling","program testing;software quality","VIBeS;transition system mutation techniques;mutation testing;model-based testing;variability-intensive behavioural testing framework;featured transition systems;FTSs;single test case execution;model-based mutation analysis;DSL;code mutation analysis","","4","8","","","","","IEEE","IEEE Conferences"
"StriSynth: Synthesis for Live Programming","S. Gulwani; M. Mayer; F. Niksic; R. Piskac","Microsoft Res., Redmond, WA, USA; EPFL, Lausanne, Switzerland; MPI-SWS, Germany; Yale Univ., New Haven, CT, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","701","704","Motivated by applications in automating repetitive file manipulations, we present a tool called StriSynth, which allows end-users to perform transformations over data using examples. Based on provided examples, our tool automatically generates scripts for non-trivial file manipulations. Although the current focus of StriSynth are file manipulations, it implements a more general string transformation framework. This framework builds on and further extends the functionality of Flash Fill -- a Microsoft Excel extension for string transformations. An accompanying video to this paper is available at the following website http://youtu.be/kkDZphqIdFM.","","","10.1109/ICSE.2015.227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203047","Synthesis;Live Programming;Scripting;File Manipulation;Programming by Example","Partitioning algorithms;Radiation detectors;Writing;Programming;Electronic mail;Computers;Benchmark testing","authoring languages;programming","StriSynth;live programming synthesis;automating repetitive file manipulations;script generation;nontrivial file manipulations;string transformation framework;Flash Fill;Microsoft Excel extension;string transformations","","4","11","","","","","IEEE","IEEE Conferences"
"TesMa and CATG: Automated Test Generation Tools for Models of Enterprise Applications","H. Tanno; X. Zhang; T. Hoshino; K. Sen","NTT Labs., Japan; NTT Labs., Japan; NTT Labs., Japan; EECS Dept., UC Berkeley, Berkeley, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","717","720","We present CATG, an open-source concolic test generation tool for Java and its integration with TesMa, a model-based testing tool which automatically generates test cases from formal design documents. TesMa takes as input a set of design documents of an application under test. The design documents are provided in the form of database table definitions, process-flow diagrams, and screen definitions. From these design documents, TesMa creates Java programs for the feasible execution scenarios of the application. CATG performs concolic testing on these Java programs to generate suitable databases and test inputs required to test the application under test. A demo video of the tool is available at https://www.youtube.com/watch?v=9lEvPwR7g-Q.","","","10.1109/ICSE.2015.231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203051","","Java;Testing;Databases;Concrete;Open source software;Business;Libraries","business data processing;data flow analysis;Java;program testing;public domain software","TesMa program;CATG;automated test generation tool;enterprise application model;open-source concolic test generation tool;Java program;design document;database table definition;process-flow diagram;screen definition","","8","8","","","","","IEEE","IEEE Conferences"
"A Security Practices Evaluation Framework","P. Morrison","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","935","938","Software development teams need guidance on choosing security practices so they can develop code securely. The academic and practitioner literature on software development security practices is large, and expanding. However, published empirical evidence for security practice use in software development is limited and fragmented, making choosing appropriate practices difficult. Measurement frameworks offer a tool for collecting and comparing software engineering data. The goal of this work is to aid software practitioners in evaluating security practice use in the development process by defining and validating a measurement framework for software development security practice use and outcomes. We define the Security Practices Evaluation Framework (SP-EF), a measurement framework for software development security practices. SP-EF supports evidence-based practice selection. To enable comparison of practices across publications and projects, we define an ontology of software development security practices. We evaluate the framework and ontology on historical data and industrial projects.","","","10.1109/ICSE.2015.296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203118","Security;Quality;Measurement Frameworks;Software Development Lifecycle.","Security;Software;Software measurement;Ontologies;Context;Size measurement;Process control","security of data;software development management;software metrics;software quality","security practice evaluation framework;software development teams;software development security practices;software engineering data;software development process;SP-EF;evidence-based practice selection;software development security practice ontology;industrial projects","","1","13","","","","","IEEE","IEEE Conferences"
"Software Engineering for Privacy in-the-Large","P. Anthonysamy; A. Rashid","Security-Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Google, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","947","948","There will be an estimated 35 zettabytes (35 √ó 1021) of digital records worldwide by the year 2020. This effectively amounts to privacy management on an ultra-large-scale. In this briefing, we discuss the privacy challenges posed by such an ultra-large-scale ecosystem - we term this ‚ÄúPrivacy in the Large‚Äù. We will contrast existing approaches to privacy management, reflect on their strengths and limitations in this regard and outline key software engineering research and practice challenges to be addressed in the future.","","","10.1109/ICSE.2015.300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203122","","Privacy;Software engineering;Data privacy;Security;Biological system modeling;Usability","data privacy;software engineering","software engineering;privacy management;ultra-large-scale ecosystem;privacy-in-the-large","","1","15","","","","","IEEE","IEEE Conferences"
"[Journal First] Augmenting and Structuring User Queries to Support Efficient Free-Form Code Search","R. Sirres; T. F. Bissyand√©; D. Kim; D. Lo; J. Klein; K. Kim; Y. Le Traon","Nat. Libr. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; Singapore Manage. Univ. - Singapore, Singapore, Singapore; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","945","945","Source code terms such as method names and variable types are often different from conceptual words mentioned in a search query. This vocabulary mismatch problem can make code search inefficient. In this paper, we present Code voCaBulary (CoCaBu), an approach to resolving the vocabulary mismatch problem when dealing with free-form code search queries. Our approach leverages common developer questions and the associated expert answers to augment user queries with the relevant, but missing, structural code entities in order to improve the performance of matching relevant code examples within large code repositories. To instantiate this approach, we build GitSearch, a code search engine, on top of GitHub and Stack Overflow Q&A data. We evaluate GitSearch in several dimensions to demonstrate that (1) its code search results are correct with respect to user-accepted answers; (2) the results are qualitatively better than those of existing Internet-scale code search engines; (3) our engine is competitive against web search engines, such as Google, in helping users solve programming tasks; and (4) GitSearch provides code examples that are acceptable or interesting to the community as answers for Stack Overflow questions.","","","10.1145/3180155.3182513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453173","Code search;GitHub;Free form search;Query augmentation;StackOverflow;Vocabulary mismatch","Search engines;Software engineering;Vocabulary;Indexes;Programming;Engines;Natural languages","Internet;query processing;question answering (information retrieval);search engines","structuring user queries;source code terms;search query;vocabulary mismatch problem;free-form code search queries;structural code entities;code repositories;GitSearch;user-accepted answers;web search engines;Internet-scale code search engines;expert answers;code vocabulary;CoCaBu;developer questions;stack overflow Q and A data;Google;programming tasks;user queries augmentation","","1","","","","","","IEEE","IEEE Conferences"
"[Journal First] Effect Sizes and their Variance for AB/BA Crossover Design Studies","L. Madeyski; B. Kitchenham","Fac. of Comput. Sci. & Manage., Wroclaw Univ. of Sci. & Technol., Wroclaw, Poland; Sch. of Comput. & Math., Keele Univ., Keele, UK","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","420","420","We addressed the issues related to repeated measures experimental design such as an AB/BA crossover design (where each participant uses each method) that have been neither discussed nor addressed in the software engineering literature. Firstly, there are potentially two different standardized mean difference effect sizes that can be calculated, depending on whether the mean difference is standardized by the pooled within groups variance or the within-participants variance. Hence, we provided equations for non-standardized and standardized effect sizes and explained the need for two different types of standardized effect size, one for the repeated measures and one that would be equivalent to an independent groups design. Secondly, as for any estimated parameters and also for the purposes of undertaking meta-analysis, it is necessary to calculate the variance of the standardized mean difference effect sizes (which is not the same as the variance of the study). Hence, we provided formulas for the small sample size effect size variance and the medium sample size approximation to the effect size variance, for both types of standardized effect size. We also presented the model underlying the AB/BA crossover design and provided two examples (an empirical analysis of the real data set by Scanniello, as well as simulated data) to demonstrate how to construct the two standardized mean difference effect sizes and their variances, both from standard descriptive statistics and from the outputs provided by the linear mixed model package lme4 in R. A conclusion is that crossover designs should be considered (instead of between groups design) only if: ¬∑ previous research has suggested that œÅ is greater than zero and preferably greater than 0.25; ¬∑ there is either strong theoretical argument, or empirical evidence from a well-powered study, that the period by technique interaction is negligible. Summarizing, our journal first paper [3]: (1) Presents the formulas needed to calculate both non-standardized and standardized mean difference effect sizes for AB/BA crossover designs (see Section 4 and 5 of our paper [3]). (2) Presents the formulas needed to estimate the variances of the non-standardized and standardized effect sizes which in the later cases need to be appropriate for the small to medium sample sizes commonly used in software engineering crossover designs (see Section 5 of our paper [3]). (3) Explains how to calculate the effect sizes and their variances both from the descriptive statistics that should be reported and from the raw data (see Section 6 of our paper [3]). It is worth mentioning that we based our formulas on our own corrections to the formulas presented earlier by Curtin et al. [1]. Our corrections for the variances of standardized weighted mean difference of an AB/BA cross-over trial were accepted by the author of the original formulas (Curtin), submitted jointly as a letter to Editor of Statistics in Medicine to assure the widespread (also beyond the software engineering domain) adoption of the corrected formulas, and accepted [2]. We proposed an alternative formulation of the standardized effect size for individual difference effects that is comparable with the standardized effect size commonly used for pretest/posttest studies. We also corrected the small sample size and moderate sample size variances reported by Curtin et al. for both the individual difference effect size and the standardized effect size comparable to independent groups trials, showing the derivation of the formulas from the variance of at-variable. Using these results, researchers can now correctly calculate standardized effect size variances, allowing the calculation of confidence intervals for AB/BA cross-over trials, which in turn provides a direct link to null hypothesis testing and supports meta-analysis. Meta-analysts can now validly aggregate together results from independent groups, pretest/posttest and AB/BA cross-over trials. Last but not least, the presented contributions allow corrections of previously reported results.","","","10.1145/3180155.3182556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453101","Empirical software engineering;Meta-analysis;Effect size","Software engineering;Size measurement;Analytical models;Data models;Standards;Clinical trials;Computer science","medical computing;software engineering;statistical analysis","standardized mean difference effect sizes;standardized weighted mean difference;sample size effect size variance;medium sample size approximation;difference effect size;AB-BA crossover design;software engineering literature;meta-analysis;standard descriptive statistics;linear mixed model package;null hypothesis testing;posttest studies;pretest studies;software engineering crossover designs","","","","","","","","IEEE","IEEE Conferences"
"Enlightened Debugging","X. Li; S. Zhu; M. d‚ÄôAmorim; A. Orso","Georgia Inst. of Technol., Atlanta, GA, USA; Georgia Inst. of Technol., Atlanta, GA, USA; Fed. Univ. of Pernambuco, Recife, Brazil; Georgia Inst. of Technol., Atlanta, GA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","82","92","Numerous automated techniques have been proposed to reduce the cost of software debugging, a notoriously time-consuming and human-intensive activity. Among these techniques, Statistical Fault Localization (SFL) is particularly popular. One issue with SFL is that it is based on strong, often unrealistic assumptions on how developers behave when debugging. To address this problem, we propose Enlighten, an interactive, feedback-driven fault localization technique. Given a failing test, Enlighten (1) leverages SFL and dynamic dependence analysis to identify suspicious method invocations and corresponding data values, (2) presents the developer with a query about the most suspicious invocation expressed in terms of inputs and outputs, (3) encodes the developer feedback on the correctness of individual data values as extra program specifications, and (4) repeats these steps until the fault is found. We evaluated Enlighten in two ways. First, we applied Enlighten to 1,807 real and seeded faults in 3 open source programs using an automated oracle as a simulated user; for over 96% of these faults, Enlighten required less than 10 interactions with the simulated user to localize the fault, and a sensitivity analysis showed that the results were robust to erroneous responses. Second, we performed an actual user study on 4 faults with 24 participants and found that participants who used Enlighten performed significantly better than those not using our tool, in terms of both number of faults localized and time needed to localize the faults.","","","10.1145/3180155.3180242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453065","debugging;fault localization;dynamic analysis","Debugging;Performance analysis;Tools;Generators;Calculators;Software debugging;Task analysis","fault diagnosis;program debugging;program testing;software fault tolerance","enlightened debugging;numerous automated techniques;software debugging;notoriously time-consuming;human-intensive activity;unrealistic assumptions;feedback-driven fault localization technique;Enlighten leverages SFL;dynamic dependence analysis;developer feedback;individual data values;extra program specifications;automated oracle;sensitivity analysis;open source programs;statistical fault localization","","2","","","","","","IEEE","IEEE Conferences"
"[Journal First] What Makes a Great Manager of Software Engineers?","E. Kalliamvakou; C. Bird; T. Zimmermann; A. Begel; R. DeLine; D. M. German","Univ. of Victoria, Victoria, BC, Canada; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Univ. of Victoria, Victoria, BC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","701","701","Having great managers is as critical to success as having a good team or organization. A great manager is seen as fuelling the team they manage, enabling it to use its full potential. Though software engineering research studies factors that may affect the performance and productivity of software engineers and teams (like tools and skill), it has overlooked the software engineering manager. On the one hand, experts are questioning how the abundant work in management applies to software engineering. On the other hand, practitioners are looking to researchers for evidence-based guidance on how to manage software teams. We conducted a mixed methods empirical study to investigate what manager attributes developers and engineering managers perceive important and why. We present a conceptual framework of manager attributes, and find that technical skills are not the sign of greatness for an engineering manager. Through statistical analysis we identify how engineers and managers relate in their views, and how software engineering differs from other knowledge work groups.","","","10.1145/3180155.3182525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453140","Manager;Software Engineering;Knowledge Work;Empirical Study;Conceptual Framework;Manager Attributes;Technical Skills","Software;Software engineering;Birds;Productivity;Organizations;Tools;Knowledge engineering","DP management;project management;software development management;statistical analysis;team working","great manager;software engineers;good team;software engineering manager;software teams;manager attributes;software engineering research studies;statistical analysis;productivity","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] An Empirical Study on the Interplay Between Semantic Coupling and Co-change of Software Classes","N. Ajienka; A. Capiluppi; S. Counsell","Dept. of Comput. Sci., Edge Hill Univ., Ormskirk, UK; Dept. of Comput. Sci., Brunel Univ. London, Uxbridge, UK; Dept. of Comput. Sci., Brunel Univ. London, Uxbridge, UK","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","432","432","The evolution of software systems is an inevitable process which has to be managed effectively to enhance software quality. Change impact analysis (CIA) is a technique that identifies impact sets, i.e., the set of classes that require correction as a result of a change made to a class or artefact. These sets can also be considered as ripple effects and typically non-local: changes propagate to different parts of a system. Two classes are considered logically coupled if they have co-changed in the past; past research has shown that the precision of CIA techniques increases if logical and semantic coupling (i.e., the extent to which the lexical content of two classes is related) are both considered. However, the relationship between semantic and logical coupling of software artefacts has not been extensively studied and no dependencies established between these two types of coupling. Are two often co-changed artefacts also strongly connected from a semantic point of view? Are two semantically similar artefacts bound to co-change in the future? Answering those questions would help increase the precision of CIA. It would also help software maintainers to focus on a smaller subset of artefacts more likely to co-evolve in the future. This study investigated the relationship between semantic and logical coupling. Using Chi-squared statistical tests, we identified similarities in semantic coupling using class corpora and class identifiers. We then computed Spearman's rank correlation between semantic and logical coupling metrics for class pairs to detect whether semantic and logical relationships co-varied in OO software. Finally, we investigated the overlap between semantic and logical relationships by identifying the proportion of classes linked through both coupling types. Our empirical study and results were based on seventy-nine open-source software projects. Results showed that: (a) measuring the semantic similarity of classes by using their identifiers is computationally efficient; (b) using identifier-based coupling can be used interchangeably with semantic similarity based on their corpora, albeit not always; (c) no correlation between the strengths of semantic and change coupling was found. Finally, (d) a directional relationship between the two was identified; 70% of semantic dependencies are linked through change coupling but not vice versa. Based on our findings, we conclude that identifying more efficient methods of semantic coupling computation as well as a directional relationship between semantic and change dependencies could help to improve CIA methods that integrate semantic coupling information. This may also help to reveal implicit dependencies not captured by static source code analysis.","","","10.1145/3180155.3190833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453103","Semantic coupling;co-change;Java software;metrics","Semantics;Couplings;Software;Computer science;Measurement;Software engineering;Correlation","object-oriented programming;software maintenance;software metrics;software quality;statistical analysis;statistical testing","directional relationship;semantic dependencies;semantic coupling computation;semantic coupling information;software classes;software systems;software quality;change impact analysis;CIA;software artefacts;semantically similar artefacts;software maintainers;class corpora;class identifiers;semantic coupling metrics;logical coupling metrics;semantic relationships;logical relationships;OO software;coupling types;open-source software projects;semantic similarity;identifier-based coupling","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction","K. E. Bennin; J. Keung; P. Phannachitta; A. Monden; S. Mensah","Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China; Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China; Coll. of Arts, Chiang Mai Univ., Chiang Mai, Thailand; Grad. Sch. of Natural Sci. & Technol., Okayama Univ., Okayama, Japan; Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","699","699","This study presents MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with five other sampling approaches using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant pf values than the other oversampling approaches, based on robust statistical tests.","","","10.1145/3180155.3182520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453138","Software defect prediction;Class imbalance learning;Synthetic sample generation;Data sampling methods;Classification problems","Software;Software engineering;Software measurement;Urban areas;Biological system modeling;Predictive models;Robustness","learning (artificial intelligence);pattern classification;sampling methods;software fault tolerance;software metrics;software quality;statistical testing","sampling approaches;prediction models;prediction performance;oversampling approaches;class imbalance issue;software defect prediction;software defect datasets;chromosomal theory;synthetic oversampling approach;MAHAKIL approach;robust statistical tests","","1","","","","","","IEEE","IEEE Conferences"
"[Journal First] Does Syntax Highlighting Help Programming Novices?","C. Hannebauer; M. Hesenius; V. Gruhn","NA; Univ. of Duisburg-Essen, Essen, Germany; Univ. of Duisburg-Essen, Essen, Germany","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","704","704","Background: Program comprehension is an important skill for programmers - extending and debugging existing source code is part of the daily routine. Syntax highlighting is one of the most common tools used to support developers in understanding algorithms. However, most research in this area originates from a time when programmers used a completely different tool chain. Objective: We examined the influence of syntax highlighting on novices' ability to comprehend source code. Additional analyses cover the influence of task type and programming experience on the code comprehension ability itself and its relation to syntax highlighting. Method: We conducted a controlled experiment with 390 undergraduate students in an introductory Java programming course. We measured the correctness with which they solved small coding tasks. Each test subject received some tasks with syntax highlighting and some without. Results: The data provided no evidence that syntax highlighting improves novices' ability to comprehend source code. Limitations: There are very few similar experiments and it is unclear as of yet which factors impact the effectiveness of syntax highlighting. One major limitation may be the types of tasks chosen for this experiment. Conclusion: The results suggest that syntax highlighting squanders a feedback channel from the IDE to the programmer that can be used more effectively.","","","10.1145/3180155.3182554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453142","Syntax Highlighting;Source Code Typography;Code Colouring;IDE Interface;Program Comprehension","Syntactics;Task analysis;Programming;Software engineering;Visualization;Human computer interaction;Tools","computer science education;educational courses;feedback;Java;programming;programming environments","source code;syntax highlighting squanders;programming novices;code comprehension;undergraduate students;program comprehension;Java programming course;feedback channel;IDE","","","","","","","","IEEE","IEEE Conferences"
"DetReduce: Minimizing Android GUI Test Suites for Regression Testing","W. Choi; K. Sen; G. Necul; W. Wang","Univ. of California, Berkeley, Berkeley, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Univ. of Illinois, Urbana, IL, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","445","455","In recent years, several automated GUI testing techniques for Android apps have been proposed. These tools have been shown to be effective in achieving good test coverage and in finding bugs without human intervention. Being automated, these tools typically run for a long time (say, for several hours), either until they saturate test coverage or until a testing time budget expires. Thus, these automated tools are not good at generating concise regression test suites that could be used for testing in incremental development of the apps and in regression testing. We propose a heuristic technique that helps create a small regression test suite for an Android app from a large test suite generated by an automated Android GUI testing tool. The key insight behind our technique is that if we can identify and remove some common forms of redundancies introduced by existing automated GUI testing tools, then we can drastically lower the time required to minimize a GUI test suite. We have implemented our algorithm in a prototype tool called DetReduce. We applied DetReduce to several Android apps and found that DetReduce reduces a test-suite by an average factor of16.9√ó in size and14.7√ó in running time. We also found that for a test suite generated by running SwiftHand and a randomized test generation algorithm for 8 hours, DetReduce minimizes the test suite in an average of 14.6 hours.","","","10.1145/3180155.3180173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453105","Android;GUI;Test minimization","Graphical user interfaces;Testing;Tools;Androids;Humanoid robots;Redundancy;Computer bugs","Android (operating system);graphical user interfaces;program testing","Android GUI test suites;randomized test generation algorithm;GUI test suite;testing tools;automated Android GUI testing tool;regression test suite;concise regression test suites;automated tools;testing time budget;Android app;automated GUI testing techniques;regression testing;DetReduce","","2","","","","","","IEEE","IEEE Conferences"
"Roles and Impacts of Hands-on Software Architects in Five Industrial Case Studies","I. Rehman; M. Mirakhorli; M. Nagappan; A. Aralbay Uulu; M. Thornton","NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","117","127","Whether software architects should also code is an enduring question. In order to satisfy performance, security, reliability and other quality concerns, architects need to compare and carefully choose a combination of architectural patterns, styles or tactics. Then later in the development cycle, these architectural choices must be implemented completely and correctly so there will not be any drift from envisioned design. In this paper, we use data analytics-based techniques to study five large-scale software systems, examining the impact and the role of software architects who write code on software quality. Our quantitative study is augmented with a follow-up interview of architects. This paper provides empirical evidence for supporting the pragmatic opinions that architects should write code. Our analysis shows that implementing architectural tactics is more complex than delivering functionality, tactics are more error prone than software functionalities, and the architects tend to introduce fewer bugs into the implementation of architectural tactics compared to the developers.","","","10.1145/3180155.3180234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453069","Architect;coding;tactics;architecture savvy","Software engineering","data analysis;software architecture;software quality","architectural choices;large-scale software systems;software architects;software quality;quantitative study;architectural tactics;software functionalities","","","","","","","","IEEE","IEEE Conferences"
"Open Source Barriers to Entry, Revisited: A Sociotechnical Perspective","C. Mendez; H. S. Padala; Z. Steine-Hanson; C. Hildebrand; A. Horvath; C. Hill; L. Simpson; N. Patil; A. Sarma; M. Burnett","Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA; Oregon State Univ., Corvallis, OR, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1004","1015","Research has revealed that significant barriers exist when entering Open-Source Software (OSS) communities and that women disproportionately experience such barriers. However, this research has focused mainly on social/cultural factors, ignoring the environment itself - the tools and infrastructure. To shed some light onto how tools and infrastructure might somehow factor into OSS barriers to entry, we conducted a field study with five teams of software professionals, who worked through five use-cases to analyze the tools and infrastructure used in their OSS projects. These software professionals found tool/infrastructure barriers in 7% to 71% of the use-case steps that they analyzed, most of which are tied to newcomer barriers that have been established in the literature. Further, over 80% of the barrier types they found include attributes that are biased against women.","","","10.1145/3180155.3180241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453179","open source software;newcomer;gender","Tools;Databases;Problem-solving;Open source software;Cultural differences;Face","cultural aspects;public domain software","sociotechnical perspective;OSS barriers;software professionals;OSS projects;newcomer barriers;open source barriers;open-source software communities;social-cultural factors;tool-infrastructure barriers;use-case steps","","8","","","","","","IEEE","IEEE Conferences"
"Prioritizing Browser Environments for Web Application Test Execution","J. Kwon; I. Ko; G. Rothermel","Sch. of Comput., KAIST, Daejeon, South Korea; Sch. of Comput., KAIST, Daejeon, South Korea; Univ. of Nebraska-Lincoln, Lincoln, NE, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","468","479","When testing client-side web applications, it is important to consider different web-browser environments. Different properties of these environments such as web-browser types and underlying platforms may cause a web application to exhibit different types of failures. As web applications evolve, they must be regression tested across these different environments. Because there are many environments to consider this process can be expensive, resulting in delayed feedback about failures in applications. In this work, we propose six techniques for providing a developer with faster feedback on failures when regression testing web applications across different web-browser environments. Our techniques draw on methods used in test case prioritization; however, in our case we prioritize web-browser environments, based on information on recent and frequent failures. We evaluated our approach using four non-trivial and popular open-source web applications. Our results show that our techniques outperform two baseline methods, namely, no ordering and random ordering, in terms of the cost-effectiveness. The improvement rates ranged from -12.24% to 39.05% for no ordering, and from -0.04% to 45.85% for random ordering.","","","10.1145/3180155.3180244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453107","Web application testing;Regression testing;Browser environments","Browsers;Testing;History;Schedules;Optimal scheduling;Operating systems;Production","Internet;online front-ends;program testing","test case prioritization;application failures;testing client-side Web application;open-source Web applications;Web application test execution;Web-browser environments;regression testing Web applications;Web-browser types;feedback delay","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Studying the Dialogue Between Users and Developers of Free Apps in the Google Play Store","S. Hassan; C. Tantithamthavorn; C. Bezemer; A. E. Hassan","Software Anal. & Intell. Lab., Queen's Univ., Kingston, ON, Canada; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Software Anal. & Intell. Lab., Queen's Univ., Kingston, ON, Canada; Software Anal. & Intell. Lab., Queen's Univ., Kingston, ON, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","164","164","The popularity of mobile apps continues to grow over the past few years. Mobile app stores, such as the Google Play Store and Apple's App Store provide a unique user feedback mechanism to app developers through app reviews. In the Google Play Store (and most recently in the Apple App Store), developers are able to respond to such user feedback. Over the past years, mobile app reviews have been studied excessively by researchers. However, much of prior work (including our own prior work) incorrectly assumes that reviews are static in nature and that users never update their reviews. In a recent study, we started analyzing the dynamic nature of the review-response mechanism. Our previous study showed that responding to a review often has a positive effect on the rating that is given by the user to an app. In this paper [1], we revisit our prior finding in more depth by studying 4.5 million reviews with 126,686 responses of 2,328 top free-to-download apps in the Google Play Store. One of the major findings of our paper is that the assumption that reviews are static is incorrect. In particular, we find that developers and users in some cases use this response mechanism as a rudimentary user support tool, where dialogues emerge between users and developers through updated reviews and responses. Even though the messages are often simple, we find instances of as many as ten user-developer back-and-forth messages that occur via the response mechanism. Using a mixed-effect model, we identify that the likelihood of a developer responding to a review increases as the review rating gets lower or as the review content gets longer. In addition, we identify four patterns of developers: 1) developers who primarily respond to only negative reviews, 2) developers who primarily respond to negative reviews or to reviews based on their content, 3) developers who primarily respond to reviews which are posted shortly after the latest release of their app, and 4) developers who primarily respond to reviews which are posted long after the latest release of their app. We perform a qualitative analysis of developer responses to understand what drives developers to respond to a review. We manually analyzed a statistically representative random sample of 347 reviews with responses of the top ten apps with the highest number of developer responses. We identify seven drivers that make a developer respond to a review, of which the most important ones are to thank the users for using the app and to ask the user for more details about the reported issue. Our findings show that it can be worthwhile for app owners to respond to reviews, as responding may lead to an increase in the given rating. In addition, our findings show that studying the dialogue between users and developers provides valuable insights that can lead to improvements in the app store and the user support process. The main contributions of this paper are as follows: (1) Our paper is the first work to demonstrate the dynamic nature of reviews. (2) Furthermore, we are the first to demonstrate a peculiar use of the app-review platforms as a user support medium. (3) In addition, our work is the first work to deeply explore developer responses in a systematic manner. (4) Finally, our classification of developer-responses highlights the value of providing canned or even automated responses in next generation app-review platforms.","","","10.1145/3180155.3182523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453075","Google Play Store;User-developer dialogue;Developer response;Mixed-effect model;Android mobile apps","Google;Software engineering;Software;Computer science;Australia;Tools;Systematics","consumer behaviour;mobile computing","free-to-download apps;review-response mechanism;mobile app reviews;Apple App Store;app developers;unique user feedback mechanism;mobile app stores;Google Play Store;free apps;developer-responses;app-review platforms;app owners;developer responses;negative reviews;review content;review rating;review increases;developer responding;user-developer;updated reviews;rudimentary user support tool","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] The Scent of a Smell: An Extensive Comparison Between Textual and Structural Smells","F. Palomba; A. Panichella; A. Zaidman; R. Oliveto; A. De Lucia","Univ. of Zurich, Zurich, Switzerland; Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Univ. of Molise, Pesche, Italy; Univ. of Salerno, Salerno, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","740","740","Code smells are symptoms of poor design or implementation choices that have a negative effect on several aspects of software maintenance and evolution, such as program comprehension or change-and fault-proneness. This is why researchers have spent a lot of effort on devising methods that help developers to automatically detect them in source code. Almost all the techniques presented in literature are based on the analysis of structural properties extracted from source code, although alternative sources of information (e.g., textual analysis) for code smell detection have also been recently investigated. Nevertheless, some studies have indicated that code smells detected by existing tools based on the analysis of structural properties are generally ignored (and thus not refactored) by the developers. In this paper, we aim at understanding whether code smells detected using textual analysis are perceived and refactored by developers in the same or different way than code smells detected through structural analysis. To this aim, we set up two different experiments. We have first carried out a software repository mining study to analyze how developers act on textually or structurally detected code smells. Subsequently, we have conducted a user study with industrial developers and quality experts in order to qualitatively analyze how they perceive code smells identified using the two different sources of information. Results indicate that textually detected code smells are easier to identify and for this reason they are considered easier to refactor with respect to code smells detected using structural properties. On the other hand, the latter are often perceived as more severe, but more difficult to exactly identify and remove.","","","10.1145/3180155.3182530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453146","code smells;empirical study;mining software repositories","Tools;Software engineering;Maintenance engineering;Data mining;Detectors;Software systems;Software quality","data mining;software maintenance;source code (software)","structural smells;source code;textual analysis;code smell detection;textually detected code smells;textual smells;software maintenance;software evolution;software repository mining study","","","","","","","","IEEE","IEEE Conferences"
"Inferring Hierarchical Motifs from Execution Traces","S. Alimadadi; A. Mesbah; K. Pattabiraman","Northeastern Univ., Boston, MA, USA; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","776","787","Program comprehension is a necessary step for performing many software engineering tasks. Dynamic analysis is effective in producing execution traces that assist comprehension. Traces are rich sources of information regarding the behaviour of a program. However, it is challenging to gain insight from traces due to their overwhelming amount of data and complexity. We propose a generic technique for facilitating comprehension by inferring recurring execution motifs. Inspired by bioinformatics, motifs are patterns in traces that are flexible to small changes in execution, and are captured in a hierarchical model. The hierarchical nature of the model provides an overview of the behaviour at a high-level, while preserving the execution details and intermediate levels in a structured manner. We design a visualization that allows developers to observe and interact with the model. We implement our approach in an open-source tool, called Sabalan, and evaluate it through a user experiment. The results show that using Sabalan improves developers' accuracy in performing comprehension tasks by 54%.","","","10.1145/3180155.3180216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453150","Program comprehension;behavioural model;hierarchical motifs","Tools;Task analysis;Electronic mail;Biological system modeling;Software engineering;Bioinformatics;Data visualization","bioinformatics;object-oriented programming;program visualisation;software engineering;software maintenance","execution traces;program comprehension;software engineering tasks;dynamic analysis;assist comprehension;execution motifs;hierarchical model;hierarchical nature;execution details;comprehension tasks;inferring hierarchical motifs","","3","","","","","","IEEE","IEEE Conferences"
"[Journal First] A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches","S. Herbold; A. Trautsch; J. Grabowski","Insititute of Comput. Sci., Univ. of Goettingen, Gottingen, Germany; Insititute of Comput. Sci., Univ. of Goettingen, Gottingen, Germany; Insititute of Comput. Sci., Univ. of Goettingen, Gottingen, Germany","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1063","1063","Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However, within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article, we provide a benchmark for CPDP. We replicate 24 approaches proposed by researchers between 2008 and 2015 and evaluate their performance on software products from five different data sets. Based on our benchmark, we determined that an approach proposed by Camargo Cruz and Ochimizu (2009) based on data standardization performs best and is always ranked among the statistically significant best results for all metrics and data sets. Approaches proposed by Turhan et al. (2009), Menzies et al. (2011), and Watanabe et al. (2008) are also nearly always among the best results. Moreover, we determined that predictions only seldom achieve a high performance of 0.75 recall, precision, and accuracy. Thus, CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.","","","10.1145/3180155.3182542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453185","cross project defect prediction;benchmark;comparison;replication","Benchmark testing;Software;Measurement;Software engineering;Computer science;Proposals;Ranking (statistics)","quality assurance;software metrics;software quality","experiment setups;performance metrics;benchmark cross-project defect prediction approaches;data standardization;software products;software projects;quality assurance;CPDP","","","4","","","","","IEEE","IEEE Conferences"
"[Journal First] Correctness Attraction: A Study of Stability of Software Behavior Under Runtime Perturbation","B. Danglot; P. Preux; B. Baudry; M. Monperrus","Nord Eur., Inria, Villeneuve-d'Ascq, France; Univ. Lille, Villeneuve-d'Ascq, France; Bretage Atlantique, Inria Rennes, Rennes, France; KTH R. Inst. of Technol., Stockholm, Sweden","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","481","481","Can the execution of software be perturbed without breaking the correctness of the output? In this paper, we devise a protocol to answer this question from a novel perspective. In an experimental study, we observe that many perturbations do not break the correctness in ten subject programs. We call this phenomenon ""correctness attraction"". The uniqueness of this protocol is that it considers a systematic exploration of the perturbation space as well as perfect oracles to determine the correctness of the output. To this extent, our findings on the stability of software under execution perturbations have a level of validity that has never been reported before in the scarce related work. A qualitative manual analysis enables us to set up the first taxonomy ever of the reasons behind correctness attraction.","","","10.1145/3180155.3182548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453109","perturbation analysis;software correctness;empirical study","Perturbation methods;Software;Protocols;Stability analysis;Runtime;Systematics","program diagnostics;program testing","execution perturbations;perturbation space;phenomenoncorrectness attraction;subject programs;runtime perturbation;software behavior","","","","","","","","IEEE","IEEE Conferences"
"The Good, the Bad and the Ugly: A Study of Security Decisions in a Cyber-Physical Systems Game","S. Frey; A. Rashid; P. Anthonysamy; M. Pinto-Albuquerque; S. A. Naqvi","Univ. of Southampton, Southampton, UK; Univ. of Bristol, Bristol, UK; Google, Switzerland; Inst. Univ. de Lisboa, Lisbon, Portugal; Lancaster Univ., Lancaster, UK","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","496","496","Motivation: The security of any system is a direct consequence of stakeholders' decisions regarding security requirements and their relative prioritisation. Such decisions are taken with varying degrees of expertise in security. In some organisations - particularly those with resources - these are the preserve of computer (or information) security teams. In others - typically smaller organisations - the computing services team may be charged with the responsibility. Often managers have a role to play as guardians of business targets and goals. Be it common workplace practices or strategic decision making, security decisions underpin not only the initial security requirements and their prioritisation but also the adaptation and evolution of these requirements as new business or security contexts arise. However, little is currently understood about how these various demographics approach cyber security decisions and the strategies and approaches that underpin those decisions. What are the typical decision patterns, if any, the consequences of such patterns and their impact (positive or negative) on the security of the system in question? Nor is there any substantial understanding of how the strategies and decision patterns of these different groups contrast. Is security expertise necessarily an advantage when making security decisions in a given context? Answers to these questions are key to understanding the ""how"" and ""why"" behind security decision processes. The Game: In this talk [1], we present a tabletop game - Decisions and Disruptions (D-D) [2] - as a means to investigate these very questions. The game tasks a group of players with managing the security of a small utility company while facing a variety of threats. The game provides a requirements sandbox in which players can experiment with threats, learn about decision making and its consequences, and reflect on their own perception of risk. The game is intentionally kept short - 2 hours - and simple enough to be played without prior training. A cyber-physical infrastructure, depicted through a Lego(R) board, makes the game easy to understand and accessible to players from varying backgrounds and security expertise, without being too trivial a setting for security experts. Key insights: We played D-D with 43 players divided into homogeneous groups (group sizes of 2-6 players): 4 groups of security experts, 4 groups of non-technical managers and 4 groups of general computer scientists. Such observations should, of course, not be generalised, however, the substantial sample size enables in-depth qualitative analysis. Our analysis reveals a number of novel insights regarding security decisions of our three demographics: - Strategies: Security experts had a strong interest in advanced technological solutions and tended to neglect intelligence gathering, to their own detriment: some security expert teams achieved poor results in the game. Managers, too, were technology-driven and focused on data protection while neglecting human factors more than other groups. Computer scientists tended to balance human factors and intelligence gathering with technical solutions, and achieved the best results of the three demographics. - Decision Processes: Technical experience significantly changes the way players think. Teams with little technical experience had shallow, intuition-driven discussions with few concrete arguments. Technical teams, and the most experienced in particular, had much richer debates, driven by concrete scenarios, anecdotes from experience, and procedural thinking. Security experts showed a high confidence in their decisions - despite some of them having bad consequences - while the other groups tended to doubt their own skills - even when they were playing good games. - Patterns: A number of characteristic plays could be identified, some good (balance between priorities, open-mindedness, and adapting strategies based on inputs that challenge one's pre-conceptions), some bad (excessive focus on particular issues, confidence in charismatic leaders), some ugly (""tunnel vision"" syndrome by over-confident players). These patterns are documented and discussed in the full paper - showing the virtue of the positive ones, discouraging the negative ones, and inviting the readers to do their own introspection. Conclusion: D-D complements existing work on gamification as a means to improve security awareness, education, and training. Beyond the analysis of the security decisions of the three demographics, there is a definite educational and awareness-raising aspect to D-D (as noted consistently by players in all our subject groups). Game boxes will be brought to the conference for demonstration purposes, and the audience will be invited to experiment with D-D themselves, make their own decisions, and reflect on their own perception of security.","","","10.1145/3180155.3182549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453113","security decisions;security requirements;game;decision patterns","Games;Cyber-physical systems;Computer security;Software engineering;Privacy;Google","computer games;cyber-physical systems;decision making;game theory;human factors;organisational aspects;security of data","decision making;tabletop game;stakeholders decisions;organisations;computer security teams;demographics approach;decisions and disruptions;D-D;sandbox requirements;qualitative analysis;human factors;gamification;security expert teams;players;cyber security decisions;cyber-physical systems game","","1","","","","","","IEEE","IEEE Conferences"
"Leveraging Program Analysis to Reduce User-Perceived Latency in Mobile Applications","Y. Zhao; M. Schmitt Laser; Y. Lyu; N. Medvidovic","Univ. of Southern California, Los Angeles, CA, USA; Pontifical Catholic Univ. of Rio Grande do Sul, Porto Alegre, Brazil; Univ. of Southern California, Los Angeles, CA, USA; Univ. of Southern California, Los Angeles, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","176","186","Reducing network latency in mobile applications is an effective way of improving the mobile user experience and has tangible economic benefits. This paper presents PALOMA, a novel client-centric technique for reducing the network latency by prefetching HTTP requests in Android apps. Our work leverages string analysis and callback control-flow analysis to automatically instrument apps using PALOMA's rigorous formulation of scenarios that address ""what"" and ""when"" to prefetch. PALOMA has been shown to incur significant runtime savings (several hundred milliseconds per prefetchable HTTP request), both when applied on a reusable evaluation benchmark we have developed and on real applications.","","","10.1145/3180155.3180249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453077","program analysis;prefetch;network latency;mobile applications","Prefetching;Uniform resource locators;Androids;Humanoid robots;Servers;Runtime;Mobile applications","mobile computing;program diagnostics;storage management","automatically instrument apps;prefetchable HTTP request;program analysis;user-perceived latency;mobile applications;mobile user experience;tangible economic benefits;novel client-centric technique;HTTP requests;Android apps","","4","","","","","","IEEE","IEEE Conferences"
"[Journal First] Journal First Presentation of an Experience Report on Applying Software Testing Academic Results in Industry: We Need Usable Automated Test Generation","A. Arcuri","Fac. of Technol., Westerdals Oslo ACT, Oslo, Norway","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1065","1065","What is the impact of software engineering research on current practices in industry? In this paper, I report on my direct experience as a PhD/post-doc working in software engineering research projects, and then spending the following five years as an engineer in two different companies (the first one being the same I worked in collaboration with during my post-doc). Given a background in software engineering research, what cutting-edge techniques and tools from academia did I use in my daily work when developing and testing the systems of these companies? Regarding validation and verification (my main area of research), the answer is rather short: as far as I can tell, only FindBugs. In this paper, I report on why this was the case, and discuss all the challenging, complex open problems we face in industry and which somehow are ""neglected"" in the academic circles. In particular, I will first discuss what actual tools I could use in my daily work, such as JaCoCo and Selenium. Then, I will discuss the main open problems I faced, particularly related to environment simulators, unit and web testing. After that, popular topics in academia are presented, such as UML, regression and mutation testing. Their lack of impact on the type of projects I worked on in industry is then discussed. Finally, from this industrial experience, I provide my opinions about how this situation can be improved, in particular related to how academics are evaluated, and advocate for a greater involvement into open-source projects.","","","10.1145/3180155.3182555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453187","Industry;Practice;Technology Transfer;Impact;Applied Research","Software engineering;Industries;Software testing;Test pattern generators;Companies;Tools","automatic test pattern generation;automatic test software;program testing;public domain software;software engineering","cutting-edge techniques;daily work;complex open problems;main open problems;web testing;regression;mutation testing;industrial experience;experience report;usable automated test generation;direct experience;PhD/post-doc;software engineering research projects;time 5.0 year","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Are Vulnerabilities Discovered and Resolved Like Other Defects?","P. Morrison; R. Pandita; X. Xiao; R. Chillarege; L. Williams","North Carolina State Univ., Raleigh, NC, USA; Phase Change Software, Golden, CO, USA; Case Western Reserve Univ., Cleveland, OH, USA; Chillarege Inc., Raleigh, NC, USA; North Carolina State Univ., Raleigh, NC, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","498","498","Software defect data has long been used to drive software development process improvement. If security defects (i.e., vulnerabilities) are discovered and resolved by different software development practices than non-security defects, the knowledge of that distinction could be applied to drive process improvement. The goal of this research is to support technical leaders in making security-specific software development process improvements by analyzing the differences between the discovery and resolution of defects versus that of vulnerabilities. We extend Orthogonal Defect Classification (ODC), a scheme for classifying software defects to support software development process improvement, to study process-related differences between vulnerabilities and defects, creating ODC + Vulnerabilities (ODC+V). We applied ODC+V to classify 583 vulnerabilities and 583 defects across 133 releases of three open-source projects (Firefox, phpMyAdmin, and Chrome). Compared with defects, vulnerabilities are found later in the development cycle and are more likely to be resolved through changes to conditional logic. In Firefox, vulnerabilities are resolved 33% more quickly than defects. From a process improvement perspective, these results indicate opportunities may exist for more efficient vulnerability detection and resolution. We found ODC+V's property of associating vulnerability and defect discovery and resolution events with their software development process contexts helpful for gaining insight into three open source software projects. The addition of the SecurityImpact attribute, in particular, brought visibility into when threat types are discovered during the development process. We would expect use of ODC+V (and of base ODC) periodically over time to be helpful for steering software development projects toward their quality assurance goals.","","","10.1145/3180155.3182553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453115","metrics;security","Random access memory;Software engineering;Software measurement;Open source software;Security;Drives","pattern classification;project management;public domain software;quality assurance;security of data;software development management","software development projects;orthogonal defect classification;ODC;vulnerability detection;security-specific software development process;Firefox;phpMyAdmin;Chrome;open source software projects;defect discovery;nonsecurity defects;security defects","","","","","","","","IEEE","IEEE Conferences"
"Hybrid Regression Test Selection","L. Zhang","Univ. of Texas at Dallas, Dallas, TX, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","199","209","Regression testing is crucial but can be extremely costly. Regression Test Selection (RTS) aims to reduce regression testing cost by only selecting and running the tests that may be affected by code changes. To date, various RTS techniques analyzing at different granularities (e.g., at the basic-block, method, and file levels) have been proposed. RTS techniques working on finer granularities may be more precise in selecting tests, while techniques working on coarser granularities may have lower overhead. According to a recent study, RTS at the file level (FRTS) can have less overall testing time compared with a finer grained technique at the method level, and represents state-of-the-art RTS. In this paper, we present the first hybrid RTS approach, HyRTS, that analyzes at multiple granularities to combine the strengths of traditional RTS techniques at different granularities. We implemented the basic HyRTS technique by combining the method and file granularity RTS. The experimental results on 2707 revisions of 32 projects, totalling over 124 Million LoC, demonstrate that HyRTS outperforms state-of-the-art FRTS significantly in terms of selected test ratio and the offline testing time. We also studied the impacts of each type of method-level changes, and further designed two new HyRTS variants based on the study results. Our additional experiments show that transforming instance method additions/deletions into file-level changes produces an even more effective HyRTS variant that can significantly outperform FRTS in both offline and online testing time.","","","10.1145/3180155.3180198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453079","Test selection;Regression testing;Dynamic analysis;Empirical study","Testing;Tools;Java;Runtime;Open source software","program testing;regression analysis","hybrid RTS approach;granularity RTS;selected test ratio;offline testing time;method-level changes;instance method additions/deletions;file-level changes;online testing time;code changes;RTS techniques;hybrid regression test selection;regression testing cost reduction;HyRTS technique;FRTS","","9","","","","","","IEEE","IEEE Conferences"
"Inheritance Usage Patterns in Open-Source Systems","J. Stevenson; M. Wood","Dept. of Comput. & Inf. Sci., Univ. of Strathclyde, Glasgow, UK; Dept. of Comput. & Inf. Sci., Univ. of Strathclyde, Glasgow, UK","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","245","255","This research investigates how object-oriented inheritance is actually used in practice. The aim is to close the gap between inheritance guidance and inheritance practice. It is based on detailed analyses of 2440 inheritance hierarchies drawn from 14 open-source systems. The original contributions made by this paper concern pragmatic assessment of inheritance hierarchy design quality. The findings show that inheritance is very widely used but that most of the usage patterns that occur in practice are simple in structure. They are so simple that they may not require much inheritance-specific design consideration. On the other hand, the majority of classes defined using inheritance actually appear within a relatively small number of large, complex hierarchies. While some of these large hierarchies appear to have a consistent structure, often based on a problem domain model or a design pattern, others do not. Another contribution is that the quality of hierarchies, especially the large problematic ones, may be assessed in practice based on size, shape, and the definition and invocation of novel methods - all properties that can be detected automatically.","","","10.1145/3180155.3180168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453083","Object-oriented;inheritance;open source;empirical;design guidance","Software engineering;Gold","inheritance;object-oriented methods;public domain software","inheritance hierarchies;complex hierarchies;inheritance-specific design consideration;inheritance hierarchy design quality;14 open-source systems;inheritance guidance;object-oriented inheritance;inheritance usage patterns","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Analyzing a Decade of Linux System Calls","M. Bagherzadeh; N. Kahani; C. Bezemer; A. E. Hassan; J. Dingel; J. R. Cordy","Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","267","267","Over the past 25 years, thousands of developers have contributed more than 18 million lines of code (LOC) to the Linux kernel. As the Linux kernel forms the central part of various operating systems that are used by millions of users, the kernel must be continuously adapted to the changing demands and expectations of these users. The Linux kernel provides its services to an application through system calls. The combined set of all system calls forms the essential Application Programming Interface (API) through which an application interacts with the kernel. In this paper, we conduct an empirical study of 8,770 changes that were made to Linux system calls during the last decade (i.e., from April 2005 to December 2014). In particular, we study the size of the changes, and we manually identify the type of changes and bug fixes that were made. Our analysis provides an overview of the evolution of the Linux system calls over the last decade. We find that there was a considerable amount of technical debt in the kernel, that was addressed by adding a number of sibling calls (i.e., 26% of all system calls). In addition, we find that by far, the ptraceand signal handling system calls are the most challenging to maintain. Our study can be used by developers who want to improve the design and ensure the successful evolution of their own kernel APIs.","","","10.1145/3180155.3182518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453085","Linux kernel;System calls;API evolution;Software evolution","Linux;Kernel;Computer bugs;Software engineering;Maintenance engineering;Testing","application program interfaces;Linux;operating system kernels;program debugging","essential application programming interface;kernel API;sibling calls;operating systems;Linux kernel forms;Linux system calls","","","","","","","","IEEE","IEEE Conferences"
"The Evolution of Requirements Practices in Software Startups","C. Gralha; D. Damian; A. Wasserman; M. Goul√£o; J. Ara√∫jo","NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","823","833","We use Grounded Theory to study the evolution of requirements practices of 16 software startups as they grow and introduce new products and services. These startups operate in a dynamic environment, with significant time and market pressure, and rarely have time for systematic requirements analysis. Our theory describes the evolution of practice along six dimensions that emerged as relevant to their requirements activities: requirements artefacts, knowledge management, requirements-related roles, planning, technical debt and product quality. Beyond the relationships among the dimensions, our theory also explains the turning points that drove the evolution along these dimensions. These changes are reactive, rather than planned, suggesting an overall pragmatic lightness, i.e., flexibility, in the startups' evolution towards engineering practices for requirements. Our theory organises knowledge about evolving requirements practice in maturing startups, and provides practical insights for startups' assessing their own evolution as they face challenges to their growth. Our research also suggests that a startup's evolution along the six dimensions is not fundamental to its success, but has significant effects on their product, their employees and the company.","","","10.1145/3180155.3180158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453156","requirements engineering;startups;evolution;grounded theory","Companies;Interviews;Software;Biological system modeling;Turning;Software engineering","organisational aspects;software development management","requirements artefacts;engineering practices;maturing startups;practical insights;software startups;systematic requirement analysis","","1","","","","","","IEEE","IEEE Conferences"
"Collaborative Model-Driven Software Engineering: A Classification Framework and a Research Map [Extended Abstract]","D. Di Ruscio; M. Franzago; I. Malavolta; H. Muccini","DISIM Dept., Univ. of L'Aquila, L'Aquila, Italy; DISIM Dept., Univ. of L'Aquila, L'Aquila, Italy; DISIM Dept., Univ. of L'Aquila, L'Aquila, Italy; Vrije Univ. Amsterdam, Amsterdam, Netherlands","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","535","535","This proposal is about a study we recently published in the IEEE Transaction of Software Engineering journal [4]. Context: Collaborative software engineering (CoSE) deals with methods, processes and tools for enhancing collaboration, communication, and co-ordination (3C) among team members. CoSE can be employed to conceive different kinds of artifacts during the development and evolution of software systems. For instance, when focusing on software design, multiple stakeholders with different expertise and responsibility collaborate on the system design. Model-Driven Software Engineering (MDSE) provides suitable techniques and tools for specifying, manipulating, and analyzing modeling artifacts including metamodels, models, and transformations. Collaborative MDSE consists of methods or techniques in which multiple stakeholders manage, collaborate, and are aware of each others' work on a set of shared models. A collaborative MDSE approach is composed of three main complementary dimensions: (i) a model management infrastructure for managing the life cycle of the models, (ii) a set of collaboration means for allowing involved stakeholders to work on the modelling artifacts collaboratively, and (iii) a set of communication means for allowing involved stakeholders to exchange, share, and communicate information within the team. Collaborative MDSE is attracting several research efforts from different research areas (e.g., model-driven engineering, global software engineering, etc.), resulting in a variegated scientific body of knowledge on the topic. Objective: In this study we aim at identifying, classifying, and understanding existing collaborative MDSE approaches. More specifically, our goal is to assess (i) the key characteristics of collaborative MDSE approaches (e.g., model editing environments, model versioning mechanisms, model repositories, support for communication and decision making), (ii) their faced challenges and limitations, and (iii) the interest of researchers in collaborative MDSE approaches over time and their focus on the three dimensions of collaborative MDSE. Method: In order to achieve this, we designed and conducted a systematic mapping study on collaborative MDSE. Starting from over 3,000 potentially relevant studies, we applied a rigorous selection procedure resulting in 106 selected papers, further clustered into 48 primary studies, along a time span of nineteen years. A suitable classification framework has been empirically defined and rigorously applied for extracting key information from each selected study. We collated, summarized, and analyzed extracted data by applying scientifically sound data synthesis techniques. Results: In addition to a number of specific insights, our analysis revealed the following key findings: (i) there is a growing scientific interest on collaborative MDSE in the last years; (ii) multi-view modeling, validation support, reuse, and branching are more rarely covered with respect to other aspects about collaborative MDSE; (iii) different primary studies focus differently on individual dimensions of collaborative MDSE (i.e., model management, collaboration, and communication); (iv) most approaches are language-specific, with a prominence of UML-based approaches; (v) few approaches support the interplay between synchronous and asynchronous collaboration. Conclusion: This study gives a solid foundation for a thorough identification and comparison of existing and future approaches for collaborative MDSE. Those results can be used by both researchers and practitioners for identifying existing research/technical gaps to attack, better scoping their own contributions to the field, or better understanding or refining existing ones.","","","10.1145/3180155.3182543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453119","Collaborative MDSE;CoMDSE;C MDSE;model driven engineering;collaborative software engineering;CoSE;systematic mapping study","Software engineering;Analytical models;Unified modeling language;Stakeholders;Collaborative software;Tools","decision making;groupware;software engineering;software maintenance;Unified Modeling Language","collaborative model-driven software engineering;CoSE;UML-based approach;decision making;understanding existing collaborative MDSE approaches;model-driven engineering","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Are Fix-Inducing Changes a Moving Target?: A Longitudinal Case Study of Just-in-Time Defect Prediction","S. McIntosh; Y. Kamei","McGill Univ., Montr√©al, QC, Canada; Kyushu Univ., Fukuoka, Japan","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","560","560","Just-In-Time (JIT) models identify fix-inducing code changes. JIT models are trained using techniques that assume that past fix-inducing changes are similar to future ones. However, this assumption may not hold, e.g., as system complexity tends to accrue, expertise may become more important as systems age. In this paper, we study JIT models as systems evolve. Through a longitudinal case study of 37,524 changes from the rapidly evolving Qt and OpenStack systems, we find that fluctuations in the properties of fix-inducing changes can impact the performance and interpretation of JIT models. More specifically: (a) the discriminatory power (AUC) and calibration (Brier) scores of JIT models drop considerably one year after being trained; (b) the role that code change properties (e.g., Size, Experience) play within JIT models fluctuates over time; and (c) those fluctuations yield over- and underestimates of the future impact of code change properties on the likelihood of inducing fixes. To avoid erroneous or misleading predictions, JIT models should be retrained using recently recorded data (within three months). Moreover, quality improvement plans should be informed by JIT models that are trained using six months (or more) of historical data, since they are more resilient to period-specific fluctuations in the importance of code change properties.","","","10.1145/3180155.3182514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453123","Just In Time prediction;Defect prediction;Mining software repositories","Software engineering;Predictive models;History;Fluctuations;Training;Data models;Software","data mining;just-in-time;learning (artificial intelligence);public domain software;software fault tolerance;software management","fix-inducing changes;JIT models;just-in-time models;just-in-time defect prediction;Qt systems;OpenStack systems;fix-inducing code changes;code change properties","","1","","","","","","IEEE","IEEE Conferences"
"Metamorphic Testing of RESTful Web APIs","S. Segura; J. A. Parejo; J. Troya; A. Ruiz-Cort√©s","Dept. of Comput. Languages & Syst., Univ. de Sevilla, Sevilla, Spain; Dept. of Comput. Languages & Syst., Univ. de Sevilla, Sevilla, Spain; Dept. of Comput. Languages & Syst., Univ. de Sevilla, Sevilla, Spain; Dept. of Comput. Languages & Syst., Univ. de Sevilla, Sevilla, Spain","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","882","882","Web Application Programming Interfaces (APIs) specify how to access services and data over the network, typically using Web services. Web APIs are rapidly proliferating as a key element to foster reusability, integration, and innovation, enabling new consumption models such as mobile or smart TV apps. Companies such as Facebook, Twitter, Google, eBay or Netflix receive billions of API calls every day from thousands of different third-party applications and devices, which constitutes more than half of their total traffic. As Web APIs are progressively becoming the cornerstone of software integration, their validation is getting more critical. In this context, the fast detection of bugs is of utmost importance to increase the quality of internal products and third-party applications. However, testing Web APIs is challenging mainly due to the difficulty to assess whether the output of an API call is correct, i.e., the oracle problem. For instance, consider the Web API of the popular music streaming service Spotify. Suppose a search for albums with the query ""redhouse"" returning 21 total matches: Is this output correct? Do all the albums in the result set contain the keyword? Are there any albums containing the keyword not included in the result set? Answering these questions is difficult, even with small result sets, and often infeasible when the results are counted by thousands or millions. Metamorphic testing alleviates the oracle problem by providing an alternative when the expected output of a test execution is complex or unknown. Rather than checking the output of an individual program execution, metamorphic testing checks whether multiple executions of the program under test fulfil certain necessary properties called metamorphic relations. For instance, consider the following metamorphic relation in Spotify: two searches for albums with the same query should return the same number of total results regardless of the size of pagination. Suppose that a new Spotify search is performed using the exact same query as before and increasing the maximum number of results per page from 20 (default value) to 50: This search returns 27 total albums (6 more matches than in the previous search), which reveals a bug. This is an example of a real and reproducible fault detected using the approach presented in this paper and reported to Spotify. According to Spotify developers, it was a regression fault caused by a fix with undesired side effects. In this paper [1], we present a metamorphic testing approach for the automated detection of faults in RESTful Web APIs (henceforth also referred to as simply Web APIs). We introduce the concept of metamorphic relation output patterns. A Metamorphic Relation Output Pattern (MROP) defines an abstract output relation typically identified in Web APIs, regardless of their application domain. Each MROP is defined in terms of set operations among test outputs such as equality, union, subset, or intersection. MROPs provide a helpful guide for the identification of metamorphic relations, broadening the scope of our work beyond a particular Web API. Based on the notion of MROP, a methodology is proposed for the application of the approach to any Web API following the REST architectural pattern. The approach was evaluated in several steps. First, we used the proposed methodology to identify 33 metamorphic relations in four Web APIs developed by undergraduate students. All the relations are instances of the proposed MROPs. Then, we assessed the effectiveness of the identified relations at revealing 317 automatically seeded faults (i.e., mutants) in the APIs under test. As a result, 302 seeded faults were detected, achieving a mutation score of 95.3%. Second, we evaluated the approach using real Web APIs and faults. In particular, we identified 20 metamorphic relations in the Web API of Spotify and 40 metamorphic relations in the Web API of YouTube. Each metamorphic relation was implemented and automatically executed using both random and manual test data. In total, 469K metamorphic tests were generated. As a result, 21 metamorphic relations were violated, and 11 issues revealed and reported (3 issues in Spotify and 8 issues in YouTube). To date, 10 of the reported issues have been either confirmed by the API developers or reproduced by other users supporting the effectiveness of our approach.","","","10.1145/3180155.3182528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453162","Metamorphic testing;REST;RESTful Web services;Web API","Testing;Software engineering;Software;Computer bugs;YouTube;Computer languages;Technological innovation","application program interfaces;program testing;Web services","metamorphic relation output pattern;RESTful Web API;MROP;metamorphic testing;REST architectural pattern","","","","","","","","IEEE","IEEE Conferences"
"On the Dichotomy of Debugging Behavior Among Programmers","M. Beller; N. Spruit; D. Spinellis; A. Zaidman","Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Athens Univ. of Econ. & Bus., Athens, Greece; Delft Univ. of Technol., Delft, Netherlands","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","572","583","Debugging is an inevitable activity in most software projects, often difficult and more time-consuming than expected, giving it the nickname the ""dirty little secret of computer science."" Surprisingly, we have little knowledge on how software engineers debug software problems in the real world, whether they use dedicated debugging tools, and how knowledgeable they are about debugging. This study aims to shed light on these aspects by following a mixed-methods research approach. We conduct an online survey capturing how 176 developers reflect on debugging. We augment this subjective survey data with objective observations on how 458 developers use the debugger included in their integrated development environments (IDEs) by instrumenting the popular Eclipse and IntelliJ IDEs with the purpose-built plugin WatchDog 2.0. To clarify the insights and discrepancies observed in the previous steps, we followed up by conducting interviews with debugging experts and regular debugging users. Our results indicate that IDE-provided debuggers are not used as often as expected, as ""printf debugging"" remains a feasible choice for many programmers. Furthermore, both knowledge and use of advanced debugging features are low. These results call to strengthen hands-on debugging experience in computer science curricula and have already refined the implementation of modern IDE debuggers.","","","10.1145/3180155.3180175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453125","Debugging;Testing;WatchDog;IntelliJ;Eclipse","Debugging;Software;Tools;Instruments;Interviews;Computer bugs;Software engineering","computer debugging;program debugging;software engineering;software maintenance","integrated development environments;debugging experts;regular debugging users;printf debugging;advanced debugging features;software projects;software engineers debug software problems;debugging tools;mixed-methods research approach","","2","","","","","","IEEE","IEEE Conferences"
"[Journal First] Challenges and Pitfalls on Surveying Evidence in the Software Engineering Technical Literature: An Exploratory Study with Novices","T. Vieira Ribeiro; J. Massollar; G. Horta Travassos","PESC/COPPE, Fed. Univ. of Rio de Janeiro, Rio de Janeiro, Brazil; PESC/COPPE, Fed. Univ. of Rio de Janeiro, Rio de Janeiro, Brazil; PESC/COPPE, Fed. Univ. of Rio de Janeiro, Rio de Janeiro, Brazil","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1194","1194","The evidence-based software engineering approach advocates the use of evidence from empirical studies to support the decisions on the adoption of software technologies by practitioners in the software industry. To this end, many guidelines have been proposed to contribute to the execution and repeatability of literature reviews, and to the confidence of their results, especially regarding systematic literature reviews (SLR). To investigate similarities and differences, and to characterize the challenges and pitfalls of the planning and generated results of SLR research protocols dealing with the same research question and performed by similar teams of novice researchers in the context of the software engineering field. We qualitatively compared (using Jaccard and Kappa coefficients) and evaluated (using DARE) same goal SLR research protocols and outcomes undertaken by similar research teams. Seven similar SLR protocols regarding quality attributes for use cases executed in 2010 and 2012 enabled us to observe unexpected differences in their planning and execution. Even when the participants reached some agreement in the planning, the outcomes were different. The research protocols and reports allowed us to observe six challenges contributing to the divergences in the results: researchers' inexperience in the topic, researchers' inexperience in the method, lack of clearness and completeness of the papers, lack of a common terminology regarding the problem domain, lack of research verification procedures, and lack of commitment to the SLR. According to our findings, it is not possible to rely on results of SLRs performed by novices. Also, similarities at a starting or intermediate step during different SLR executions may not directly translate to the next steps, since non-explicit information might entail differences in the outcomes, hampering the repeatability and confidence of the SLR process and results. Although we do have expectations that the presence and follow-up of a senior researcher can contribute to increasing SLRs' repeatability, this conclusion can only be drawn upon the existence of additional studies on this topic. Yet, systematic planning, transparency of decisions and verification procedures are key factors to guarantee the reliability of SLRs.","","","10.1145/3180155.3182557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453200","Novice researchers;Systematic literature review;Evidence based software engineering;Exploratory study","Software engineering;Software;Planning;Protocols;Knowledge engineering;Systematics;Terminology","DP industry;project management;software engineering","unexpected differences;research verification procedures;similar SLR protocols;software engineering field;SLR research protocols;systematic literature reviews;software industry;software technologies;evidence-based software engineering approach;software engineering technical literature;systematic planning;additional studies;senior researcher;SLR process","","","","","","","","IEEE","IEEE Conferences"
"Understanding the Factors for Fast Answers in Technical Q&A Websites: An Empirical Study of Four Stack Exchange Websites","S. Wang; T. Chen; A. E. Hassan","Software Anal. & Intell. Lab., Queen's Univ., Kingston, ON, Canada; Dept. of Comput. Sci. & Eng., Concordia Univ., Montreal, QC, Canada; Software Anal. & Intell. Lab., Queen's Univ., Kingston, ON, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","884","884","Technical questions and answers (Q&A) websites accumulate a significant amount of knowledge from users. Developers are especially active on these Q&A websites, since developers are constantly facing new development challenges that require help from other experts. Over the years, Q&A website designers have derived several incentive systems (e.g., gamification) to encourage users to answer questions that are posted by others. However, the current incentive systems primarily focus on the quantity and quality of the answers instead of encouraging the rapid answering of questions. Improving the speed of getting an answer can significantly improve the user experience and increase user engagement on such Q&A websites. In this paper [1], we study the factors for fast answers on such Q&A websites. Our goal is to explore how one may improve the current incentive systems to motivate fast answering of questions. We use a logistic regression model to analyze 46 factors along four dimensions (i.e., question, asker, answer, and answerer dimension) in order to understand the relationship between the studied factors and the needed time to get an accepted answer. The question dimension calculates various textual and readability features of a question, as well as the popularity and difficulty of the question's tags. The asker dimension calculates the reputation of an asker and his/her historical tendency to get answers. The answer dimension computes textual features from the text of the accepted answer. The answerer dimension computes the historical activity level of the answerer who answered the question. We conduct our study on the four most popular (i.e., with the most questions) Q&A Stack Exchange websites: Stack Overflow, Mathematics, Ask Ubuntu, and Superuser. We find that (i) factors in the answerer dimension have the strongest effect on the needed time to get an accepted answer, after controlling for other factors; (ii) the current incentive system does not recognize non-frequent answerers who often answer questions which frequent answerers are not able to answer well. Such questions that are answered by non-frequent answerers are as important as those that are answered by frequent answerers; (iii) the current incentive system motivates frequent answerers well, but such frequent answerers tend to answer short questions. Our findings suggest that the designers of Q&A website should improve their incentive systems to motivate non-frequent answerers to be more active and to answer questions faster, in order to shorten the waiting time for an answer (especially for questions that require specific knowledge that frequent answerers might not possess). In addition, the question answering incentive system needs to factor in the value and difficulty of answering the questions (e.g., by providing more rewards to harder questions or questions that remain unanswered for a long period of time).","","","10.1145/3180155.3182521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453164","Q&A website;Factor importance analysis;Response time","Software engineering;Software;Knowledge engineering;Computer science;Logistics;Analytical models;Mathematics","human factors;question answering (information retrieval);regression analysis;software engineering;Web sites","technical questions;incentive systems;answer questions;rapid answering;Q&A website;fast answering;answerer dimension;accepted answer;question dimension;answer dimension;nonfrequent answerers;current incentive system motivates frequent answerers;answer short questions;question answering incentive system;stack exchange Websites;answer Websites","","3","","","","","","IEEE","IEEE Conferences"
"Towards Practical Program Repair with On-demand Candidate Generation","J. Hua; M. Zhang; K. Wang; S. Khurshid","Univ. of Texas at Austin, Austin, TX, USA; Univ. of Texas at Austin, Austin, TX, USA; Univ. of Texas at Austin, Austin, TX, USA; Univ. of Texas at Austin, Austin, TX, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","12","23","Effective program repair techniques, which modify faulty programs to fix them with respect to given test suites, can substantially reduce the cost of manual debugging. A common repair approach is to iteratively first generate candidate programs with possible bug fixes and then validate them against the given tests until a candidate that passes all the tests is found. While this approach is conceptually simple, due to the potentially high number of candidates that need to first be generated and then be compiled and tested, existing repair techniques that embody this approach have relatively low effectiveness, especially for faults at a fine granularity. To tackle this limitation, we introduce a novel repair technique, SketchFix, which generates candidate fixes on demand (as needed) during the test execution. Instead of iteratively re-compiling and re-executing each actual candidate program, SketchFix translates faulty programs to sketches, i.e., partial programs with ""holes"", and compiles each sketch once which may represent thousands of concrete candidates. With the insight that the space of candidates can be reduced substantially by utilizing the runtime behaviors of the tests, SketchFix lazily initializes the candidates of the sketches while validating them against the test execution. We experimentally evaluate SketchFix on the Defects4J benchmark and the experimental results show that SketchFix works particularly well in repairing bugs with expression manipulation at the AST node-level granularity compared to other program repair techniques. Specifically, SketchFix correctly fixes 19 out of 357 defects in 23 minutes on average using the default setting. In addition, SketchFix finds the first repair with 1.6% of re-compilations (#compiled sketches/#candidates) and 3.0% of re-executions out of all repair candidates.","","","10.1145/3180155.3180245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453056","debugging;program repair;program synthesis;lazy initialization;execution driven pruning","Maintenance engineering;Computer bugs;Runtime;Syntactics;Debugging;Java","program compilers;program debugging;program diagnostics;program testing;software fault tolerance;software maintenance","effective program repair techniques;faulty programs;manual debugging;common repair approach;candidate programs;possible bug fixes;relatively low effectiveness;novel repair technique;SketchFix;candidate fixes;test execution;iteratively re-compiling;re-executing each actual candidate program;partial programs;concrete candidates;re-compilations;repair candidates;practical program repair;on-demand candidate generation;#compiled sketches-#candidates","","13","","","","","","IEEE","IEEE Conferences"
"Reducer-Based Construction of Conditional Verifiers","D. Beyer; M. Jakobs; T. Lemberger; H. Wehrheim","LMU Munich, Munich, Germany; LMU Munich, Munich, Germany; LMU Munich, Munich, Germany; Paderborn Univ., Paderborn, Germany","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1182","1193","Despite recent advances, software verification remains challenging. To solve hard verification tasks, we need to leverage not just one but several different verifiers employing different technologies. To this end, we need to exchange information between verifiers. Conditional model checking was proposed as a solution to exactly this problem: The idea is to let the first verifier output a condition which describes the state space that it successfully verified and to instruct the second verifier to verify the yet unverified state space using this condition. However, most verifiers do not understand conditions as input. In this paper, we propose the usage of an off-the-shelf construction of a conditional verifier from a given traditional verifier and a reducer. The reducer takes as input the program to be verified and the condition, and outputs a residual program whose paths cover the unverified state space described by the condition. As a proof of concept, we designed and implemented one particular reducer and composed three conditional model checkers from the three best verifiers at SV-COMP 2017. We defined a set of claims and experimentally evaluated their validity. All experimental data and results are available for replication.","","","10.1145/3180155.3180259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453199","Conditional Model Checking;Formal Verification;Testing;Program Analysis;Software Verification;Sequential Combination","Automata;Software;Model checking;Tools;Software engineering;Task analysis","formal verification;program diagnostics;program verification","conditional model checking;verifier output;unverified state space;conditional model checkers;hard verification tasks;software verification;conditional verifier;reducer-based construction","","","","","","","","IEEE","IEEE Conferences"
"Data Scientists in Software Teams: State of the Art and Challenges","M. Kim; T. Zimmermann; R. DeLine; A. Begel","UCLA, Los Angeles, CA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","585","585","The demand for analyzing large scale telemetry, machine, and quality data is rapidly increasing in software industry. Data scientists are becoming popular within software teams. For example, Facebook, LinkedIn and Microsoft are creating a new career path for data scientists. In this paper, we present a large-scale survey with 793 professional data scientists at Microsoft to understand their educational background, problem topics that they work on, tool usages, and activities. We cluster these data scientists based on the time spent for various activities and identify 9 distinct clusters of data scientists and their corresponding characteristics. We also discuss the challenges that they face and the best practices they share with other data scientists. Our study finds several trends about data scientists in the software engineering context at Microsoft, and should inform managers on how to leverage data science capability effectively within their teams.","","","10.1145/3180155.3182515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453127","Software productivity;data science","Software;Tools;Data science;Software engineering;Face;Best practices;Instruments","DP industry;social networking (online)","software teams;data scientists;software industry;Facebook;LinkedIn;Microsoft","","","","","","","","IEEE","IEEE Conferences"
"Secure Coding Practices in Java: Challenges and Vulnerabilities","N. Meng; S. Nagy; D. Yao; W. Zhuang; G. Arango-Argoty","Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","372","383","The Java platform and its third-party libraries provide useful features to facilitate secure coding. However, misusing them can cost developers time and effort, as well as introduce security vulnerabilities in software. We conducted an empirical study on StackOverflow posts, aiming to understand developers' concerns on Java secure coding, their programming obstacles, and insecure coding practices. We observed a wide adoption of the authentication and authorization features provided by Spring Security - a third-party framework designed to secure enterprise applications. We found that programming challenges are usually related to APIs or libraries, including the complicated cross-language data handling of cryptography APIs, and the complex Java-based or XML-based approaches to configure Spring Security. In addition, we reported multiple security vulnerabilities in the suggested code of accepted answers on the StackOverflow forum. The vulnerabilities included disabling the default protection against Cross-Site Request Forgery (CSRF) attacks, breaking SSL/TLS security through bypassing certificate validation, and using insecure cryptographic hash functions. Our findings reveal the insufficiency of secure coding assistance and documentation, as well as the huge gap between security theory and coding practices.","","","10.1145/3180155.3180201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453095","Secure coding;Spring security;CSRF;SSL/TLS;certificate validation;cryptographic hash functions;authentication;authorization;StackOverflow;cryptography","Java;Cryptography;Encoding;Libraries;Programming;Authentication","application program interfaces;authorisation;computer crime;cryptography;Java;XML","secure coding practices;Java platform;third-party libraries;developers time;empirical study;StackOverflow posts;Java secure coding;programming obstacles;insecure coding practices;authorization features;third-party framework;programming challenges;complicated cross-language data handling;complex Java-based;XML-based approaches;cross-site request forgery attacks;Spring security;cryptography API;SSL-TLS security;secure coding assistance;StackOverflow forum;multiple security vulnerabilities","","6","","","","","","IEEE","IEEE Conferences"
"Identifying Design Problems in the Source Code: A Grounded Theory","L. Sousa; A. Oliveira; W. Oizumi; S. Barbosa; A. Garcia; J. Lee; M. Kalinowski; R. de Mello; B. Fonseca; R. Oliveira; C. Lucena; R. Paes","NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","921","931","The prevalence of design problems may cause re-engineering or even discontinuation of the system. Due to missing, informal or outdated design documentation, developers often have to rely on the source code to identify design problems. Therefore, developers have to analyze different symptoms that manifest in several code elements, which may quickly turn into a complex task. Although researchers have been investigating techniques to help developers in identifying design problems, there is little knowledge on how developers actually proceed to identify design problems. In order to tackle this problem, we conducted a multi-trial industrial experiment with professionals from 5 software companies to build a grounded theory. The resulting theory offers explanations on how developers identify design problems in practice. For instance, it reveals the characteristics of symptoms that developers consider helpful. Moreover, developers often combine different types of symptoms to identify a single design problem. This knowledge serves as a basis to further understand the phenomena and advance towards more effective identification techniques.","","","10.1145/3180155.3180239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453170","design problem;grounded theory;software design;symptoms","Software systems;Task analysis;Software design;Fats;Documentation;Companies","DP industry;software engineering;source code (software);system documentation","source code;grounded theory;design documentation;design problems identification;code elements;software companies","","3","","","","","","IEEE","IEEE Conferences"
"[Journal First] Do Automated Program Repair Techniques Repair Hard and Important Bugs?","M. Motwani; S. Sankaranarayanan; R. Just; Y. Brun","Univ. of Massachusetts, Amherst, MA, USA; Univ. of Massachusetts, Amherst, MA, USA; Univ. of Massachusetts, Amherst, MA, USA; Univ. of Massachusetts, Amherst, MA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","25","25","The full version of this article is: Manish Motwani, Sandhya Sankaranarayanan, Rene Just, and Yuriy Brun, ""Do Automated Program Repair Techniques Repair Hard and Important Bugs?"" in Empirical Software Engineering, http://dx.doi.org/10.1007/s10664-017-9550-0.","","","10.1145/3180155.3182533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453058","Automated program repair;Repairability","Maintenance engineering;Java;Computer bugs;Correlation;Software engineering;Complexity theory;Benchmark testing","program debugging;software maintenance","repair techniques;important bugs;automated program","","","","","","","","IEEE","IEEE Conferences"
"EARMO: An Energy-Aware Refactoring Approach for Mobile Apps","R. Morales; R. Saborido; F. Khomh; F. Chicano; G. Antoniol","NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","59","59","With millions of smartphones sold every year, the development of mobile apps has grown substantially. The battery power limitation of mobile devices has push developers and researchers to search for methods to improve the energy efficiency of mobile apps. We propose a multiobjective refactoring approach to automatically improve the architecture of mobile apps, while controlling for energy efficiency. In this extended abstract we briefly summarize our work.","","","10.1145/3180155.3182524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453062","Refactoring;Anti-patterns;Mobile apps;Energy consumption","Energy efficiency;Software engineering;Batteries;Energy measurement;Mobile handsets;Energy consumption;Software","C language;energy conservation;smart phones;software maintenance","multiobjective refactoring approach;mobile apps;energy efficiency;energy-aware refactoring approach;mobile devices;push developers","","","","","","","","IEEE","IEEE Conferences"
"When Not to Comment: Questions and Tradeoffs with API Documentation for C++ Projects","A. Head; C. Sadowski; E. Murphy-Hill; A. Knight","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","643","653","Without usable and accurate documentation of how to use an API, developers can find themselves deterred from reusing relevant code. In C++, one place developers can find documentation is in a header file. When information is missing, they may look at the corresponding implementation code. To understand what's missing from C++ API documentation and the factors influencing whether it will be fixed, we conducted a mixed-methods study involving two experience sampling surveys with hundreds of developers at the moment they visited implementation code, interviews with 18 of those developers, and interviews with 8 API maintainers. In many cases, updating documentation may provide only limited value for developers, while requiring effort maintainers don't want to invest. We identify a set of questions maintainers and tool developers should consider when improving API-level documentation.","","","10.1145/3180155.3180176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453133","documentation;human factors;developer workflow;APIs;usability","Documentation;Interviews;Tools;Task analysis;C++ languages;Google;Software engineering","application program interfaces;C++ language;system documentation","API-level documentation improvement;tool developers;questions maintainers;updating documentation;experience sampling surveys;mixed-methods study;C++ API documentation;corresponding implementation code;header file;place developers;relevant code;accurate documentation;usable documentation","","1","","","","","","IEEE","IEEE Conferences"
"Search-Based Test Data Generation for SQL Queries","J. Castelein; M. Aniche; M. Soltani; A. Panichella; A. van Deursen","NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1220","1230","Database-centric systems strongly rely on SQL queries to manage and manipulate their data. These SQL commands can range from very simple selections to queries that involve several tables, subqueries, and grouping operations. And, as with any important piece of code, developers should properly test SQL queries. In order to completely test a SQL query, developers need to create test data that exercise all possible coverage targets in a query, e.g., JOINs and WHERE predicates. And indeed, this task can be challenging and time-consuming for complex queries. Previous studies have modeled the problem of generating test data as a constraint satisfaction problem and, with the help of SAT solvers, generate the required data. However, such approaches have strong limitations, such as partial support for queries with JOINs, subqueries, and strings (which are commonly used in SQL queries). In this paper, we model test data generation for SQL queries as a search-based problem. Then, we devise and evaluate three different approaches based on random search, biased random search, and genetic algorithms (GAs). The GA, in particular, uses a fitness function based on information extracted from the physical query plan of a database engine as search guidance. We then evaluate each approach in 2,135 queries extracted from three open source software and one industrial software system. Our results show that GA is able to completely cover 98.6% of all queries in the dataset, requiring only a few seconds per query. Moreover, it does not suffer from the limitations affecting state-of-the art techniques.","","","10.1145/3180155.3180202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453204","search based software engineering;automated test data generation;SQL;databases","Databases;Genetic algorithms;Search problems;Structured Query Language;Toy manufacturing industry;Software systems;Engines","database management systems;genetic algorithms;program testing;query processing;search problems;SQL","SQL query;complex queries;model test data generation;physical query plan;Search-Based Test Data Generation;database-centric systems;SQL queries;SQL commands;constraint satisfaction problem;search-based problem;biased random search;genetic algorithms;database engine;search guidance;open source software;industrial software system","","2","","","","","","IEEE","IEEE Conferences"
"Large-Scale Analysis of Framework-Specific Exceptions in Android Apps","L. Fan; T. Su; S. Chen; G. Meng; Y. Liu; L. Xu; G. Pu; Z. Su","Sch. of Comput. Sci. & Software Eng., East China Normal Univ., Shanghai, China; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Sci. & Software Eng., East China Normal Univ., Shanghai, China; SKLOIS, Inst. of Inf. Eng., Beijing, China; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Sci. & Software Eng., East China Normal Univ., Shanghai, China; Shanghai Key Lab. of Trustworthy Comput., East China Normal Univ., Shanghai, China; Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","408","419","Mobile apps have become ubiquitous. For app developers, it is a key priority to ensure their apps' correctness and reliability. However, many apps still suffer from occasional to frequent crashes, weakening their competitive edge. Large-scale, deep analyses of the characteristics of real-world app crashes can provide useful insights to guide developers, or help improve testing and analysis tools. However, such studies do not exist - this paper fills this gap. Over a four-month long effort, we have collected 16,245 unique exception traces from 2,486 open-source Android apps, and observed that framework-specific exceptions account for the majority of these crashes. We then extensively investigated the 8,243 framework-specific exceptions (which took six person-months): (1) identifying their characteristics (e.g., manifestation locations, common fault categories), (2) evaluating their manifestation via state-of-the-art bug detection techniques, and (3) reviewing their fixes. Besides the insights they provide, these findings motivate and enable follow-up research on mobile apps, such as bug detection, fault localization and patch generation. In addition, to demonstrate the utility of our findings, we have optimized Stoat, a dynamic testing tool, and implemented ExLocator, an exception localization tool, for Android apps. Stoat is able to quickly uncover three previously-unknown, confirmed/fixed crashes in Gmail and Google+; ExLocator is capable of precisely locating the root causes of identified exceptions in real-world apps. Our substantial dataset is made publicly available to share with and benefit the community.","","","10.1145/3180155.3180222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453100","Empirical study;mobile app bugs;testing;static analysis","Testing;Androids;Humanoid robots;Computer bugs;Tools;Google","Android (operating system);dynamic testing;mobile computing;program debugging;program testing;public domain software","unique exception;open-source Android apps;framework-specific exceptions;bug detection techniques;real-world apps;identified exceptions;confirmed/fixed crashes;exception localization tool;dynamic testing tool;mobile apps;four-month long effort;analysis tools;real-world app crashes;frequent crashes;app developers","","12","","","","","","IEEE","IEEE Conferences"
"From UI Design Image to GUI Skeleton: A Neural Machine Translator to Bootstrap Mobile GUI Implementation","C. Chen; T. Su; G. Meng; Z. Xing; Y. Liu","Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; Res. Sch. of Comput. Sciecne, Australian Nat. Univ., Canberra, ACT, Australia; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","665","676","A GUI skeleton is the starting point for implementing a UI design image. To obtain a GUI skeleton from a UI design image, developers have to visually understand UI elements and their spatial layout in the image, and then translate this understanding into proper GUI components and their compositions. Automating this visual understanding and translation would be beneficial for bootstraping mobile GUI implementation, but it is a challenging task due to the diversity of UI designs and the complexity of GUI skeletons to generate. Existing tools are rigid as they depend on heuristically-designed visual understanding and GUI generation rules. In this paper, we present a neural machine translator that combines recent advances in computer vision and machine translation for translating a UI design image into a GUI skeleton. Our translator learns to extract visual features in UI images, encode these features' spatial layouts, and generate GUI skeletons in a unified neural network framework, without requiring manual rule development. For training our translator, we develop an automated GUI exploration method to automatically collect large-scale UI data from real-world applications. We carry out extensive experiments to evaluate the accuracy, generality and usefulness of our approach.","","","10.1145/3180155.3180240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453135","User interface;reverse engineering;deep learning","Graphical user interfaces;Skeleton;Layout;Visualization;Feature extraction;Tools;Task analysis","computer bootstrapping;computer vision;graphical user interfaces;language translation;mobile computing;neural nets","large-scale UI data;GUI exploration method;GUI components;computer vision;GUI generation rules;heuristically-designed visual understanding;bootstrap mobile GUI implementation;neural machine translator;GUI skeleton;UI design image","","8","","","","","","IEEE","IEEE Conferences"
"Does the Propagation of Artifact Changes Across Tasks Reflect Work Dependencies?","C. Mayr-Dorn; A. Egyed","Johannes Kepler Univ., Linz, Austria; Johannes Kepler Univ., Linz, Austria","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","397","407","Developers commonly define tasks to help coordinate software development efforts--whether they be feature implementation, refactoring, or bug fixes. Developers establish links between tasks to express implicit dependencies that needs explicit handling--dependencies that often require the developers responsible for a given task to assess how changes in a linked task affect their own work and vice versa (i.e., change propagation). While seemingly useful, it is unknown if change propagation indeed coincides with task links. No study has investigated to what extent change propagation actually occurs between task pairs and whether it is able to serve as a metric for characterizing the underlying task dependency. In this paper, we study the temporal relationship between developer reading and changing of source code in relationship to task links. We identify seven situations that explain the varying correlation of change propagation with linked task pairs and find six motifs describing when change propagation occurs between non-linked task pairs. Our paper demonstrates that task links are indeed useful for recommending which artifacts to monitor for changes, which developers to involve in a task, or which tasks to inspect.","","","10.1145/3180155.3180185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453099","task links;change propagation;bugzilla;mylyn;empirical study","Licenses","project management;software engineering;software maintenance","implicit dependencies;task links;extent change propagation;underlying task dependency;linked task pairs;nonlinked task pairs;software development efforts;explicit handling","","2","","","","","","IEEE","IEEE Conferences"
"Automated Refactoring of OCL Constraints with Search","H. Lu; S. Wang; T. Yue; S. Ali; J. Nygard","Simula Res. Lab., Lysaker, Norway; Simula Res. Lab., Lysaker, Norway; Simula Res. Lab., Lysaker, Norway; Simula Res. Lab., Lysaker, Norway; Cancer Registry of Norway, Oslo, Norway","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1243","1243","Object Constraint Language (OCL) constraints are typically used for providing precise semantics to models developed with the Unified Modeling Language (UML). When OCL constraints evolve in a regular basis, it is essential that they are easy to understand and maintain. For instance, in cancer registries, to ensure the quality of cancer data, more than one thousand medical rules are defined and evolve regularly. Such rules can be specified with OCL. It is, therefore, important to ensure the understandability and maintainability of medical rules specified with OCL. To tackle such a challenge, we propose an automated search-based OCL constraint refactoring approach (SBORA) by defining and applying three OCL quality metrics (Complexity, Coupling, and Cohesion) and four semantics-preserving refactoring operators (i.e., Context Change, Swap, Split and Merge) which are encoded as potential solutions for search algorithms. A solution is therefore an optimal sequence of refactoring operators, which are sequentially applied to the original set of OCL constraints to automatically obtain a semantically equivalent set of OCL constraints with better understandability and maintainability in terms of Complexity, Coupling, and Cohesion. We evaluate SBORA along with six commonly used multi-objective search algorithms (e.g., Indicator-Based Evolutionary Algorithm (IBEA)) by employing four case studies from different domains: healthcare (i.e., cancer registry system from Cancer Registry of Norway (CRN)), Oil&Gas (i.e., subsea production systems), warehouse (i.e., handling systems), and an open source case study named SEPA. Results show: 1) IBEA achieves the best performance among all the search algorithms and 2) the refactoring approach along with IBEA can manage to reduce on average 29.25% Complexity and 39% Coupling and improve 47.75% Cohesion, as compared to the original OCL constraint set from CRN. To further test the performance of SBORA, we also applied it to refactor an OCL constraint set specified on the UML 2.3 metamodel and we obtained encouraging results. Furthermore, we conducted a controlled experiment with 96 subjects and results show that the understandability and maintainability of the original constraint set can be improved significantly from the perspectives of the 96 participants of the controlled experiment.","","","10.1145/3180155.3182546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453206","Refactoring;Search;Object Constraint Language","Cancer;Unified modeling language;Complexity theory;Couplings;Software engineering;Semantics;Measurement","evolutionary computation;object-oriented programming;search problems;software maintenance;Unified Modeling Language","cancer registries;automated search-based OCL constraint refactoring approach;OCL quality metrics;semantics-preserving refactoring operators;search algorithms;Cancer Registry;original OCL constraint;original constraint set;object constraint language constraints","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Experiences and Challenges in Building a Data Intensive System for Data Migration","M. Scavuzzo; E. Di Nitto; D. Ardagna","Dipt. di Elettron. Inf. e Bioingegneria Milano, Politec. di MilanoDipartimento di Elettronica Informazione e Bioingegneria Milano, Milan, Italy; Dipt. di Elettron. Inf. e Bioingegneria Milano, Politec. di MilanoDipartimento di Elettronica Informazione e Bioingegneria Milano, Milan, Italy; Dipt. di Elettron. Inf. e Bioingegneria Milano, Politec. di MilanoDipartimento di Elettronica Informazione e Bioingegneria Milano, Milan, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","93","93","Recent analyses[2, 4, 5] report that many sectors of our economy and society are more and more guided by data-driven decision processes (e.g., health care, public administrations, etc.). As such, Data Intensive (DI) applications are becoming more and more important and critical. They must be fault-tolerant, they should scale with the amount of data, and be able to elastically leverage additional resources as and when these last ones are provided [3]. Moreover, they should be able to avoid data drops introduced in case of sudden overloads and should offer some Quality of Service (QoS) guarantees. Ensuring all these properties is, per se, a challenge, but it becomes even more difficult for DI applications, given the large amount of data to be managed and the significant level of parallelism required for its components. Even if today some technological frameworks are available for the development of such applications (for instance, think of Spark, Storm, Flink), we still lack solid software engineering approaches to support their development and, in particular, to ensure that they offer the required properties in terms of availability, throughput, data loss, etc. In fact, at the time of writing, identifying the right solution can require several rounds of experiments and the adoption of many different technologies. This implies the need for highly skilled persons and the execution of experiments with large data sets and a large number of resources, and, consequently, a significant amount of time and budget. To experiment with currently available approaches, we performed an action research experiment focusing on developing- testing-reengineering a specific DI application, Hegira4Cloud, that migrates data between widely used NoSQL databases, including so-called Database as a Service (DaaS), as well as on-premise databases. This is a representative DI system because it has to handle large volumes of data with different structures and has to guarantee that some important characteristics, in terms of data types and transactional properties, are preserved. Also, it poses stringent requirements in terms of correctness, high performance, fault tolerance, and fast and effective recovery. In our action research, we discovered that the literature offered some high level design guidelines for DI applications, as well as some tools to support modelling and QoS analysis/simulation of complex architectures, however the available tools were not yet. suitable to support DI systems. Moreover, we realized that the available big data frameworks we could have used were not flexible enough to cope with all possible application-specific aspects of our system. Hence, to achieve the desired level of performance, fault tolerance and recovery, we had to adopt a time-consuming, experiment-based approach [1, 6], which, in our case, consisted of three iterations: (1) the design and implementation of a Mediation Data Model capable of managing data extracted from different databases, together with a first monholitical prototype of Hegira4Cloud; (2) the improvement of performance of our prototype when managing and transferring huge amounts of data; (3) the introduction of fault-tolerant data extraction and management mechanisms, which are independent from the targeted databases. Among the others, an important issue that has forced us to reiterate in the development of Hegira4Cloud concerned the DaaS we interfaced with. In particular these DaaS, which are well-known services with a large number of users: (1) were missing detailed information regarding the behaviour of their APIs; (2) did not offer a predictable service; (3) were suffering of random downtimes not correlated with the datasets we were experimenting with. In this journal first presentation, we describe our experience and the issues we encountered that led to some important decisions during the software design and engineering process. Also, we analyse the state of the art of software design and verification tools and approaches in the light of our experience, and identify weaknesses, alternative design approaches and open challenges that could generate new research in these areas. More details can be found in the journal publication.","","","10.1145/3180155.3182534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453066","Data intensive applications;Experiment driven action research;Big data;Data migration","Big Data;Databases;Quality of service;Tools;Fault tolerance;Fault tolerant systems;Software","Big Data;cloud computing;data analysis;data models;formal verification;NoSQL databases;program testing;quality of service;software quality","Hegira4Cloud;fault-tolerant data extraction;software design;verification tools;Data Intensive system;data loss;Mediation Data Model;software engineering;QoS analysis;big data frameworks;NoSQL databases;data migration;Quality of Service;developing- testing-reengineering;Database as a Service","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Sentiment Polarity Detection for Software Development","F. Calefato; F. Lanubile; F. Maiorano; N. Novielli","Univ. of Bari Aldo Moro, Bari, Italy; Univ. of Bari Aldo Moro, Bari, Italy; Univ. of Bari Aldo Moro, Bari, Italy; Univ. of Bari Aldo Moro, Bari, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","128","128","The role of sentiment analysis is increasingly emerging to study software developers' emotions by mining crowd-generated content within software repositories and information sources. With a few notable exceptions, empirical software engineering studies have exploited off-the-shelf sentiment analysis tools. However, such tools have been trained on non-technical domains and general-purpose social media, thus resulting in misclassifications of technical jargon and problem reports. In particular, Jongeling et al. show how the choice of the sentiment analysis tool may impact the conclusion validity of empirical studies because not only these tools do not agree with human annotation of developers' communication channels, but they also disagree among themselves. Our goal is to move beyond the limitations of off-the-shelf sentiment analysis tools when applied in the software engineering domain. Accordingly, we present Senti4SD, a sentiment polarity classifier for software developers' communication channels. Senti4SD exploits a suite of lexicon-based, keyword-based, and semantic features for appropriately dealing with the domain-dependent use of a lexicon. We built a Distributional Semantic Model (DSM) to derive the semantic features exploited by Senti4SD. Specifically, we ran word2vec on a collection of over 20 million documents from Stack Overflow, thus obtaining word vectors that are representative of developers' communication style. The classifier is trained and validated using a gold standard of 4,423 Stack Overflow posts, including questions, answers, and comments, which were manually annotated for sentiment polarity. We release the full lab package, which includes both the gold standard and the emotion annotation guidelines, to ease the execution of replications as well as new studies on emotion awareness in software engineering. To inform future research on word embedding for text categorization and information retrieval in software engineering, the replication kit also includes the DSM. Results. The contribution of the lexicon-based, keyword-based, and semantic features is assessed by our empirical evaluation leveraging different feature settings. With respect to SentiStrength, a mainstream off-the-shelf tool that we use as a baseline, Senti4SD reduces the misclassifications of neutral and positive posts as emotionally negative. Furthermore, we provide empirical evidence of better performance also in presence of a minimal set of training documents.","","","10.1145/3180155.3182519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453070","Sentiment Analysis;Communication Channels;Stack Overflow;Word Embedding;Social Software Engineering","Software;Software engineering;Collaboration;Programming","data mining;information retrieval;pattern classification;sentiment analysis;social networking (online);software engineering","keyword-based features;sentiment polarity detection;empirical software engineering;distributional semantic model;DSM;stack overflow;emotion annotation guidelines;text categorization;information retrieval;replication kit;sentistrength;word embedding;software developers emotions;crowd-generated content mining;lexicon-based features;software developers communication channels;word vectors;sentiment polarity classifier;software engineering domain;problem reports;technical jargon;general-purpose social media;nontechnical domains;off-the-shelf sentiment analysis tools;information sources;software repositories;software development;Senti4SD;semantic features","","","","","","","","IEEE","IEEE Conferences"
"Redefining Prioritization: Continuous Prioritization for Continuous Integration","J. Liang; S. Elbaum; G. Rothermel","Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Univ. of Nebraska-Lincoln, Lincoln, NE, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","688","698","Continuous integration (CI) development environments allow soft-ware engineers to frequently integrate and test their code. While CI environments provide advantages, they also utilize non-trivial amounts of time and resources. To address this issue, researchers have adapted techniques for test case prioritization (TCP) to CI environments. To date, however, the techniques considered have operated on test suites, and have not achieved substantial improvements. Moreover, they can be inappropriate to apply when system build costs are high. In this work we explore an alternative: prioritization of commits. We use a lightweight approach based on test suite failure and execution history that is highly efficient; our approach ""continuously"" prioritizes commits that are waiting for execution in response to the arrival of each new commit and the completion of each previously scheduled commit. We have evaluated our approach on three non-trivial CI data sets. Our results show that our approach can be more effective than prior techniques.","","","10.1145/3180155.3180213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453137","continuous integration;regression testing;large scale testing","Software engineering","program testing;software engineering","continuous prioritization;continuous integration development environments;CI environments;nontrivial amounts;test case prioritization;test suites;test suite failure;nontrivial CI data sets;software engineers","","1","","","","","","IEEE","IEEE Conferences"
"[Journal First] Older Adults and Hackathons: A Qualitative Study","W. Kopec; B. Balcerzak; R. Nielek; G. Kowalik; A. Wierzbicki; F. Casati","Polish-Japanese Acad. of Inf. Technol., Warsaw, Japan; Polish-Japanese Acad. of Inf. Technol., Warsaw, Japan; Polish-Japanese Acad. of Inf. Technol., Warsaw, Japan; Polish-Japanese Acad. of Inf. Technol., Warsaw, Japan; Polish-Japanese Acad. of Inf. Technol., Warsaw, Japan; Univ. of Trento, Povo, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","702","703","Globally observed trends in aging indicate that older adults constitute a growing share of the population and an increasing demographic in the modern technologies marketplace. Therefore, it has become important to address the issue of participation of older adults in the process of developing solutions suitable for their group. In this study, we approached this topic by organizing a hackathon involving teams of young programmers and older adult participants. In our paper we describe a case study of that hackathon, in which our objective was to motivate older adults to participate in software engineering processes. Based on our results from an array of qualitative methods, we propose a set of good practices that may lead to improved older adult participation in similar events and an improved process of developing apps that target older adults.","","","10.1145/3180155.3182547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453141","older adults;elderly;participatory design;co-design;user-centered design;user experience;hackathons;qualitative methods;intergenerational interaction;intergenerational cooperation","Information technology;Software engineering;Software;Collaboration;Human computer interaction;Programming profession","age issues;geriatrics;human factors;software engineering","young programmers;software engineering processes;older adult participants;hackathon","","","","","","","","IEEE","IEEE Conferences"
"DeFlaker: Automatically Detecting Flaky Tests","J. Bell; O. Legunsen; M. Hilton; L. Eloussi; T. Yung; D. Marinov","George Mason Univ., Fairfax, VA, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","433","444","Developers often run tests to check that their latest changes to a code repository did not break any previously working functionality. Ideally, any new test failures would indicate regressions caused by the latest changes. However, some test failures may not be due to the latest changes but due to non-determinism in the tests, popularly called flaky tests. The typical way to detect flaky tests is to rerun failing tests repeatedly. Unfortunately, rerunning failing tests can be costly and can slow down the development cycle. We present the first extensive evaluation of rerunning failing tests and propose a new technique, called DeFlaker, that detects if a test failure is due to a flaky test without rerunning and with very low runtime overhead. DeFlaker monitors the coverage of latest code changes and marks as flaky any newly failing test that did not execute any of the changes. We deployed DeFlaker live, in the build process of 96 Java projects on TravisCI, and found 87 previously unknown flaky tests in 10 of these projects. We also ran experiments on project histories, where DeFlaker detected 1,874 flaky tests from 4,846 failures, with a low false alarm rate (1.5%). DeFlaker had a higher recall (95.5% vs. 23%) of confirmed flaky tests than Maven's default flaky test detector.","","","10.1145/3180155.3180164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453104","software testing;flaky tests;code coverage","Monitoring;Testing;Java;Software;Tools;Syntactics;Detectors","Java;program testing;public domain software;regression analysis","DeFlaker;test failure;unknown flaky tests","","7","","","","","","IEEE","IEEE Conferences"
"Identifying Features in Forks","S. Zhou; S. Stanciulescu; O. Le√üenich; Y. Xiong; A. Wasowski; C. K√§stner","NA; NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","105","116","Fork-based development has been widely used both in open source communities and in industry, because it gives developers flexibility to modify their own fork without affecting others. Unfortunately, this mechanism has downsides: When the number of forks becomes large, it is difficult for developers to get or maintain an overview of activities in the forks. Current tools provide little help. We introduce INFOX, an approach to automatically identify non-merged features in forks and to generate an overview of active forks in a project. The approach clusters cohesive code fragments using code and network-analysis techniques and uses information-retrieval techniques to label clusters with keywords. The clustering is effective, with 90% accuracy on a set of known features. In addition, a human-subject evaluation shows that INFOX can provide actionable insight for developers of forks.","","","10.1145/3180155.3180205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453068","Fork-based development;Github;Community detection;Information retrieval;overview of forks;transparency","Feature extraction;Computer bugs;Navigation;History;Tools;Visualization;Google","feature extraction;information retrieval;pattern clustering","identifying features;fork-based development;open source communities;INFOX;nonmerged features;clusters cohesive code fragments;network-analysis techniques;information-retrieval techniques;human-subject evaluation","","3","","","","","","IEEE","IEEE Conferences"
"Automated Repair of Mobile Friendly Problems in Web Pages","S. Mahajan; N. Abolhassani; P. McMinn; W. G. J. Halfond","Univ. of Southern California, Los Angeles, CA, USA; Univ. of Southern California, Los Angeles, CA, USA; Univ. of Sheffield, Sheffield, UK; Univ. of Southern California, Los Angeles, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","140","150","Mobile devices have become a primary means of accessing the Internet. Unfortunately, many websites are not designed to be mobile friendly. This results in problems such as unreadable text, cluttered navigation, and content over owing a device's viewport; all of which can lead to a frustrating and poor user experience. Existing techniques are limited in helping developers repair these mobile friendly problems. To address this limitation of prior work, we designed a novel automated approach for repairing mobile friendly problems in web pages. Our empirical evaluation showed that our approach was able to successfully resolve mobile friendly problems in 95% of the evaluation subjects. In a user study, participants preferred our repaired versions of the subjects and also considered the repaired pages to be more readable than the originals.","","","10.1145/3180155.3180262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453072","Mobile Friendly Problems;automated repair;web apps","Web pages;Maintenance engineering;Mobile handsets;Cascading style sheets;Layout;Navigation;Organizations","computer displays;Internet;mobile computing;Web sites","mobile devices;mobile friendly problems;Web pages;Internet;Websites;cluttered navigation;user experience","","3","","","","","","IEEE","IEEE Conferences"
"[Journal First] On the Use of Hidden Markov Model to Predict the Time to Fix Bugs","M. Habayeb; S. S. Murtaza; A. Miranskyy; A. B. Bener","Dept. of Mech. & Ind. Eng., Ryerson Univ., Toronto, ON, Canada; Dept. of Mech. & Ind. Eng., Ryerson Univ., Toronto, ON, Canada; Dept. of Comput. Sci., Ryerson Univ., Toronto, ON, Canada; Dept. of Mech. & Ind. Eng., Ryerson Univ., Toronto, ON, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","700","700","A significant amount of time is spent by software developers in investigating bug reports. It is useful to indicate when a bug report will be closed, since it would help software teams to prioritise their work. Several studies have been conducted to address this problem in the past decade. Most of these studies have used the frequency of occurrence of certain developer activities as input attributes in building their prediction models. However, these approaches tend to ignore the temporal nature of the occurrence of these activities. In this paper, a novel approach using Hidden Markov models (HMMs) and temporal sequences of developer activities is proposed. The approach is empirically demonstrated in a case study using eight years of bug reports collected from the Firefox project.","","","10.1145/3180155.3182522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453139","Bug repositories;Temporal activities;Time to fix a bug;Hidden Markov model","Computer bugs;Hidden Markov models;Software;Software engineering;Data science;Predictive models;Industrial engineering","hidden Markov models;program debugging","software developers;bug report;software teams;prediction models;hidden Markov model;bug fixing;Firefox project;HMM","","","","","","","","IEEE","IEEE Conferences"
"Do Programmers Work at Night or During the Weekend?","M. Claes; M. V. M√§ntyl√§; M. Kuutila; B. Adams","ITEE, Univ. of Oulu, Oulu, Finland; ITEE, Univ. of Oulu, Oulu, Finland; ITEE, Univ. of Oulu, Oulu, Finland; MCIS, Polytech. Montreal, Montreal, QC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","705","715","Abnormal working hours can reduce work health, general well-being, and productivity, independent from a profession. To inform future approaches for automatic stress and overload detection, this paper establishes empirically collected measures of the work patterns of software engineers. To this aim, we perform the first largescale study of software engineers' working hours by investigating the time stamps of commit activities of 86 large open source software projects, both containing hired and volunteer developers. We find that two thirds of software engineers mainly follow typical office hours, empirically established to be from 10h to 18h, and do not usually work during nights and weekends. Large variations between projects and individuals exist. Surprisingly, we found no support that project maturation would decrease abnormal working hours. In the Firefox case study, we found that hired developers work more during office hours while seniority, either in terms of number of commits or job status, did not impact working hours. We conclude that the use of working hours or timestamps of work products for stress detection requires establishing baselines at the level of individuals.","","","10.1145/3180155.3180193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453143","software repository mining;overtime;overwork;open source;apache;mozilla;weekend;night","Companies;Software;Computer bugs;Software engineering;Productivity;Rhythm;Stress","health care;occupational health;project management;public domain software;software development management","abnormal working hours;work health;work patterns;software engineers;work products;open source software projects;overload detection;time stamps;stress detection;Firefox","","2","","","","","","IEEE","IEEE Conferences"
"Context-Aware Conversational Developer Assistants","N. Bradley; T. Fritz; R. Holmes","Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","993","1003","Building and maintaining modern software systems requires developers to perform a variety of tasks that span various tools and information sources. The crosscutting nature of these development tasks requires developers to maintain complex mental models and forces them (a) to manually split their high-level tasks into low-level commands that are supported by the various tools, and (b) to (re) establish their current context in each tool. In this paper we present Devy, a Conversational Developer Assistant (CDA) that enables developers to focus on their high-level development tasks. Devy reduces the number of manual, often complex, low-level commands that developers need to perform, freeing them to focus on their high-level tasks. Specifically, Devy infers high-level intent from developer's voice commands and combines this with an automatically-generated context model to determine appropriate workflows for invoking low-level tool actions; where needed, Devy can also prompt the developer for additional information. Through a mixed methods evaluation with 21 industrial developers, we found that Devy provided an intuitive interface that was able to support many development tasks while helping developers stay focused within their development environment. While industrial developers were largely supportive of the automation Devy enabled, they also provided insights into several other tasks and workflows CDAs could support to enable them to better focus on the important parts of their development tasks.","","","10.1145/3180155.3180238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453178","Conversational Development Assistants;Natural User Interfaces","Task analysis;Tools;Context;Context modeling;Software;Switches","interactive systems;software engineering;ubiquitous computing","high-level tasks;low-level commands;Devy;high-level development tasks;high-level intent;automatically-generated context model;low-level tool actions;development environment;context-aware conversational developer assistants;modern software systems","","4","","","","","","IEEE","IEEE Conferences"
"[Journal First] On the Diffuseness and the Impact on Maintainability of Code Smells: A Large Scale Empirical Investigation","F. Palomba; G. Bavota; M. Di Penta; F. Fasano; R. Oliveto; A. De Lucia","Univ. of Zurich, Zurich, Switzerland; Univ. della Svizzera Italiana, Lugano, Switzerland; Univ. of Sannio, Benevento, Italy; Univ. of Molise, Pesche, Italy; Univ. of Molise, Pesche, Italy; Univ. of Salerno, Salerno, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","482","482","Code smells are symptoms of poor design and implementation choices that may hinder code comprehensibility and maintainability. Despite the effort devoted by the research community in studying code smells, the extent to which code smells in software systems affect software maintainability remains still unclear. In this paper we present a large scale empirical investigation on the diffuseness of code smells and their impact on code change- and fault-proneness. The study was conducted across a total of 395 releases of 30 open source projects and considering 17,350 manually validated instances of 13 different code smell types. The results show that smells characterized by long and/or complex code (e.g., Complex Class) are highly diffused, and that smelly classes have a higher change- and fault-proneness than smell-free classes.","","","10.1145/3180155.3182532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453110","code smells;empirical studies;mining software repositories","Software engineering;History;Detectors;Maintenance engineering;Software systems;Correlation","public domain software;software maintenance","software maintainability;code fault-proneness;code change-proneness;open source projects;code comprehensibility;scale empirical investigation;code smells;smell-free classes;complex code","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Overfitting in Semantics-Based Automated Program Repair","X. D. Le; F. Thung; D. Lo; C. Le Goues","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","163","163","The primary goal of Automated Program Repair (APR) is to automatically fix buggy software, to reduce the manual bug-fix burden that presently rests on human developers. Existing APR techniques can be generally divided into two families: semantics-vs. heuristics-based. Semantics-based APR uses symbolic execution and test suites to extract semantic constraints, and uses program synthesis to synthesize repairs that satisfy the extracted constraints. Heuristic-based APR generates large populations of repair candidates via source manipulation, and searches for the best among them. Both families largely rely on a primary assumption that a program is correctly patched if the generated patch leads the program to pass all provided test cases. Patch correctness is thus an especially pressing concern. A repair technique may generate overfitting patches, which lead a program to pass all existing test cases, but fails to generalize beyond them. In this work, we revisit the overfitting problem with a focus on semantics-based APR techniques, complementing previous studies of the overfitting problem in heuristics-based APR. We perform our study using IntroClass and Codeflaws benchmarks, two datasets well-suited for assessing repair quality, to systematically characterize and understand the nature of overfitting in semantics-based APR. We find that similar to heuristics-based APR, overfitting also occurs in semantics-based APR in various different ways.","","","10.1145/3180155.3182536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453074","Automated Program Repair;Program Synthesis;Symbolic Execution;Patch Overfitting","Maintenance engineering;Semantics;Benchmark testing;Software engineering;Tools;Engines;Sociology","program debugging;program diagnostics;program testing;software fault tolerance;software maintenance","symbolic execution;test suites;program synthesis;overfitting patches;semantics-based APR techniques;semantics-based Automated Program Repair;buggy software;patch correctness;IntroClass;repair quality assessment;Codeflaws","","2","","","","","","IEEE","IEEE Conferences"
"Self-Hiding Behavior in Android Apps: Detection and Characterization","Z. Shan; I. Neamtiu; R. Samuel","Wichita State Univ., Wichita, KS, USA; New Jersey Inst. of Technol., Newark, NJ, USA; New Jersey Inst. of Technol., Newark, NJ, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","728","739","Applications (apps) that conceal their activities are fundamentally deceptive; app marketplaces and end-users should treat such apps as suspicious. However, due to its nature and intent, activity concealing is not disclosed up-front, which puts users at risk. In this paper, we focus on characterization and detection of such techniques, e.g., hiding the app or removing traces, which we call ""self hiding behavior"" (SHB). SHB has not been studied per se - rather it has been reported on only as a byproduct of malware investigations. We address this gap via a study and suite of static analyses targeted at SH in Android apps. Specifically, we present (1) a detailed characterization of SHB, (2) a suite of static analyses to detect such behavior, and (3) a set of detectors that employ SHB to distinguish between benign and malicious apps. We show that SHB ranges from hiding the app's presence or activity to covering an app's traces, e.g., by blocking phone calls/text messages or removing calls and messages from logs. Using our static analysis tools on a large dataset of 9,452 Android apps (benign as well as malicious) we expose the frequency of 12 such SH behaviors. Our approach is effective: it has revealed that malicious apps employ 1.5 SHBs per app on average. Surprisingly, SH behavior is also employed by legitimate (""benign"") apps, which can affect users negatively in multiple ways. When using our approach for separating malicious from benign apps, our approach has high precision and recall (combined F-measure = 87.19%). Our approach is also efficient, with analysis typically taking just 37 seconds per app. We believe that our findings and analysis tool are beneficial to both app marketplaces and end-users.","","","10.1145/3180155.3180214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453145","Android;static analysis;malware;mobile security","Malware;Smart phones;Tools;Static analysis;Security;Google;Software engineering","Android (operating system);invasive software;mobile computing;program diagnostics","Android apps;trace removal;self hiding behavior detection;activity concealing;app marketplaces;benign apps;legitimate apps;malicious apps;static analyses","","2","","","","","","IEEE","IEEE Conferences"
"[Journal First] Analyzing the Effects of Test Driven Development in GitHub","N. Borle; M. Feghhi; E. Stroulia; R. Grenier; A. Hindle","Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada; Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada; Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada; Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada; Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1062","1062","Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models recommend Test Driven Development (TDD) as a key practice for reducing costs and improving code quality. The objective of this work is to perform a cost-benefit analysis of this practice. Previous work by Fucci et al. engaged in laboratory studies of developers actively engaged in test-driven development practices. Fucci et al. found little difference between test-first behaviour of TDD and test-later behaviour. To that end, we opted to conduct a study about TDD behaviours in the ""wild"" rather than in the laboratory. Thus we have conducted a comparative analysis of GitHub repositories that adopts TDD to a lesser or greater extent, in order to determine how TDD affects software development productivity and software quality. We classified GitHub repositories archived in 2015 in terms of how rigorously they practiced TDD, thus creating a TDD spectrum. We then matched and compared various subsets of these repositories on this TDD spectrum with control sets of equal size. The control sets were samples from all GitHub repositories that matched certain characteristics, and that contained at least one test file. We compared how the TDD sets differed from the control sets on the following characteristics: number of test files, average commit velocity, number of bug-referencing commits, number of issues recorded, usage of continuous integration, number of pull requests, and distribution of commits per author. We found that Java TDD projects were relatively rare. In addition, there were very few significant differences in any of the metrics we used to compare TDD-like and non-TDD projects; therefore, our results do not reveal any observable benefits from using TDD.","","","10.1145/3180155.3182535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453184","Test Driven Development;Human Factors in Software Development;GitHub Repositories;Continuous Integration","Software engineering;Software;Testing;Computational modeling;Java;Blogs;Analytical models","cost-benefit analysis;Java;program testing;software engineering;software maintenance;software quality;software reliability","GitHub repositories;TDD spectrum;control sets;test file;TDD sets;Java TDD projects;nonTDD projects;software development lifecycle;agile process models;improving code quality;cost-benefit analysis;test-driven development practices;test-first behaviour;test-later behaviour;software development productivity;software quality;test driven development","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] An Empirical Study of Early Access Games on the Steam Platform","D. Lin; C. Bezemer; A. E. Hassan","Software Anal. & Intell. Lab. (SAIL), Queen's Univ. Kingston, Kingston, ON, Canada; Software Anal. & Intell. Lab. (SAIL), Queen's Univ. Kingston, Kingston, ON, Canada; Software Anal. & Intell. Lab. (SAIL), Queen's Univ. Kingston, Kingston, ON, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","480","480","""Early access"" is a release strategy for software that allows consumers to purchase an unfinished version of the software. In turn, consumers can influence the software development process by giving developers early feedback. This early access model has become increasingly popular through digital distribution platforms, such as Steam which is the most popular distribution platform for games. The plethora of options offered by Steam to communicate between developers and game players contribute to the popularity of the early access model. The early access model made a name for itself through several successful games, such as the DayZ game. The multiplayer survival-based game reached 400,000 sales during its first week as an early access game. However, the benefits of the early access model have been questioned as well. For instance, the Spacebase DF-9 game abandoned the early access stage unexpectedly, disappointing many players of the game. Shortly after abandoning the early access stage and terminating the development, twelve employees were laid off including the programmer and project lead. In this paper, we conduct an empirical study on 1,182 Early Access Games (EAGs) on the Steam platform to understand the characteristics, advantages and limitations of the early access model. We find that 15% of the games on Steam make use of the early access model, with the most popular EAG having as many as 29 million owners. 88% of the EAGs are classified by their developers as so-called ""indie"" games, indicating that most EAGs are developed by individual developers or small studios. We study the interaction between players and developers of EAGs and the Steam platform. We observe that on the one hand, developers update their games more frequently in the early access stage. On the other hand, the percentage of players that review a game during its early access stage is lower than the percentage of players that review the game after it leaves the early access stage. However, the average rating of the reviews is much higher during the early access stage, suggesting that players are more tolerant of imperfections in the early access stage. The positive review rate does not correlate with the length or the game update frequency of the early access stage. In addition, we discuss several learned lessons from the failure of an early access game. The main learned lesson from this failure is that the communication between the game developer and the players of the EAG is crucial. Players enjoy getting involved in the development of an early access game and they get emotionally involved in the decision-making about the game. Based on our findings, we suggest game developers to use the early access model as a method for eliciting early feedback and more positive reviews to attract additional new players. In addition, our findings suggest that developers can determine their release schedule without worrying about the length of the early access stage and the game update frequency during the early access stage.","","","10.1145/3180155.3182512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453108","early access games;computer games;Steam","Games;Software;Software engineering;Decision making;Schedules;Lead;Computational modeling","computer games;sales management;software engineering","game developer;game players;Steam platform;software development process;consumers;digital distribution platforms;DayZ game;multiplayer survival-based game;Spacebase DF-9 game;employees;programmer;project lead;decision-making;EAG;early access stage;early access game;early access model","","","","","","","","IEEE","IEEE Conferences"
"ENTRUST: Engineering Trustworthy Self-Adaptive Software with Dynamic Assurance Cases","R. Calinescu; D. Weyns; S. Gerasimou; M. U. Iftikhar; I. Habli; T. Kelly","Dept. of Comput. Sci., Univ. of York, York, UK; Dept. of Comput. Sci., Katholieke Univ. Leuven, Leuven, Belgium; Dept. of Comput. Sci., Univ. of York, York, UK; Dept. of Comput. Sci., Linnaeus Univ., Vaxjo, Sweden; Dept. of Comput. Sci., Univ. of York, York, UK; Dept. of Comput. Sci., Univ. of York, York, UK","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","495","495","Software systems are increasingly expected to cope with variable workloads, component failures and other uncertainties through self-adaptation. As such, self-adaptive software has been the subject of intense research over the past decade. Our work focuses on the use of self-adaptive software in applications with strict functional and non-functional requirements. These applications need compelling assurances that the software continues to meet its requirements while it reconfigures its architecture and parameters at runtime. To address this need, we introduce an end-to-end methodology for the ENgineering of TRUstworthy Self-adaptive sofTware (ENTRUST).","","","10.1145/3180155.3182540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453112","self adaptive software systems;software engineering methodology;assurance evidence;assurance cases","Computer science;Runtime;Software systems;Standards;Safety","formal specification;software architecture;trusted computing","engineering trustworthy self-adaptive software;dynamic assurance cases;software systems;nonfunctional requirements;self-adaptive software","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] A Comparison of Program Comprehension Strategies by Blind and Sighted Programmers","A. Armaly; P. Rodeghero; C. McMillan","Univ. of Notre Dame, Notre Dame, IN, USA; Univ. of Notre Dame, Notre Dame, IN, USA; Univ. of Notre Dame, Notre Dame, IN, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","788","788","Programmers who are blind use a screen reader to speak source code one word at a time, as though the code were text. This process of reading is in stark contrast to sighted programmers, who skim source code rapidly with their eyes. At present, it is not known whether the difference in these processes has effects on the program comprehension gained from reading code. These effects are important because they could reduce both the usefulness of accessibility tools and the generalizability of software engineering studies to persons with low vision. In this paper, we present an empirical study comparing the program comprehension of blind and sighted programmers. We found that both blind and sighted programmers prioritize reading method signatures over other areas of code. Both groups obtained an equal and high degree of comprehension, despite the different reading processes.","","","10.1145/3180155.3182544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453151","Program comprehension;accessibility technology;blindness","Software engineering;Tools;Java;Measurement;Software maintenance;Visualization","handicapped aids;programming environments;public domain software;software engineering","program comprehension strategies;sighted programmers;source code;reading processes","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] MSeer ‚Äì An Advanced Technique for Locating Multiple Bugs in Parallel","R. Gao; W. E. Wong","Dept. of Comput. Sci., Univ. of Texas at Dallas, Richardson, TX, USA; Dept. of Comput. Sci., Univ. of Texas at Dallas, Richardson, TX, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1064","1064","In practice, a program may contain multiple bugs. The simultaneous presence of these bugs may deteriorate the effectiveness of existing fault-localization techniques to locate program bugs. While it is acceptable to use all failed and successful tests to identify suspicious code for programs with exactly one bug, it is not appropriate to use the same approach for programs with multiple bugs because the due-to relationship between failed tests and underlying bugs cannot be easily identified. One solution is to generate fault-focused clusters by grouping failed tests caused by the same bug into the same clusters. We propose MSeer - an advanced fault localization technique for locating multiple bugs in parallel. Our major contributions include the use of (1) a revised Kendall tau distance to measure the distance between two failed tests, (2) an innovative approach to simultaneously estimate the number of clusters and assign initial medoids to these clusters, and (3) an improved K-medoids clustering algorithm to better identify the due-to relationship between failed tests and their corresponding bugs. Case studies on 840 multiple-bug versions of seven programs suggest that MSeer performs better in terms of effectiveness and efficiency than two other techniques for locating multiple bugs in parallel.","","","10.1145/3180155.3182552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453186","Software fault localization;parallel debugging;multiple bugs;clustering;distance metrics","Computer bugs;Software;Fault diagnosis;Computer science;Clustering algorithms;Measurement;Software engineering","parallel processing;pattern clustering;program debugging;program testing;software fault tolerance","fault-focused clusters;failed tests;advanced fault localization technique;program bugs;bug locating;fault-localization techniques;K-medoids clustering;MSeer","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Lightweight, Obfuscation-Resilient Detection and Family Identification of Android Malware","J. Garcia; M. Hammad; S. Malek","Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","497","497","The number of malicious Android apps has been and continues to increase rapidly. These malware can damage or alter other files or settings, install additional applications, obfuscate their behaviors, propagate quickly, and so on. To identify and handle such malware, a security analyst can significantly benefit from identifying the family to which a malicious app belongs rather than only detecting if an app is malicious. To address these challenges, we present a novel machine learning-based Android malware detection and family-identification approach, RevealDroid, that operates without the need to perform complex program analyses or extract large sets of features. RevealDroid's selected features leverage categorized Android API usage, reflection-based features, and features from native binaries of apps. We assess RevealDroid for accuracy, efficiency, and obfuscation resilience using a large dataset consisting of more than 54,000 malicious and benign apps. Our experiments show that RevealDroid achieves an accuracy of 98% in detection of malware and an accuracy of 95% in determination of their families. We further demonstrate RevealDroid's superiority against state-of-the-art approaches.","","","10.1145/3180155.3182551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453114","obfuscation;machine learning;lightweight;native code;reflection;Android malware","Malware;Feature extraction;Androids;Humanoid robots;Resilience;Machine learning;Reflection","Android (operating system);application program interfaces;invasive software;learning (artificial intelligence);mobile computing;program diagnostics","obfuscation-resilient detection;malicious Android apps;propagate quickly;security analyst;malicious app;Android malware detection;family-identification approach;Android API usage;reflection-based features;obfuscation resilience;complex program analysis;RevealDroid selected feature","","","","","","","","IEEE","IEEE Conferences"
"Do You Remember This Source Code?","J. Kr√ºger; J. Wiemann; W. Fenske; G. Saake; T. Leich","Harz Univ. of Appl. Sci., Magdeburg, Germany; Otto-von-Guericke-Univ., Magdeburg, Germany; Otto-von-Guericke-Univ., Magdeburg, Germany; Otto-von-Guericke-Univ., Magdeburg, Germany; METOP GmbH, Harz Univ. of Appl. Sci., Magdeburg, Germany","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","764","775","Being familiar with the source code of a program comprises knowledge about its purpose, structure, and details. Consequently, familiarity is an important factor in many contexts of software development, especially for maintenance and program comprehension. As a result, familiarity is considered to some extent in many different approaches, for example, to model costs or to identify experts. Still, all approaches we are aware of require a manual assessment of familiarity and empirical analyses of forgetting in software development are missing. In this paper, we address this issue with an empirical study that we conducted with 60 open-source developers. We used a survey to receive information on the developers' familiarity and analyze the responses based on data we extract from their used version control systems. The results show that forgetting is an important factor when considering familiarity and program comprehension of developers. We find that a forgetting curve is partly applicable for software development, investigate three factors - the number of edits, ratio of owned code, and tracking behavior - that can impact familiarity with code, and derive a general memory strength for our participants. Our findings can be used to scope approaches that have to consider familiarity and they provide insights into forgetting in the context of software development.","","","10.1145/3180155.3180215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453149","familiarity;forgetting;empirical study;maintenance;program comprehension;expert identification;knowledge management","Software;Software engineering;Task analysis;Maintenance engineering;Psychology;Software reliability","configuration management;software development management;software maintenance","source code;software development;owned code;open-source developers","","1","","","","","","IEEE","IEEE Conferences"
"How not to Structure Your Database-Backed Web Applications: A Study of Performance Bugs in the Wild","J. Yang; C. Yan; P. Subramaniam; S. Lu; A. Cheung","NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","800","810","Many web applications use databases for persistent data storage, and using Object Relational Mapping (ORM) frameworks is a common way to develop such database-backed web applications. Unfortunately, developing efficient ORM applications is challenging, as the ORM framework hides the underlying database query generation and execution. This problem is becoming more severe as these applications need to process an increasingly large amount of persistent data. Recent research has targeted specific aspects of performance problems in ORM applications. However, there has not been any systematic study to identify common performance anti-patterns in real-world such applications, how they affect resulting application performance, and remedies for them. In this paper, we try to answer these questions through a comprehensive study of 12 representative real-world ORM applications. We generalize 9 ORM performance anti-patterns from more than 200 performance issues that we obtain by studying their bug-tracking systems and profiling their latest versions. To prove our point, we manually fix 64 performance issues in their latest versions and obtain a median speedup of 2√ó (and up to 39√ó max) with fewer than 5 lines of code change in most cases. Many of the issues we found have been confirmed by developers, and we have implemented ways to identify other code fragments with similar issues as well.","","","10.1145/3180155.3180194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453153","performance anti-patterns;Object-Relational Mapping frameworks;database-backed applications;bug study","Rails;Scalability;Servers;Indexes;Computer bugs;Semantics","Internet;program debugging;public domain software;query processing;relational databases","persistent data storage;efficient ORM applications;ORM framework hides;underlying database query generation;performance problems;common performance anti-patterns;resulting application performance;real-world ORM applications;200 performance issues;performance bugs;object relational mapping frameworks;database-backed Web applications;ORM performance anti-patterns","","2","","","","","","IEEE","IEEE Conferences"
"[Journal First] ChangeLocator: Locate Crash-Inducing Changes Based on Crash Reports","R. Wu; M. Wen; S. Cheung; H. Zhang","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Sch. of Electr. Eng. & Comput., Univ. of Newcastle, Newcastle, NSW, Australia","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","536","536","Software crashes are severe manifestations of software bugs. Debugging crashing bugs is tedious and time-consuming. Understanding software changes that induce a crashing bug can provide useful contextual information for bug fixing and is highly demanded by developers. Locating the bug inducing changes is also useful for automatic program repair, since it narrows down the root causes and reduces the search space of bug fix location. However, currently there are no systematic studies on locating the software changes to a source code repository that induce a crashing bug reflected by a bucket of crash reports. To tackle this problem, we first conducted an empirical study on characterizing the bug inducing changes for crashing bugs (denoted as crashinducing changes). We also propose ChangeLocator, a method to automatically locate crash-inducing changes for a given bucket of crash reports. We base our approach on a learning model that uses features originated from our empirical study and train the model using the data from the historical fixed crashes. We evaluated ChangeLocator with six release versions of Netbeans project. The results show that it can locate the crash-inducing changes for 44.7%, 68.5%, and 74.5% of the bugs by examining only top 1, 5 and 10 changes in the recommended list, respectively. It significantly outperforms the existing state-of-the-art approach.","","","10.1145/3180155.3182516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453120","crash-inducing change;software crash;crash stack;bug localization","Computer bugs;Software;Software engineering;Data models;Computer science;Maintenance engineering","program debugging;software maintenance","historical fixed crashes;crashinducing changes;bug fix location;bug inducing changes;crashing bug;software bugs;software crashes;crash reports;crash-inducing changes","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Empirical Study on the Discrepancy Between Performance Testing Results from Virtual and Physical Environments","M. M. Arif; W. Shang; E. Shihab","Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada; Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada; Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","822","822","Large software systems often undergo performance tests to ensure their capability to handle expected loads. These performance tests often consume large amounts of computing resources and time since heavy loads need to be generated. Making it worse, the ever evolving eld requires frequent updates to the performance testing environment. In practice, virtual machines (VMs) are widely exploited to provide exible and less costly environments for performance tests. However, the use of VMs may introduce confounding overhead (e.g., a higher than expected memory utilization with unstable I/O tra c) to the testing environment and lead to unre-alistic performance testing results. Yet, little research has studied the impact on test results of using VMs in performance testing activities. To evaluate the discrepancy between the performance testing results from virtual and physical environments, we perform a case study on two open source systems - namely Dell DVD Store (DS2) and CloudStore. We conduct the same performance tests in both virtual and physical environments and compare the performance testing results based on the three aspects that are typically examined for performance testing results: 1) single performance metric (e.g. CPU Time from virtual environment vs. CPU Time from physical environment), 2) the relationship among performance metrics (e.g. correlation between CPU and I/O) and 3) performance models that are built to predict system performance. Our results show that 1) A single metric from virtual and physical environments do not follow the same distribution, hence practitioners cannot simply use a scaling factor to compare the performance between environments, 2) correlations among performance metrics in virtual environments are different from those in physical environments 3) statistical models built based on the performance metrics from virtual environments are different from the models built from physical environments suggesting that practitioners cannot use the performance testing results across virtual and physical environments. In order to assist the practitioners leverage performance testing results in both environments, we investigate ways to reduce the discrepancy. We find that such discrepancy can be reduced by normalizing performance metrics based on deviance. Overall, we suggest that practitioners should not use the performance testing results from virtual environment with the simple assumption of straightforward performance overhead. Instead, practitioners should consider leveraging normalization techniques to reduce the discrepancy before examining performance testing results from virtual and physical environments.","","","10.1145/3180155.3182527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453155","Software performance engineering;Software performance analysis;Testing on virtual environments","Testing;Measurement;Software engineering;Virtual environments;Correlation;Software performance","program testing;public domain software;software metrics;statistical analysis;virtual machines","performance metrics;performance testing environment;unre-alistic performance testing results;performance testing activities;physical environments;software systems;open source systems;Dell DVD store;CloudStore;practitioners leverage performance testing;virtual environments;scaling factor;statistical models","","","","","","","","IEEE","IEEE Conferences"
"A Posteriori Typing for Model-Driven Engineering: Concepts, Analysis, and Applications","J. de Lara; E. Guerra","Modelling & Software Eng. Group, Univ. Autonoma de Madrid, Cantoblanco, Spain; Modelling & Software Eng. Group, Univ. Autonoma de Madrid, Cantoblanco, Spain","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1136","1136","Model-Driven Engineering (MDE) is a software engineering paradigm where models are actively used to specify, test, simulate, analyse and maintain the systems to be built, among other activities. Models can be defined using general-purpose modelling languages like the UML, but for particular domains, the use of domain-specific languages is pervasive. Either way, models must conform to a meta-model which defines their abstract syntax. In MDE, the definition of model management operations - often typed over project-specific meta-models - is recurrent. However, even if two operations are similar, they must be developed from scratch whenever they are applied to instances of different meta-models. This is so as operations defined (i.e., typed) over a meta-model cannot be directly reused for another. Part of this difficulty of reuse is because classes in meta-models are used in two ways: as templates to create objects and as static classifiers for them. These two aspects are inherently tied in most meta-modelling approaches, which results in unnecessarily rigid systems and hinders reusability of MDE artefacts. To enhance flexibility and reuse in MDE, we propose an approach to decouple object creation from typing [1]. The approach relies on standard mechanisms for object creation, and proposes the notion of a posteriori typing as a means to retype objects and enable multiple, partial, dynamic typings. A posteriori typing enhances flexibility because it allows models to be retyped with respect to other meta-models. Hence, we distinguish between creation meta-models used to construct models, and role meta-models into which models are retyped. This permits unanticipated reuse, as a model management operation defined for a role meta-model can be reused as-is with models built using a different creation meta-model, once such models are reclassified. Moreover, our approach permits expressing some types of bidirectional model transformations by reclassification. The transformations defined as reclassifications have better performance than the equivalent ones defined with traditional transformation languages, because reclassification does not require creating new objects. In [1], we propose two mechanisms to define a posteriori typings: type-level (mappings between meta-models) and instance-level (set of model queries). The paper presents the underlying theory and type correctness criteria of both mechanisms, defines some analysis methods, identifies practical restrictions for retyping specifications, and demonstrates the feasibility of the approach by an implementation atop our meta-modelling tool MetaDepth. We also explore application scenarios of a posteriori typing (to define transformations, for model transformation reuse, and to improve transformation expressiveness by dynamic type change), and present an experiment showing the potential performance gains when expressing transformations as retypings.","","","10.1145/3180155.3182545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453194","Model-driven engineering;reuse;model typing;partial typing;dynamic typing;model transformations;bidirectionality;MetaDepth","Unified modeling language;Software engineering;Model driven engineering;Analytical models;Tools;Domain specific languages;Syntactics","formal specification;software engineering;software reusability;specification languages;Unified Modeling Language","posteriori typing;model transformation reuse;general-purpose modelling languages;model management operation;project-specific meta-models;meta-modelling approaches;creation meta-models;role meta-model;bidirectional model transformations;model queries;model-driven engineering;MetaDepth;meta-modelling tool","","","","","","","","IEEE","IEEE Conferences"
"Efficient Sampling of SAT Solutions for Testing","R. Dutra; K. Laeufer; J. Bachrach; K. Sen","EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA; EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA; EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA; EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","549","559","In software and hardware testing, generating multiple inputs which satisfy a given set of constraints is an important problem with applications in fuzz testing and stimulus generation. However, it is a challenge to perform the sampling efficiently, while generating a diverse set of inputs which satisfy the constraints. We developed a new algorithm QuickSampler which requires a small number of solver calls to produce millions of samples which satisfy the constraints with high probability. We evaluate QuickSampler on large real-world benchmarks and show that it can produce unique valid solutions orders of magnitude faster than other state-of-the-art sampling tools, with a distribution which is reasonably close to uniform in practice.","","","10.1145/3180155.3180248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453122","sampling;stimulus generation;constraint-based testing;constrained random verification","Hardware;Software;Fuzzing;Benchmark testing;Software engineering;Tools","computability;probability;program testing","quicksampler;sampling tools;unique valid solutions;fuzz testing;multiple inputs;hardware testing;SAT solutions;solver calls;stimulus generation","","2","","","","","","IEEE","IEEE Conferences"
"Precise Concolic Unit Testing of C Programs Using Extended Units and Symbolic Alarm Filtering","Y. Kim; Y. Choi; M. Kim","Sch. of Comput., KAIST, Daejeon, South Korea; Sch. of Comput. Sci. & Eng., Kyungpook Nat. Univ., Daegu, South Korea; Sch. of Comput., KAIST, Daejeon, South Korea","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","315","326","Automated unit testing reduces manual effort to write unit test drivers/stubs and generate unit test inputs. However, automatically generated unit test drivers/stubs raise false alarms because they often over-approximate real contexts of a target function f and allow infeasible executions off. To solve this problem, we have developed a concolic unit testing technique CONBRIO. To provide realistic context to f, it constructs an extended unit of f that consists of f and closely relevant functions to f. Also, CONBRIO filters out a false alarm by checking feasibility of a corresponding symbolic execution path with regard to f's symbolic calling contexts obtained by combining symbolic execution paths of f's closely related predecessor functions. In the experiments on the crash bugs of 15 real-world C programs, CONBRIO shows both high bug detection ability (i.e. 91.0% of the target bugs detected) and high precision (i.e. a true to false alarm ratio is 1:4.5). Also, CONBRIO detects 14 new bugs in 9 target C programs studied in papers on crash bug detection techniques.","","","10.1145/3180155.3180253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453090","automated unit testing;unit test driver/stub generation;dynamic symbolic execution;false alarm reduction","Testing;Computer bugs;Filtering;Manuals;Software engineering;Space exploration","C language;program debugging;program diagnostics;program verification","symbolic alarm filtering;automated unit testing;manual effort;unit test inputs;automatically generated unit test drivers/stubs;over-approximate real contexts;infeasible executions;technique CONBRIO;closely relevant functions;corresponding symbolic execution path;symbolic calling contexts;symbolic execution paths;predecessor functions;false alarm ratio;crash bug detection techniques;C program precise concolic unit testing","","1","","","","","","IEEE","IEEE Conferences"
"Integrating Technical Debt Management and Software Quality Management Processes: A Framework and Field Tests","N. Ramasubbu; C. Kemerer","Univ. of Pittsburgh, Pittsburgh, PA, USA; Univ. of Pittsburgh, Pittsburgh, PA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","883","883","Technical debt, defined as the maintenance obligations arising from shortcuts taken during the design, development, and deployment of software systems, has been shown to significantly impact the reliability and long-term evolution of software systems [1], [2]. Although academic research has moved beyond using technical debt only as a metaphor, and has begun compiling strong empirical evidence on the economic implications of technical debt, industry practitioners continue to find managing technical debt a challenging balancing act [3]. Despite the increasing awareness of the importance of managing technical debt in software product development, systematic processes for implementing technical debt management in software production have not been readily available. To address this gap, we developed and field tested a normative process framework that systematically incorporates steps for managing technical debt in commercial software production. The framework integrates processes required for technical debt management with existing software quality management processes prescribed by the project management body of knowledge (PMBOK) [4], and organizes the different processes for technical debt management under three steps: (1) make technical debt visible, (2) perform cost-benefit analysis, and (3) control technical debt. To implement the processes, we introduce a new artifact, called the technical debt register, which stores, for each software asset, the outstanding principal and the associated interest estimated for the technical debt embedded in the asset. The technical debt register also stores the desired control target for each software asset's technical debt, which is populated and used during the cost-benefit analysis and control target calculations. There are three main benefits from this integrated approach. First, it enables the uncovering of hidden technical debt embedded in systems. Established quality assurance and control practices can be utilized to effectively associate software defects with specific design and deployment decisions made by programmers. Such associations make technical debt visible to the team and thereby facilitate the quantification of debt-related principal and interest. Second, it helps to bridge the gaps that exist between the technical and economic assessments of technical debt, and aid in formulating actionable policies related to technical debt management. Finally, integrating technical debt management processes with established quality frameworks aids the wider adoption of emerging prescriptions for managing technical debt. We partnered with three commercial software product development organizations to implement the framework in real-world software production settings. All three organizations, irrespective of their varying software process maturity levels, were able to adopt the proposed framework and integrate the prescribed technical debt management processes with their existing software quality management processes. Our longitudinal data and case-study interviews indicate that the organizations were able to accrue economic benefits from the adoption and use of the integrated framework. And, based on our field study observations, we also identified a set of best practices that support the implementation and use of our framework: facilitating engagement between business and engineering stakeholders, adoption of policies based on a probabilistic analysis framework, and limiting process overheads.","","","10.1145/3180155.3182529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453163","Technical debt;software quality;software maintenance;software engineering economics;cost of quality;software product development;software process;case study","Software quality;Economics;Software engineering;Software systems;Product development;Production","product development;project management;quality assurance;quality management;software development management;software maintenance;software quality","software systems;managing technical debt;existing software quality management processes;technical debt register;software asset;hidden technical debt;prescribed technical debt management processes;integrating technical debt management;control technical debt","","","","","","","","IEEE","IEEE Conferences"
"Debugging with Intelligence via Probabilistic Inference","Z. Xu; S. Ma; X. Zhang; S. Zhu; B. Xu","State Key Lab. of Novel Software Technol., Nanjing Univ., Nanjing, China; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; State Key Lab. of Novel Software Technol., Nanjing Univ., Nanjing, China; State Key Lab. of Novel Software Technol., Nanjing Univ., Nanjing, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1171","1181","We aim to debug a single failing execution without the assistance from other passing/failing runs. In our context, debugging is a process with substantial uncertainty - lots of decisions have to be made such as what variables shall be inspected first. To deal with such uncertainty, we propose to equip machines with human-like intelligence. Specifically, we develop a highly automated debugging technique that aims to couple human-like reasoning (e.g., dealing with uncertainty and fusing knowledge) with program semantics based analysis, to achieve benefits from the two and mitigate their limitations. We model debugging as a probabilistic inference problem, in which the likelihood of each executed statement instance and variable being correct/faulty is modeled by a random variable. Human knowledge, human-like reasoning rules and program semantics are modeled as conditional probability distributions, also called probabilistic constraints. Solving these constraints identifies the most likely faulty statements. Our results show that the technique is highly effective. It can precisely identify root causes for a set of real-world bugs in a very small number of interactions with developers, much smaller than a recent proposal that does not encode human intelligence. Our user study also confirms that it substantially improves human productivity.","","","10.1145/3180155.3180237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453198","Debugging;Probabilistic Inference;Python","Debugging;Probabilistic logic;Uncertainty;Cognition;Semantics;Python;Tools","inference mechanisms;program debugging","reasoning rules;program semantics;conditional probability distributions;faulty statements;human intelligence;human productivity;single failing execution;substantial uncertainty;highly automated debugging technique;couple human-like reasoning;fusing knowledge;model debugging;probabilistic inference problem;executed statement instance;human knowledge;passing-failing runs","","","","","","","","IEEE","IEEE Conferences"
"Measuring Program Comprehension: A Large-Scale Field Study with Professionals","X. Xia; L. Bao; D. Lo; Z. Xing; A. E. Hassan; S. Li","Fac. of Inf. Technol., Monash Univ., Clayton, VIC, Australia; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China; Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore; Res. Sch. of Comput. Sci., Australian Nat. Univ., Canberra, ACT, Australia; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","584","584","This paper is published in IEEE Transaction on Software Engineering (DOI: 10.1109/TSE.2017.2734091). Comparing with previous programming comprehension studies that are usually in controlled settings or have a small number of participants, we perform a more realistic investigation of program comprehension activities. To do this, we extend our ActivitySpace framework to collect and analyze Human-Computer Interaction (HCI) data across many applications (not just the IDEs). We collect 3,148 working hour data from 78 professional developers in a field study. We follow Minelli et al.'s approach to assign developers' activities into four categories: navigation, editing, comprehension, and other. Then we measure comprehension time by calculating the time that developers spend on program comprehension. We find that on average developers spend ~58% of their time on program comprehension activities, and that they frequently use web browsers and document editors to perform program comprehension activities. We also investigate the impact of programming language, developers' experience, and project phase on the time that is spent on program comprehension.","","","10.1145/3180155.3182538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453126","Program Comprehension;Field Study;Inference Model","Computer science;Software;Software engineering;Australia;Conferences;Software measurement;Information technology","online front-ends;reverse engineering;software engineering;software maintenance","large-scale field study;program comprehension activities;measure comprehension time;professional developers;program comprehension measurement","","2","","","","","","IEEE","IEEE Conferences"
"Towards Reusing Hints from Past Fixes: An Exploratory Study on Thousands of Real Samples","H. Zhong; N. Meng","Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China; Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","885","885","Researchers have recently proposed various automatic program repair (APR) approaches that reuse past fixes to fix new bugs. However, some fundamental questions, such as how new fixes overlap with old fixes, have not been investigated. Intuitively, the overlap between old and new fixes decides how APR approaches can construct new fixes with old ones. Based on this intuition, we systematically designed six overlap metrics, and performed an empirical study on 5,735 bug fixes to investigate the usefulness of past fixes when composing new fixes. For each bug fix, we created delta dependency graphs (i.e., program dependency graphs for code changes), and identified how bug fixes overlapped with each other in terms of the content, code structure, and identifier names of fixes. Our results show that if an APR approach composes new fixes by fully or partially reusing the content of past fixes, only 2.1% and 3.2% new fixes can be created from single or multiple past fixes in the same project, compared with 0.9% and 1.2% fixes created from past fixes across projects. However, if an APR approach composes new fixes by fully or partially reusing the code structure of past fixes, up to 41.3% and 29.7% new fixes can be created.","","","10.1145/3180155.3182550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453165","reusing past fix;empirical study;program repair","Computer bugs;Maintenance engineering;Syntactics;Software engineering;Computer science;Software;Measurement","program debugging;software maintenance","automatic program repair;APR approach;delta dependency graphs","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] A Correlation Study Between Automated Program Repair and Test-Suite Metrics","J. Yi; S. H. Tan; S. Mechtaev; M. B√∂hme; A. Roychoudhury","NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","24","24","Automated program repair has attracted attention due to its potential to reduce debugging cost. Prior works show the feasibility of automated repair, and the research focus is gradually shifting towards the quality of generated patches. One promising direction is to control the quality of generated patches by controlling the quality of test-suites used. In this paper, we investigate the question: """"Can traditional test-suite metrics used in software testing be used for automated program repair?"""". We empirically investigate the effectiveness of test-suite metrics (statement / branch coverage and mutation score) in controlling the reliability of repairs (the likelihood that repairs cause regressions). We conduct the largest-scale experiments to date with real-world software, and perform the first correlation study between test-suite metrics and the reliability of generated repairs. Our results show that by increasing test-suite metrics, the reliability of repairs tend to increase. Particularly, such trend is most strongly observed in statement coverage. This implies that traditional test-suite metrics used in software testing can also be used to improve the reliability of repairs in program repair.","","","10.1145/3180155.3182517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453057","Code Coverage;Program Repair;Mutation Testing","Maintenance engineering;Measurement;Correlation;Software reliability;Software;Software testing","program debugging;program testing;software maintenance","regressions;test-suite metrics;automated repair;generated repairs;correlation study;automated program repair;software testing;test-suites;generated patches","","","","","","","","IEEE","IEEE Conferences"
"Online App Review Analysis for Identifying Emerging Issues","C. Gao; J. Zeng; M. R. Lyu; I. King","Shenzhen Res. Inst., Chinese Univ. of Hong Kong, Shenzhen, China; Shenzhen Res. Inst., Chinese Univ. of Hong Kong, Shenzhen, China; Shenzhen Res. Inst., Chinese Univ. of Hong Kong, Shenzhen, China; Shenzhen Res. Inst., Chinese Univ. of Hong Kong, Shenzhen, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","48","58","Detecting emerging issues (e.g., new bugs) timely and precisely is crucial for developers to update their apps. App reviews provide an opportunity to proactively collect user complaints and promptly improve apps' user experience, in terms of bug fixing and feature refinement. However, the tremendous quantities of reviews and noise words (e.g., misspelled words) increase the difficulties in accurately identifying newly-appearing app issues. In this paper, we propose a novel and automated framework IDEA, which aims to IDentify Emerging App issues effectively based on online review analysis. We evaluate IDEA on six popular apps from Google Play and Apple's App Store, employing the official app changelogs as our ground truth. Experiment results demonstrate the effectiveness of IDEA in identifying emerging app issues. Feedback from engineers and product managers shows that 88.9% of them think that the identified issues can facilitate app development in practice. Moreover, we have successfully applied IDEA to several products of Tencent, which serve hundreds of millions of users.","","","10.1145/3180155.3180218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453061","app reviews;online analysis;emerging issues","Computer bugs;Meteorology;Facebook;Google;Semantics;Software engineering","program debugging;program testing;smart phones","noise words;emerging app issues;IDEA;popular apps;official app changelogs;app development;online App review analysis;App reviews;Apple App Store","","7","","","","","","IEEE","IEEE Conferences"
"Automatic Software Repair: A Survey","L. Gazzola; L. Mariani; D. Micucci","Univ. degli Studi di Milano-Bicocca, Milan, Italy; Univ. degli Studi di Milano-Bicocca, Milan, Italy; Univ. degli Studi di Milano-Bicocca, Milan, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1219","1219","Despite their growing complexity and increasing size, modern software applications must satisfy strict release requirements that impose short bug fixing and maintenance cycles, putting significant pressure on developers who are responsible for timely producing high-quality software. To reduce developers workload, repairing and healing techniques have been extensively investigated as solutions for efficiently repairing and maintaining software in the last few years. In particular, repairing solutions have been able to automatically produce useful fixes for several classes of bugs that might be present in software programs. A range of algorithms, techniques, and heuristics have been integrated, experimented, and studied, producing a heterogeneous and articulated research framework where automatic repair techniques are proliferating. This paper organizes the knowledge in the area by surveying a body of 108 papers about automatic software repair techniques, illustrating the algorithms and the approaches, comparing them on representative examples, and discussing the open challenges and the empirical evidence reported so far.","","","10.1145/3180155.3182526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453203","Automatic Program Repair;Generate and Validate;Search Based;Semantics driven repair;Correct by Construction;Program Synthesis;Self Repairing","Maintenance engineering;Debugging;Software engineering;Fault diagnosis;Automation;Software systems","program debugging;software maintenance;software quality","articulated research framework;automatic repair techniques;automatic software repair techniques;modern software applications;strict release requirements;short bug;maintenance cycles;significant pressure;software programs;heterogeneous research framework;high-quality software","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Inference of Development Activities from Interaction with Uninstrumented Applications","L. Bao; Z. Xing; X. Xia; D. Lo; A. E. Hassan","Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China; Res. Sch. of Comput. Sci., Australian Nat. Univ., Canberra, ACT, Australia; Fac. of Inf. Technol., Monash Univ., Clayton, VIC, Australia; Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore; Sch. of Comput., Queen's Univ., Kingston, ON, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","897","897","This paper is published in Journal of Empirical Software Engineering (DOI: 10.1007/s10664-017-9547-8). Studying developers' behavior is crucial for designing effective techniques and tools to support developers' daily work. However, there are two challenges in collecting and analyzing developers' behavior data. First, instrumenting many software tools commonly used in real work settings (e.g., IDEs, web browsers) is difficult and requires significant resources. Second, the collected behavior data consist of low-level and fine-grained event sequences, which must be abstracted into high-level development activities for further analysis. To address these two challenges, we first use our ActivitySpace framework to improve the generalizability of the data collection. Then, we propose a Condition Random Field (CRF) based approach to segment and label the developers' low-level actions into a set of basic, yet meaningful development activities. To evaluate our proposed approach, we deploy the ActivitySpace framework in an industry partner's company and collect the real working data from ten professional developers' one-week work. We conduct an experiment with the collected data and a small number of initial human-labeled training data using the CRF model and the other three baselines (i.e., a heuristic-rules based method, a SVM classifier, and a random weighted classifier). The proposed CRF model achieves better performance (i.e., 0.728 accuracy and 0.672 macro-averaged F1-score) than the other three baselines.","","","10.1145/3180155.3182537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453167","Software development;Developers' interaction data;Condition Random Field","Software engineering;Australia;Tools;Software;Computer science;Information technology;Information systems","pattern classification;software engineering;software tools","empirical software engineering;Web browsers;condition random field based approach;low-level actions;data collection;high-level development activities;fine-grained event sequences;collected behavior data;work settings;software tools;uninstrumented applications;CRF model;one-week work;professional developers;working data;ActivitySpace framework;meaningful development activities","","","","","","","","IEEE","IEEE Conferences"
"Predicting Future Developer Behavior in the IDE Using Topic Models","K. Damevski; H. Chen; D. C. Shepherd; N. A. Kraft; L. Pollock","Virginia Commonwealth Univ., Richmond, VA, USA; Brooklyn, New York, NY, USA; ABB Corp. Res., Raleigh, NC, USA; ABB Corp. Res., Raleigh, NC, USA; Univ. of Delaware, Newark, DE, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","932","932","Interaction data, gathered from developers' daily clicks and key presses in the IDE, has found use in both empirical studies and in recommendation systems for software engineering. We observe that this data has several characteristics, common across IDEs: 1) exponentially distributed - some events or commands dominate the trace (e.g., cursor movement commands), while most other commands occur relatively infrequently; 2) noisy - the traces include spurious commands (or clicks), or unrelated events, that may not be important to the behavior of interest; 3) comprise of overlapping events and commands - specific commands can be invoked by separate mechanisms, and similar events can be triggered by different sources. These characteristics of this data are analogous to the characteristics of synonymy and polysemy in natural language corpora. Therefore, this paper (and presentation) presents a new modeling approach for this type of data, leveraging topic models typically applied to streams of natural language text.","","","10.1145/3180155.3182541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453171","command recommendation systems;IDE interaction data","Software engineering","natural language processing;recommender systems;software engineering;text analysis","modeling approach;leveraging topic models;IDE;interaction data;key presses;recommendation systems;software engineering;spurious commands;unrelated events;future developer behavior prediction;developers daily clicks;cursor movement commands;overlapping events;overlapping commands;synonymy;polysemy;natural language corpora;natural language text","","","","","","","","IEEE","IEEE Conferences"
"[Journal First] Privacy by Designers: Software Developers' Privacy Mindset","I. Hadar; T. Hasson; O. Ayalon; E. Toch; M. Birnhack; S. Sherman; A. Balissa","Dept. of Inf. Syst., Univ. of Haifa, Haifa, Israel; Dept. of Inf. Syst., Univ. of Haifa, Haifa, Israel; Fac. of Eng., Tel Aviv Univ., Tel Aviv, Israel; Fac. of Eng., Tel Aviv Univ., Tel Aviv, Israel; Fac. of Eng., Tel Aviv Univ., Tel Aviv, Israel; Dept. of Inf. Syst., Univ. of Haifa, Haifa, Israel; Fac. of Eng., Tel Aviv Univ., Tel Aviv, Israel","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","396","396","Privacy by design (PbD) is a policy measure that guides software developers to apply inherent solutions to achieve better privacy protection. For PbD to be a viable option, it is important to understand developers' perceptions, interpretation and practices as to informational privacy (or data protection). To this end, we conducted in-depth interviews with 27 developers from different domains, who practice software design. Grounded analysis of the data revealed an interplay between several different forces affecting the way in which developers handle privacy concerns. Borrowing the schema of Social Cognitive Theory (SCT), we classified and analyzed the cognitive, organizational and behavioral factors that play a role in developers' privacy decision making. Our findings indicate that developers use the vocabulary of data security to approach privacy challenges, and that this vocabulary limits their perceptions of privacy mainly to third-party threats coming from outside of the organization; that organizational privacy climate is a powerful means for organizations to guide developers toward particular practices of privacy; and that software architectural patterns frame privacy solutions that are used throughout the development process, possibly explaining developers' preference of policy-based solutions to architectural solutions. Further, we show, through the use of the SCT schema for framing the findings of this study, how a theoretical model of the factors that influence developers' privacy practices can be conceptualized and used as a guide for future research toward effective implementation of PbD.","","","10.1145/3180155.3182531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453098","Data protection;Privacy;Privacy by design;Qualitative research;Grounded analysis;Social cognitive theory;Organizational climate","Privacy;Data privacy;Meteorology;Software;Information systems;Vocabulary;Software engineering","cognition;data privacy;decision making;security of data;software architecture","decision making;privacy by design;organizational privacy;data protection;software development process;software architectural patterns;informational privacy;privacy protection;PbD;policy-based solutions;data security;behavioral factors;Social Cognitive Theory;software design","","","","","","","","IEEE","IEEE Conferences"
"TypeDevil: Dynamic Type Inconsistency Analysis for JavaScript","M. Pradel; P. Schuh; K. Sen","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","314","324","Dynamic languages, such as JavaScript, give programmers the freedom to ignore types, and enable them to write concise code in short time. Despite this freedom, many programs follow implicit type rules, for example, that a function has a particular signature or that a property has a particular type. Violations of such implicit type rules often correlate with problems in the program. This paper presents Type Devil, a mostly dynamic analysis that warns developers about inconsistent types. The key idea is to assign a set of observed types to each variable, property, and function, to merge types based in their structure, and to warn developers about variables, properties, and functions that have inconsistent types. To deal with the pervasiveness of polymorphic behavior in real-world JavaScript programs, we present a set of techniques to remove spurious warnings and to merge related warnings. Applying Type Devil to widely used benchmark suites and real-world web applications reveals 15 problematic type inconsistencies, including correctness problems, performance problems, and dangerous coding practices.","","","10.1109/ICSE.2015.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194584","Dynamic languages;types;dynamic analysis;JavaScript;program analysis","Instruments;Performance analysis;Runtime;Computer crashes;Arrays;Receivers;Benchmark testing","Java","TypeDevil;dynamic type inconsistency analysis;JavaScript;dynamic language;polymorphic behavior pervasiveness","","28","45","","","","","IEEE","IEEE Conferences"
"Performance Analysis Using Subsuming Methods: An Industrial Case Study","D. Maplesden; K. v. Randow; E. Tempero; J. Hosking; J. Grundy","Univ. of Auckland, Auckland, New Zealand; NA; Univ. of Auckland, Auckland, New Zealand; Univ. of Auckland, Auckland, New Zealand; Swinburne Univ. of Technol., Hawthorn, VIC, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","149","158","Large-scale object-oriented applications consist of tens of thousands of methods and exhibit highly complex runtime behaviour that is difficult to analyse for performance. Typical performance analysis approaches that aggregate performance measures in a method-centric manner result in thinly distributed costs and few easily identifiable optimisation opportunities. Subsuming methods analysis is a new approach that aggregates performance costs across repeated patterns of method calls that occur in the application's runtime behaviour. This allows automatic identification of patterns that are expensive and represent practical optimisation opportunities. To evaluate the practicality of this analysis with a real world large-scale object-oriented application we completed a case study with the developers of letterboxd.com - a social network website for movie goers. Using the results of the analysis we were able to rapidly implement changes resulting in a 54.8% reduction in CPU load and an 49.6% reduction in average response time.","","","10.1109/ICSE.2015.143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202959","Subsuming methods;Runtime bloat;Performance analysis;Object oriented software","Servers;Time factors;Runtime;Optimization;Performance analysis;Databases;Context","object-oriented methods;optimisation;pattern recognition;social networking (online);software performance evaluation","performance analysis;subsuming methods;large-scale object-oriented applications;complex runtime behaviour;optimisation opportunities;subsuming method analysis;application runtime behaviour;automatic pattern identification;large-scale object-oriented application;social network Website;CPU load reduction;average response time reduction","","5","27","","","","","IEEE","IEEE Conferences"
"Design and Evaluation of a Customizable Multi-Domain Reference Architecture on Top of Product Lines of Self-Driving Heavy Vehicles - An Industrial Case Study","J. Schroeder; D. Holzner; C. Berger; C. Hoel; L. Laine; A. Magnusson","NA; NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","189","198","Self-driving vehicles for commercial use cases like logistics or overcast mines increase their owners' economic competitiveness. Volvo maintains, evolves, and distributes a vehicle control product line for different brands like Volvo Trucks, Renault, and Mack in more than 190 markets world-wide. From the different application domains of their customers originates the need for a multi-domain reference architecture concerned with transport mission planning, execution, and tracking on top of the vehicle control product line. This industrial case study is the first of its kind reporting about the systematic process to design such a reference architecture involving all relevant external and internal stakeholders, development documents, low level artifacts, and literature. Quantitative and qualitative metrics were applied to evaluate non-functional requirements on the reference architecture level before a concrete variant was evaluated using a Volvo FMX truck in an exemplary construction site setting.","","","10.1109/ICSE.2015.147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202963","self-driving vehicles;reference architecture;design;evaluation;variability;industrial case study","Computer architecture;Vehicles;Stakeholders;Bibliographies;Interviews;Conferences;Planning","control engineering computing;logistics;mobile robots;road vehicles","customizable multidomain reference architecture;product lines;self-driving heavy vehicles;industrial case study;commercial use cases;logistics;overcast mines;economic competitiveness;vehicle control product line;Renault;Mack;multidomain reference architecture;transport mission planning;quantitative metrics;qualitative metrics;nonfunctional requirements;Volvo FMX truck;construction site setting","","2","64","","","","","IEEE","IEEE Conferences"
"When App Stores Listen to the Crowd to Fight Bugs in the Wild","M. Gomez; M. Martineza; M. Monperrus; R. Rouvoy","Inria Lille - Nord Eur., Univ. of Lille 1, Lille, France; Inria Lille - Nord Eur., Univ. of Lille 1, Lille, France; Inria Lille - Nord Eur., Univ. of Lille 1, Lille, France; Inria Lille - Nord Eur., Univ. of Lille 1, Lille, France","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","567","570","App stores are digital distribution platforms that put available apps that run on mobile devices. Current stores are software repositories that deliver apps upon user requests. However, when an app has a bug, the store continues delivering defective apps until the developer uploads a fixed version, thus impacting on the reputation of both store and app developer. In this paper, we envision a new generation of app stores that: (a) reduce human intervention to maintain mobile apps; and (b) enhance store services with smart and autonomous functionalities to automatically increase the quality of the delivered apps. We sketch a prototype of our envisioned app store and we discuss the functionalities that current stores an enhance by incorporating automatic software repair techniques.","","","10.1109/ICSE.2015.195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203014","","Monitoring;Computer bugs;Androids;Humanoid robots;Maintenance engineering;Google","mobile computing;software quality","App stores;digital distribution platforms;mobile devices;software repository;automatic software repair techniques","","5","11","","","","","IEEE","IEEE Conferences"
"Interdisciplinary Design Patterns for Socially Aware Computing","H. Baraki; K. Geihs; C. Voigtmann; A. Hoffmann; R. Kniewel; B. Macek; J. Zirfas","Zentrum fur Informationstechnik-Gestaltung (ITeG), Univ. of Kassel, Kassel, Germany; Zentrum fur Informationstechnik-Gestaltung (ITeG), Univ. of Kassel, Kassel, Germany; Zentrum fur Informationstechnik-Gestaltung (ITeG), Univ. of Kassel, Kassel, Germany; Zentrum fur Informationstechnik-Gestaltung (ITeG), Univ. of Kassel, Kassel, Germany; Zentrum fur Informationstechnik-Gestaltung (ITeG), Univ. of Kassel, Kassel, Germany; Zentrum fur Informationstechnik-Gestaltung (ITeG), Univ. of Kassel, Kassel, Germany; Zentrum fur Informationstechnik-Gestaltung (ITeG), Univ. of Kassel, Kassel, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","477","486","The success of software applications that collect and process personal data does not only depend on technical aspects, but is also linked to social compatibility and user acceptance. It requires experts from different disciplines to ensure legal compliance, to foster the users' trust, to enhance the usability of the application and to finally realize the application. Multidisciplinary requirements have to be formulated, interwoven and implemented. We advocate the use of interdisciplinary design patterns that capture the design know-how of typical, recurring features in socially aware applications with particular concern for socio-technical requirements. The proposed patterns address interdisciplinary concerns in a tightly interwoven manner and are intended to facilitate the development of accepted and acceptable applications that in particular deal with sensitive user context information.","","","10.1109/ICSE.2015.180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202998","Interdisciplinary Design Patterns;Socially Aware Computing","Law;Context;Venus;Software engineering;Usability","human factors;software engineering","interdisciplinary design patterns;socially aware computing;software applications;social compatibility;user acceptance;legal compliance;user trust;socially aware applications;socio-technical requirements;user context information","","7","32","","","","","IEEE","IEEE Conferences"
"ChangeScribe: A Tool for Automatically Generating Commit Messages","M. Linares-V√°squez; L. F. Cort√©s-Coy; J. Aponte; D. Poshyvanyk","Coll. of William & Mary, Williamsburg, VA, USA; Univ. Nac. de Colombia, Bogota, Colombia; Univ. Nac. de Colombia, Bogota, Colombia; Coll. of William & Mary, Williamsburg, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","709","712","During software maintenances tasks, commit messages are an important source of information, knowledge, and documentation that developers rely upon. However, the number and nature of daily activities and interruptions can influence the quality of resulting commit messages. This formal demonstration paper presents ChangeScribe, a tool for automatically generating commit messages. ChangeScribe is available at http://www.cs.wm.edu/semeru/changescribe (Eclipse plugin, instructions, demos and the source code).","","","10.1109/ICSE.2015.229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203049","Commit message;summarization;code changes","Software;Context;Java;Semantics;XML;Visualization;Documentation","software maintenance;system documentation","ChangeScribe;automatic commit message generation;software maintenance task;information source;knowledge source;documentation;Eclipse plugin","","26","19","","","","","IEEE","IEEE Conferences"
"What Makes a Great Software Engineer?","P. L. Li; A. J. Ko; J. Zhu","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","700","710","Good software engineers are essential to the creation of good software. However, most of what we know about software-engineering expertise are vague stereotypes, such as 'excellent communicators' and 'great teammates'. The lack of specificity in our understanding hinders researchers from reasoning about them, employers from identifying them, and young engineers from becoming them. Our understanding also lacks breadth: what are all the distinguishing attributes of great engineers (technical expertise and beyond)? We took a first step in addressing these gaps by interviewing 59 experienced engineers across 13 divisions at Microsoft, uncovering 53 attributes of great engineers. We explain the attributes and examine how the most salient of these impact projects and teams. We discuss implications of this knowledge on research and the hiring and training of engineers.","","","10.1109/ICSE.2015.335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194618","Software engineers;expertise;teamwork","Software;Software engineering;Interviews;Lead;Knowledge engineering;Companies","project management;software engineering","software engineering expertise;engineer attribute;software project","","14","37","","","","","IEEE","IEEE Conferences"
"Coexecutability for Efficient Verification of Data Model Updates","I. Bocic; T. Bultan","Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA; Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","744","754","Modern applications use back-end data stores for persistent data. Automated verification of the code that updates the data store would prevent bugs that can cause loss or corruption of data. In this paper, we focus on the most challenging part of this problem: automated verification of code that updates the data store and contains loops. Due to dependencies between loop iterations, verification of code that contains loops is a hard problem, and typically requires manual assistance in the form of loop invariants. We present a fully automated technique that improves verifiability of loops. We first define co execution, a method for modeling loop iterations that simplifies automated reasoning about loops. Then, we present a fully automated static program analysis that detects whether the behavior of a given loop can be modeled using co execution. We provide a customized verification technique for co executable loops that results in more effective verification. In our experiments we observed that, in 45% of cases, modeling loops using co execution reduces verification time between 1 and 4 orders of magnitude. In addition, the rate of inconclusive verification results in the presence of loops is reduced from 65% down to 24%, all without requiring loop invariants or any manual intervention.","","","10.1109/ICSE.2015.87","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194622","Data Models;Logic-based Verification;Loop Analysis","Data models;Cognition;Object oriented modeling;Semantics;Rails;Computer bugs;Manuals","data handling;program control structures;program diagnostics;reasoning about programs","coexecutability;data model update verification;back-end data store;persistent data;automated code verification;data store update;bug prevention;data loss;data corruption;loop invariants;loop verifiability;loop iteration modeling;automated reasoning about loops;fully automated static program analysis;loop behavior;customized verification technique","","4","32","","","","","IEEE","IEEE Conferences"
"AutoCSP: Automatically Retrofitting CSP to Web Applications","M. Fazzini; P. Saxena; A. Orso","Georgia Inst. of Technol., Atlanta, GA, USA; Nat. Univ. of Singapore, Singapore, Singapore; Georgia Inst. of Technol., Atlanta, GA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","336","346","Web applications often handle sensitive user data, which makes them attractive targets for attacks such as cross-site scripting (XSS). Content security policy (CSP) is a content-restriction mechanism, now supported by all major browsers, that offers thorough protection against XSS. Unfortunately, simply enabling CSP for a web application would affect the application's behavior and likely disrupt its functionality. To address this issue, we propose AutoCSP, an automated technique for retrofitting CSP to web applications. AutoCSP (1) leverages dynamic taint analysis to identify which content should be allowed to load on the dynamically-generated HTML pages of a web application and (2) automatically modifies the server-side code to generate such pages with the right permissions. Our evaluation, performed on a set of real-world web applications, shows that AutoCSP can retrofit CSP effectively and efficiently.","","","10.1109/ICSE.2015.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194586","Content security policy;cross-site scripting","HTML;Web pages;Browsers;Heuristic algorithms;Security;Servers;Algorithm design and analysis","Internet;security of data","AutoCSP policy;content security policy;CSP retrofitting;Web applications;cross-site scripting;CSP content-restriction mechanism;XSS protection;dynamic taint analysis;dynamically-generated HTML pages;server-side code modification","","12","31","","","","","IEEE","IEEE Conferences"
"Morpheus: Variability-Aware Refactoring in the Wild","J. Liebig; A. Janker; F. Garbe; S. Apel; C. Lengauer","Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","380","391","Today, many software systems are configurable with conditional compilation. Just like any software system, configurable systems need to be refactored in their evolution, but their inherent variability induces an additional dimension of complexity that is not addressed well by current academic and industrial refactoring engines. To improve the state of the art, we propose a variability-aware refactoring approach that relies on a canonical variability representation and recent work on variability-aware analysis. The goal is to preserve the behavior of all variants of a configurable system, without compromising general applicability and scalability. To demonstrate practicality, we developed Morpheus, a sound, variability-aware refactoring engine for C code with preprocessor directives. We applied Morpheus to three substantial real-world systems (Busybox, OpenSSL, and SQLite) showing that it scales reasonably well, despite of its heavy reliance on satisfiability solvers. By extending a standard approach of testing refactoring engines with support for variability, we provide evidence for the correctness of the refactorings implemented.","","","10.1109/ICSE.2015.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194590","","Engines;Standards;Data structures;Software systems;Complexity theory;Scalability;Testing","C language;computability;program compilers;program diagnostics;software maintenance;software reliability","Morpheus;software systems;conditional compilation;variability-aware refactoring approach;canonical variability representation;variability-aware analysis;C code;preprocessor directives;satisfiability solvers;testing refactoring engines","","16","62","","","","","IEEE","IEEE Conferences"
"Avoiding Security Pitfalls with Functional Programming: A Report on the Development of a Secure XML Validator","D. Doligez; C. Faure; T. Hardin; M. Maarek","Inria, Le Chesnay, France; SafeRiver, Montrouge, France; SafeRiver, Montrouge, France; SafeRiver, Montrouge, France","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","209","218","While the use of XML is pervading all areas of IT, security challenges arise when XML files are used to transfer security data such as security policies. To tackle this issue, we have developed a lightweight secure XML validator and have chosen to base the development on the strongly typed functional language OCaml. The initial development took place as part of the LaFoSec Study which aimed at investigating the impact of using functional languages for security. We then turned the validator into an industrial application, which was successfully evaluated at EAL4+ level by independent assessors. In this paper, we explain the challenges involved in processing XML data in a critical context, we describe our choices in designing a secure XML validator, and we detail how we used features of functional languages to enforce security requirements.","","","10.1109/ICSE.2015.149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202965","Security;Software Engineering;Functional Programming;XML Security","XML;Syntactics;Software engineering;Computer crime;Standards;Context","security of data;XML","security pitfalls avoidance;functional programming;secure XML validator;extensible markup language;security policy;OCaml functional language;LaFoSec Study;XML data processing;security requirements","","2","14","","","","","IEEE","IEEE Conferences"
"An Initiative to Improve Reproducibility and Empirical Evaluation of Software Testing Techniques","F. G. d. Oliveira Neto; R. Torkar; P. D. L. Machado","NA; Dept. of Comput. Sci. & Eng., Chalmers & the Univ. of Gothenburg, Gothenburg, Sweden; Software Practices Lab., Fed. Univ. of Campina Grande, Campina Grande, Brazil","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","575","578","The current concern regarding quality of evaluation performed in existing studies reveals the need for methods and tools to assist in the definition and execution of empirical studies and experiments. However, when trying to apply general methods from empirical software engineering in specific fields, such as evaluation of software testing techniques, new obstacles and threats to validity appears, hindering researchers' use of empirical methods. This paper discusses those issues specific for evaluation of software testing techniques and proposes an initiative for a collaborative effort to encourage reproducibility of experiments evaluating software testing techniques (STT). We also propose the development of a tool that enables automatic execution and analysis of experiments producing a reproducible research compendia as output that is, in turn, shared among researchers. There are many expected benefits from this Endeavour, such as providing a foundation for evaluation of existing and upcoming STT, and allowing researchers to devise and publish better experiments.","","","10.1109/ICSE.2015.197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203016","Empirical Software Engineering;Software Testing;Reproducibility in Software Engineering","Software engineering;Software testing;Software;Collaboration;Guidelines;Conferences","program testing;software engineering","reproducibility;software testing technique;empirical software engineering;STT","","3","13","","","","","IEEE","IEEE Conferences"
"Security Toolbox for Detecting Novel and Sophisticated Android Malware","B. Holland; T. Deering; S. Kothari; J. Mathews; N. Ranade","Dept. of Electr. & Comput. Eng., Iowa State Univ., Ames, IA, USA; Dept. of Electr. & Comput. Eng., Iowa State Univ., Ames, IA, USA; Dept. of Electr. & Comput. Eng., Iowa State Univ., Ames, IA, USA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","733","736","This paper presents a demo of our Security Toolbox to detect novel malware in Android apps. This Toolbox is developed through our recent research project funded by the DARPA Automated Program Analysis for Cybersecurity (APAC) project. The adversarial challenge (""Red"") teams in the DARPA APAC program are tasked with designing sophisticated malware to test the bounds of malware detection technology being developed by the research and development (""Blue"") teams. Our research group, a Blue team in the DARPA APAC program, proposed a ""human-in-the-loop program analysis"" approach to detect malware given the source or Java bytecode for an Android app. Our malware detection apparatus consists of two components: a general-purpose program analysis platform called Atlas, and a Security Toolbox built on the Atlas platform. This paper describes the major design goals, the Toolbox components to achieve the goals, and the workflow for auditing Android apps. The accompanying video illustrates features of the Toolbox through a live audit.","","","10.1109/ICSE.2015.235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203055","Android;malware;program analysis;mobile security","Androids;Humanoid robots;Malware;Semantics;XML;Software","invasive software;Java;program diagnostics;research and development;smart phones;source code (software)","security toolbox;Android apps;DARPA automated program analysis for cybersecurity;APAC program;research and development teams;blue teams;human-in-the-loop program analysis approach;source bytecode;Java bytecode;malware detection apparatus;general-purpose program analysis platform;Atlas platform;live audit","","6","18","","","","","IEEE","IEEE Conferences"
"A Programming Model for Sustainable Software","H. S. Zhu; C. Lin; Y. D. Liu","SUNY Binghamton, Binghamton, NY, USA; SUNY Binghamton, Binghamton, NY, USA; SUNY Binghamton, Binghamton, NY, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","767","777","This paper presents a novel energy-aware and temperature-aware programming model with first-class support for sustainability. A program written in the new language, named Eco, may adaptively adjusts its own behaviors to stay on a given (energy or temperature) budget, avoiding both deficit that would lead to battery drain or CPU overheating, and surplus that could have been used to improve the quality of results. Sustainability management in Eco is captured as a form of supply and demand matching, and the language runtime consistently maintains the equilibrium between supply and demand. Among the efforts of energy-adaptive and temperature-adaptive systems, Eco is distinctive in its role in bridging the programmer and the underlying system, and in particular, bringing both programmer knowledge and application-specific traits into energy optimization. Through a number of intuitive programming abstractions, Eco reduces challenging issues in this domain --- such as workload characterization and decision making in adaptation --- to simple programming tasks, ultimately offering fine-grained, programmable, and declarative sustainability to energy-efficient computing. Eco is an minimal extension to Java, and has been implemented as an open-source compiler. We validate the usefulness of Eco by upgrading real-world Java applications with energy awareness and temperature awareness.","","","10.1109/ICSE.2015.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194624","sustainability;programming models;energy management;thermal management","Programming;Batteries;Runtime;Calibration;Thermal management;Software;Java","decision making;Java;program compilers;public domain software;sustainable development","sustainable software;energy-aware programming model;temperature-aware programming model;Eco;sustainability management;supply and demand matching;energy-adaptive system;temperature-adaptive system;energy optimization;intuitive programming abstractions;workload characterization;decision making;programming tasks;energy-efficient computing;open-source compiler;Java applications;energy awareness;temperature awareness","","12","41","","","","","IEEE","IEEE Conferences"
"Work Practices and Challenges in Pull-Based Development: The Integrator's Perspective","G. Gousios; A. Zaidman; M. Storey; A. v. Deursen","Radboud Univ. Nijmegen, Nijmegen, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Univ. of Victoria, Victoria, BC, Canada; Delft Univ. of Technol., Delft, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","358","368","In the pull-based development model, the integrator has the crucial role of managing and integrating contributions. This work focuses on the role of the integrator and investigates working habits and challenges alike. We set up an exploratory qualitative study involving a large-scale survey of 749 integrators, to which we add quantitative data from the integrator's project. Our results provide insights into the factors they consider in their decision making process to accept or reject a contribution. Our key findings are that integrators struggle to maintain the quality of their projects and have difficulties with prioritizing contributions that are to be merged. Our insights have implications for practitioners who wish to use or improve their pull-based development process, as well as for researchers striving to understand the theoretical implications of the pull-based model in software development.","","","10.1109/ICSE.2015.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194588","Distributed Software Development;Pull-based Development;Pull Request;GitHub","Software;Electronic mail;Collaboration;Face;Databases;Inspection;Birds","decision making;software quality","pull-based software development model;decision making process;software quality","","73","24","","","","","IEEE","IEEE Conferences"
"When and Why Your Code Starts to Smell Bad","M. Tufano; F. Palomba; G. Bavota; R. Oliveto; M. Di Penta; A. De Lucia; D. Poshyvanyk","Coll. of William & Mary, Williamsburg, VA, USA; Univ. of Salerno, Fisciano, Italy; Free Univ. of Bozen-Bolzano, Bolzano, Italy; Univ. of Molise, Pesche, Italy; Univ. of Sannio, Benevento, Italy; Univ. of Salerno, Fisciano, Italy; Coll. of William & Mary, Williamsburg, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","403","414","In past and recent years, the issues related to managing technical debt received significant attention by researchers from both industry and academia. There are several factors that contribute to technical debt. One of these is represented by code bad smells, i.e., Symptoms of poor design and implementation choices. While the repercussions of smells on code quality have been empirically assessed, there is still only anecdotal evidence on when and why bad smells are introduced. To fill this gap, we conducted a large empirical study over the change history of 200 open source projects from different software ecosystems and investigated when bad smells are introduced by developers, and the circumstances and reasons behind their introduction. Our study required the development of a strategy to identify smell-introducing commits, the mining of over 0.5M commits, and the manual analysis of 9,164 of them (i.e., Those identified as smell-introducing). Our findings mostly contradict common wisdom stating that smells are being introduced during evolutionary tasks. In the light of our results, we also call for the need to develop a new generation of recommendation systems aimed at properly planning smell refactoring activities.","","","10.1109/ICSE.2015.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194592","bad code smells;mining software repositories;empirical study","Measurement;Software;Ecosystems;History;Androids;Humanoid robots;Maintenance engineering","recommender systems;software maintenance;software quality","technical debt management;code quality;software ecosystems;smell-introducing commits identification;recommendation systems;smell refactoring activities","","59","51","","","","","IEEE","IEEE Conferences"
"A Field Study on Fostering Structural Navigation with Prodet","V. Augustine; P. Francis; X. Qu; D. Shepherd; W. Snipes; C. Braunlich; T. Fritz","ABB Corp. Res., Raleigh, NC, USA; ABB Corp. Res., Raleigh, NC, USA; ABB Corp. Res., Raleigh, NC, USA; ABB Corp. Res., Raleigh, NC, USA; ABB Corp. Res., Raleigh, NC, USA; Wotan Eng. GmbH, Otelfingen, Switzerland; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","229","238","Past studies show that developers who navigate code in a structural manner complete tasks faster and more correctly than those whose behavior is more opportunistic. The goal of this work is to move professional developers towards more effective program comprehension and maintenance habits by providing an approach that fosters structural code navigation. To this end, we created a Visual Studio plugin called Prodet that integrates an always-on navigable visualization of the most contextually relevant portions of the call graph. We evaluated the effectiveness of our approach by deploying it in a six week field study with professional software developers. The study results show a statistically significant increase in developers' use of structural navigation after installing Prodet. The results also show that developers continuously used the filtered and navigable call graph over the three week period in which it was deployed in production. These results indicate the maturity and value of our approach to increase developers' effectiveness in a practical and professional environment.","","","10.1109/ICSE.2015.151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202967","Software Maintenance;Structural Navigation;Code Recommendation;Field Study","Navigation;Context;Visualization;Software engineering;Maintenance engineering;Software;History","program visualisation;software maintenance;source code (software)","structural code navigation;Prodet;program comprehension;program maintenance habits;Visual Studio plugin;always-on navigable visualization;call graph;professional software developers","","5","36","","","","","IEEE","IEEE Conferences"
"Effectiveness of Persona with Personality Traits on Conceptual Design","F. Anvari; D. Richards; M. Hitchens; M. A. Babar","Dept. of Comput., Macquarie Univ., Sydney, NSW, Australia; Dept. of Comput., Macquarie Univ., Sydney, NSW, Australia; Dept. of Comput., Macquarie Univ., Sydney, NSW, Australia; CREST - The Centre for Res. on Eng. Software Technol., Univ. of Adelaide, Adelaide, SA, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","263","272","Conceptual design is an important skill in Software Engineering. Teaching conceptual design that can deliver a useful product is challenging, particularly when access to real users is limited. This study explores the effects of the use of Holistic Personas (i.e. a persona enriched with personality traits) on students' performance in creating conceptual designs. Our results indicate that the students were able to identify the personality traits of personas and their ratings of the personalities match closely with the intended personalities. A majority of the participants stated that their designs were tailored to meet the needs of the given personas' personality traits. Results suggest that the Holistic Personas can help students to take into account personality traits in the conceptual design process. Further studies are warranted to assess the value of incorporating Holistic Personas in conceptual design training for imparting skills of producing in-depth design by taking personalities into account.","","","10.1109/ICSE.2015.155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202971","User-Centered Design;persona;personality;conceptual design;software engineering education","Software;Software engineering;Training;Context;Joints;Stability analysis","computer science education;educational courses;software engineering;teaching","personality traits;software engineering;conceptual design teaching;holistic personas;conceptual design process;conceptual design training;in-depth design","","8","38","","","","","IEEE","IEEE Conferences"
"Automated Planning for Self-Adaptive Systems","R. Gil","Inst. Super. Tecnico, Univ. de Lisboa, Lisbon, Portugal","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","839","842","Self-adaptation has been proposed as a viable solution to alleviate the management burden that is induced by the dynamic nature and increasing complexity of computer systems. In this context, architectural-based self-adaptation has emerged as one of the most promising approaches to automatically manage such systems, resorting to a control loop that includes monitoring, analyzing, planning, and executing adequate actions. This work addresses the challenges of adaptation planning -the decision-making process for selecting an appropriate course of action- with a focus on the problem of provisioning automated mechanisms for assembling adaptation plans, as a means to enhance adaptive capabilities under uncertainty. To this purpose, adaptations are modeled in a hierarchical manner, defining primitive actions, guarded actions, and deliberate plans, which may guide the system towards a desired state.","","","10.1109/ICSE.2015.273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203094","automated planning;PDDL;self-adaptive;self-management;planning","Planning;Adaptation models;Measurement;Uncertainty;Software;Adaptive systems;Medical services","decision making;fault tolerant computing;planning","automated planning;self-adaptive systems;computer systems;architectural-based self-adaptation;system management;control loop;adaptation planning;decision-making process","","","26","","","","","IEEE","IEEE Conferences"
"Fast Feedback Cycles in Empirical Software Engineering Research","A. Vetr√≤; S. Ognawala; D. M. Fern√°ndez; S. Wagner","Tech. Univ. Munchen, Munich, Germany; Tech. Univ. Munchen, Munich, Germany; Tech. Univ. Munchen, Munich, Germany; Univ. of Stuttgart, Stuttgart, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","583","586","Background/Context: Gathering empirical knowledge is a time consuming task and the results from empirical studies often are soon outdated by new technological solutions. As a result, the impact of empirical results on software engineering practice is often not guaranteed.Objective/Aim: In this paper, we summarise the ongoing discussion on ""Empirical Software Engineering 2.0"" as a way to improve the impact of empirical results on industrial practices. We propose a way to combine data mining and analysis with domain knowledge to enable fast feedback cycles in empirical software engineering research.Method: We identify the key concepts on gathering fast feedback in empirical software engineering by following an experience-based line of reasoning by argument. Based on the identified key concepts, we design and execute a small proof of concept with a company to demonstrate potential benefits of the approach.Results: In our example, we observed that a simple double feedback mechanism notably increased the precision of the data analysis and improved the quality of the knowledge gathered.Conclusion: Our results serve as a basis to foster discussion and collaboration within the research community for a development of the idea.","","","10.1109/ICSE.2015.198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203018","Empirical methods;Research methods;Data mining;Knowledge transfer","Software engineering;Software;Data mining;Stakeholders;Collaboration;Data analysis;Physics","data analysis;data mining;inference mechanisms;software engineering","feedback cycle;empirical software engineering 2.0;EMSE 2.0;data mining;data analysis;domain knowledge;double feedback mechanism","","4","22","","","","","IEEE","IEEE Conferences"
"Information Transformation: An Underpinning Theory for Software Engineering","D. Clark; R. Feldt; S. Poulding; S. Yoo","Dept. of Comput. Sci., Univ. Coll. London, London, UK; Dept. of Software Eng., Blekinge Inst. of Technol., Blekinge, Sweden; Dept. of Software Eng., Blekinge Inst. of Technol., Blekinge, Sweden; Dept. of Comput. Sci., Univ. Coll. London, London, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","599","602","Software engineering lacks underpinning scientific theories both for the software it produces and the processes by which it does so. We propose that an approach based on information theory can provide such a theory, or rather many theories. We envision that such a benefit will be realised primarily through research based on the quantification of information involved and a mathematical study of the limiting laws that arise. However, we also argue that less formal but more qualitative uses for information theory will be useful. The main argument in support of our vision is based on the fact that both a program and an engineering process to develop such a program are fundamentally processes that transform information. To illustrate our argument we focus on software testing and develop an initial theory in which a test suite is input/output adequate if it achieves the channel capacity of the program as measured by the mutual information between its inputs and its outputs. We outline a number of problems, metrics and concrete strategies for improving software engineering, based on information theoretical analyses. We find it likely that similar analyses and subsequent future research to detail them would be generally fruitful for software engineering.","","","10.1109/ICSE.2015.202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203022","information theory;software engineering;software testing","Software engineering;Entropy;Software;Channel capacity;Software testing;Measurement","information theory;program testing;software engineering","information transformation theory;software engineering;information quantification;software testing","","4","20","","","","","IEEE","IEEE Conferences"
"Revisiting the Impact of Classification Techniques on the Performance of Defect Prediction Models","B. Ghotra; S. McIntosh; A. E. Hassan","Software Anal. & Intell. Lab. (SAIL), Queen's Univ., Kingston, ON, Canada; Software Anal. & Intell. Lab. (SAIL), Queen's Univ., Kingston, ON, Canada; Software Anal. & Intell. Lab. (SAIL), Queen's Univ., Kingston, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","789","800","Defect prediction models help software quality assurance teams to effectively allocate their limited resources to the most defect-prone software modules. A variety of classification techniques have been used to build defect prediction models ranging from simple (e.g., Logistic regression) to advanced techniques (e.g., Multivariate Adaptive Regression Splines (MARS)). Surprisingly, recent research on the NASA dataset suggests that the performance of a defect prediction model is not significantly impacted by the classification technique that is used to train it. However, the dataset that is used in the prior study is both: (a) noisy, i.e., Contains erroneous entries and (b) biased, i.e., Only contains software developed in one setting. Hence, we set out to replicate this prior study in two experimental settings. First, we apply the replicated procedure to the same (known-to-be noisy) NASA dataset, where we derive similar results to the prior study, i.e., The impact that classification techniques have appear to be minimal. Next, we apply the replicated procedure to two new datasets: (a) the cleaned version of the NASA dataset and (b) the PROMISE dataset, which contains open source software developed in a variety of settings (e.g., Apache, GNU). The results in these new datasets show a clear, statistically distinct separation of groups of techniques, i.e., The choice of classification technique has an impact on the performance of defect prediction models. Indeed, contrary to earlier research, our results suggest that some classification techniques tend to produce defect prediction models that outperform others.","","","10.1109/ICSE.2015.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194626","Defect Prediction;Classification Techniques","Predictive models;NASA;Software;Decision trees;Training;Logistics;Complexity theory","pattern classification;quality assurance;software quality","classification techniques;defect prediction models;software quality assurance teams;defect-prone software modules;NASA dataset;PROMISE dataset;open source software","","96","65","","","","","IEEE","IEEE Conferences"
"Dynamic Generation of Likely Invariants for Multithreaded Programs","M. Kusano; A. Chattopadhyay; C. Wang","Dept. of ECE, Virginia Tech, Blacksburg, VA, USA; Dept. of ECE, Virginia Tech, Blacksburg, VA, USA; Dept. of ECE, Virginia Tech, Blacksburg, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","835","846","We propose a new method for dynamically generating likely invariants from multithreaded programs.While existing invariant generation tools work well on sequential programs, they are ineffective at reasoning about multithreaded programs both in terms of the number of real invariants generated and in terms of their usefulness in helping programmers. We address this issue by developing a new dynamic invariant generator consisting of an LLVM based code instrumentation front end, a systematic thread interleaving explorer, and a customized invariant inference engine. We show that efficient interleaving exploration strategies can be used to generate a diversified set of executions with little runtime overhead. Furthermore, we show that focusing on a small subset of thread-local transition invariants is often sufficient for reasoning about the concurrency behavior of programs. We have evaluated our new method on a set of open-source multithreaded C/C++ benchmarks. Our experiments show that our method can generate invariants that are significantly higher in quality than the previous state-of-the-art.","","","10.1109/ICSE.2015.95","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194630","invariant generation;likely invariant;concurrent program;transition invariant;partial order reduction","Concurrent computing;Instruments;Instruction sets;Engines;Systematics;Schedules;Programming","C++ language;multi-threading;software tools","dynamic likely invariant generation;multithreaded programs;invariant generation tools;sequential programs;dynamic invariant generator;LLVM;code instrumentation front end;systematic thread interleaving explorer;customized invariant inference engine;interleaving exploration strategies;thread-local transition invariants;concurrency behavior;open-source multithreaded C/C++ benchmarks","","4","58","","","","","IEEE","IEEE Conferences"
"Mining Apps for Abnormal Usage of Sensitive Data","V. Avdiienko; K. Kuznetsov; A. Gorla; A. Zeller; S. Arzt; S. Rasthofer; E. Bodden","Saarland Univ., Saarbrucken, Germany; Saarland Univ., Saarbrucken, Germany; IMDEA Software Inst., Madrid, Spain; Saarland Univ., Saarbrucken, Germany; Tech. Univ. Darmstadt, Darmstadt, Germany; Tech. Univ. Darmstadt, Darmstadt, Germany; Tech. Univ. Darmstadt, Darmstadt, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","426","436","What is it that makes an app malicious? One important factor is that malicious apps treat sensitive data differently from benign apps. To capture such differences, we mined 2,866 benign Android applications for their data flow from sensitive sources, and compare these flows against those found in malicious apps. We find that (a) for every sensitive source, the data ends up in a small number of typical sinks; (b) these sinks differ considerably between benign and malicious apps; (c) these differences can be used to flag malicious apps due to their abnormal data flow; and (d) malicious apps can be identified by their abnormal data flow alone, without requiring known malware samples. In our evaluation, our MUDFLOW prototype correctly identified 86.4% of all novel malware, and 90.1% of novel malware leaking sensitive data.","","","10.1109/ICSE.2015.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194594","","Malware;Androids;Humanoid robots;Smart phones;Google;Data mining;Twitter","data mining;invasive software;mobile computing;smart phones","data mining;Android application;abnormal data flow;malware","","61","30","","","","","IEEE","IEEE Conferences"
"Evolution of Software Development Strategies","K. Falkner; C. Szabo; R. Vivian; N. Falkner","Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","243","252","The development of discipline-specific cognitive and meta-cognitive skills is fundamental to the successful mastery of software development skills and processes. This development happens over time and is influenced by many factors, however its understanding by teachers is crucial in order to develop activities and materials to transform students from novice to expert software engineers. In this paper, we analyse the evolution of learning strategies of novice, first year students, to expert, final year students. We analyse reflections on software development processes from students in an introductory software development course, and compare them to those of final year students, in a distributed systems development course. Our study shows that computer science - specific strategies evolve as expected, with the majority of final year students including design before coding in their software development process, but that several areas still require scaffolding activities to assist in learning development.","","","10.1109/ICSE.2015.153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202969","software development strategies;self regulated learning behavior","Software;Encoding;Software engineering;Planning;Context;Programming profession","computer science education;educational courses;software engineering;teaching","software development strategies;discipline-specific meta-cognitive skills development;software development skills;learning strategies;software development course;distributed system development course;computer science specific strategies;software coding;scaffolding activities","","1","40","","","","","IEEE","IEEE Conferences"
"Novice Code Understanding Strategies during a Software Maintenance Assignment","C. Szabo","Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","276","284","Existing efforts on teaching software maintenance have focussed on constructing adequate codebases that students with limited knowledge could maintain, with little focus on the learning outcomes of such exercises and of the approaches that students employ while performing maintenance. An analysis of the code understanding strategies employed by novice students as they perform software maintenance exercises is fundamental for the effective teaching of software maintenance. In this paper, we analyze the strategies employed by second year students in a maintenance exercise over a large codebase. We analyze student reflections on their code understanding, maintenance process and the use of tools. We show that students are generally capable of working with large codebases. Our study also finds that the majority of students follow a systematic approach to code understanding, but that their approach can be significantly improved through the use of tools and a better understanding of reverse engineering approaches.","","","10.1109/ICSE.2015.341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202973","software maintenance;software engineering;cognitive models","Software maintenance;Maintenance engineering;Software engineering;Education;Testing;Systematics","computer science education;reverse engineering;software maintenance","novice code understanding strategies;software maintenance assignment;adequate codebases;learning outcomes;novice students;software maintenance exercises;second year students;reverse engineering approaches","","1","20","","","","","IEEE","IEEE Conferences"
"Scalable Formal Verification of UML Models","M. M. Pourhashem Kallehbasti","Dipt. di Elettron., Inf. e Bioingegneria, Politec. di Milano, Milan, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","847","850","UML (Unified Modeling Language) has been used for years in diverse domains. Its notations usually come with a reasonably well-defined syntax, but its semantics is left under-specified and open to different interpretations. This freedom hampers the formal verification of produced specifications and calls for more rigor and precision. This work aims to bridge this gap and proposes a flexible and modular formalization approach based on temporal logic. We studied the different interpretations for some of its constructs, and our framework allows one to assemble the semantics of interest by composing the selected formalizations for the different pieces. However, the formalization per-se is not enough. The verification process, in general, becomes slow and impossible -as the model grows in size. To tackle the scalability problem, this work also proposes a bit-vector-based encoding of LTL formulae. The first results witness a significant increase in the size of analyzable models, not only for our formalization of UML models, but also for numerous other models that can be reduced to bounded satisfiability checking of LTL formulae.","","","10.1109/ICSE.2015.275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203096","UML;Formal Methods;Temporal Logic;Bounded Model Checking;Bit-Vector Logic","Unified modeling language;Encoding;Semantics;Model checking;Scalability;Analytical models;Conferences","formal verification;temporal logic;Unified Modeling Language","scalable formal verification;UML model;unified modeling language;modular formalization approach;temporal logic;bit-vector-based encoding;LTL formulae;satisfiability checking","","1","14","","","","","IEEE","IEEE Conferences"
"Views on Internal and External Validity in Empirical Software Engineering","J. Siegmund; N. Siegmund; S. Apel","Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","9","19","Empirical methods have grown common in software engineering, but there is no consensus on how to apply them properly. Is practical relevance key? Do internally valid studies have any value? Should we replicate more to address the tradeoff between internal and external validity? We asked the community how empirical research should take place in software engineering, with a focus on the tradeoff between internal and external validity and replication, complemented with a literature review about the status of empirical research in software engineering. We found that the opinions differ considerably, and that there is no consensus in the community when to focus on internal or external validity and how to conduct and review replications.","","","10.1109/ICSE.2015.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194557","","Software engineering;Guidelines;Bibliographies;Computer languages;Context;Standards;History","software engineering","external validity;internal validity;software engineering;empirical research","","46","37","","","","","IEEE","IEEE Conferences"
"Making System User Interactive Tests Repeatable: When and What Should We Control?","Z. Gao; Y. Liang; M. B. Cohen; A. M. Memon; Z. Wang","Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska-Lincoln, Lincoln, NE, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","55","65","System testing and invariant detection is usually conducted from the user interface perspective when the goal is to evaluate the behavior of an application as a whole. A large number of tools and techniques have been developed to generate and automate this process, many of which have been evaluated in the literature or internally within companies. Typical metrics for determining effectiveness of these techniques include code coverage and fault detection, however, with the assumption that there is determinism in the resulting outputs. In this paper we examine the extent to which a common set of factors such as the system platform, Java version, application starting state and tool harness configurations impact these metrics. We examine three layers of testing outputs: the code layer, the behavioral (or invariant) layer and the external (or user interaction) layer. In a study using five open source applications across three operating system platforms, manipulating several factors, we observe as many as 184 lines of code coverage difference between runs using the same test cases, and up to 96 percent false positives with respect to fault detection. We also see some a small variation among the invariants inferred. Despite our best efforts, we can reduce, but not completely eliminate all possible variation in the output. We use our findings to provide a set of best practices that should lead to better consistency and smaller differences in test outcomes, allowing more repeatable and reliable testing and experimentation.","","","10.1109/ICSE.2015.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194561","software testing; experimentation; benchmarking; graphical user interfaces","Testing;Entropy;Graphical user interfaces;Java;Delays;Operating systems","graphical user interfaces;operating systems (computers);program testing;public domain software;software fault tolerance","user interactive application testing;code coverage;fault detection;open source application;operating system platform;graphical user interface;GUI","","9","40","","","","","IEEE","IEEE Conferences"
"The Impact of Mislabelling on the Performance and Interpretation of Defect Prediction Models","C. Tantithamthavorn; S. McIntosh; A. E. Hassan; A. Ihara; K. Matsumoto","Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan; Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Nara, Japan","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","812","823","The reliability of a prediction model depends on the quality of the data from which it was trained. Therefore, defect prediction models may be unreliable if they are trained using noisy data. Recent research suggests that randomly-injected noise that changes the classification (label) of software modules from defective to clean (and vice versa) can impact the performance of defect models. Yet, in reality, incorrectly labelled (i.e., mislabelled) issue reports are likely non-random. In this paper, we study whether mislabelling is random, and the impact that realistic mislabelling has on the performance and interpretation of defect models. Through a case study of 3,931 manually-curated issue reports from the Apache Jackrabbit and Lucene systems, we find that: (1) issue report mislabelling is not random; (2) precision is rarely impacted by mislabelled issue reports, suggesting that practitioners can rely on the accuracy of modules labelled as defective by models that are trained using noisy data; (3) however, models trained on noisy data typically achieve 56%-68% of the recall of models trained on clean data; and (4) only the metrics in top influence rank of our defect models are robust to the noise introduced by mislabelling, suggesting that the less influential metrics of models that are trained on noisy data should not be interpreted or used to make decisions.","","","10.1109/ICSE.2015.93","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194628","Software Quality Assurance;Software Defect Prediction;Data Quality;Mislabelling","Predictive models;Data models;Noise measurement;Noise;Data mining;Software","software performance evaluation;software reliability","mislabelling impact;defect prediction model performance;defect prediction model interpretation;prediction model reliability;defect prediction models;randomly-injected noise;software modules;Apache Jackrabbit system;Lucene system","","33","51","","","","","IEEE","IEEE Conferences"
"Graph-Based Statistical Language Model for Code","A. T. Nguyen; T. N. Nguyen","Iowa State Univ., Ames, IA, USA; Iowa State Univ., Ames, IA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","858","868","n-gram statistical language model has been successfully applied to capture programming patterns to support code completion and suggestion. However, the approaches using n-gram face challenges in capturing the patterns at higher levels of abstraction due to the mismatch between the sequence nature in n-grams and the structure nature of syntax and semantics in source code. This paper presents GraLan, a graph-based statistical language model and its application in code suggestion. GraLan can learn from a source code corpus and compute the appearance probabilities of any graphs given the observed (sub)graphs. We use GraLan to develop an API suggestion engine and an AST-based language model, ASTLan. ASTLan supports the suggestion of the next valid syntactic template and the detection of common syntactic templates. Our empirical evaluation on a large corpus of open-source projects has shown that our engine is more accurate in API code suggestion than the state-of-the-art approaches, and in 75% of the cases, it can correctly suggest the API with only five candidates. ASTLan has also high accuracy in suggesting the next syntactic template and is able to detect many useful and common syntactic templates.","","","10.1109/ICSE.2015.336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194632","Graph-based Language Model;API Suggestion;Syntactic Template Suggestion","Context;Syntactics;Probability;Engines;Programming;Accuracy;Computational modeling","graph theory;object-oriented programming;probability;public domain software;source code (software)","graph-based statistical language model;n-gram statistical language model;programming patterns;code completion;code suggestion;GraLan;source code corpus;appearance probability;API suggestion engine;AST-based language model;ASTLan;valid syntactic template;common syntactic template detection;open-source projects","","36","43","","","","","IEEE","IEEE Conferences"
"DirectFix: Looking for Simple Program Repairs","S. Mechtaev; J. Yi; A. Roychoudhury","Nat. Univ. of Singapore, Singapore, Singapore; Nat. Univ. of Singapore, Singapore, Singapore; Nat. Univ. of Singapore, Singapore, Singapore","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","448","458","Recent advances in program repair techniques have raised the possibility of patching bugs automatically. For an automatically generated patch to be accepted by developers, it should not only resolve the bug but also satisfy certain human-related factors including readability and comprehensibility. In this paper, we focus on the simplicity of patches (the size of changes). We present a novel semantics-based repair method that generates the simplest patch such that the program structure of the buggy program is maximally preserved. To take into account the simplicity of repairs in an efficient way (i.e., Without explicitly enumerating each repair candidate for each fault location), our method fuses fault localization and repair generation into one step. We do so by leveraging partial Max SAT constraint solving and component-based program synthesis. We compare our prototype implementation, Direct Fix, with the state-of-the-art semantics-based repair tool Sem Fix, that performs fault localization before repair generation. In our experiments with SIR programs and GNU Coreutils, Direct Fix generates repairs that are simpler than those generated by Sem Fix. Since both Direct Fix and Sem Fix are test-driven repair tools, they can introduce regressions for other tests which do not drive the repair. We found that Direct Fix causes substantially less regression errors than Sem Fix.","","","10.1109/ICSE.2015.63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194596","Automated Repair;SMT solving;Program Synthesis","Maintenance engineering;Semantics;Encoding;Computer bugs;Fault location;Fuses","human factors;object-oriented programming;program debugging;regression analysis;software fault tolerance;software maintenance","DirectFix;program repair technique;bug patching;human-related factor;readability;comprehensibility;patch simplicity;semantics-based repair method;fault location;repair generation;Max SAT constraint solving;component-based program synthesis;regression error","","79","40","","","","","IEEE","IEEE Conferences"
"Automated Data Structure Generation: Refuting Common Wisdom","K. Dewey; L. Nichols; B. Hardekopf","Univ. of California, Santa Barbara, Santa Barbara, CA, USA; Univ. of California, Santa Barbara, Santa Barbara, CA, USA; Univ. of California, Santa Barbara, Santa Barbara, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","32","43","Common wisdom in the automated data structure generation community states that declarative techniques have better usability than imperative techniques, while imperative techniques have better performance. We show that this reasoning is fundamentally flawed: if we go to the declarative limit and employ constraint logic programming (CLP), the CLP data structure generation has orders of magnitude better performance than comparable imperative techniques. Conversely, we observe and argue that when it comes to realistically complex data structures and properties, the CLP specifications become more obscure, indirect, and difficult to implement and understand than their imperative counterparts. We empirically evaluate three competing generation techniques, CLP, Korat, and UDITA, to validate these observations on more complex and interesting data structures than any prior work in this area. We explain why these observations are true, and discuss possible techniques for attaining the best of both worlds.","","","10.1109/ICSE.2015.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194559","Constraint Logic Programming;Data Structure Generation","Data structures;Java;Usability;Engines;Search problems;Semantics;Generators","constraint handling;data structures","automated data structure generation;common wisdom;constraint logic programming;CLP;Korat;UDITA","","3","38","","","","","IEEE","IEEE Conferences"
"Composite Constant Propagation: Application to Android Inter-Component Communication Analysis","D. Octeau; D. Luchaup; M. Dering; S. Jha; P. McDaniel","Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA; Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA; Dept. of Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA; Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA; Dept. of Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","77","88","Many program analyses require statically inferring the possible values of composite types. However, current approaches either do not account for correlations between object fields or do so in an ad hoc manner. In this paper, we introduce the problem of composite constant propagation. We develop the first generic solver that infers all possible values of complex objects in an interprocedural, flow and context-sensitive manner, taking field correlations into account. Composite constant propagation problems are specified using COAL, a declarative language. We apply our COAL solver to the problem of inferring Android Inter-Component Communication (ICC) values, which is required to understand how the components of Android applications interact. Using COAL, we model ICC objects in Android more thoroughly than the state-of-the-art. We compute ICC values for 460 applications from the Play store. The ICC values we infer are substantially more precise than previous work. The analysis is efficient, taking slightly over two minutes per application on average. While this work can be used as the basis for many whole-program analyses of Android applications, the COAL solver can also be used to infer the values of composite objects in many other contexts.","","","10.1109/ICSE.2015.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194563","inter-component communication;composite constant;constant propagation;Android;Android IPC;Android ICC","Coal;Androids;Humanoid robots;Data models;Analytical models;Computational modeling;Correlation","mobile computing;program diagnostics;smart phones","composite constant propagation;Android application;intercomponent communication analysis;ICC;program analysis;COAL solver;declarative language","","42","","","","","","IEEE","IEEE Conferences"
"How Can I Use This Method?","L. Moreno; G. Bavota; M. Di Penta; R. Oliveto; A. Marcus","Univ. of Texas at Dallas, Dallas, TX, USA; Free Univ. of Bozen-Bolzano, Bolzano, Italy; Univ. of Sannio, Benevento, Italy; Univ. of Molise, Campobasso, Italy; Univ. of Texas at Dallas, Dallas, TX, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","880","890","Code examples are small source code fragments whose purpose is to illustrate how a programming language construct, an API, or a specific function/method works. Since code examples are not always available in the software documentation, researchers have proposed techniques to automatically extract them from existing software or to mine them from developer discussions. In this paper we propose MUSE (Method USage Examples), an approach for mining and ranking actual code examples that show how to use a specific method. MUSE combines static slicing (to simplify examples) with clone detection (to group similar examples), and uses heuristics to select and rank the best examples in terms of reusability, understandability, and popularity. MUSE has been empirically evaluated using examples mined from six libraries, by performing three studies involving a total of 140 developers to: (i) evaluate the selection and ranking heuristics, (ii) provide their perception on the usefulness of the selected examples, and (iii) perform specific programming tasks using the MUSE examples. The results indicate that MUSE selects and ranks examples close to how humans do, most of the code examples (82%) are perceived as useful, and they actually help when performing programming tasks.","","","10.1109/ICSE.2015.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194634","Code examples;Empirical studies;Software documentation;Static software analysis","Cloning;Libraries;Software;Documentation;Measurement;Data mining;Context","program slicing;programming languages;software engineering;source code (software)","clone detection;static slicing;MUSE;method usage examples;software development;software documentation;programming language;source code fragment","","22","21","","","","","IEEE","IEEE Conferences"
"relifix: Automated Repair of Software Regressions","S. H. Tan; A. Roychoudhury","Nat. Univ. of Singapore, Singapore, Singapore; Nat. Univ. of Singapore, Singapore, Singapore","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","471","482","Regression occurs when code changes introduce failures in previously passing test cases. As software evolves, regressions may be introduced. Fixing regression errors manually is time-consuming and error-prone. We propose an approach of automated repair of software regressions, called relifix, that considers the regression repair problem as a problem of reconciling problematic changes. Specifically, we derive a set of code transformations obtained from our manual inspection of 73 real software regressions; this set of code transformations uses syntactical information from changed statements. Regression repair is then accomplished via a search over the code transformation operators - which operator to apply, and where. Our evaluation compares the repairability of relifix with GenProg on 35 real regression errors. relifix repairs 23 bugs, while GenProg only fixes five bugs. We also measure the likelihood of both approaches in introducing new regressions given a reduced test suite. Our experimental results shows that our approach is less likely to introduce new regressions than GenProg.","","","10.1109/ICSE.2015.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194598","Automated Repair;Genetic Programming;Real-life Software Regressions","Maintenance engineering;Software;Computer bugs;Benchmark testing;Inspection;Manuals","regression analysis;software maintenance","relifix;automated repair;software regressions;regression repair problem;code transformations;manual inspection;code transformation operators;GenProg","","28","55","","","","","IEEE","IEEE Conferences"
"Improving Student Group Work with Collaboration Patterns: A Case Study","C. K√∂ppe; M. v. Eekelen; S. Hoppenbrouwers","HAN Univ. of Appl. Sci., Arnhem, Netherlands; NA; HAN Univ. of Appl. Sci., Arnhem, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","303","306","Group work skills are essential for Computer Scientists and especially Software Engineers. Group work is included in most CS curricula in order to support students in acquiring these skills. During group work, problems can occur related to a variety of factors, such as unstable group constellations or (missing) instructor support. Students need to find strategies for solving or preventing such problems. Student collaboration patterns offer a way of supporting students by providing problem-solving strategies that other students have already applied successfully. In this work we describe how student collaboration patterns were applied in an interdisciplinary software engineering project, and show that their application was generally experienced as helpful by the students.","","","10.1109/ICSE.2015.160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202977","Group Work;Student Projects;Collaboration Patterns","Teamwork;Software engineering;Software;Conferences;Team working;Computer science","computer science education;software engineering","student group work skills;student collaboration patterns;CS curricula;problem-solving strategy;interdisciplinary software engineering project","","","13","","","","","IEEE","IEEE Conferences"
"Collaborative and Cooperative-Learning in Software Engineering Courses","N. Soundarajan; S. Joshi; R. Ramnath","Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA; Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","319","322","Collaborative learning is a key component of software engineering (SE) courses in most undergraduate computing curricula. Thus these courses include fairly intensive team projects, the intent being to ensure that not only do students develop an understanding of key software engineering concepts and practices, but also develop the skills needed to work effectively in large design and development teams. But there is a definite risk in collaborative learning in that there is a potential that individual learning gets lost in the focus on the team's success in completing the project (s). While the team's success is indeed the primary goal of an industrial SE team, ensuring individual learning is obviously an essential goal of SE courses. We have developed a novel approach that exploits the affordances of mobile and web technologies to help ensure that individual students in teams in SE courses develop a thorough understanding of the relevant concepts and practices while working on team projects, indeed, that the team contributes in an essential manner to the learning of each member of the team. We describe the learning theory underlying our approach, provide some details concerning the prototype implementation of a tool based on the approach, and describe how we are using it in an SE course in our program.","","","10.1109/ICSE.2015.164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202981","Collaborative Learning;Cooperative Learning;Use of technology in classroom","Information services;Electronic publishing;Internet;Collaborative work;Software engineering;Education;Collaboration","computer science education;educational courses;Internet;mobile computing;software engineering","software engineering courses;cooperative-learning;collaborative learning;SE courses;undergraduate computing curricula;industrial SE team;Web technology;mobile technology;learning theory","","2","14","","","","","IEEE","IEEE Conferences"
"Leveraging Informal Documentation to Summarize Classes and Methods in Context","L. Guerrouj; D. Bourque; P. C. Rigby","Dept. of Software Eng., Concordia Univ., Montreal, QC, Canada; Dept. of Software Eng., Concordia Univ., Montreal, QC, Canada; Dept. of Software Eng., Concordia Univ., Montreal, QC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","639","642","Critical information related to a software developer'scurrent task is trapped in technical developer discussions,bug reports, code reviews, and other software artefacts. Muchof this information pertains to the proper use of code elements(e.g., methods and classes) that capture vital problem domainknowledge. To understand the purpose of these code elements, software developers must either access documentation and online posts and understand the source code or peruse a substantial amount of text. In this paper, we use the context that surrounds code elements in StackOverflow posts to summarize the use and purpose of code elements. To provide focus to our investigation, we consider the generation of summaries for library identifiers discussed in StackOverflow. Our automatic summarization approach was evaluated on a sample of 100 randomly-selected library identifiers with respect to a benchmark of summaries provided by two annotators. The results show that the approach attains an R-precision of 54%, which is appropriate given the diverse ways in which code elements can be used.","","","10.1109/ICSE.2015.212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203032","","Context;Documentation;Libraries;Java;Androids;Humanoid robots;Software","software engineering;source code (software)","informal documentation;software artefacts;code elements;source code;StackOverflow;library identifiers;automatic summarization approach","","11","22","","","","","IEEE","IEEE Conferences"
"A Flexible and Non-intrusive Approach for Computing Complex Structural Coverage Metrics","M. W. Whalen; S. Person; N. Rungta; M. Staats; D. Grijincu","Univ. of Minnesota, Minneapolis, MN, USA; NASA Langley Res. Center, Hampton, VA, USA; NASA Ames Res. Center, Moffett Field, CA, USA; Google Inc., Zurich, Switzerland; Univ. of St. Andrews, St. Andrews, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","506","516","Software analysis tools and techniques often leverage structural code coverage information to reason about the dynamic behavior of software. Existing techniques instrument the code with the required structural obligations and then monitor the execution of the compiled code to report coverage. Instrumentation based approaches often incur considerable runtime overhead for complex structural coverage metrics such as Modified Condition/Decision (MC/DC). Code instrumentation, in general, has to be approached with great care to ensure it does not modify the behavior of the original code. Furthermore, instrumented code cannot be used in conjunction with other analyses that reason about the structure and semantics of the code under test. In this work, we introduce a non-intrusive preprocessing approach for computing structural coverage information. It uses a static partial evaluation of the decisions in the source code and a source-to-bytecode mapping to generate the information necessary to efficiently track structural coverage metrics during execution. Our technique is flexible; the results of the preprocessing can be used by a variety of coverage-driven software analysis tasks, including automated analyses that are not possible for instrumented code. Experimental results in the context of symbolic execution show the efficiency and flexibility of our non- intrusive approach for computing code coverage information.","","","10.1109/ICSE.2015.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194601","","Instruments;Measurement;Software;Java;Monitoring;Runtime;Electronic mail","partial evaluation (compilers);program control structures;program diagnostics;reasoning about programs;software metrics","flexible nonintrusive approach;software analysis tools;software analysis technique;structural code coverage information;software dynamic behavior reasoning;structural obligation;compiled code execution monitoring;coverage reporting;instrumentation based approach;runtime overhead;modified condition-decision;code instrumentation;code behavior;code semantics;nonintrusive preprocessing approach;structural coverage information;static partial evaluation;source code;source-to-bytecode mapping;structural coverage metrics tracking;coverage-driven software analysis;symbolic execution","","3","40","","","","","IEEE","IEEE Conferences"
"Truth in Advertising: The Hidden Cost of Mobile Ads for Software Developers","J. Gui; S. Mcilroy; M. Nagappan; W. G. J. Halfond","Univ. of Southern California, Los Angeles, CA, USA; Queen's Univ., Kingston, ON, Canada; Rochester Inst. of Technol., Rochester, NY, USA; Univ. of Southern California, Los Angeles, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","100","110","The ""free app"" distribution model has been extremely popular with end users and developers. Developers use mobile ads to generate revenue and cover the cost of developing these free apps. Although the apps are ostensibly free, they in fact do come with hidden costs. Our study of 21 real world Android apps shows that the use of ads leads to mobile apps that consume significantly more network data, have increased energy consumption, and require repeated changes to ad related code. We also found that complaints about these hidden costs are significant and can impact the ratings given to an app. Our results provide actionable information and guidance to software developers in weighing the tradeoffs of incorporating ads into their mobile apps.","","","10.1109/ICSE.2015.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194565","Mobile advertisements;mobile devices","Mobile communication;Energy consumption;Advertising;Mobile handsets;Performance evaluation;Instruments","advertising data processing;mobile computing;smart phones;software engineering","mobile advertising;software developer;free app distribution model;Android app","","42","46","","","","","IEEE","IEEE Conferences"
"Enron's Spreadsheets and Related Emails: A Dataset and Analysis","F. Hermans; E. Murphy-Hill","Delft Univ. of Technol., Delft, Netherlands; North Carolina State Univ., Raleigh, NC, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","7","16","Spreadsheets are used extensively in business processes around the world and as such, are a topic of research interest. Over the past few years, many spreadsheet studies have been performed on the EUSES spreadsheet corpus. While this corpus has served the spreadsheet community well, the spreadsheets it contains are mainly gathered with search engines and might therefore not represent spreadsheets used in companies. This paper presents an analysis of a new dataset, extracted from the Enron email archive, containing over 15,000 spreadsheets used within the Enron Corporation. In addition to the spreadsheets, we also present an analysis of the associated emails, where we look into spreadsheet-specific email behavior. Our analysis shows that 1) 24% of Enron spreadsheets with at least one formula contain an Excel error, 2) there is little diversity in the functions used in spreadsheets: 76% of spreadsheets in the presented corpus use the same 15 functions and, 3) the spreadsheets are substantially more smelly than the EUSES corpus, especially in terms of long calculation chains. Regarding the emails, we observe that spreadsheets 1) are a frequent topic of email conversation with 10% of emails either referring to or sending spreadsheets and 2) the emails are frequently discussing errors in and updates to spreadsheets.","","","10.1109/ICSE.2015.129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202944","","Electronic mail;Software engineering;Software;Measurement;Companies;Economics;Industries","data analysis;electronic mail;financial data processing;spreadsheet programs","email conversation;calculation chain;Excel error;spreadsheet-specific email behavior;email analysis;Enron Corporation;Enron email archive;EUSES spreadsheet corpus;business process;emails;Enron spreadsheet","","29","39","","","","","IEEE","IEEE Conferences"
"CARAMEL: Detecting and Fixing Performance Problems That Have Non-Intrusive Fixes","A. Nistor; P. Chang; C. Radoi; S. Lu","Chapman Univ., Orange, NJ, USA; Univ. of Wisconsin-Madison, Madison, WI, USA; Univ. of Illinois, Urbana, IL, USA; Univ. of Chicago, Chicago, IL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","902","912","Performance bugs are programming errors that slow down program execution. While existing techniques can detect various types of performance bugs, a crucial and practical aspect of performance bugs has not received the attention it deserves: how likely are developers to fix a performance bug? In practice, fixing a performance bug can have both benefits and drawbacks, and developers fix a performance bug only when the benefits outweigh the drawbacks. Unfortunately, for many performance bugs, the benefits and drawbacks are difficult to assess accurately. This paper presents CARAMEL, a novel static technique that detects and fixes performance bugs that have non-intrusive fixes likely to be adopted by developers. Each performance bug detected by CARAMEL is associated with a loop and a condition. When the condition becomes true during the loop execution, all the remaining computation performed by the loop is wasted. Developers typically fix such performance bugs because these bugs waste computation in loops and have non-intrusive fixes: when some condition becomes true dynamically, just break out of the loop. Given a program, CARAMEL detects such bugs statically and gives developers a potential source-level fix for each bug. We evaluate CARAMEL on real-world applications, including 11 popular Java applications (e.g., Groovy, Log4J, Lucene, Struts, Tomcat, etc) and 4 widely used C/C++ applications (Chromium, GCC, Mozilla, and My SQL). CARAMEL finds 61 new performance bugs in the Java applications and 89 new performance bugs in the C/C++ applications. Based on our bug reports, developers so far have fixed 51 and 65 performance bugs in the Java and C/C++ applications, respectively. Most of the remaining bugs are still under consideration by developers.","","","10.1109/ICSE.2015.100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194636","performance bugs;bug detection;automatic bug fixing;static analysis;real-world bugs","Computer bugs;Java;Algorithm design and analysis;Complexity theory;Cognition;Software engineering;Programming","C++ language;Java;program control structures;program debugging","CARAMEL;fixing performance problems;detecting performance problems;nonintrusive fixes;performance bugs;programming errors;static technique;loop execution;Java;C-C++ applications","","40","62","","","","","IEEE","IEEE Conferences"
"Dynamic Data Flow Testing of Object Oriented Systems","G. Denaro; A. Margara; M. Pezz√®; M. Vivanti","Univ. of Milano Bicocca, Milan, Italy; Univ. della Svizzera Italiana (USI), Lugano, Switzerland; Univ. della Svizzera Italiana (USI), Lugano, Switzerland; Univ. della Svizzera Italiana (USI), Lugano, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","947","958","Data flow testing has recently attracted new interest in the context of testing object oriented systems, since data flow information is well suited to capture relations among the object states, and can thus provide useful information for testing method interactions. Unfortunately, classic data flow testing, which is based on static analysis of the source code, fails to identify many important data flow relations due to the dynamic nature of object oriented systems. In this paper, we propose a new technique to generate test cases for object oriented software. The technique exploits useful inter-procedural data flow information extracted dynamically from execution traces for object oriented systems. The technique is designed to enhance an initial test suite with test cases that exercise complex state based method interactions. The experimental results indicate that dynamic data flow testing can indeed generate test cases that exercise relevant behaviors otherwise missed by both the original test suite and by test suites that satisfy classic data flow criteria.","","","10.1109/ICSE.2015.104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194640","","Testing;Object recognition;Runtime;Object oriented modeling;Performance analysis;Data models;Context","data flow computing;object-oriented programming;program diagnostics;source code (software)","dynamic data flow testing;object oriented systems;static analysis;source code;interprocedural data flow information;state based method interactions","","9","66","","","","","IEEE","IEEE Conferences"
"Masters-Level Software Engineering Education and the Enriched Student Context","J. G. Hall; L. Rapanotti","Dept. of Comput. & Commun., Open Univ., Milton Keynes, UK; Dept. of Comput. & Commun., Open Univ., Milton Keynes, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","311","314","Currently, adult higher education software engineering pedagogy isolates the student in a controlled environment during delivery, with application of their learning temporally distant from their professional practice. Delivering software engineering teaching that is immediately relevant to professional practice remains an open challenge. In this paper, we discuss a new pedagogical model which addresses this problem by embedding the validation of the student's learning within their rich professional context. We discuss our experience of applying the model to the design and delivery of a new post-graduate software development module, a core component in our new software engineering Masters qualification at the Open University, UK, a market leader in adult higher education at a distance.","","","10.1109/ICSE.2015.162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202979","software engineering education;Masters;distance education","Software engineering;Education;Context;Software;Context modeling;Unified modeling language;Knowledge engineering","computer science education;further education;software engineering","masters-level software engineering education;adult higher education software engineering pedagogy;pedagogical model;professional context;post-graduate software development module;Open University","","1","9","","","","","IEEE","IEEE Conferences"
"System Thinking: Educating T-Shaped Software Engineers","B. Boehm; S. K. Mobasser","Center for Syst. & Software Eng., Univ. of Southern California, Los Angeles, CA, USA; Center for Syst. & Software Eng., Univ. of Southern California, Los Angeles, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","333","342","With respect to system thinking, a T-shaped person is one who has technical depth in at least one aspect of the system's content, and a workable level of understanding of a fair number of the other system aspects. Many pure computer science graduates are strongly I-shaped, with a great deal of depth in software technology, but little understanding of the other disciplines involved in such areas as business, medicine, transportation, or Internets of Things. This leaves them poorly prepared to participate in the increasing numbers of projects involving multi-discipline system thinking, and in strong need of software skills. We have developed and evolved an MS-level software engineering curriculum that enables CS majors to become considerably more T-shaped than when they entered. It includes courses in software management and economics, human-computer interaction, embedded software systems, systems and software requirements, architecture, and V&V, and a two-semester, real-client team project course that gives students experience in applying these skills. We find via feedback on the students' internships and job experiences that they and their employers have high rates of success in job offers and job performance.","","","10.1109/ICSE.2015.166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202983","Software Engineering;Systems Engineering;System Thinking;T-shaped;Curriculum;Education and Training;The Incremental Commitment Spiral Model","Software;Software engineering;Hardware;Stakeholders;Aircraft;Aircraft propulsion","computer science education;embedded systems;further education;human computer interaction;Internet of Things;software architecture;software management;systems engineering","system thinking;system content;computer science graduate;I-shaped;software technology;Internet of Things;multidiscipline system;software skill;MS-level software engineering curriculum;software management;human-computer interaction;embedded software system;software requirement;software architecture;real-client team project course","","1","15","","","","","IEEE","IEEE Conferences"
"TaskNav: Task-Based Navigation of Software Documentation","C. Treude; M. Sicard; M. Klocke; M. Robillard","Dept. de Inf. e Mat. Aplic., Univ. Fed. do Rio Grande do Norte, Natal, Brazil; Sch. of Comput. Sci., McGill Univ., Montreal, QC, Canada; Sch. of Comput. Sci., McGill Univ., Montreal, QC, Canada; Sch. of Comput. Sci., McGill Univ., Montreal, QC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","649","652","To help developers navigate documentation, we introduce Task Nav, a tool that automatically discovers and indexes task descriptions in software documentation. With Task Nav, we conceptualize tasks as specific programming actions that have been described in the documentation. Task Nav presents these extracted task descriptions along with concepts, code elements, and section headers in an auto-complete search interface. Our preliminary evaluation indicates that search results identified through extracted task descriptions are more helpful to developers than those found through other means, and that they help bridge the gap between documentation structure and the information needs of software developers. Video: https://www.youtube.com/watch?v=opnGYmMGnqY.","","","10.1109/ICSE.2015.214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203034","Software Documentation;Development Tasks;Navigation;Auto-Complete;Natural Language Processing","Documentation;Instruction sets;Software engineering;Interference;Navigation;Electronic mail","document handling;information retrieval;software engineering","task-based navigation;software documentation;TaskNav;task descriptions;programming actions;code elements;section headers;auto-complete search interface;extracted task descriptions;documentation structure;software developers","","8","16","","","","","IEEE","IEEE Conferences"
"A Genetic Algorithm for Detecting Significant Floating-Point Inaccuracies","D. Zou; R. Wang; Y. Xiong; L. Zhang; Z. Su; H. Mei","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","529","539","It is well-known that using floating-point numbers may inevitably result in inaccurate results and sometimes even cause serious software failures. Safety-critical software often has strict requirements on the upper bound of inaccuracy, and a crucial task in testing is to check whether significant inaccuracies may be produced. The main existing approach to the floating-point inaccuracy problem is error analysis, which produces an upper bound of inaccuracies that may occur. However, a high upper bound does not guarantee the existence of inaccuracy defects, nor does it give developers any concrete test inputs for debugging. In this paper, we propose the first metaheuristic search-based approach to automatically generating test inputs that aim to trigger significant inaccuracies in floating-point programs. Our approach is based on the following two insights: (1) with FPDebug, a recently proposed dynamic analysis approach, we can build a reliable fitness function to guide the search; (2) two main factors - the scales of exponents and the bit formations of significands - may have significant impact on the accuracy of the output, but in largely different ways. We have implemented and evaluated our approach over 154 real-world floating-point functions. The results show that our approach can detect significant inaccuracies in the subjects.","","","10.1109/ICSE.2015.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194603","","Genetic algorithms;Sociology;Statistics;Algorithm design and analysis;Accuracy;Search problems;Software","floating point arithmetic;genetic algorithms;program debugging;search problems;system monitoring","genetic algorithm;floating-point inaccuracy detection;floating-point numbers;software failures;safety-critical software;floating-point inaccuracy problem;error analysis;debugging;metaheuristic search-based approach;floating-point programs;FPDebug;dynamic analysis approach;fitness function","","13","34","","","","","IEEE","IEEE Conferences"
"Automated Decomposition of Build Targets","M. Vakilian; R. Sauciuc; J. D. Morgenthaler; V. Mirrokni","Google Inc., Mountain View, CA, USA; Google Inc., Mountain View, CA, USA; Google Inc., Mountain View, CA, USA; Google Inc., Mountain View, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","123","133","A (build) target specifies the information that is needed to automatically build a software artifact. This paper focuses on underutilized targets - an important dependency problem that we identified at Google. An underutilized target is one with files not needed by some of its dependents. Underutilized targets result in less modular code, overly large artifacts, slow builds, and unnecessary build and test triggers. To mitigate these problems, programmers decompose underutilized targets into smaller targets. However, manually decomposing a target is tedious and error-prone. Although we prove that finding the best target decomposition is NP-hard, we introduce a greedy algorithm that proposes a decomposition through iterative unification of the strongly connected components of the target. Our tool found that 19,994 of 40,000 Java library targets at Google can be decomposed to at least two targets. The results show that our tool is (1) efficient because it analyzes a target in two minutes on average and (2) effective because for each of 1,010 targets, it would save at least 50% of the total execution time of the tests triggered by the target.","","","10.1109/ICSE.2015.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194567","software evolution;refactoring;build;modularity;regression testing;continuous integration;empirical","Google;Java;Libraries;Servers;Software;Target tracking;Greedy algorithms","graph theory;greedy algorithms;Java;program testing;software libraries","automated build target decomposition;software artifact;underutilized targets;dependency problem;Google;modular code;build trigger;test trigger;manual target decomposition;NP-hard problem;greedy algorithm;iterative unification;strongly-connected components;Java library targets;total execution time","","8","53","","","","","IEEE","IEEE Conferences"
"Gray Computing: An Analysis of Computing with Background JavaScript Tasks","Y. Pan; J. White; Y. Sun; J. Gray","Vanderbilt Univ., Nashville, TN, USA; Vanderbilt Univ., Nashville, TN, USA; California State Polytech. Univ., Pomona, CA, USA; Univ. of Alabama, Tuscaloosa, AL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","167","177","Websites routinely distribute small amounts of work to visitors' browsers in order to validate forms, render animations, and perform other computations. This paper examines the feasibility, cost effectiveness, and approaches for increasing the workloads offloaded to web visitors' browsers in order to turn them into a large-scale distributed data processing engine, which we term gray computing. Past research has looked primarily at either non-browser based volunteer computing or browser-based volunteer computing where the visitors keep their browsers open to a single web page for a long period of time. This paper provides a deep analysis of the architectural, cost effectiveness, user experience, performance, security, and other issues of gray computing distributed data processing engines with high heterogeneity, non-uniform page view times, and high computing pool volatility.","","","10.1109/ICSE.2015.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194571","","Servers;Data processing;Browsers;Engines;Cloud computing;Computer architecture;Distributed processing","authoring languages;Java;online front-ends;volunteer computing;Web sites","gray computing;background JavaScript tasks;Web sites;animation rendering;distributed data processing engine;nonbrowser based volunteer computing;browser-based volunteer computing;deep analysis;cost effectiveness;user experience;security","","3","26","","","","","IEEE","IEEE Conferences"
"Automatic and Continuous Software Architecture Validation","M. Goldstein; I. Segall","IBM Res. - Haifa, Haifa, Israel; IBM Res. - Haifa, Haifa, Israel","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","59","68","Software systems tend to suffer from architectural problems as they are being developed. While modern software development methodologies such as Agile and Dev-Ops suggest different ways of assuring code quality, very little attention is paid to maintaining high quality of the architecture of the evolving systems. By detecting and alerting about violations of the intended software architecture, one can often avoid code-level bad smells such as spaghetti code. Typically, if one wants to reason about the software architecture, the burden of first defining the intended architecture falls on the developer's shoulders. This includes definition of valid and invalid dependencies between software components. However, the developers are seldom familiar with the entire software system, which makes this task difficult, time consuming and error-prone. We propose and implement a solution for automatic detection of architectural violations in software artifacts. The solution, which utilizes a number of predefined and user-defined patterns, does not require prior knowledge of the system or its intended architecture. We propose to leverage this solution as part of the nightly build process used by development teams, thus achieving continuous automatic validation of the system's software architecture. As we show in multiple open-source and proprietary cases, a small set of predefined patterns can detect architectural violations as they are introduced over the course of development, and also capture deterioration in existing architectural problems. By evaluating the tool on relatively large open-source projects, we also validate its scalability and practical applicability to large software systems.","","","10.1109/ICSE.2015.135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202950","","Production facilities;Software architecture;Software systems;Computer architecture;Semantics","object-oriented programming;program verification;software architecture;software quality;source code (software)","automatic software architecture validation;continuous software architecture validation;software systems;architectural problems;agile software development methodologies;Dev-Ops;code quality;quality maintenance;systems architecture;code-level;spaghetti code;software components;architectural violations automatic detection;software artifacts;predefined patterns;user-defined patterns;development teams","","2","44","","","","","IEEE","IEEE Conferences"
"Does the Failing Test Execute a Single or Multiple Faults? An Approach to Classifying Failing Tests","Z. Yu; C. Bai; K. Cai","Dept. of Autom. Control, Beihang Univ., Beijing, China; Dept. of Autom. Control, Beihang Univ., Beijing, China; Dept. of Autom. Control, Beihang Univ., Beijing, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","924","935","Debugging is an indispensable yet frustrating activity in software development and maintenance. Thus, numerous techniques have been proposed to aid this task. Despite the demonstrated effectiveness and future potential of these techniques, many of them have the unrealistic single-fault failure assumption. To alleviate this problem, we propose a technique that can be used to distinguish failing tests that executed a single fault from those that executed multiple faults in this paper. The technique suitably combines information from (i) a set of fault localization ranked lists, each produced for a certain failing test and (ii) the distance between a failing test and the passing test that most resembles it to achieve this goal. An experiment on 5 real-life medium-sized programs with 18, 920 multiple-fault versions, which are shipped with number of faults ranging from 2 to 8, has been conducted to evaluate the technique. The results indicate that the performance of the technique in terms of evaluation measures precision, recall, and F-measure is promising. In addition, for the identified failing tests that executed a single fault, the technique can also properly cluster them.","","","10.1109/ICSE.2015.102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194638","distance calculation;fault localization;binary classification;debugging","Maintenance engineering;Fault diagnosis;Debugging;Indexes;Software;Classification algorithms;Testing","pattern classification;program debugging;program testing;software fault tolerance;software maintenance","failing test classification;debugging;software development;software maintenance;single-fault failure assumption;fault localization;evaluation measures precision;recall;F-measure","","1","46","","","","","IEEE","IEEE Conferences"
"Engineering Sustainability Through Language","R. Chitchyan; W. Cazzola; A. Rashid","Dept. of Comput. Sci., Univ. of Leicester, Leicester, UK; Dept. of Comput. Sci., Univ. degli Studi di Milano, Milan, Italy; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","501","504","As our understanding and care for sustainability concerns increases, so does the demand for incorporating these concerns into software. Yet, existing programming language constructs are not well-aligned with concepts of the sustainability domain. This undermines what we term technical sustainability of the software due to (i) increased complexity in programming of such concerns and (ii) continuous code changes to keep up with changes in (environmental, social, legal and other) sustainability-related requirements. In this paper we present a proof-of-concept approach on how technical sustainability support for new and existing concerns can be provided through flexible language-level programming. We propose to incorporate sustainability-related behaviour into programs through micro-languages enabling such behaviour to be updated and/or redefined as and when required.","","","10.1109/ICSE.2015.183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203001","sustainabiity;micro-languages;adaptability;change management","Semantics;Software;Syntactics;Batteries;Programming;Software engineering;Computer languages","programming languages;software engineering;sustainable development","engineering sustainability;programming language;continuous code;sustainability-related requirements;technical sustainability support;flexible language-level programming;sustainability-related behaviour;microlanguages","","5","17","","","","","IEEE","IEEE Conferences"
"Educating Software Engineering Managers - Revisited What Software Project Managers Need to Know Today","L. Peters; A. M. Moreno","Univ. Politec. de Madrid, Madrid, Spain; Univ. Politec. de Madrid, Madrid, Spain","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","353","359","In 2003, the original paper with this title was published as part of CSEET 2003. It focused on resolving communication issues between software project managers and developers and introduced a corporate strategy based means of evaluating software engineers. Now, more than a decade later, we could benefit from what we have learned in other fields about managing people involved in knowledge work and how to improve our success in software development. But are we? This paper is intended to present what Software Engineering students can be taught today that will help them to be successful as software project managers now and in the future. It is based on the premise that effective software project managers are not born but made through education.","","","10.1109/ICSE.2015.168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202985","Software Project Management;Software Project Management Curriculum;Project Management","Software;Software engineering;Project management;Schedules;Training","computer science education;project management;software development management","software engineering manager education;software project managers;software project developers;corporate strategy;software engineering students","","4","54","","","","","IEEE","IEEE Conferences"
"Borrowing from the Crowd: A Study of Recombination in Software Design Competitions","T. D. LaToza; M. Chen; L. Jiang; M. Zhao; A. v. d. Hoek","Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Grad. Sch. of Inf., Univ. of Amsterdam, Amsterdam, Netherlands; Grad. Sch. of Inf., Univ. of Amsterdam, Amsterdam, Netherlands; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","551","562","One form of crowdsourcing is the competition, which poses an open call for competing solutions. Commercial systems such as TopCoder have begun to explore the application of competitions to software development, but have important limitations diminishing the potential benefits drawn from the crowd. In particular, they employ a model of independent work that ignores the opportunity for designs to arise from the ideas of multiple designers. In this paper, we examine the potential for software design competitions to incorporate recombination, in which competing designers are given the designs of others and encouraged to use them to revise their own designs. To explore this, we conducted two software design competitions in which participants were asked to produce both an initial and a revised design, drawing on lessons learned from the crowd. We found that, in both competitions, all participants borrowed ideas and most improved the quality of their designs. Our findings demonstrate the potential benefits of recombination in software design and suggest several ways in which software design competitions can be improved.","","","10.1109/ICSE.2015.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194605","crowdsourcing;software design;collective intelligence;collaborative design","Crowdsourcing;Software design;Interviews;Software engineering;Distance measurement;User interfaces","outsourcing;software engineering","crowdsourcing;software design competition recombination;software development","","16","40","","","","","IEEE","IEEE Conferences"
"Data-Delineation in Software Binaries and its Application to Buffer-Overrun Discovery","D. Gopan; E. Driscoll; D. Nguyen; D. Naydich; A. Loginov; D. Melski","GrammaTech, Inc., Madison, WI, USA; GrammaTech, Inc., Madison, WI, USA; GrammaTech, Inc., Ithaca, NY, USA; GrammaTech, Inc., Ithaca, NY, USA; GrammaTech, Inc., Ithaca, NY, USA; GrammaTech, Inc., Ithaca, NY, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","145","155","Detecting memory-safety violations in binaries is complicated by the lack of knowledge of the intended data layout, i.e., the locations and sizes of objects. We present lightweight, static, heuristic analyses for recovering the intended layout of data in a stripped binary. Comparison against DWARF debugging information shows high precision and recall rates for inferring source-level object boundaries. On a collection of benchmarks, our analysis eliminates a third to a half of incorrect object boundaries identified by an IDA Pro-inspired heuristic, while retaining nearly all valid object boundaries. In addition to measuring their accuracy directly, we evaluate the effect of using the recovered data for improving the precision of static buffer-overrun detection in the defect-detection tool CodeSonar/x86. We demonstrate that CodeSonar's false-positive rate drops by about 80% across our internal evaluation suite for the tool, while our approximation of CodeSonar's recall only degrades about 25%.","","","10.1109/ICSE.2015.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194569","reverse engineering;data delineation;binary analysis;static analysis;buffer overrun detection","Registers;Layout;Benchmark testing;Approximation methods;Libraries;Accuracy;Optimization","program diagnostics;security of data;software tools","software security;CodeSonar/x86;defect-detection tool;static analysis;memory-safety violation detection;buffer-overrun discovery;software binary;DDA;data delineation analysis","","6","29","","","","","IEEE","IEEE Conferences"
"Symbolic Model Checking of Product-Line Requirements Using SAT-Based Methods","S. Ben-David; B. Sterin; J. M. Atlee; S. Beidu","David Cheriton Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada; Dept. of EECS, Univ. of California, Berkeley, Berkeley, CA, USA; David Cheriton Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada; David Cheriton Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","189","199","Product line (PL) engineering promotes the development of families of related products, where individual products are differentiated by which optional features they include. Modelling and analyzing requirements models of PLs allows for early detection and correction of requirements errors -- including unintended feature interactions, which are a serious problem in feature-rich systems. A key challenge in analyzing PL requirements is the efficient verification of the product family, given that the number of products is too large to be verified one at a time. Recently, it has been shown how the high-level design of an entire PL, that includes all possible products, can be compactly represented as a single model in the SMV language, and model checked using the NuSMV tool. The implementation in NuSMV uses BDDs, a method that has been outperformed by SAT-based algorithms. In this paper we develop PL model checking using two leading SAT-based symbolic model checking algorithms: IMC and IC3. We describe the algorithms, prove their correctness, and report on our implementation. Evaluating our methods on three PL models from the literature, we demonstrate an improvement of up to 3 orders of magnitude over the existing BDD-based method.","","","10.1109/ICSE.2015.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194573","Product Lines;Symbolic Model Checking;IC3;IMC","Model checking;Interpolation;Adaptation models;Computational modeling;Data structures;Boolean functions;Analytical models","binary decision diagrams;computability;program verification;software product lines;systems analysis","product-line requirements;SAT-based method;product line engineering;requirement error detection;requirement error correction;feature interaction;product family verification;high-level design;SMV language;NuSMV tool;BDD method;PL model checking;SAT-based symbolic model checking algorithm;IMC algorithm;IC3 algorithm;correctness proving","","5","","","","","","IEEE","IEEE Conferences"
"Empirically Detecting False Test Alarms Using Association Rules","K. Herzig; N. Nagappan","Microsoft Res., Cambridge, UK; Microsoft Res., Redmond, WA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","39","48","Applying code changes to software systems and testing these code changes can be a complex task that involves many different types of software testing strategies, e.g. system and integration tests. However, not all test failures reported during code integration are hinting towards code defects. Testing large systems such as the Microsoft Windows operating system requires complex test infrastructures, which may lead to test failures caused by faulty tests and test infrastructure issues. Such false test alarms are particular annoying as they raise engineer attention and require manual inspection without providing any benefit. The goal of this work is to use empirical data to minimize the number of false test alarms reported during system and integration testing. To achieve this goal, we use association rule learning to identify patterns among failing test steps that are typically for false test alarms and can be used to automatically classify them. A successful classification of false test alarms is particularly valuable for product teams as manual test failure inspection is an expensive and time-consuming process that not only costs engineering time and money but also slows down product development. We evaluating our approach on system and integration tests executed during Windows 8.1 and Microsoft Dynamics AX development. Performing more than 10,000 classifications for each product, our model shows a mean precision between 0.85 and 0.90 predicting between 34% and 48% of all false test alarms.","","","10.1109/ICSE.2015.133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202948","","Association rules;Testing;Manuals;Software engineering;Inspection;Software systems","data mining;learning (artificial intelligence);operating systems (computers);program testing;software reliability","false test alarm detection;software systems;software testing strategy;integration tests;test failures;code integration;code defects;Microsoft Windows operating system;complex test infrastructures;association rule learning;manual test failure inspection;Microsoft Dynamics AX development;Windows 8.1","","18","44","","","","","IEEE","IEEE Conferences"
"SPF: A Middleware for Social Interaction in Mobile Proximity Environments","L. Baresi; L. Goix; S. Guinea; V. Panzica La Manna; J. Aliprandi; D. Archetti","Dipt. di Elettron. Inf. e Bioingegneria, Politec. di Milano, Milan, Italy; Econocom-Osiatis, Lyon, France; Dipt. di Elettron. Inf. e Bioingegneria, Politec. di Milano, Milan, Italy; MIT Media Lab., Cambridge, MA, USA; Dipt. di Elettron. Inf. e Bioingegneria, Politec. di Milano, Milan, Italy; Dipt. di Elettron. Inf. e Bioingegneria, Politec. di Milano, Milan, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","79","88","Smart interconnected devices are changing our lives and are turning conventional spaces into smart ones. Physical proximity, a key enabler of social interactions in the old days is not exploited by smart solutions, where the social dimension is always managed through the Internet. This paper aims to blend the two forces and proposes the idea of social smart space, where modern technologies can help regain and renew social interactions, and where proximity is seen as enabler for dedicated and customized functionality provided by users to users. A Social Proximity Framework (SPF) provides the basis for the creation of this new flavor of smart spaces. Two different versions of the SPF, based on different communication infrastructures, help explain the characteristics of the different components, and show how the SPF can benefit from emerging connection-less communication protocols. A first assessment of the two implementations concludes the paper.","","","10.1109/ICSE.2015.137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202952","","Middleware;Context;Androids;Humanoid robots;IEEE 802.11 Standard;Protocols","Internet;middleware;mobile computing;protocols","social interaction middleware;mobile proximity environments;smart interconnected devices;conventional spaces;smart solutions;Internet;social smart space;social proximity framework;communication infrastructures;SPF;connection-less communication protocols","","2","19","","","","","IEEE","IEEE Conferences"
"AppCivist - A Service-Oriented Software Platform for Socially Sustainable Activism","A. Pathak; V. Issarny; J. Holston","Inria, Rennes, France; Inria, Rennes, France; Univ. of California, Berkeley, Berkeley, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","515","518","The increased adoption of mobile devices and social networking is drastically changing the way people monitor and share knowledge about their environment. Here, information and communication technologies (ICT) offer significant new ways to support social activism in cities by providing residents with new digital tools to articulate projects and mobilize activities. However, the development of ICT for activism is still in its infancy, with activists using basic tools stitched together in an ad hoc manner for their needs. Still, Internet-based technologies and related software architectures feature various enablers for civic action beyond base social networking. To that end, this paper discusses the vision and initial details of AppCivist, a platform that builds on cross-domain research among social scientists and computer scientists to revisit service-oriented architecture and relevant services to further social activism. We discuss the ICT challenges inherent in this project and present our recent work to address them.","","","10.1109/ICSE.2015.185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203003","service-oriented computing;social activism;social sustainability","Assembly;Organizations;Software engineering;Software;Context;Computer architecture;Ontologies","Internet;service-oriented architecture;social networking (online)","service-oriented software platform;socially sustainable activism;AppCivist platform;mobile devices;social networking;information and communication technology;ICT;digital tools;Internet-based technology;software architectures","","5","9","","","","","IEEE","IEEE Conferences"
"Concurrent Software Engineering and Robotics Education","J. Shin; A. Rusakov; B. Meyer","Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","370","379","This paper presents a new, multidisciplinary robotics programming course, reports initial results, and describes subsequent improvements. With equal emphasis on software engineering and robotics, the course teaches students how software engineering applies to robotics. Students learn independently and interactively and gain hands-on experience by implementing robotics algorithms on a real robot. To understand the effects of the course, we conducted an exit and an 8-month survey and measured software quality of the students' solutions. The analysis shows that the hands-on experience helped everyone learn and retain robotics well, but the students' knowledge gain in software engineering depended on their prior programming knowledge. Based on these findings, we propose improvements to the course. Lastly, we reflect our experience on andragogy, minimalism, and interactive learning.","","","10.1109/ICSE.2015.169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202987","","Software engineering;Robot sensing systems;Computer science;Education;Software quality","computer science education;concurrency control;control engineering computing;control engineering education;robot programming;software quality;teaching","concurrent software engineering;robotics education;multidisciplinary robotics programming course;teaching;students independent learning;interactive learning;hands-on experience;robotics algorithms;software quality;student knowledge gain;programming knowledge;andragogy;minimalism","","2","30","","","","","IEEE","IEEE Conferences"
"Does Outside-In Teaching Improve the Learning of Object-Oriented Programming?","E. Janke; P. Brune; S. Wagner","Univ. of Appl. Sci. Neu-Ulm, Neu-Ulm, Germany; Univ. of Appl. Sci. Neu-Ulm, Neu-Ulm, Germany; Univ. of Stuttgart, Stuttgart, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","408","417","Object-oriented programming (OOP) is widely used in the software industry and university introductory courses today. Following the structure of most textbooks, such courses frequently are organised starting with the concepts of imperative and structured programming and only later introducing OOP. An alternative approach is to begin directly with OOP following the Outside-In teaching method as proposed by Meyer. Empirical results for the effects of Outside-In teaching on students and lecturers are sparse, however. We describe the conceptual design and empirical evaluation of two OOP introductory courses from different universities based on Outside-In teaching. The evaluation results are compared to those from a third course serving as the control group, which was taught OOP the ""traditional"" way. We evaluate the initial motivation and knowledge of the participants and the learning outcomes. In addition, we analyse results of the end term exams and qualitatively analyse the results of interviews with the lecturers and tutors. Regarding the learning outcomes, the results show no significant differences between the Outside-In and the ""traditional"" teaching method. In general, students found it harder to solve and implement algorithmic problems than to understand object oriented (OO) concepts. Students taught OOP by the Outside-In method, however, were less afraid that they would not pass the exam at the end of term and understood the OO paradigm more quickly. Therefore, the Outside-In method is no silver bullet for teaching OOP regarding the learning outcomes but has positive effects on motivation and interest.","","","10.1109/ICSE.2015.173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202991","","Education;Java;Programming profession;Software;Computers","computer aided instruction;computer science education;object-oriented programming","object-oriented programming;OOP;software industry;university introductory courses;structured programming;imperative programming;outside-in teaching method;algorithmic problems","","1","21","","","","","IEEE","IEEE Conferences"
"Open Source-Style Collaborative Development Practices in Commercial Projects Using GitHub","E. Kalliamvakou; D. Damian; K. Blincoe; L. Singer; D. M. German","NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","574","585","Researchers are currently drawn to study projects hosted on GitHub due to its popularity, ease of obtaining data, and its distinctive built-in social features. GitHub has been found to create a transparent development environment, which together with a pull request-based workflow, provides a lightweight mechanism for committing, reviewing and managing code changes. These features impact how GitHub is used and the benefits it provides to teams' development and collaboration. While most of the evidence we have is from GitHub's use in open source software (OSS) projects, GitHub is also used in an increasing number of commercial projects. It is unknown how GitHub supports these projects given that GitHub's workflow model does not intuitively fit the commercial development way of working. In this paper, we report findings from an online survey and interviews with GitHub users on how GitHub is used for collaboration in commercial projects. We found that many commercial projects adopted practices that are more typical of OSS projects including reduced communication, more independent work, and self-organization. We discuss how GitHub's transparency and popular workflow can promote open collaboration, allowing organizations to increase code reuse and promote knowledge sharing across their teams.","","","10.1109/ICSE.2015.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194607","GitHub;open source;collaboration;coordination;workflow;pull requests;practices;commercial projects","Interviews;Organizations;Software;Encoding;Writing;Collaborative software","computer software;public domain software","open source-style collaborative development practices;commercial projects;built-in social features;transparent development environment;pull request-based workflow;code changes;open source software projects;OSS projects;GitHub users;self-organization;knowledge sharing;online code hosting service","","21","49","","","","","IEEE","IEEE Conferences"
"DASE: Document-Assisted Symbolic Execution for Improving Automated Software Testing","E. Wong; L. Zhang; S. Wang; T. Liu; L. Tan","Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada; Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada; Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada; Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada; Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","620","631","We propose and implement a new approach, Document-Assisted Symbolic Execution (DASE), to improve automated test generation and bug detection. DASE leverages natural language processing techniques and heuristics to analyze program documentation to extract input constraints automatically. DASE then uses the input constraints to guide symbolic execution to focus on inputs that are semantically more important.We evaluated DASE on 88 programs from 5 mature real-world software suites: COREUTILS, FINDUTILS, GREP, BINUTILS, and ELFTOOLCHAIN. DASE detected 12 previously unknown bugs that symbolic execution without input constraints failed to detect, 6 of which have already been confirmed by the developers. In addition, DASE increases line coverage, branch coverage, and call coverage by 14.2 -- 120.3%, 2.3 -- 167.7%, and 16.9 -- 135.2% respectively, which are 6.0 -- 21.1 percentage points (pp), 1.6 -- 18.9 pp, and 2.8 -- 20.1 pp increases. The accuracies of input constraint extraction are 97.8 -- 100%.","","","10.1109/ICSE.2015.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194611","natural language processing;symbolic execution;software testing","Arrays;Computer bugs;Testing;Ground penetrating radar;Geophysical measurement techniques;Search problems;Grammar","natural language processing;program debugging;program testing;system documentation","document-assisted symbolic execution;DASE;automated software testing;automated test generation;bug detection;natural language processing techniques;program documentation;software suites;COREUTILS;FINDUTILS;GREP;BINUTILS;ELFTOOLCHAIN;line coverage;branch coverage;call coverage","","8","61","","","","","IEEE","IEEE Conferences"
"On the Architecture-Driven Development of Software-Intensive Systems-of-Systems","E. Cavalcante","Dept. of Inf. & Appl. Math., Fed. Univ. of Rio Grande do Norte, Natal, Brazil","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","899","902","Nowadays, complex software-intensive systems have resulted from the integration of heterogeneous independent systems, thus leading to a new class of systems called Systems-of-Systems (SoS). As in any system, SoS architectures have been regarded as an important element for determining their success. However, the state of the art reveals shortcomings that contribute to compromise the quality of these systems, as their inherent characteristics (such as emergent behavior and evolutionary development) are often not properly addressed. In this context, this PhD research aims at investigating how SoS software architectures can be used to model and evolve these systems. As main contribution, an architecture-centric approach for developing software-intensive SoS with focus on the formal specification and dynamic reconfiguration of their architectures is proposed. Such an approach mainly intends to contribute to fill some of the relevant existing gaps regarding the development of software-intensive SoS driven by their software architectures.","","","10.1109/ICSE.2015.287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203109","systems-of-systems;SoS;software architecture;architecture-driven engineering","Computer architecture;Runtime;Context;Middleware","formal specification;software architecture;software quality","architecture-driven development;software-intensive systems-of-systems;heterogeneous independent systems;SoS software architectures;architecture-centric approach;formal specification","","","18","","","","","IEEE","IEEE Conferences"
"Tempura: Temporal Dimension for IDEs","Y. Y. Lee; D. Marinov; R. E. Johnson","Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","212","222","Modern integrated development environments (IDEs) make many software engineering tasks easier by providing automated programming support such as code completion and navigation. However, such support -- and therefore IDEs as awhole -- operate on one revision of the code at a time, and leave handling of code history to external tools or plugins, such asEGit for Eclipse. For example, when a method is removed froma class, developers can no longer find the method through code completion. This forces developers to manually switch across different revisions or resort to using external tools when they need to learn about previous code revisions.We propose a novel approach of adding a temporal dimensionto IDEs, enabling code completion and navigation to operate on multiple revisions of code at a time. We previously introduced the idea of temporal code completion and navigation,and presented a vision for how that idea may be realized.This paper realizes that vision by implementing and evaluatinga prototype tool called Tempura. We describe our algorithmfor processing and indexing historical code information from repositories for Tempura, and demonstrate Tempura's scalability with three large Eclipse projects. We also evaluate Tempura's usability through a controlled user study. The study participantslearned about the code history with more accuracy when usingTempura compared to EGit. Although the sample size was notlarge enough to provide strong statistical significance, the resultsshow a promising outlook for our approach.","","","10.1109/ICSE.2015.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194575","","Proposals;History;Navigation;Receivers;Context;Indexing;Java","software tools","Tempura;prototype tool;temporal dimension;integrated development environment;IDE;software engineering;code revision;temporal code completion","","","44","","","","","IEEE","IEEE Conferences"
"Online Defect Prediction for Imbalanced Data","M. Tan; L. Tan; S. Dara; C. Mayeux","Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Waterloo, Waterloo, ON, Canada; Cisco Syst., Bangalore, India; Cisco Syst., Bangalore, India","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","99","108","Many defect prediction techniques are proposed to improve software reliability. Change classification predicts defects at the change level, where a change is the modifications to one file in a commit. In this paper, we conduct the first study of applying change classification in practice. We identify two issues in the prediction process, both of which contribute to the low prediction performance. First, the data are imbalanced -- there are much fewer buggy changes than clean changes. Second, the commonly used cross-validation approach is inappropriate for evaluating the performance of change classification. To address these challenges, we apply and adapt online change classification, resampling, and updatable classification techniques to improve the classification performance. We perform the improved change classification techniques on one proprietary and six open source projects. Our results show that these techniques improve the precision of change classification by 12.2-89.5% or 6.4 -- 34.8 percentage points (pp.) on the seven projects. In addition, we integrate change classification in the development process of the proprietary project. We have learned the following lessons: 1) new solutions are needed to convince developers to use and believe prediction results, and prediction results need to be actionable, 2) new and improved classification algorithms are needed to explain the prediction results, and insensible and unactionable explanations need to be filtered or refined, and 3) new techniques are needed to improve the relatively low precision.","","","10.1109/ICSE.2015.139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202954","","Training;Software;Predictive models;Feature extraction;Computer bugs;Data models;Software engineering","pattern classification;public domain software;software performance evaluation;software reliability","online defect prediction techniques;imbalanced data;software reliability;change classification performance evaluation;low prediction performance;cross-validation approach;updatable classification techniques;resampling classification techniques;online change classification techniques;open source projects;proprietary project development process","","51","53","","","","","IEEE","IEEE Conferences"
"Managing Emergent Ethical Concerns for Software Engineering in Society","A. Rashid; K. Moore; C. May-Chahal; R. Chitchyan","Security Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Security Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Security Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Dept. of Comput. Sci., Univ. of Leicester, Leicester, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","523","526","This paper presents an initial framework for managing emergent ethical concerns during software engineering in society projects. We argue that such emergent considerations can neither be framed as absolute rules about how to act in relation to fixed and measurable conditions. Nor can they be addressed by simply framing them as non-functional requirements to be satisficed. Instead, a continuous process is needed that accepts the 'messiness' of social life and social research, seeks to understand complexity (rather than seek clarity), demands collective (not just individual) responsibility and focuses on dialogue over solutions. The framework has been derived based on retrospective analysis of ethical considerations in four software engineering in society projects in three different domains.","","","10.1109/ICSE.2015.187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203005","ethics;software in society;cyber crime;citizen science","Software engineering;Ethics;Software;Media;Societies;Stakeholders;Law enforcement","ethical aspects;software engineering;software management","emergent ethical concern management;software engineering;society projects","","2","13","","","","","IEEE","IEEE Conferences"
"Software Design Studio: A Practical Example","J. Lee; G. Kotonya; J. Whittle; C. Bull","Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","389","397","We have been generally successful for transferring software engineering knowledge to industry through various forms of education. However, many challenges in software engineering training remain. A key amongst these is how best to energise software engineering education with real-world software engineering practices. This paper describes our experience of delivering a radically different approach based on the notion of a Software Design Studio. The Software Design Studio is both a lab for students engaged in conceiving, designing and developing software products as well as an approach for teaching software engineering in the lab which emphasizes practical hands-on work and experimentation. The feedback on the Software Design Studio -- from both staff and students -- has been outstanding. Although the programme is designed as a small, elite programme there is interest to see if the teaching methods can be transferred across to the much larger undergraduate programme in Computer Science. In this paper, we provide a detailed description of how our studio works in practice so that others, thinking of tak-ing a studio or studio-inspired approach, can use in designing their own courses.","","","10.1109/ICSE.2015.171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202989","Software engineering education;software design studio;reflective teaching approach.","Software engineering;Software design;Testing;Conferences;Training","computer science education;educational courses;product development;software development management;teaching","Software Design Studio;software engineering knowledge;software engineering training;software engineering education;software product conceiving;software product design;software product development;software engineering teaching;teaching methods;computer science;studio approach;studio-inspired approach;courses","","6","15","","","","","IEEE","IEEE Conferences"
"In Search of the Emotional Design Effect in Programming","L. Haaranen; P. Ihantola; J. Sorva; A. Vihavainen","NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","428","434","A small number of recent studies have suggested that learning is enhanced when the illustrations in instructional materials are designed to appeal to the learners' emotions through the use of color and the personification of key elements. We sought to replicate this emotional design effect in the context of introductory object-oriented programming (OOP). In this preliminary study, a group of freshmen studied a text on objects which was illustrated using anthropomorphic graphics while a control group had access to abstract graphics. We found no significant difference in the groups' scores on a comprehension post-test, but the experimental group spent substantially less time on the task than the control group. Among those participants who had no prior programming experience, the materials inspired by emotional design were perceived as less intelligible and appealing and led to lower self-reported concentration levels. Although this result does not match the pattern of results from earlier studies, it shows that the choice of illustrations in learning materials matters and calls for more research that addresses the limitations of this preliminary study.","","","10.1109/ICSE.2015.175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202993","emotional design;programming;learning;multimedia","Visualization;Programming profession;Object oriented programming;Education;Multimedia communication","computer science education;object-oriented programming;social aspects of automation","emotional design effect;instructional materials;object-oriented programming;OOP;anthropomorphic graphics;abstract graphics;comprehension post-test;control group;learning materials;self-reported concentration levels","","5","21","","","","","IEEE","IEEE Conferences"
"Interactive Synthesis Using Free-Form Queries","T. Gvero; V. Kuncak","Ecole Polytech. Fed. de Lausanne (EPFL), Lausanne, Switzerland; Ecole Polytech. Fed. de Lausanne (EPFL), Lausanne, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","689","692","We present a new code assistance tool for integrated development environments. Our system accepts free-form queries allowing a mixture of English and Java as an input, and produces Java code fragments that take the query into account and respect syntax, types, and scoping rules of Java as well as statistical usage patterns. The returned results need not have the structure of any previously seen code fragment. As part of our system we have constructed a probabilistic context free grammar for Java constructs and library invocations, as well as an algorithm that uses a customized natural language processing tool chain to extract information from free-form text queries. The evaluation results show that our technique can tolerate much of the flexibility present in natural language, and can also be used to repair incorrect Java expressions that contain useful information about the developer's intent. Our demo video is available at http://youtu.be/tx4-XgAZkKU.","","","10.1109/ICSE.2015.224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203044","Program Synthesis;Program Repair;Natural Language Processing;Code Completion","Java;Context;Natural language processing;Programming;Grammar;Chapters","Java;natural language processing;query processing;software libraries;statistical analysis","interactive synthesis;code assistance tool;integrated development environments;free-form queries;English;Java code fragments;statistical usage patterns;library invocations;customized natural language processing tool chain;free-form text queries","","8","28","","","","","IEEE","IEEE Conferences"
"Tricorder: Building a Program Analysis Ecosystem","C. Sadowski; J. v. Gogh; C. Jaspan; E. S√∂derberg; C. Winter","NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","598","608","Static analysis tools help developers find bugs, improve code readability, and ensure consistent style across a project. However, these tools can be difficult to smoothly integrate with each other and into the developer workflow, particularly when scaling to large codebases. We present Tricorder, a program analysis platform aimed at building a data-driven ecosystem around program analysis. We present a set of guiding principles for our program analysis tools and a scalable architecture for an analysis platform implementing these principles. We include an empirical, in-situ evaluation of the tool as it is used by developers across Google that shows the usefulness and impact of the platform.","","","10.1109/ICSE.2015.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194609","program analysis;static analysis","Google;Computer bugs;Buildings;Ecosystems;Java;Libraries;Usability","ecology;program diagnostics;software architecture","program analysis ecosystem;tricorder;static analysis tools;code readability;developer workflow;codebases;scalable architecture;Google","","50","43","","","","","IEEE","IEEE Conferences"
"Regular Property Guided Dynamic Symbolic Execution","Y. Zhang; Z. Chen; J. Wang; W. Dong; Z. Liu","Key Lab. of High Performance Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Key Lab. of High Performance Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Centre for Software Eng., Birmingham City Univ., Birmingham, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","643","653","A challenging problem in software engineering is to check if a program has an execution path satisfying a regular property. We propose a novel method of dynamic symbolic execution (DSE) to automatically find a path of a program satisfying a regular property. What makes our method distinct is when exploring the path space, DSE is guided by the synergy of static analysis and dynamic analysis to find a target path as soon as possible. We have implemented our guided DSE method for Java programs based on JPF and WALA, and applied it to 13 real-world open source Java programs, a total of 225K lines of code, for extensive experiments. The results show the effectiveness, efficiency, feasibility and scalability of the method. Compared with the pure DSE on the time to find the first target path, the average speedup of the guided DSE is more than 258X when analyzing the programs that have more than 100 paths.","","","10.1109/ICSE.2015.80","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194613","Dynamic Symbolic Execution;Regular Property;Finite State Machine;Static Analysis;Dynamic Analysis","Monitoring;History;Java;Context;Software engineering;Space exploration;Algorithm design and analysis","Java;program diagnostics;public domain software;software engineering;symbol manipulation","dynamic symbolic execution;regular property;software engineering;execution path;path space;synergy;static analysis;guided DSE method;JPF;WALA;real-world open source Java programs","","13","53","","","","","IEEE","IEEE Conferences"
"Cascade: A Universal Programmer-Assisted Type Qualifier Inference Tool","M. Vakilian; A. Phaosawasdi; M. D. Ernst; R. E. Johnson","Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Washington, Seattle, WA, USA; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","234","245","Type qualifier inference tools usually operate in batch mode and assume that the program must not be changed except to add the type qualifiers. In practice, programs must be changed to make them type-correct, and programmers must understand them. Cascade is an interactive type qualifier inference tool that is easy to implement and universal (i.e., it can work for any type qualifier system for which a checker is implemented). It shows that qualifier inference can achieve better results by involving programmers rather than relying solely on automation.","","","10.1109/ICSE.2015.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194577","software evolution;refactoring;human-computer interaction;design;type system;type qualifier inference","Java;Tutorials;Prototypes;Software;Safety;Automation;Ports (Computers)","inference mechanisms;software engineering;software tools","Cascade;universal programmer-assisted type qualifier inference tool;interactive type qualifier inference tool;programmers;type-correct programs","","2","46","","","","","IEEE","IEEE Conferences"
"IccTA: Detecting Inter-Component Privacy Leaks in Android Apps","L. Li; A. Bartel; T. F. Bissyand√©; J. Klein; Y. Le Traon; S. Arzt; S. Rasthofer; E. Bodden; D. Octeau; P. McDaniel","NA; NA; NA; NA; NA; NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","280","291","Shake Them All is a popular ""Wallpaper"" application exceeding millions of downloads on Google Play. At installation, this application is given permission to (1) access the Internet (for updating wallpapers) and (2) use the device microphone (to change background following noise changes). With these permissions, the application could silently record user conversations and upload them remotely. To give more confidence about how Shake Them All actually processes what it records, it is necessary to build a precise analysis tool that tracks the flow of any sensitive data from its source point to any sink, especially if those are in different components. Since Android applications may leak private data carelessly or maliciously, we propose IccTA, a static taint analyzer to detect privacy leaks among components in Android applications. IccTA goes beyond state-of-the-art approaches by supporting inter- component detection. By propagating context information among components, IccTA improves the precision of the analysis. IccTA outperforms existing tools on two benchmarks for ICC-leak detectors: DroidBench and ICC-Bench. Moreover, our approach detects 534 ICC leaks in 108 apps from MalGenome and 2,395 ICC leaks in 337 apps in a set of 15,000 Google Play apps.","","","10.1109/ICSE.2015.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194581","","Androids;Humanoid robots;Malware;Privacy;Google;Data privacy;Java","Android (operating system);data privacy;Internet;mobile computing","IccTA;intercomponent privacy leak detection;Android application;Google Play;Internet","","187","51","","","","","IEEE","IEEE Conferences"
"A Large-Scale Technology Evaluation Study: Effects of Model-based Analysis and Testing","M. Kl√§s; T. Bauer; A. Dereani; T. S√∂derqvist; P. Helle","Fraunhofer Inst. for Exp. Software Eng., Kaiserslautern, Germany; Fraunhofer Inst. for Exp. Software Eng., Kaiserslautern, Germany; Daimler AG, Sindelfingen, Germany; Adv. Technol. & Res., Volvo Group Trucks Technol., Gothenburg, Sweden; Airbus Group Innovations, Hamburg, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","119","128","Besides model-based development, model-based quality assurance and the tighter integration of static and dynamic quality assurance activities are becoming increasingly relevant in the development of software-intensive systems. Thus, this paper reports on an empirical study aimed at investigating the promises regarding quality improvements and cost savings. The evaluation comprises data from 13 industry case studies conducted during a three-year large-scale research project in the transportation domain (automotive, avionics, rail system). During the evaluation, we identified major goals and strategies associated with (integrated) model-based analysis and testing and evaluated the improvements achieved. The aggregated results indicate an average cost reduction of between 29% and 34% for verification and validation and of between 22% and 32% for defect removal. Compared with these cost savings, improvements regarding test coverage (~8%), number of remaining defects (~13%), and time to market (~8%) appear less noticeable.","","","10.1109/ICSE.2015.141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202956","Empirical study;embedded software quality assurance;multiple case study;GQM+Strategies;quantitative technology evaluation;model-based testing;internal baselines","Analytical models;Testing;Data models;Context;Software engineering;Software;Atmospheric measurements","program testing;program verification;software cost estimation;software quality","large-scale technology evaluation study;model-based development;model-based quality assurance;static quality assurance activities;dynamic quality assurance activities;software-intensive systems development;quality improvements;cost savings;transportation domain;automotive system;avionics;rail system;model-based analysis;testing;cost reduction;verification;validation;defect removal;test coverage;time to market;software quality assurance","","1","36","","","","","IEEE","IEEE Conferences"
"An Industrial Case Study on the Automated Detection of Performance Regressions in Heterogeneous Environments","K. C. Foo; Z. M. Jiang; B. Adams; A. E. Hassan; Y. Zou; P. Flora","BlackBerry, Canada; York Univ., Toronto, ON, Canada; Polytech. Montreal, Montreal, QC, Canada; Queen's Univ., Kingston, ON, Canada; Queen's Univ., Kingston, ON, Canada; BlackBerry, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","159","168","A key goal of performance testing is the detection of performance degradations (i.e., regressions) compared to previous releases. Prior research has proposed the automation of such analysis through the mining of historical performance data (e.g., CPU and memory usage) from prior test runs. Nevertheless, such research has had limited adoption in practice. Working with a large industrial performance testing lab, we noted that a major hurdle in the adoption of prior work (including our own work) is the incorrect assumption that prior tests are always executed in the same environment (i.e., labs). All too often, tests are performed in heterogenous environments with each test being run in a possibly different lab with different hardware and software configurations. To make automated performance regression analysis techniques work in industry, we propose to model the global expected behaviour of a system as an ensemble (combination) of individual models, one for each successful previous test run (and hence configuration). The ensemble of models of prior test runs are used to flag performance deviations (e.g., CPU counters showing higher usage) in new tests. The deviations are then aggregated using simple voting or more advanced weighting to determine whether the counters really deviate from the expected behaviour or whether it was simply due to an environment-specific variation. Case studies on two open-source systems and a very large scale industrial application show that our weighting approach outperforms a state-of-the-art environment-agnostic approach. Feedback from practitioners who used our approach over a 4 year period (across several major versions) has been very positive.","","","10.1109/ICSE.2015.144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202960","load testing;performance testing;performance analysis;performance regression testing;performance regression","Radiation detectors;Association rules;Throughput;Testing;Databases;Bagging","program testing;public domain software;regression analysis;software performance evaluation","automated performance regression detection;heterogeneous environments;performance testing;performance degradation detection;automated performance regression analysis techniques;open-source systems;weighting approach","","14","37","","","","","IEEE","IEEE Conferences"
"Cognitively Sustainable ICT with Ubiquitous Mobile Services - Challenges and Opportunities","M. J√§gemar; G. Dodig-Crnkovic","Sch. of Innovation, Design & Eng., Malardalen Univ., Vasteras, Sweden; Dept. of Appl. Inf. Technol., Chalmers Univ. of Technol., Gothenburg, Sweden","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","531","540","Information and Communication Technology (ICT) has led to an unprecedented development in almost all areas of human life. It forms the basis for what is called ""the cognitive revolution"" -- a fundamental change in the way we communicate, feel, think and learn based on an extension of individual information processing capacities by communication with other people through technology. This so-called ""extended cognition"" shapes human relations in a radically new way. It is accompanied by a decrease of shared attention and affective presence within closely related groups. This weakens the deepest and most important bonds, that used to shape human identity. Sustainability, both environmental and social (economic, technological, political and cultural) is one of the most important issues of our time. In connection with ""extended cognition"" we have identified a new, basic type of social sustainability that everyone takes for granted, and which we claim is in danger due to our changed ways of communication. We base our conclusion on a detailed analysis of the current state of the practice and observed trends. The contribution of our article consists of identifying cognitive sustainability and explaining its central role for all other aspects of sustainability, showing how it relates to the cognitive revolution, its opportunities and challenges. Complex social structures with different degrees of proximity have always functioned as mechanisms behind belongingness and identity. To create a long-term cognitive sustainability, we need to rethink and design new communication technologies that support differentiated and complex social relationships.","","","10.1109/ICSE.2015.189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203007","Cognitive sustainability;Social sustainability;Sustainable ICT;Cognitive revolution;Privacy;Shared attention;Social cognition;Software engineering for social good.","Cognition;Games;Mobile communication;Mobile handsets;Software engineering;Computers","cognition;cultural aspects;environmental economics;mobile computing;politics;social sciences computing;socio-economic effects;sustainable development","cognitively sustainable ICT;ubiquitous mobile services;information and communication technology;cognitive revolution;information processing capacities;extended cognition;shared attention;affective presence;closely-related groups;human identity;environmental sustainability;social sustainability;economic sustainability;technological sustainability;political sustainability;cultural sustainability;cognitive sustainability;complex social structures;proximity degrees;differentiated relationships","","3","54","","","","","IEEE","IEEE Conferences"
"Teaching Software Architecture to Undergraduate Students: An Experience Report","C. R. Rupakheti; S. V. Chenoweth","Dept. of Comput. Sci. & Software Eng., Rose-Hulman Inst. of Technol., Terre Haute, IN, USA; Dept. of Comput. Sci. & Software Eng., Rose-Hulman Inst. of Technol., Terre Haute, IN, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","445","454","Software architecture lies at the heart of system thinking skills for software. Teaching software architecture requires contending with the problem of how to make the learning realistic -- most systems which students can learn quickly are too simple for them to express architectural issues. We address here the ten years' history of teaching an undergraduate software architecture course, as a part of a bachelor's program in software engineering. Included are descriptions of what we perceive the realistic goals to be, of teaching software architecture at this level. We go on to analyze the successes and issues of various approaches we have taken over the years. We finish with recommendations for others who teach this same subject, either as a standalone undergraduate course or integrated into a software engineering course.","","","10.1109/ICSE.2015.177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202995","Software Architecture;Project-Based Learning;Course Evolution","Software architecture;Computer architecture;Software;History;Training","computer science education;educational courses;further education;software architecture;teaching","undergraduate students;undergraduate software architecture course teaching;software engineering course","","8","18","","","","","IEEE","IEEE Conferences"
"Are Students Representatives of Professionals in Software Engineering Experiments?","I. Salman; A. T. Misirli; N. Juristo","Dept. of Inf. Process. Sci., Univ. of Oulu, Oulu, Finland; Fac. of Comput. & Inf., Istanbul Tech. Univ., Istanbul, Turkey; Dept. of Inf. Process. Sci., Univ. of Oulu, Oulu, Finland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","666","676","Background: Most of the experiments in software engineering (SE) employ students as subjects. This raises concerns about the realism of the results acquired through students and adaptability of the results to software industry. Aim: We compare students and professionals to understand how well students represent professionals as experimental subjects in SE research. Method: The comparison was made in the context of two test-driven development experiments conducted with students in an academic setting and with professionals in a software organization. We measured the code quality of several tasks implemented by both subject groups and checked whether students and professionals perform similarly in terms of code quality metrics. Results: Except for minor differences, neither of the subject groups is better than the other. Professionals produce larger, yet less complex, methods when they use their traditional development approach, whereas both subject groups perform similarly when they apply a new approach for the first time. Conclusion: Given a carefully scoped experiment on a development approach that is new to both students and professionals, similar performances are observed. Further investigation is necessary to analyze the effects of subject demographics and level of experience on the results of SE experiments.","","","10.1109/ICSE.2015.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194615","experimentation;empirical study;test-driven development;code quality","Measurement;Industries;Software;Context;Training;Inspection;Complexity theory","computer science education;DP industry;software engineering","student;software engineering;SE;software industry;test-driven development experiment;software organization;code quality metrics","","59","30","","","","","IEEE","IEEE Conferences"
"A Synergistic Analysis Method for Explaining Failed Regression Tests","Q. Yi; Z. Yang; J. Liu; C. Zhao; C. Wang","Inst. of Software, Beijing, China; Dept. of Comput. Sci., Western Michigan Univ., Kalamazoo, MI, USA; Inst. of Software, Beijing, China; Inst. of Software, Beijing, China; Dept. of Electr. & Comput. Eng., Virginia Tech, Blacksburg, VA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","257","267","We propose a new automated debugging method for regression testing based on a synergistic application of both dynamic and semantic analysis. Our method takes a failure- inducing test input, a buggy program, and an earlier correct version of the same program, and computes a minimal set of code changes responsible for the failure, as well as explaining how the code changes lead to the failure. Although this problem has been the subject of intensive research in recent years, existing methods are rarely adopted by developers in practice since they do not produce sufficiently accurate fault explanations for real applications. Our new method is significantly faster and more accurate than existing methods for explaining failed regression tests in real applications, due to its synergistic analysis framework that iteratively applies both dynamic analysis and a constraint solver based semantic analysis to leverage their complementary strengths. We have implemented our new method in a software tool based on the LLVMcompiler and the KLEE symbolic virtual machine. Our experiments on large real Linux applications show that the new method is both efficient and effective in practice.","","","10.1109/ICSE.2015.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194579","fault localization;error diagnosis;regression testing;delta debugging;weakest precondition;SMT solver","Semantics;Algorithm design and analysis;Generators;Debugging;Heuristic algorithms;Reactive power;Testing","Linux;program debugging;program testing;software tools","synergistic analysis method;regression testing failure;automated debugging method;dynamic analysis;semantic analysis;software tool;LLVM compiler;KLEE symbolic virtual machine;Linux application","","5","38","","","","","IEEE","IEEE Conferences"
"AppContext: Differentiating Malicious and Benign Mobile App Behaviors Using Context","W. Yang; X. Xiao; B. Andow; S. Li; T. Xie; W. Enck","Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; NEC Labs. America, Princeton, NJ, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","303","313","Mobile malware attempts to evade detection during app analysis by mimicking security-sensitive behaviors of benign apps that provide similar functionality (e.g., sending SMS messages), and suppressing their payload to reduce the chance of being observed (e.g., executing only its payload at night). Since current approaches focus their analyses on the types of security-sensitive resources being accessed (e.g., network), these evasive techniques in malware make differentiating between malicious and benign app behaviors a difficult task during app analysis. We propose that the malicious and benign behaviors within apps can be differentiated based on the contexts that trigger security-sensitive behaviors, i.e., the events and conditions that cause the security-sensitive behaviors to occur. In this work, we introduce AppContext, an approach of static program analysis that extracts the contexts of security-sensitive behaviors to assist app analysis in differentiating between malicious and benign behaviors. We implement a prototype of AppContext and evaluate AppContext on 202 malicious apps from various malware datasets, and 633 benign apps from the Google Play Store. AppContext correctly identifies 192 malicious apps with 87.7% precision and 95% recall. Our evaluation results suggest that the maliciousness of a security-sensitive behavior is more closely related to the intention of the behavior (reflected via contexts) than the type of the security-sensitive resources that the behavior accesses.","","","10.1109/ICSE.2015.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194583","Mobile Security; Context; Program Analysis","Context;Malware;Androids;Humanoid robots;Mobile communication;Electrocardiography;Payloads","invasive software;mobile computing;program diagnostics","AppContext;malicious mobile app behavior;benign mobile app behavior;mobile malware;app analysis;security-sensitive behaviors;static program analysis;Google Play Store","","65","51","","","","","IEEE","IEEE Conferences"
"Improving Predictability, Efficiency and Trust of Model-Based Proof Activity","J. Etienne; M. Maarek; F. Anseaume; V. Delebarre","SafeRiver, Montrouge, France; SafeRiver, Montrouge, France; SafeRiver, Montrouge, France; SafeRiver, Montrouge, France","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","139","148","We report on our industrial experience in using formal methods for the analysis of safety-critical systems developed in a model-based design framework. We first highlight the formal proof workflow devised for the verification and validation of embedded systems developed in Matlab/Simulink. In particular, we show that there is a need to: determine the compatibility of the model to be analysed with the proof engine, establish whether the model facilitates proof convergence or when optimisation is required, and avoid over-specification when specifying the hypotheses constraining the inputs of the model during analysis. We also stress on the importance of having a certain harness over the proof activity and present a set of tools we developed to achieve this purpose. Finally, we give a list of best practices, methods and any necessary tools aiming at guaranteeing the validity of the verification results obtained.","","","10.1109/ICSE.2015.142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202958","Verification and Validation;Model-Based Design;Functional Hazard Analysis (FHA);Model Checking;Matlab/Simulink","Analytical models;Safety;Mathematical model;Software packages;Computational modeling;Convergence;Complexity theory","formal specification;program verification;safety-critical software","predictability improvement;efficiency improvement;trust improvement;model-based proof activity;formal methods;safety-critical system analysis;model-based design framework;formal proof workflow;embedded system verification;embedded system validation;Matlab/Simulink;model compatibility analysis;proof engine;proof convergence","","","15","","","","","IEEE","IEEE Conferences"
"A Case Study in Locating the Architectural Roots of Technical Debt","R. Kazman; Y. Cai; R. Mo; Q. Feng; L. Xiao; S. Haziyev; V. Fedak; A. Shapochka","SEU/CMU, Univ. of Hawaii, Honolulu, HI, USA; Drexel Univ., Philadelphia, PA, USA; Drexel Univ., Philadelphia, PA, USA; Drexel Univ., Philadelphia, PA, USA; Drexel Univ., Philadelphia, PA, USA; SoftServe Inc., Lviv, Ukraine; SoftServe Inc., Lviv, Ukraine; SoftServe Inc., Lviv, Ukraine","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","179","188","Our recent research has shown that, in large-scale software systems, defective files seldom exist alone. They are usually architecturally connected, and their architectural structures exhibit significant design flaws which propagate bugginess among files. We call these flawed structures the architecture roots, a type of technical debt that incurs high maintenance penalties. Removing the architecture roots of bugginess requires refactoring, but the benefits of refactoring have historically been difficult for architects to quantify or justify. In this paper, we present a case study of identifying and quantifying such architecture debts in a large-scale industrial software project. Our approach is to model and analyze software architecture as a set of design rule spaces (DRSpaces). Using data extracted from the project's development artifacts, we were able to identify the files implicated in architecture flaws and suggest refactorings based on removing these flaws. Then we built economic models of the before and (predicted) after states, which gave the organization confidence that doing the refactorings made business sense, in terms of a handsome return on investment.","","","10.1109/ICSE.2015.146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202962","","Computer architecture;Software engineering;Business;History;Sonar detection;Microprocessors","software architecture;software maintenance","technical debt;large-scale software systems;architecture roots;software refactoring;large-scale industrial software project;software architecture flaws;design rule spaces;DRSpaces","","27","33","","","","","IEEE","IEEE Conferences"
"Virtual Reality in Software Engineering: Affordances, Applications, and Challenges","A. Elliott; B. Peiris; C. Parnin","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; NA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","547","550","Software engineers primarily interact with source code using a keyboard and mouse, and typically view software on a small number of 2D monitors. This interaction paradigm does not take advantage of many affordances of natural human movement and perception. Virtual reality (VR) can use these affordances more fully than existing developer environments to enable new creative opportunities and potentially result in higher productivity, lower learning curves, and increased user satisfaction. This paper describes the affordances offered by VR, demonstrates the benefits of VR and software engineering in prototypes for live coding and code review, and discusses future work, open questions, and the challenges of VR.","","","10.1109/ICSE.2015.191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203009","virtual reality;software engineering;live coding;code review","Three-dimensional displays;Software;Navigation;Software engineering;Cognition;Keyboards;Encoding","software engineering;software reviews;source code (software);virtual reality","virtual reality;VR;software engineering;source code;live coding;code review","","17","21","","","","","IEEE","IEEE Conferences"
"A Vision of Crowd Development","T. D. LaToza; A. v. d. Hoek","Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","563","566","Crowdsourcing has had extraordinary success in solving a diverse set of problems, ranging from digitization of libraries and translation of the Internet, to scientific challenges such as classifying elements in the galaxy or determining the 3D shape of an enzyme. By leveraging the power of the masses, it is feasible to complete tasks in mere days and sometimes even hours, and to take on tasks that were previously impossible because of their sheer scale. Underlying the success of crowdsourcing is a common theme - the microtask. By breaking down the overall task at hand into microtasks providing short, self-contained pieces of work, work can be performed independently, quickly, and in parallel - enabling numerous and often untrained participants to chip in. This paper puts forth a research agenda, examining the question of whether the same kinds of successes that microtask crowdsourcing is having in revolutionizing other domains can be brought to software development. That is, we ask whether it is possible to push well beyond the open source paradigm, which still relies on traditional, coarse-grained tasks, to a model in which programming proceeds through microtasks performed by vast numbers of crowd developers.","","","10.1109/ICSE.2015.194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203013","crowdsourcing;collaborative software development;open source software development","Crowdsourcing;Games;Context;Libraries;Programming;Open source software","Internet;public domain software;software engineering","crowd development vision;digital libraries;3D shape;Internet;microtask crowdsourcing;software development;open source paradigm;coarse-grained tasks","","12","20","","","","","IEEE","IEEE Conferences"
"Sustainability Design and Software: The Karlskrona Manifesto","C. Becker; R. Chitchyan; L. Duboc; S. Easterbrook; B. Penzenstadler; N. Seyff; C. C. Venters","Fac. of Inf., Univ. of Toronto, Toronto, ON, Canada; Dept. of Comput. Sci., Univ. of Leicester, Leicester, UK; Dept. of Inf. & Comput. Sci., State Univ. of Rio de Janeiro, Rio de Janeiro, Brazil; Dept. of Comput. Sci., Univ. of Toronto, Toronto, ON, Canada; Inst. for Software Res., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Sch. of Comput. & Eng., Univ. of Huddersfield, Huddersfield, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","467","476","Sustainability has emerged as a broad concern for society. Many engineering disciplines have been grappling with challenges in how we sustain technical, social and ecological systems. In the software engineering community, for example, maintainability has been a concern for a long time. But too often, these issues are treated in isolation from one another. Misperceptions among practitioners and research communities persist, rooted in a lack of coherent understanding of sustainability, and how it relates to software systems research and practice. This article presents a cross-disciplinary initiative to create a common ground and a point of reference for the global community of research and practice in software and sustainability, to be used for effectively communicating key issues, goals, values and principles of sustainability design for software-intensive systems.The centrepiece of this effort is the Karlskrona Manifesto for Sustainability Design, a vehicle for a much needed conversation about sustainability within and beyond the software community, and an articulation of the fundamental principles underpinning design choices that affect sustainability. We describe the motivation for developing this manifesto, including some considerations of the genre of the manifesto as well as the dynamics of its creation. We illustrate the collaborative reflective writing process and present the current edition of the manifesto itself. We assess immediate implications and applications of the articulated principles, compare these to current practice, and suggest future steps.","","","10.1109/ICSE.2015.179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202997","Sustainability;sustainability design;systems thinking;software engineering;long-term thinking;environmental sustainability;social sustainability;economic sustainability;societal sustainability;technical sustainability;ethics","Conferences;Software engineering;Software systems;Economics;Meteorology;History","software maintenance","sustainability design;Karlskrona manifesto;ecological systems;social systems;software engineering community;software-intensive systems;collaborative reflective writing process","","45","52","","","","","IEEE","IEEE Conferences"
"Stuck and Frustrated or in Flow and Happy: Sensing Developers' Emotions and Progress","S. C. M√ºller; T. Fritz","Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","688","699","Software developers working on change tasks commonly experience a broad range of emotions, ranging from happiness all the way to frustration and anger. Research, primarily in psychology, has shown that for certain kinds of tasks, emotions correlate with progress and that biometric measures, such as electro-dermal activity and electroencephalography data, might be used to distinguish between emotions. In our research, we are building on this work and investigate developers' emotions, progress and the use of biometric measures to classify them in the context of software change tasks. We conducted a lab study with 17 participants working on two change tasks each. Participants were wearing three biometric sensors and had to periodically assess their emotions and progress. The results show that the wide range of emotions experienced by developers is correlated with their perceived progress on the change tasks. Our analysis also shows that we can build a classifier to distinguish between positive and negative emotions in 71.36% and between low and high progress in 67.70% of all cases. These results open up opportunities for improving a developer's productivity. For instance, one could use such a classifier for providing recommendations at opportune moments when a developer is stuck and making no progress.","","","10.1109/ICSE.2015.334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194617","","Biosensors;Software;Atmospheric measurements;Particle measurements;Electroencephalography;Software engineering;Psychology","behavioural sciences computing;industrial psychology;signal classification;software development management","software developer emotions;software developer progress;psychology;biometric measures;electro-dermal activity;electroencephalography data;software change tasks;pattern classifier","","43","69","","","","","IEEE","IEEE Conferences"
"Specifying Event-Based Systems with a Counting Fluent Temporal Logic","G. Regis; R. Degiovanni; N. D'Ippolito; N. Aguirre","Dept. de Comput., Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina; Dept. de Comput., Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina; Dept. de Comput., Univ. de Buenos Aires, Buenos Aires, Argentina; Dept. de Comput., Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","733","743","Fluent linear temporal logic is a formalism for specifying properties of event-based systems, based on propositions called fluents, defined in terms of activating and deactivating events. In this paper, we propose complementing the notion of fluent by the related concept of counting fluent. As opposed to the boolean nature of fluents, counting fluents are numerical values, that enumerate event occurrences, and allow us to specify naturally some properties of reactive systems. Although by extending fluent linear temporal logic with counting fluents we obtain an undecidable, strictly more expressive formalism, we develop a sound (but incomplete) model checking approach for the logic, that reduces to traditional temporal logic model checking, and allows us to automatically analyse properties involving counting fluents, on finite event-based systems. Our experiments, based on relevant models taken from the literature, show that: (i) counting fluent temporal logic is better suited than traditional temporal logic for expressing properties in which the number of occurrences of certain events is relevant, and (ii) our model checking approach on counting fluent specifications is more efficient and scales better than model checking equivalent fluent temporal logic specifications.","","","10.1109/ICSE.2015.86","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194621","Model checking;Linear Temporal Logics;Event-Based System Analysis","Bridges;Model checking;Monitoring;Safety;Software;Mechanical factors;Analytical models","formal specification;formal verification;temporal logic","event-based systems specification;counting fluent temporal logic;fluent linear temporal logic;event activation;event deactivation;counting fluent concept;reactive systems;model checking approach;temporal logic model checking;finite event-based systems;counting fluent specifications","","2","34","","","","","IEEE","IEEE Conferences"
"Detecting Inconsistencies in JavaScript MVC Applications","F. S. Ocariza; K. Pattabiraman; A. Mesbah","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","325","335","Higher demands for more reliable and maintainable JavaScript-based web applications have led to the recent development of MVC (Model-View-Controller) frameworks. One of the main advantages of using these frameworks is that they abstract out DOM API method calls, which are one of the leading causes of web application faults, due to their often complicated interaction patterns. However, MVC frameworks are susceptible to inconsistencies between the identifiers and types of variables and functions used throughout the application. In response to this problem, we introduce a formal consistency model for web applications made using MVC frameworks. We propose an approach -- called Aurebesh -- that automatically detects inconsistencies in such applications. We evaluate Aurebesh by conducting a fault injection experiment and by running it on real applications. Our results show that Aurebesh is accurate, with an overall recall of 96.1% and a precision of 100%. It is also useful in detecting bugs, allowing us to find 15 real-world bugs in applications built on Angular JS, a popular MVC framework.","","","10.1109/ICSE.2015.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194585","","HTML;Data models;Motion pictures;Computer bugs;Detectors;Analytical models;Reliability","Internet;Java;program debugging;software fault tolerance","MVC applications;JavaScript-based Web applications;model-view-controller frameworks;formal consistency model;AUREBESH;fault injection;bugs detection;AngularJS;inconsistencies detection","","11","35","","","","","IEEE","IEEE Conferences"
"Approximating Attack Surfaces with Stack Traces","C. Theisen; K. Herzig; P. Morrison; B. Murphy; L. Williams","Dept. of Comput. Sci., NCSU, Raleigh, NC, USA; Microsoft Res., Cambridge, UK; Dept. of Comput. Sci., NCSU, Raleigh, NC, USA; Microsoft Res., Cambridge, UK; Dept. of Comput. Sci., NCSU, Raleigh, NC, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","199","208","Security testing and reviewing efforts are a necessity for software projects, but are time-consuming and expensive to apply. Identifying vulnerable code supports decision-making during all phases of software development. An approach for identifying vulnerable code is to identify its attack surface, the sum of all paths for untrusted data into and out of a system. Identifying the code that lies on the attack surface requires expertise and significant manual effort. This paper proposes an automated technique to empirically approximate attack surfaces through the analysis of stack traces. We hypothesize that stack traces from user-initiated crashes have several desirable attributes for measuring attack surfaces. The goal of this research is to aid software engineers in prioritizing security efforts by approximating the attack surface of a system via stack trace analysis. In a trial on Windows 8, the attack surface approximation selected 48.4% of the binaries and contained 94.6% of known vulnerabilities. Compared with vulnerability prediction models (VPMs) run on the entire codebase, VPMs run on the attack surface approximation improved recall from .07 to .1 for binaries and from .02 to .05 for source files. Precision remained at .5 for binaries, while improving from .5 to .69 for source files.","","","10.1109/ICSE.2015.148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202964","stack traces;security;vulnerability;models;testing;reliability;attack surface","Computer crashes;Security;Measurement;Approximation methods;Software;Predictive models;Surface treatment","decision making;program diagnostics;project management;software engineering","attack surface approximation;security testing;effort reviewing;software projects;vulnerable code identification;decision-making;software development;stack trace analysis;attack surface measurement;Windows 8","","17","44","","","","","IEEE","IEEE Conferences"
"The Role of Design Thinking and Physical Prototyping in Social Software Engineering","P. Newman; M. A. Ferrario; W. Simm; S. Forshaw; A. Friday; J. Whittle","Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Manage. Sch., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; LICA, Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","487","496","Social Software Engineering (Social SE), that is SE aiming to promote positive social change, is a rapidly emerging area. Here, software and digital artefacts are seen as tools for social change, rather than end products or 'solutions'. Moreover, Social SE requires a sustained buy-in from a range of stakeholders and end-users working in partnership with multidisciplinary software development teams often at a distance. This context poses new challenges to software engineering: it requires both an agile approach for handling uncertainties in the software development process, and the application of participatory, creative design processes to bridge the knowledge asymmetries and the geographical distances in the partnership. This paper argues for the role of design thinking in Social SE and highlights its implications for software engineering in general. It does so by reporting on the contributions that design thinking - and in particular physical design - has brought to (1) the problem space definition, (2) user requirements capture and (3) system feature design of a renewable energy forecasting system developed in partnership with a remote Scottish Island community.","","","10.1109/ICSE.2015.181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202999","","Conferences;Prototypes;Software;Software engineering;Context;Games;Space exploration","load forecasting;power engineering computing;renewable energy sources;software prototyping","design thinking;physical prototyping;social software engineering;social SE;sustained buy-in;multidisciplinary software development teams;agile approach;creative design processes;knowledge asymmetries;geographical distances;physical design;problem space definition;user requirements capture;system feature design;renewable energy forecasting system;remote Scottish island community","","8","41","","","","","IEEE","IEEE Conferences"
"Efficient Scalable Verification of LTL Specifications","L. Baresi; M. M. Pourhashem Kallehbasti; M. Rossi","Dipt. di Elettron., Inf. e Bioingegneria, Politec. di Milano, Milan, Italy; Dipt. di Elettron., Inf. e Bioingegneria, Politec. di Milano, Milan, Italy; Dipt. di Elettron., Inf. e Bioingegneria, Politec. di Milano, Milan, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","711","721","Linear Temporal Logic (LTL) has been used in computer science for decades to formally specify programs, systems, desired properties, and relevant behaviors. This paper presents a novel, efficient technique for verifying LTL specifications in a fully automated way. Our technique belongs to the category of Bounded Satisfiability Checking approaches, where LTL formulae are encoded as formulae of another decidable logic that can be solved through modern satisfiability solvers. The target logic in our approach is Bit-Vector Logic. We present our novel encoding, show its correctness, and experimentally compare it against existing encodings implemented in well-known formal verification tools.","","","10.1109/ICSE.2015.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194619","Formal Methods;Temporal Logic;Bounded Model Checking;Bit-Vector Logic","Encoding;Semantics;Unified modeling language;Model checking;Systematics;Analytical models","formal verification;temporal logic","scalable verification;LTL specification;linear temporal logic;computer science;bounded satisfiability checking approach;LTL formulae;target logic;bit-vector logic;formal verification tool","","5","28","","","","","IEEE","IEEE Conferences"
"Assert Use in GitHub Projects","C. Casalnuovo; P. Devanbu; A. Oliveira; V. Filkov; B. Ray","Comput. Sci. Dept., Univ. of California, Davis, Davis, CA, USA; Comput. Sci. Dept., Univ. of California, Davis, Davis, CA, USA; Comput. Sci. Dept., Univ. of California, Davis, Davis, CA, USA; Comput. Sci. Dept., Univ. of California, Davis, Davis, CA, USA; Comput. Sci. Dept., Univ. of California, Davis, Davis, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","755","766","Asserts have long been a strongly recommended (if non-functional) adjunct to programs. They certainly don't add any user-evident feature value; and it can take quite some skill and effort to devise and add useful asserts. However, they are believed to add considerable value to the developer. Certainly, they can help with automated verification; but even in the absence of that, claimed advantages include improved understandability, maintainability, easier fault localization and diagnosis, all eventually leading to better software quality. We focus on this latter claim, and use a large dataset of asserts in C and C++ programs to explore the connection between asserts and defect occurrence. Our data suggests a connection: functions with asserts do have significantly fewer defects. This indicates that asserts do play an important role in software quality; we therefore explored further the factors that play a role in assertion placement: specifically, process factors (such as developer experience and ownership) and product factors, particularly interprocedural factors, exploring how the placement of assertions in functions are influenced by local and global network properties of the callgraph. Finally, we also conduct a differential analysis of assertion use across different application domains.","","","10.1109/ICSE.2015.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194623","Assertions;GitHub;Defects","Software;History;Computer bugs;Java;Runtime;Collaboration;Gain measurement","formal verification;software quality","GitHub projects;assert use;automated verification;C program;C++ program;asserts occurrence;defect occurrence;software quality;assertion placement;process factors;product factors;interprocedural factors;callgraph local network property;callgraph global network property;differential analysis;application domain","","13","50","","","","","IEEE","IEEE Conferences"
"How Much Up-Front? A Grounded theory of Agile Architecture","M. Waterman; J. Noble; G. Allan","Specialised Archit. Services Ltd., Wellington, New Zealand; Sch. of Eng. & Comput. Sci., Victoria Univ. of Wellington, Wellington, New Zealand; Sch. of Eng. & Comput. Sci., Victoria Univ. of Wellington, Wellington, New Zealand","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","347","357","The tension between software architecture and agility is not well understood by agile practitioners or researchers. If an agile software team spends too little time designing architecture up-front then the team faces increased risk and higher chance of failure, if the team spends too much time the delivery of value to the customer is delayed, and responding to change can become extremely difficult. This paper presents a grounded theory of agile architecture that describes how agile software teams answer the question of how much upfront architecture design effort is enough. This theory, based on grounded theory research involving 44 participants, presents six forces that affect the team's context and five strategies that teams use to help them determine how much effort they should put into up-front design.","","","10.1109/ICSE.2015.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194587","","Computer architecture;Scrum (Software development);Planning;Software;Complexity theory;Business;Interviews","software architecture;software prototyping;team working","grounded theory;agile architecture;software architecture;software agility;agile software teams;upfront architecture design effort","","10","54","","","","","IEEE","IEEE Conferences"
"Does Automated Refactoring Obviate Systematic Editing?","Na Meng; L. Hua; Miryung Kim; K. S. McKinley","Univ. of Texas at Austin, Austin, TX, USA; Univ. of Texas at Austin, Austin, TX, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA; Microsoft Res., Redmond, WA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","392","402","When developers add features and fix bugs, they often make systematic edits-similar edits to multiple locations. Systematic edits may indicate that developers should instead refactor to eliminate redundancy. This paper explores this question by designing and implementing a fully automated refactoring tool called RASE, which performs clone removal. RASE (1) extracts common code guided by a systematic edit; (2) creates new types and methods as needed; (3) parameterizes differences in types, methods, variables, and expressions; and (4) inserts return objects and exit labels based on control and data flow. To our knowledge, this functionality makes RASE the most advanced refactoring tool for automated clone removal. We evaluate RASE with real-world systematic edits and compare to method based clone removal. RASE successfully performs clone removal in 30 of 56 method pairs (n=2) and 20 of 30 method groups (n‚â•3) with systematic edits. We find that scoping refactoring based on systematic edits (58%), rather than the entire method (33%), increases the applicability of automated clone removal. Automated refactoring is not feasible in the other 42% cases, which indicates that automated refactoring does not obviate the need for systematic editing.","","","10.1109/ICSE.2015.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194591","","Systematics;Cloning;Concrete;Data mining;Software;Merging;Context","data flow computing;software maintenance;software tools","systematic editing;automated refactoring tool;RASE;data flow;automated clone removal;scoping refactoring","","5","34","","","","","IEEE","IEEE Conferences"
"""Should We Move to Stack Overflow?"" Measuring the Utility of Social Media for Developer Support","M. Squire","Dept. of Comput. Sci., Elon Univ., Elon, NC, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","219","228","Stack Overflow is an enormously popular question-and-answer web site intended for software developers to help each other with programming issues. Some software projects aimed at developers (for example, application programming interfaces, application engines, cloud services, development frameworks, and the like) are closing their self-supported developer discussion forums and mailing lists and instead directing developers to use special-purpose tags on Stack Overflow. The goals of this paper are to document the main reasons given for moving developer support to Stack Overflow, and then to collect and analyze data from a group of software projects that have done this, in order to show whether the expected quality of support was actually achieved. The analysis shows that for all four software projects in this study, two of the desired quality indicators, developer participation and response time, did show improvements on Stack Overflow as compared to mailing lists and forums. However, we also found several projects that moved back from Stack Overflow, despite achieving these desired improvements. The results of this study are applicable to a wide variety of software projects that provide developer support using social media.","","","10.1109/ICSE.2015.150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202966","developer support;technical support;quality;Stack Overflow;mailing list;forums;metrics;social media","Software;Google;Time factors;Media;Documentation;Message systems;Software engineering","social networking (online);software engineering","stack overflow;social media;developer support;question-and-answer Web site;software developers;software projects;self-supported developer discussion forums;mailing lists;special-purpose tags;support quality","","18","18","","","","","IEEE","IEEE Conferences"
"Drawing Insight from Student Perceptions of Reflective Design Learning","T. V. Wilkins; J. C. Georgas","Dept. of Electr. Eng. & Comput. Sci., Northern Arizona Univ., Flagstaff, AZ, USA; Dept. of Electr. Eng. & Comput. Sci., Northern Arizona Univ., Flagstaff, AZ, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","253","262","While design and designing are core elements in computer science and software engineering, conventional curricular structures do not adequately support design learning. Current methods tend to isolate the study of design within specific subject matter and lack a strong emphasis on reflection. This paper reports on insights and lessons learned from a user study in the context of ongoing work on developing an educational intervention that better supports design learning with a particular emphasis on learner-driven reflection. Insights drawn from this study relate to general aspects of design learning, such as the importance of collaborative reflection and the impact of learner perceptions regarding their abilities, as well as to specific improvements to our approach.","","","10.1109/ICSE.2015.154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202970","software engineering education;software design;design learning;reflection;structured reflection","Context;Marine vehicles;Computer science;Software engineering;Training;Joints;Software","computer science education;software engineering","student perceptions;reflective design learning;computer science;software engineering;curricular structures;educational intervention;learner-driven reflection;collaborative reflection","","1","15","","","","","IEEE","IEEE Conferences"
"Inferring Behavioral Specifications from Large-scale Repositories by Leveraging Collective Intelligence","H. Rajan; T. N. Nguyen; G. T. Leavens; R. Dyer","Iowa State Univ., Ames, IA, USA; Iowa State Univ., Ames, IA, USA; Univ. of Central Florida, Orlando, FL, USA; Bowling Green State Univ., Bowling Green, OH, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","579","582","Despite their proven benefits, useful, comprehensible, and efficiently checkable specifications are not widely available. This is primarily because writing useful, non-trivial specifications from scratch is too hard, time consuming, and requires expertise that is not broadly available. Furthermore, the lack of specifications for widely-used libraries and frameworks, caused by the high cost of writing specifications, tends to have a snowball effect. Core libraries lack specifications, which makes specifying applications that use them expensive. To contain the skyrocketing development and maintenance costs of high assurance systems, this self-perpetuating cycle must be broken. The labor cost of specifying programs can be significantly decreased via advances in specification inference and synthesis, and this has been attempted several times, but with limited success. We believe that practical specification inference and synthesis is an idea whose time has come. Fundamental breakthroughs in this area can be achieved by leveraging the collective intelligence available in software artifacts from millions of open source projects. Fine-grained access to such data sets has been unprecedented, but is now easily available. We identify research directions and report our preliminary results on advances in specification inference that can be had by using such data sets to infer specifications.","","","10.1109/ICSE.2015.339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203017","","Data mining;Software;Software engineering;History;Writing;Libraries;Maintenance engineering","formal specification;public domain software","behavioral specification;collective intelligence;specification writing;core libraries;program specification;specification inference;specification synthesis;software artifacts;open source projects","","2","39","","","","","IEEE","IEEE Conferences"
"On Architectural Diversity of Dynamic Adaptive Systems","H. Song; A. Elgammal; V. Nallur; F. Chauvel; F. Fleurey; S. Clarke","SINTEF ICT, Oslo, Norway; Distrib. Syst. Group, Trinity Coll. Dublin, Dublin, Ireland; Distrib. Syst. Group, Trinity Coll. Dublin, Dublin, Ireland; SINTEF ICT, Oslo, Norway; SINTEF ICT, Oslo, Norway; Distrib. Syst. Group, Trinity Coll. Dublin, Dublin, Ireland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","595","598","We introduce a novel concept of ``architecture diversity'' for adaptive systems and posit that increased diversity has an inverse correlation with adaptation costs. We propose an index to quantify diversity and a static method to estimate the adaptation cost, and conduct an initial experiment on an exemplar cloud-based system which reveals the posited correlation.","","","10.1109/ICSE.2015.201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203021","software architecture;software diversity;self-adaptive systems;constraint solving","Computer architecture;Diversity reception;Context;Indexes;Routing;Software;Adaptive systems","cloud computing;software architecture","dynamic adaptive systems;architectural diversity;adaptation cost estimation;exemplar cloud-based system","","1","8","","","","","IEEE","IEEE Conferences"
"A Comparative Study of Programming Languages in Rosetta Code","S. Nanz; C. A. Furia","Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","778","788","Sometimes debates on programming languages are more religious than scientific. Questions about which language is more succinct or efficient, or makes developers more productive are discussed with fervor, and their answers are too often based on anecdotes and unsubstantiated beliefs. In this study, we use the largely untapped research potential of Rosetta Code, a code repository of solutions to common programming tasks in various languages, which offers a large data set for analysis. Our study is based on 7'087 solution programs corresponding to 745 tasks in 8 widely used languages representing the major programming paradigms (procedural: C and Go, object-oriented: C# and Java, functional: F# and Haskell, scripting: Python and Ruby). Our statistical analysis reveals, most notably, that: functional and scripting languages are more concise than procedural and object-oriented languages, C is hard to beat when it comes to raw speed on large inputs, but performance differences over inputs of moderate size are less pronounced and allow even interpreted languages to be competitive, compiled strongly-typed languages, where more defects can be caught at compile time, are less prone to runtime failures than interpreted or weakly-typed languages. We discuss implications of these results for developers, language designers, and educators.","","","10.1109/ICSE.2015.90","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194625","","Java;Programming;Indexes;Statistical analysis;Runtime;Standards","authoring languages;functional languages;Java;object-oriented programming;program compilers;program interpreters;statistical analysis","programming languages;Rosetta Code;code repository;Go;C#;Java;F#;Haskell;Python;Ruby;statistical analysis;functional language;scripting language;procedural language;object-oriented language;language interpretation;strongly-typed language compilation","","25","32","","","","","IEEE","IEEE Conferences"
"Build It Yourself! Homegrown Tools in a Large Software Company","E. K. Smith; C. Bird; T. Zimmermann","Sch. of Comput. Sci., Univ. of Massachusetts, Amherst, MA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","369","379","Developers sometimes take the initiative to build toolsto solve problems they face. What motivates developers to buildthese tools? What is the value for a company? Are the tools builtuseful for anyone besides their creator? We conducted a qualitativestudy of tool building, adoption, and impact within Microsoft. Thispaper presents our findings on the extrinsic and intrinsic factorslinked to toolbuilding, the value of building tools, and the factorsassociated with tool spread. We find that the majority of developersbuild tools. While most tools never spread beyond their creator'steam, most have more than one user, and many have more than onecollaborator. Organizational cultures that are receptive towardstoolbuilding produce more tools, and more collaboration on tools.When nurtured and spread, homegrown tools have the potential tocreate significant impact on organizations.","","","10.1109/ICSE.2015.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194589","Homegrown Tools","Interviews;Testing;Software;Buildings;Automation;Visualization;Monitoring","project management;software development management;software tools","software development;software company;software tools;tool building;tool adoption;tool impact;organizational cultures","","6","27","","","","","IEEE","IEEE Conferences"
"Learning to Log: Helping Developers Make Informed Logging Decisions","J. Zhu; P. He; Q. Fu; H. Zhang; M. R. Lyu; D. Zhang","Shenzhen Res. Inst., Chinese Univ. of Hong Kong, Shenzhen, China; Shenzhen Res. Inst., Chinese Univ. of Hong Kong, Shenzhen, China; Microsoft, Washington, DC, USA; Microsoft Res., Beijing, China; Shenzhen Res. Inst., Chinese Univ. of Hong Kong, Shenzhen, China; Microsoft Res., Beijing, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","415","425","Logging is a common programming practice of practical importance to collect system runtime information for postmortem analysis. Strategic logging placement is desired to cover necessary runtime information without incurring unintended consequences (e.g., Performance overhead, trivial logs). However, in current practice, there is a lack of rigorous specifications for developers to govern their logging behaviours. Logging has become an important yet tough decision which mostly depends on the domain knowledge of developers. To reduce the effort on making logging decisions, in this paper, we propose a ""learning to log"" framework, which aims to provide informative guidance on logging during development. As a proof of concept, we provide the design and implementation of a logging suggestion tool, Log Advisor, which automatically learns the common logging practices on where to log from existing logging instances and further leverages them for actionable suggestions to developers. Specifically, we identify the important factors for determining where to log and extract them as structural features, textual features, and syntactic features. Then, by applying machine learning techniques (e.g., Feature selection and classifier learning) and noise handling techniques, we achieve high accuracy of logging suggestions. We evaluate Log Advisor on two industrial software systems from Microsoft and two open-source software systems from Git Hub (totally 19.1M LOC and 100.6K logging statements). The encouraging experimental results, as well as a user study, demonstrate the feasibility and effectiveness of our logging suggestion tool. We believe our work can serve as an important first step towards the goal of ""learning to log"".","","","10.1109/ICSE.2015.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194593","","Feature extraction;Software systems;Context;Data mining;Runtime;Syntactics","learning (artificial intelligence);programming;public domain software","logging programming practice;logging decisions;system runtime information;postmortem analysis;strategic logging placement;learning-to-log framework;Log Advisor logging suggestion tool;machine learning techniques;noise handling techniques;logging suggestions;industrial software systems;Microsoft;open-source software systems;Git Hub","","40","48","","","","","IEEE","IEEE Conferences"
"Automated Modularization of GUI Test Cases","R. Yandrapally; G. Sridhara; S. Sinha","IBM Res., Bangalore, India; IBM Res., Bangalore, India; IBM Res., Bangalore, India","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","44","54","Test cases that drive an application under test via its graphical user interface (GUI) consist of sequences of steps that perform actions on, or verify the state of, the application user interface. Such tests can be hard to maintain, especially if they are not properly modularized - that is, common steps occur in many test cases, which can make test maintenance cumbersome and expensive. Performing modularization manually can take up considerable human effort. To address this, we present an automated approach for modularizing GUI test cases. Our approach consists of multiple phases. In the first phase, it analyzes individual test cases to partition test steps into candidate subroutines, based on how user-interface elements are accessed in the steps. This phase can analyze the test cases only or also leverage execution traces of the tests, which involves a cost-accuracy tradeoff. In the second phase, the technique compares candidate subroutines across test cases, and refines them to compute the final set of subroutines. In the last phase, it creates callable subroutines, with parameterized data and control flow, and refactors the original tests to call the subroutines with context-specific data and control parameters. Our empirical results, collected using open-source applications, illustrate the effectiveness of the approach.","","","10.1109/ICSE.2015.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194560","","Graphical user interfaces;Navigation;HTML;Maintenance engineering;Registers;Partitioning algorithms","graphical user interfaces;program testing","GUI test case modularization;graphical user interface;application user interface;test case analysis;candidate subroutines;test steps partitioning;user-interface elements;callable subroutines;context-specific data;control parameters;open-source applications","","1","33","","","","","IEEE","IEEE Conferences"
"LACE2: Better Privacy-Preserving Data Sharing for Cross Project Defect Prediction","F. Peters; T. Menzies; L. Layman","Lero - The Irish Software Res. Centre, Univ. of Limerick, Limerick, Ireland; Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Fraunhofer Center for Exp. SE, College Park, MD, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","801","811","Before a community can learn general principles, it must share individual experiences. Data sharing is the fundamental step of cross project defect prediction, i.e. the process of using data from one project to predict for defects in another. Prior work on secure data sharing allowed data owners to share their data on a single-party basis for defect prediction via data minimization and obfuscation. However the studied method did not consider that bigger data required the data owner to share more of their data. In this paper, we extend previous work with LACE2 which reduces the amount of data shared by using multi-party data sharing. Here data owners incrementally add data to a cache passed among them and contribute ""interesting"" data that are not similar to the current content of the cache. Also, before data owner i passes the cache to data owner j, privacy is preserved by applying obfuscation algorithms to hide project details. The experiments of this paper show that (a) LACE2 is comparatively less expensive than the single-party approach and (b) the multi-party approach of LACE2 yields higher privacy than the prior approach without damaging predictive efficacy (indeed, in some cases, LACE2 leads to better defect predictors).","","","10.1109/ICSE.2015.92","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194627","privacy-preserving data sharing;cross project defect prediction","Data privacy;Privacy;Software;Minimization;Organizations;Measurement;Clustering algorithms","cache storage;data encapsulation;data privacy;project management;security of data;software development management","LACE2;privacy-preserving data sharing;cross project defect prediction;secure data sharing;data minimization;multiparty data sharing;cache;interesting data;obfuscation algorithm;project detail hiding;single-party approach;multiparty approach","","25","44","","","","","IEEE","IEEE Conferences"
"GPredict: Generic Predictive Concurrency Analysis","J. Huang; Q. Luo; G. Rosu","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","847","857","Predictive trace analysis (PTA) is an effective approach for detecting subtle bugs in concurrent programs. Existing PTA techniques, however, are typically based on adhoc algorithms tailored to low-level errors such as data races or atomicity violations, and are not applicable to high-level properties such as ""a resource must be authenticated before use"" and ""a collection cannot be modified when being iterated over"". In addition, most techniques assume as input a globally ordered trace of events, which is expensive to collect in practice as it requires synchronizing all threads. In this paper, we present GPredict: a new technique that realizes PTA for generic concurrency properties. Moreover, GPredict does not require a global trace but only the local traces of each thread, which incurs much less runtime overhead than existing techniques. Our key idea is to uniformly model violations of concurrency properties and the thread causality as constraints over events. With an existing SMT solver, GPredict is able to precisely predict property violations allowed by the causal model. Through our evaluation using both benchmarks and real world applications, we show that GPredict is effective in expressing and predicting generic property violations. Moreover, it reduces the runtime overhead of existing techniques by 54% on DaCapo benchmarks on average.","","","10.1109/ICSE.2015.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194631","","Concurrent computing;Runtime;Schedules;Predictive models;Syntactics;Java;Prediction algorithms","concurrency control;program debugging;program diagnostics","GPredict;generic predictive concurrency analysis;predictive trace analysis;PTA;subtle bug detection;concurrent programs;local traces;SMT solver;DaCapo benchmarks","","12","40","","","","","IEEE","IEEE Conferences"
"Tracking Static Analysis Violations over Time to Capture Developer Characteristics","P. Avgustinov; A. I. Baars; A. S. Henriksen; G. Lavender; G. Menzel; O. d. Moor; M. Sch√§fer; J. Tibble","Semmle Ltd., Oxford, UK; Semmle Ltd., Oxford, UK; Semmle Ltd., Oxford, UK; Semmle Ltd., Oxford, UK; Semmle Ltd., Oxford, UK; NA; Semmle Ltd., Oxford, UK; Semmle Ltd., Oxford, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","437","447","Many interesting questions about the software quality of a code base can only be answered adequately if fine-grained information about the evolution of quality metrics over time and the contributions of individual developers is known. We present an approach for tracking static analysis violations (which are often indicative of defects) over the revision history of a program, and for precisely attributing the introduction and elimination of these violations to individual developers. As one application, we demonstrate how this information can be used to compute ``fingerprints'' of developers that reflect which kinds of violations they tend to introduce or to fix. We have performed an experimental study on several large open-source projects written in different languages, providing evidence that these fingerprints are well-defined and capture characteristic information about the coding habits of individual developers.","","","10.1109/ICSE.2015.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194595","","Position measurement;Software quality;Java;Libraries;History;Open source software","program diagnostics;public domain software;software quality","static analysis violations tracking;fine-grained information;quality metrics;program revision history;open-source projects;coding habits","","6","38","","","","","IEEE","IEEE Conferences"
"Learning Global Agile Software Engineering Using Same-Site and Cross-Site Teams","M. Paasivaara; K. Blincoe; C. Lassenius; D. Damian; J. Sheoran; F. Harrison; P. Chhabra; A. Yussuf; V. Isotalo","Software Process Res. Group, Aalto Univ., Aalto, Finland; SEGAL, Univ. of Victoria, Victoria, BC, Canada; Software Process Res. Group, Aalto Univ., Aalto, Finland; SEGAL, Univ. of Victoria, Victoria, BC, Canada; SEGAL, Univ. of Victoria, Victoria, BC, Canada; SEGAL, Univ. of Victoria, Victoria, BC, Canada; SEGAL, Univ. of Victoria, Victoria, BC, Canada; SEGAL, Univ. of Victoria, Victoria, BC, Canada; Software Process Res. Group, Aalto Univ., Aalto, Finland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","285","294","We describe an experience in teaching global software engineering (GSE) using distributed Scrum augmented with industrial best practices. Our unique instructional technique had students work in both same-site and cross-site teams to contrast the two modes of working. The course was a collaboration between Aalto University, Finland and University of Victoria, Canada. Fifteen Canadian and eight Finnish students worked on a single large project, divided into four teams, working on interdependent user stories as negotiated with the industrial product owner located in Finland. Half way through the course, we changed the teams so each student worked in both a local and a distributed team. We studied student learning using a mixed-method approach including 14 post-course interviews, pre-course and Sprint questionnaires, observations, meeting recordings, and repository data from git and Flow dock, the primary communication tool. Our results show no significant differences between working in distributed vs. Non-distributed teams, suggesting that Scrum helps alleviate many GSE problems. Our post-course interviews and survey data allows us to explain this effect, we found that students over time learned to better self-select tasks with less inter-team dependencies, to communicate more, and to work better in teams.","","","10.1109/ICSE.2015.157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202974","scrum;global software engineering;distributed scrum;teaching;project","Interviews;Teamwork;Software;Training;Planning","computer science education;educational courses;educational institutions;software prototyping;teaching;team working","global agile software engineering learning;same-site teams;cross-site teams;GSE;distributed Scrum;instructional technique;Aalto University;Finland;University of Victoria;Canadian students;Finnish students;mixed-method approach;student learning;communication tool;interteam dependencies","","11","28","","","","","IEEE","IEEE Conferences"
"Developing and Evaluating Software Engineering Process Theories","P. Ralph","Dept. of Comput. Sci., Univ. of Auckland, Auckland, New Zealand","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","20","31","A process theory is an explanation of how an entity changes and develops. While software engineering is fundamentally concerned with how software artifacts change and develop, little research explicitly builds and empirically evaluates software engineering process theories. This lack of theory obstructs scientific consensus by focusing the academic community on methods. Methods inevitably oversimplify and over-rationalize reality, obfuscating crucial phenomena including uncertainty, problem framing and illusory requirements. Better process theories are therefore needed to ground software engineering in empirical reality. However, poor understanding of process theory issues impedes research and publication. This paper therefore attempts to clarify the nature and types of process theories, explore their development and provide specific guidance for their empirically evaluation.","","","10.1109/ICSE.2015.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194558","Research methodology;process theory;questionnaire;case study;field study","Context;Software engineering;Sociology;Statistics;Encoding;Software design","software engineering","software engineering process theories;software artifacts;empirical software evaluation","","5","74","","","","","IEEE","IEEE Conferences"
"ZoomIn: Discovering Failures by Detecting Wrong Assertions","F. Pastore; L. Mariani","Centre For Security, Reliability & Trust, Univ. of Luxembourg, Luxembourg, Luxembourg; Dept. of Inf., Syst. & Commun., Univ. of Milano - Bicocca, Milan, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","66","76","Automatic testing, although useful, is still quite ineffective against faults that do not cause crashes or uncaught exceptions. In the majority of the cases automatic tests do not include oracles, and only in some cases they incorporate assertions that encode the observed behavior instead of the intended behavior, that is if the application under test produces a wrong result, the synthesized assertions will encode wrong expectations that match the actual behavior of the application. In this paper we present Zoom In, a technique that extends the fault-revealing capability of test case generation techniques from crash-only faults to faults that require non-trivial oracles to be detected. Zoom In exploits the knowledge encoded in the manual tests written by developers and the similarity between executions to automatically determine an extremely small set of suspicious assertions that are likely wrong and thus worth manual inspection. Early empirical results show that Zoom In has been able to detect 50% of the analyzed non-crashing faults in the Apache Commons Math library requiring the inspection of less than 1.5% of the assertions automatically generated by EvoSuite.","","","10.1109/ICSE.2015.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194562","oracle problem;oracle generation;anomaly detection","Manuals;Generators;Inspection;Data mining;Computer crashes;Encoding;Law","program testing;software fault tolerance","ZoomIn;failure discovery;wrong assertion detection;automatic testing;synthesized assertions;fault-revealing capability;test case generation;Apache Commons Math library;EvoSuite","","2","35","","","","","IEEE","IEEE Conferences"
"ReCBuLC: Reproducing Concurrency Bugs Using Local Clocks","X. Yuan; C. Wu; Z. Wang; J. Li; P. Yew; J. Huang; X. Feng; Y. Lan; Y. Chen; Y. Guan","State Key Lab. of Comput. Archit., Inst. of Comput. Technol., Beijing, China; State Key Lab. of Comput. Archit., Inst. of Comput. Technol., Beijing, China; State Key Lab. of Comput. Archit., Inst. of Comput. Technol., Beijing, China; State Key Lab. of Comput. Archit., Inst. of Comput. Technol., Beijing, China; Dept. of Comput. Sci. & Eng., Univ. of Minnesota at Twin-Cities, Minneapolis, MN, USA; Dept. of Comput. Sci. & Eng., Texas A&M Univ., College Station, TX, USA; State Key Lab. of Comput. Archit., Inst. of Comput. Technol., Beijing, China; Key Lab. of Network Data Sci. & Technol., Inst. of Comput. Technol., Beijing, China; State Key Lab. of Comput. Archit., Inst. of Comput. Technol., Beijing, China; Coll. of Inf. Eng., Capital Normal Univ., Beijing, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","824","834","Multi-threaded programs play an increasingly important role in current multi-core environments. Exposing concurrency bugs and debugging such multi-threaded programs have become quite challenging due to their inherent non-determinism. In order to eliminate such non-determinism, many approaches such as record-and-replay and other similar bug reproducing systems have been proposed. However, those approaches often suffer significant performance degradation because they require a large amount of recorded information and/or long analysis and replay time. In this paper, we propose an effective approach, ReCBuLC, to take advantage of the hardware clocks available on modern processors. The key idea is to reduce the recording overhead and analyzing events' global order by using time stamps recorded in each thread. Those timestamps are used to determine the global orders of shared accesses. To avoid the large overhead incurred in accessing system-wide global clock, we opt to use local per-core clocks that incur much less access overhead. We then propose techniques to resolve differences among local clocks and obtain an accurate global event order. By using per-core clocks, state-of-the-art bug reproducing systems such as PRES and CLAP can reduce the recording overheads by 1% ~ 85%, and the analysis time by 84.66% ~ 99.99%, respectively.","","","10.1109/ICSE.2015.94","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194629","concurrency;bug reproducing;local clock","Clocks;Program processors;Computer bugs;Hardware;Coherence;Concurrent computing;Debugging","clocks;concurrency control;multiprocessing systems;multi-threading;program debugging","ReCBuLC;concurrency bug reproduction;multicore environment;concurrency bugs;multithreaded program debugging;nondeterminism elimination;record-and-replay approach;bug reproducing system;hardware clock;recording overhead reduction;event global order analysis;time stamp;shared access;local per-core clock;PRES;CLAP","","6","30","","","","","IEEE","IEEE Conferences"
"Discovering Information Explaining API Types Using Text Classification","G. Petrosyan; M. P. Robillard; R. De Mori","Sch. of Comput. Sci., McGill Univ., Montreal, QC, Canada; Sch. of Comput. Sci., McGill Univ., Montreal, QC, Canada; Sch. of Comput. Sci., McGill Univ., Montreal, QC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","869","879","Many software development tasks require developers to quickly learn a subset of an Application Programming Interface (API). API learning resources are crucial for helping developers learn an API, but the knowledge relevant to a particular topic of interest may easily be scattered across different documents, which makes finding the necessary information more challenging. This paper proposes an approach to discovering tutorial sections that explain a given API type. At the core of our approach, we classify fragmented tutorial sections using supervised text classification based on linguistic and structural features. Experiments conducted on five tutorials show that our approach is able to discover sections explaining an API type with precision between 0.69 and 0.87 (depending on the tutorial) when trained and tested on the same tutorial. When trained and tested across tutorials, we obtained a precision between 0.74 and 0.94 and lower recall values.","","","10.1109/ICSE.2015.97","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194633","","Tutorials;Feature extraction;HTML;Libraries;Java;Documentation;Programming","application program interfaces;learning (artificial intelligence);pattern classification;software engineering;text analysis","application programming interface;API;supervised text classification;software development;linguistic feature;structural feature","","26","31","","","","","IEEE","IEEE Conferences"
"Safe Memory-Leak Fixing for C Programs","Q. Gao; Y. Xiong; Y. Mi; L. Zhang; W. Yang; Z. Zhou; B. Xie; H. Mei","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","459","470","Automatic bug fixing has become a promising direction for reducing manual effort in debugging. However, general approaches to automatic bug fixing may face some fundamental difficulties. In this paper, we argue that automatic fixing of specific types of bugs can be a useful complement. This paper reports our first attempt towards automatically fixing memory leaks in C programs. Our approach generates only safe fixes, which are guaranteed not to interrupt normal execution of the program. To design such an approach, we have to deal with several challenging problems such as inter-procedural leaks, global variables, loops, and leaks from multiple allocations. We propose solutions to all the problems and integrate the solutions into a coherent approach. We implemented our inter-procedural memory leak fixing into a tool named Leak Fix and evaluated Leak Fix on 15 programs with 522k lines of code. Our evaluation shows that Leak Fix is able to successfully fix a substantial number of memory leaks, and Leak Fix is scalable for large applications.","","","10.1109/ICSE.2015.64","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194597","","Resource management;Algorithm design and analysis;Safety;Software;Computer bugs;Leak detection;Face","C language;object-oriented programming;program control structures;program debugging;storage management","safe memory-leak fixing;C program;automatic bug fixing;debugging;interprocedural leak;global variables;loops;interprocedural memory leak fixing;Leak Fix tool","","21","48","","","","","IEEE","IEEE Conferences"
"Remote Development and Distance Delivery of Innovative Courses: Challenges and Opportunities","K. Marasovic; M. Lutz","Dept. of Inf. Technol., Rochester Inst. of Technol., Zagreb, Croatia; Dept. of Software Eng., Rochester Inst. of Technol., Rochester, NY, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","299","302","The Rochester Institute of Technology (RIT) offers programs of study at several of RIT's international campuses: Dubrovnik and Zagreb (Croatia), Dubai (United Arab Emirates) and Priatina (Kosovo). At RIT Croatia, some courses are delivered as distance education courses using Polycom, a video conferencing system, supported by other online education tools. Although distance learning methods and tools provide an effective way to offer instructions remotely, delivering a course that emphasizes team-based software development, with laboratory exercises and in-class team activities, creates new challenges that need to be addressed. This paper discusses the authors' experiences with the remote development and delivery of one of those courses - the SWEN-383 Software Design Principles and Patterns course in the Information Technology program at RIT Croatia. The paper first explains the role and need for offering this particular course. It then discusses how the collaborative development of this new course was conducted between the U.S. And the Croatian campuses, including remote delivery from Zagreb to Dubrovnik. The paper concludes with observations and suggestions for those who may engage in such a project in the future.","","","10.1109/ICSE.2015.159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202976","remote collaboration;distance education;software engineering;information technology education;team projects","Education;Collaboration;Software;Google;Computers;Software engineering;Context","computer science education;distance learning;educational courses;software engineering","Rochester Institute of Technology;RIT;course development;course delivery;Croatia;United Arab Emirates;Kosovo;Dubrovnik;Zagreb;Dubai;Priatina;distance education courses;Polycom system;video conferencing system;online education tools;team-based software development;laboratory exercises;in-class team activities;SWEN-383 software design principles and patterns course;information technology program","","1","11","","","","","IEEE","IEEE Conferences"
"Towards Explicitly Elastic Programming Frameworks","K. R. Jayaram","IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","619","622","It is a widely held view that software engineers should not be ""burdened"" with the responsibility of making their application components elastic, and that elasticity should be either be implicit and automatic in the programming framework; or that it is the responsibility of the cloud provider's operational staff (DevOps) to make distributed applications written for dedicated clusters elastic and execute them on cloud environments. In this paper, we argue the opposite - we present a case for explicit elasticity, where software engineers are given the flexibility to explicitly engineer elasticity into their distributed applications. We present several scenarios where elasticity retrofitted to applications by DevOps is ineffective, present preliminary empirical evidence that explicit elasticity improves efficiency, and argue for elastic programming languages and frameworks to reduce programmer effort in engineering elastic distributed applications. We also present a bird's eye view of ongoing work on two explicitly elastic programming frameworks - Elastic Thrift (based on Apache Thrift) and Elastic Java, an extension of Java with support for explicit elasticity.","","","10.1109/ICSE.2015.207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203027","","Elasticity;Programming;Runtime;Java;Servers;Software;Measurement","cloud computing;Java;software engineering","explicit elastic programming frameworks;software engineers;cloud provider operational staff;DevOps;cloud environments;elastic programming languages;elastic thrift programming frameworks;elastic Java","","2","16","","","","","IEEE","IEEE Conferences"
"Rapid Multi-Purpose, Multi-Commit Code Analysis","C. V. Alexandru; H. C. Gall","Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","635","638","Existing code- and software evolution studies typically operate on the scale of a few revisions of a small number of projects, mostly because existing tools are unsuited for performing large-scale studies. We present a novel approach, which can be used to analyze an arbitrary number of revisions of a software project simultaneously and which can be adapted for the analysis of mixed-language projects. It lays the foundation for building high-performance code analyzers for a variety of scenarios. We show that for one particular scenario, namely code metric computation, our prototype outperforms existing tools by multiple orders of magnitude when analyzing thousands of revisions.","","","10.1109/ICSE.2015.211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203031","code analysis;graph;abstract syntax tree;software evolution","Software;Conferences;Measurement;Computer languages;Data mining;Prototypes;Software engineering","program diagnostics;software metrics","rapid multipurpose multicommit code analysis;code evolution;software evolution;software project revisions;mixed-language projects;high-performance code analyzers;code metric computation","","6","16","","","","","IEEE","IEEE Conferences"
"No PAIN, No Gain? The Utility of PArallel Fault INjections","S. Winter; O. Schwahn; R. Natella; N. Suri; D. Cotroneo","DEEDS Group, Tech. Univ. Darmstadt, Darmstadt, Germany; DEEDS Group, Tech. Univ. Darmstadt, Darmstadt, Germany; DIETI, Federico II Univ. of Naples, Naples, Italy; DEEDS Group, Tech. Univ. Darmstadt, Darmstadt, Germany; DIETI, Federico II Univ. of Naples, Naples, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","494","505","Software Fault Injection (SFI) is an established technique for assessing the robustness of a software under test by exposing it to faults in its operational environment. Depending on the complexity of this operational environment, the complexity of the software under test, and the number and type of faults, a thorough SFI assessment can entail (a) numerous experiments and (b) long experiment run times, which both contribute to a considerable execution time for the tests. In order to counteract this increase when dealing with complex systems, recent works propose to exploit parallel hardware to execute multiple experiments at the same time. While Parallel fault Injections (PAIN) yield higher experiment throughput, they are based on an implicit assumption of non-interference among the simultaneously executing experiments. In this paper we investigate the validity of this assumption and determine the trade-off between increased throughput and the accuracy of experimental results obtained from PAIN experiments.","","","10.1109/ICSE.2015.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194600","Software Fault Injection;Robustness Testing;Test Automation;Test Parallelization","Hardware;Throughput;Parallel processing;Detectors;Testing;Kernel","parallel processing;software fault tolerance","PAIN;parallel fault injection;software fault injection;SFI","","10","77","","","","","IEEE","IEEE Conferences"
"Static Control-Flow Analysis of User-Driven Callbacks in Android Applications","S. Yang; D. Yan; H. Wu; Y. Wang; A. Rountev","NA; NA; NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","89","99","Android software presents many challenges for static program analysis. In this work we focus on the fundamental problem of static control-flow analysis. Traditional analyses cannot be directly applied to Android because the applications are framework-based and event-driven. We consider user-event-driven components and the related sequences of callbacks from the Android framework to the application code, both for lifecycle callbacks and for event handler callbacks. We propose a program representation that captures such callback sequences. This representation is built using context-sensitive static analysis of callback methods. The analysis performs graph reachability by traversing context-compatible interprocedural control-flow paths and identifying statements that may trigger callbacks, as well as paths that avoid such statements. We also develop a client analysis that builds a static model of the application's GUI. Experimental evaluation shows that this context-sensitive approach leads to substantial precision improvements, while having practical cost.","","","10.1109/ICSE.2015.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194564","","Context;Graphical user interfaces;Smart phones;Algorithm design and analysis;Androids;Humanoid robots;Analytical models","data flow analysis;graphical user interfaces;mobile computing;smart phones","static control-flow analysis;user-driven callback sequence;Android application;static program analysis;program representation;context-sensitive static analysis;client analysis;GUI","","49","45","","","","","IEEE","IEEE Conferences"
"Hercules: Reproducing Crashes in Real-World Application Binaries","V. Pham; W. B. Ng; K. Rubinov; A. Roychoudhury","Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","891","901","Binary analysis is a well-investigated area in software engineering and security. Given real-world program binaries, generating test inputs which cause the binaries to crash is crucial. Generation of crashing inputs has many applications including off-line analysis of software prior to deployment, or online analysis of software patches as they are inserted. In this work, we present a method for generating inputs which reach a given ""potentially crashing"" location. Such potentially crashing locations can be found by a separate static analysis (or by gleaning crash reports submitted by internal / external users) and serve as the input to our method. The test input generated by our method serves as a witness of the crash. Our method is particularly suited for binaries of programs which take in complex structured inputs. Experiments on real-life applications such as the Adobe Reader and the Windows Media Player demonstrate that our Hercules tool built on selective symbolic execution engine S2E can generate crashing inputs within few hours, where symbolic approaches (as embodied by S2E) or blackbox fuzzing approaches (as embodied by the commercial tool PeachFuzzer) failed.","","","10.1109/ICSE.2015.99","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194635","binary analysis;test generation;symbolic execution","Computer crashes;Concrete;Registers;Hybrid power systems;Heuristic algorithms;Search problems;Ash","security of data;software tools","Hercules tool;crash reproduction;binary analysis;software engineering;software security;software off-line analysis;Adobe Reader;Windows Media Player;selective symbolic execution engine;S2E","","6","31","","","","","IEEE","IEEE Conferences"
"The Art of Testing Less without Sacrificing Quality","K. Herzig; M. Greiler; J. Czerwonka; B. Murphy","Microsoft Res., Cambridge, UK; Microsoft Corp., Redmond, WA, USA; Microsoft Corp., Redmond, WA, USA; Microsoft Res., Cambridge, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","483","493","Testing is a key element of software development processes for the management and assessment of product quality. In most development environments, the software engineers are responsible for ensuring the functional correctness of code. However, for large complex software products, there is an additional need to check that changes do not negatively impact other parts of the software and they comply with system constraints such as backward compatibility, performance, security etc. Ensuring these system constraints may require complex verification infrastructure and test procedures. Although such tests are time consuming and expensive and rarely find defects they act as an insurance process to ensure the software is compliant. However, long lasting tests increasingly conflict with strategic aims to shorten release cycles. To decrease production costs and to improve development agility, we created a generic test selection strategy called THEO that accelerates test processes without sacrificing product quality. THEO is based on a cost model, which dynamically skips tests when the expected cost of running the test exceeds the expected cost of removing it. We replayed past development periods of three major Microsoft products resulting in a reduction of 50% of test executions, saving millions of dollars per year, while maintaining product quality.","","","10.1109/ICSE.2015.66","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194599","","Context;Software;Inspection;Testing;Quality assessment;Product design;Reliability","product quality;program testing;program verification;software quality","software development processes;product quality assessment;product quality management;large complex software products;complex verification infrastructure;test procedures;insurance process;production cost model;THEO generic test selection strategy","","25","31","","","","","IEEE","IEEE Conferences"
"Teaching Software Systems Thinking at The Open University","M. Wermelinger; J. G. Hall; L. Rapanotti; L. Barroca; M. Ramage; A. Bandara","Comput. & Commun. Dept., Open Univ., Milton Keynes, UK; Comput. & Commun. Dept., Open Univ., Milton Keynes, UK; Comput. & Commun. Dept., Open Univ., Milton Keynes, UK; Comput. & Commun. Dept., Open Univ., Milton Keynes, UK; Comput. & Commun. Dept., Open Univ., Milton Keynes, UK; Comput. & Commun. Dept., Open Univ., Milton Keynes, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","307","310","The Open University is a distance-based higher education institution. Most of our students are in employment and study from home, contacting their tutor and fellow students via e-mail and discussion forums. In this paper, we describe our undergraduate and postgraduate modules in the software systems area, how we teach them at a distance, and our focus on shifting our students' minds into a reflective, critical, holistic socio-technical view of software systems that is relevant to their particular professional contexts.","","","10.1109/ICSE.2015.161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202978","","Software engineering;Context;Software systems;Training;Information systems","computer aided instruction;computer science education;distance learning;educational institutions;further education;professional aspects;software engineering;teaching","software system thinking teaching;Open University;distance-based higher education institution;student employment;e-mail;discussion forums;undergraduate modules;postgraduate modules;reflective view;critical view;holistic socio-technical view;professional contexts","","1","14","","","","","IEEE","IEEE Conferences"
"Using GSwE2009 for the Evaluation of a Master Degree in Software Engineering in the Universidad de la Rep√∫blica","L. Camilloni; D. Vallespir; M. Ardis","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","323","332","This paper presents an adoption and adaptation of the Curriculum Guidelines for Graduate Degree Programs in Software Engineering (GSwE2009) proposed by the IEEE-CS and the ACM for the creation of a curriculum for a Master's degree in software engineering at the Universidad de la Rep√∫blica (Uruguay). A method for evaluating contents and its application is also presented. This evaluation allows us to know the obtained thematic coverage, effort and balance. It also provides information that enables the detection of numerous opportunities for the improvement in the implementation of the program.","","","10.1109/ICSE.2015.165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202982","","Software engineering;Software;Guidelines;Computer architecture;Joints;Training","computer science education;educational administrative data processing;educational institutions;further education;software engineering","GSwE2009;master degree;software engineering;Universidad de la Rep√∫blica;curriculum guidelines adoption;curriculum guidelines adaptation;graduate degree programs;IEEE-CS;ACM;curriculum creation;Uruguay;contents evaluation","","2","19","","","","","IEEE","IEEE Conferences"
"Combining Multi-Objective Search and Constraint Solving for Configuring Large Software Product Lines","C. Henard; M. Papadakis; M. Harman; Y. Le Traon","Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg, Luxembourg; Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg, Luxembourg; Univ. Coll. London, London, UK; Interdiscipl. Centre for Security, Univ. of Luxembourg, Luxembourg, Luxembourg","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","517","528","Software Product Line (SPL) feature selection involves the optimization of multiple objectives in a large and highly constrained search space. We introduce SATIBEA, that augments multi-objective search-based optimization with constraint solving to address this problem, evaluating it on five large real-world SPLs, ranging from 1,244 to 6,888 features with respect to three different solution quality indicators and two diversity metrics. The results indicate that SATIBEA statistically significantly outperforms the current state-of-the-art (p <; 0.01) for all five SPLs on all three quality indicators and with maximal effect size (»Ç12 = 1.0). We also present results that demonstrate the importance of combining constraint solving with search-based optimization and the significant improvement SATIBEA produces over pure constraint solving. Finally, we demonstrate the scalability of SATIBEA: within less than half an hour, it finds thousands of constraint-satisfying optimized software products, even for the largest SPL considered in the literature to date.","","","10.1109/ICSE.2015.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194602","","Optimization;Software;Frequency modulation;Search problems;Measurement;Software product lines;Filtering algorithms","configuration management;optimisation;search problems;software metrics;software product lines","constraint solving;software product lines configuration;SPL feature selection;SATIBEA framework;multiobjective search-based optimization;diversity metrics","","35","55","","","","","IEEE","IEEE Conferences"
"Interactive Code Review for Systematic Changes","T. Zhang; M. Song; J. Pinedo; M. Kim","Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of Texas at Austin, Austin, TX, USA; Univ. of Texas at Austin, Austin, TX, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","111","122","Developers often inspect a diff patch during peer code reviews. Diff patches show low-level program differences per file without summarizing systematic changes -- similar, related changes to multiple contexts. We present Critics, an interactive approach for inspecting systematic changes. When a developer specifies code change within a diff patch, Critics allows developers to customize the change template by iteratively generalizing change content and context. By matching a generalized template against the codebase, it summarizes similar changes and detects potential mistakes. We evaluated Critics using two methods. First, we conducted a user study at Salesforce.com, where professional engineers used Critics to investigate diff patches authored by their own team. After using Critics, all six participants indicated that they would like Critics to be integrated into their current code review environment. This also attests to the fact that Critics scales to an industry-scale project and can be easily adopted by professional engineers. Second, we conducted a user study where twelve participants reviewed diff patches using Critics and Eclipse diff. The results show that human subjects using Critics answer questions about systematic changes 47.3% more correctly with 31.9% saving in time during code review tasks, in comparison to the baseline use of Eclipse diff. These results show that Critics should improve developer productivity in inspecting systematic changes during peer code reviews.","","","10.1109/ICSE.2015.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194566","","Systematics;Context;Switches;Interviews;Software;Syntactics;Data mining","software engineering;software reviews;source code (software)","peer code review;software development;systematic change;interactive code review;Critics","","23","44","","","","","IEEE","IEEE Conferences"
"Measuring Software Redundancy","A. Carzaniga; A. Mattavelli; M. Pezz√®","Univ. della Svizzera italiana (USI), Lugano, Switzerland; Univ. della Svizzera italiana (USI), Lugano, Switzerland; Univ. della Svizzera italiana (USI), Lugano, Switzerland","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","156","166","Redundancy is the presence of different elements with the same functionality. In software, redundancy is useful (and used) in many ways, for example for fault tolerance and reliability engineering, and in self-adaptive and self-checking programs. However, despite the many uses, we still do not know how to measure software redundancy to support a proper and effective design. If, for instance, the goal is to improve reliability, one might want to measure the redundancy of a solution to then estimate the reliability gained with that solution. Or one might compare alternative solutions to choose the one that expresses more redundancy and therefore, presumably, more reliability. We first formalize a notion of redundancy whereby two code fragments are considered redundant when they achieve the same functionality with different executions. On the basis of this abstract and general notion, we then develop a concrete method to obtain a meaningful quantitative measure of software redundancy. The results we obtain are very positive: we show, through an extensive experimental analysis, that it is possible to distinguish code that is only minimally different, from truly redundant code, and that it is even possible to distinguish low-level code redundancy from high-level algorithmic redundancy. We also show that the measurement is significant and useful for the designer, as it can help predict the effectiveness of techniques that exploit redundancy.","","","10.1109/ICSE.2015.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194570","Software redundancy;functional equivalence;execution diversity","Redundancy;Software;Software measurement;Semantics;Atmospheric measurements;Particle measurements","software reliability","software redundancy measurement;software reliability;low-level code redundancy;high-level algorithmic redundancy","","12","36","","","","","IEEE","IEEE Conferences"
"An Empirical Study on Quality Issues of Production Big Data Platform","H. Zhou; J. Lou; H. Zhang; H. Lin; H. Lin; T. Qin","Microsoft Res., Beijing, China; Microsoft Res., Beijing, China; Microsoft Res., Beijing, China; Microsoft, Beijing, China; Microsoft Res., Beijing, China; Microsoft Res., Beijing, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","17","26","Big Data computing platform has evolved to be a multi-tenant service. The service quality matters because system failure or performance slowdown could adversely affect business and user experience. There is few study in literature on service quality issues of production Big Data computing platform. In this paper, we present an empirical study on the service quality issues of Microsoft ProductA, which is a company-wide multi-tenant Big Data computing platform, serving thousands of customers from hundreds of teams. ProductA has a well-defined incident management process, which helps customers report and mitigate service quality issues on 24/7 basis. This paper explores the common symptom, causes and mitigation of service quality issues in Big Data computing. We conduct an empirical study on 210 real service quality issues in ProductA. Our major findings include (1) 21.0% of escalations are caused by hardware faults; (2) 36.2% are caused by system side defects; (3) 37.2% are due to customer side faults. We also studied the general diagnosis process and the commonly adopted mitigation solutions. Our findings can help improve current development and maintenance practice of Big Data computing platform, and motivate tool support.","","","10.1109/ICSE.2015.130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202945","","Big data;Hardware;Electronic mail;Iron;Software engineering;Business;Programming","Big Data;software quality","production Big Data computing platform;service quality;Microsoft ProductA;multitenant Big Data computing platform;incident management process;hardware faults;system side defects;customer side faults","","7","30","","","","","IEEE","IEEE Conferences"
"An Empirical Study on Real Bug Fixes","H. Zhong; Z. Su","Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China; Univ. of California, Davis, Davis, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","913","923","Software bugs can cause significant financial loss and even the loss of human lives. To reduce such loss, developers devote substantial efforts to fixing bugs, which generally requires much expertise and experience. Various approaches have been proposed to aid debugging. An interesting recent research direction is automatic program repair, which achieves promising results, and attracts much academic and industrial attention. However, people also cast doubt on the effectiveness and promise of this direction. A key criticism is to what extent such approaches can fix real bugs. As only research prototypes for these approaches are available, it is infeasible to address the criticism by evaluating them directly on real bugs. Instead, in this paper, we design and develop BUGSTAT, a tool that extracts and analyzes bug fixes. With BUGSTAT's support, we conduct an empirical study on more than 9,000 real-world bug fixes from six popular Java projects. Comparing the nature of manual fixes with automatic program repair, we distill 15 findings, which are further summarized into four insights on the two key ingredients of automatic program repair: fault localization and faulty code fix. In addition, we provide indirect evidence on the size of the search space to fix real bugs and find that bugs may also reside in non-source files. Our results provide useful guidance and insights for improving the state-of-the-art of automatic program repair.","","","10.1109/ICSE.2015.101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194637","","Computer bugs;Maintenance engineering;Java;Software;Shape;Manuals;Interference","Java;program debugging;search problems;software fault tolerance","bug fixing;software bugs;financial loss;debugging;automatic program repair;BUGSTAT;Java projects;fault localization;faulty code fix;search space","","35","45","","","","","IEEE","IEEE Conferences"
"On the Role of Value Sensitive Concerns in Software Engineering Practice","B. Barn; R. Barn; F. Raimondi","Sch. of Sci. & Technol., Middlesex Univ., London, UK; R. Holloway Univ. of London, Egham, UK; Sch. of Sci. & Technol., Middlesex Univ., London, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","497","500","The role of software systems on societal sustainability has generally not been the subject of substantive research activity. In this paper we examine the role of software engineering practice as an agent of change/impact for societal sustainability through the manifestation of value sensitive concerns. These concerns remain relatively neglected by software design processes except at early stages of user interface design. Here, we propose a conceptual model that can contribute to a translation of value sensitive design from its current focus in participatory design to one located in mainstream software engineering processes. Addressing this need will have an impact of societal sustainability and we outline some of the key research challenges for that journey.","","","10.1109/ICSE.2015.182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203000","Value Sensitive Design;Values;Co-Design;Requirements elicitation","Software engineering;Stakeholders;Unified modeling language;Privacy;Conferences;Computers;Computational modeling","social aspects of automation;software engineering;user interfaces","value sensitive concerns;software systems;societal sustainability;user interface design;value sensitive design;participatory design;mainstream software engineering processes","","9","22","","","","","IEEE","IEEE Conferences"
"Transparently Teaching in the Context of Game-based Learning: the Case of SimulES-W","E. S. Monsalve; J. C. S. d. P. Leite; V. M. B. Werneck","Dept. de Informdtica, Pontiticia Univ. Catdlica do Rio de Janeiro, Rio de Janeiro, Brazil; NA; Dept. de Inf. e Cienc. da Computacau, Univ. do Estado do Rio de Janeiro, Rio de Janeiro, Brazil","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","343","352","This work presents a pedagogical proposal, in the context of game-based learning (GBL), that uses the concept of Transparency Pedagogy. As such, it aims to improve the quality of teaching, and the relationship between student, teacher and teaching methods. Transparency is anchored in the principle of information disclosure. In pedagogy, transparency emerges as an important issue that proposes to raise student awareness about the educational processes. Using GBL as an educational strategy we managed to make the game, a software, transparent. That is we made the inner processes of the game known to the students. As such, besides learning by playing, students had access to the game design, through intentional modeling. We collected evidence that, by disclosure of the information about the design, students better performed on learning software engineering.","","","10.1109/ICSE.2015.167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202984","Transparency;Games-based Learning;SimulES-W;Pedagogy","","computer aided instruction;computer games;software engineering","game-based learning;SimulES-W;GBL;transparency pedagogy;educational process;educational strategy;learning software engineering","","4","40","","","","","IEEE","IEEE Conferences"
"Learning Combinatorial Interaction Test Generation Strategies Using Hyperheuristic Search","Y. Jia; M. B. Cohen; M. Harman; J. Petke","Univ. Coll. London, London, UK; Univ. of Nebraska-Lincoln, Lincoln, NE, USA; Univ. Coll. London, London, UK; Univ. Coll. London, London, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","540","550","The surge of search based software engineering research has been hampered by the need to develop customized search algorithms for different classes of the same problem. For instance, two decades of bespoke Combinatorial Interaction Testing (CIT) algorithm development, our exemplar problem, has left software engineers with a bewildering choice of CIT techniques, each specialized for a particular task. This paper proposes the use of a single hyperheuristic algorithm that learns search strategies across a broad range of problem instances, providing a single generalist approach. We have developed a Hyperheuristic algorithm for CIT, and report experiments that show that our algorithm competes with known best solutions across constrained and unconstrained problems: For all 26 real-world subjects, it equals or outperforms the best result previously reported in the literature. We also present evidence that our algorithm's strong generic performance results from its unsupervised learning. Hyperheuristic search is thus a promising way to relocate CIT design intelligence from human to machine.","","","10.1109/ICSE.2015.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194604","Hyperheuristic;CIT;SBSE","Arrays;Search problems;Heuristic algorithms;Simulated annealing;Software algorithms;Algorithm design and analysis;Testing","program testing;software engineering;unsupervised learning","combinatorial interaction test generation strategies;hyperheuristic search strategies;search based software engineering;CIT algorithm development;unsupervised learning","","28","40","","","","","IEEE","IEEE Conferences"
"Helping Developers Help Themselves: Automatic Decomposition of Code Review Changesets","M. Barnett; C. Bird; J. Brunet; S. K. Lahiri","Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Fed. Univ. of Campina Grande, Campina Grande, Brazil; Microsoft Res., Redmond, WA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","134","144","Code Reviews, an important and popular mechanism for quality assurance, are often performed on a change set, a set of modified files that are meant to be committed to a source repository as an atomic action. Understanding a code review is more difficult when the change set consists of multiple, independent, code differences. We introduce CLUSTERCHANGES, an automatic technique for decomposing change sets and evaluate its effectiveness through both a quantitative analysis and a qualitative user study.","","","10.1109/ICSE.2015.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194568","","Prototypes;Histograms;Quality assurance;Manuals;Software;Computer bugs;Standards","software quality;software reviews;source code (software)","software development;code review changeset;quality assurance;CLUSTERCHANGES;automatic decomposition technique","","34","28","","","","","IEEE","IEEE Conferences"
"Automatic Documentation Generation via Source Code Summarization","P. W. McBurney","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","903","906","Programmers need software documentation. However, documentation is expensive to produce and maintain, and often becomes outdated over time. Programmers often lack the time and resources to write documentation. Therefore, automated solutions are desirable. Designers of automatic documentation tools are limited because there is not yet a clear understanding of what characteristics are important to generating high quality summaries. I propose three specific research objectives to improving automatic documentation generation. I propose to study the similarity between source code and summary. Second, I propose studying whether or not including contextual information about source code improves summary quality. Finally, I propose to study the problem of similarity in source code structure and source code documentation. This paper discusses my work on these three objectives towards my Ph.D. dissertation, including my preliminary and proposed work.","","","10.1109/ICSE.2015.288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203110","source code summarization;automatic documentation;software engineering","Documentation;Software;Java;Context;Natural languages;Semantics;Measurement","software quality;source code (software);system documentation","source code summarization;software documentation;programmers;automatic documentation tools;automatic documentation generation;summary quality;source code structure similarity;source code documentation","","1","31","","","","","IEEE","IEEE Conferences"
"Presence-Condition Simplification in Highly Configurable Systems","A. v. Rhein; A. Grebhahn; S. Apel; N. Siegmund; D. Beyer; T. Berger","NA; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Univ. of Waterloo, Waterloo, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","178","188","For the analysis of highly configurable systems, analysis approaches need to take the inherent variability of these systems into account. The notion of presence conditions is central to such approaches. A presence condition specifies a subset of system configurations in which a certain artifact or a concern of interest is present (e.g., a defect associated with this subset). In this paper, we introduce and analyze the problem of presence-condition simplification. A key observation is that presence conditions often contain redundant information, which can be safely removed in the interest of simplicity and efficiency. We present a formalization of the problem, discuss application scenarios, compare different algorithms for solving the problem, and empirically evaluate the algorithms by means of a set of substantial case studies.","","","10.1109/ICSE.2015.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194572","","Electronic mail;Context;Data structures;Boolean functions;Cryptography;Size measurement;Algorithm design and analysis","program diagnostics","presence-condition simplification;highly configurable systems analysis;systems variability;presence conditions notion;system configuration","","10","48","","","","","IEEE","IEEE Conferences"
"Systematic Testing of Reactive Software with Non-Deterministic Events: A Case Study on LG Electric Oven","Y. Park; S. Hong; M. Kim; D. Lee; J. Cho","CS Dept., KAIST, Daejeon, South Korea; CS Dept., KAIST, Daejeon, South Korea; CS Dept., KAIST, Daejeon, South Korea; LG Electron., Seoul, South Korea; LG Electron., Seoul, South Korea","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","29","38","Most home appliance devices such as electric ovens are reactive systems which repeat receiving a user input/event through an event handler, updating their internal state based on the input, and generating outputs. A challenge to test a reactive program is to check if the program correctly reacts to various non-deterministic sequence of events because an unexpected sequence of events may make the system fail due to the race conditions between the main loop and asynchronous event handlers. Thus, it is important to systematically generate/test various sequences of events by controlling the order of events and relative timing of event occurrences with respect to the main loop execution. In this paper, we report our industrial experience to solve the aforementioned problem by developing a systematic event generation framework based on concolic testing technique. We have applied the framework to a LG electric oven and detected several critical bugs including one that makes the oven ignore user inputs due to the illegal state transition.","","","10.1109/ICSE.2015.132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202947","","Ovens;Probes;Software;Testing;Light emitting diodes;Systematics;Computer bugs","electrical engineering computing;ovens;program debugging;program testing","systematic reactive software testing;nondeterministic events;LG electric oven;home appliance devices;reactive systems;user input-event;event handler;nondeterministic events sequence;asynchronous event handlers;main loop execution;systematic event generation framework;concolic testing technique;critical bugs;illegal state transition","","1","17","","","","","IEEE","IEEE Conferences"
"Comparing Software Architecture Recovery Techniques Using Accurate Dependencies","T. Lutellier; D. Chollak; J. Garcia; L. Tan; D. Rayside; N. Medvidovic; R. Kroeger","Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Waterloo, Waterloo, ON, Canada; George Mason Univ., Fairfax, VA, USA; Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Waterloo, Waterloo, ON, Canada; Univ. of Southern California, Los Angeles, CA, USA; Google, Waterloo, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","69","78","Many techniques have been proposed to automatically recover software architectures from software implementations. A thorough comparison among the recovery techniques is needed to understand their effectiveness and applicability. This study improves on previous studies in two ways. First, we study the impact of leveraging more accurate symbol dependencies on the accuracy of architecture recovery techniques. Previous studies have not seriously considered how the quality of the input might affect the quality of the output for architecture recovery techniques. Second, we study a system (Chromium) that is substantially larger (9.7 million lines of code) than those included in previous studies. Obtaining the ground-truth architecture of Chromium involved two years of collaboration with its developers. As part of this work we developed a new sub module-based technique to recover preliminary versions of ground-truth architectures. The other systems that we study have been examined previously. In some cases, we have updated the ground-truth architectures to newer versions, and in other cases we have corrected newly discovered inconsistencies. Our evaluation of nine variants of six state-of-the-art architecture recovery techniques shows that symbol dependencies generally produce architectures with higher accuracies than include dependencies. Despite this improvement, the overall accuracy is low for all recovery techniques. The results suggest that (1) in addition to architecture recovery techniques, the accuracy of dependencies used as their inputs is another factor to consider for high recovery accuracy, and (2) more accurate recovery techniques are needed. Our results show that some of the studied architecture recovery techniques scale to the 10M lines-of-code range (the size of Chromium), whereas others do not.","","","10.1109/ICSE.2015.136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202951","","Computer architecture;Accuracy;Chromium;Software;Clustering algorithms;Java;Software architecture","software architecture;software quality","software architecture recovery techniques;accurate symbol dependency;chromium ground-truth architecture;submodule-based technique;software quality","","21","33","","","","","IEEE","IEEE Conferences"
"Trivial Compiler Equivalence: A Large Scale Empirical Study of a Simple, Fast and Effective Equivalent Mutant Detection Technique","M. Papadakis; Y. Jia; M. Harman; Y. Le Traon","Interdiscipl. Centre for Security, Reliability & Trust, Univ. of Luxembourg, Luxembourg, Luxembourg; CREST Centre, Univ. Coll. London, London, UK; CREST Centre, Univ. Coll. London, London, UK; Interdiscipl. Centre for Security, Reliability & Trust, Univ. of Luxembourg, Luxembourg, Luxembourg","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","936","946","Identifying equivalent mutants remains the largest impediment to the widespread uptake of mutation testing. Despite being researched for more than three decades, the problem remains. We propose Trivial Compiler Equivalence (TCE) a technique that exploits the use of readily available compiler technology to address this long-standing challenge. TCE is directly applicable to real-world programs and can imbue existing tools with the ability to detect equivalent mutants and a special form of useless mutants called duplicated mutants. We present a thorough empirical study using 6 large open source programs, several orders of magnitude larger than those used in previous work, and 18 benchmark programs with hand-analysis equivalent mutants. Our results reveal that, on large real-world programs, TCE can discard more than 7% and 21% of all the mutants as being equivalent and duplicated mutants respectively. A human- based equivalence verification reveals that TCE has the ability to detect approximately 30% of all the existing equivalent mutants.","","","10.1109/ICSE.2015.103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194639","","Optimization;Java;Scalability;Benchmark testing;Syntactics","formal verification;program compilers;program testing","trivial compiler equivalence technology;mutant detection technique;mutation testing;TCE technique;duplicated mutants;human-based equivalence verification","","55","58","","","","","IEEE","IEEE Conferences"
"Enabling the Definition and Enforcement of Governance Rules in Open Source Systems","J. L. C√°novas Izquierdo; J. Cabot","NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","505","514","Governance rules in software development projects help to prioritize and manage their development tasks, and contribute to the long-term sustainability of the project by clarifying how core and external contributors should collaborate in order to advance the project during its whole lifespan. Despite their importance, specially in Open Source Software (OSS) projects, these rules are usually implicit or scattered in the project documentation/tools (e.g., Tracking-systems or forums), hampering the correct understanding of the development process. We propose to enable the explicit definition and enforcement of governance rules for OSS projects. We believe this brings several important benefits, including improvements in the transparency of the process, its traceability and the semi-automation of the governance itself. Our approach has been implemented on top of My Lyn, a project-management Eclipse plug-in supporting most popular tracking-systems.","","","10.1109/ICSE.2015.184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203002","governance;open source systems;sustainability","Documentation;Software;Computer bugs;DSL;Software engineering;Syntactics;Organizations","public domain software;software engineering","governance rules;software development projects;long-term sustainability;open source software projects;OSS projects;My Lyn;project-management;Eclipse plug-in","","","29","","","","","IEEE","IEEE Conferences"
"Contest Based Learning with Blending Software Engineering and Business Management: For Students' High Motivation and High Practice Ability","N. Hanakawa","Fac. of Inf. Manage., Hannan Univ., Matsubara, Japan","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","360","369","We began implementing contest-based learning with a blend of software engineering and business management 10 years ago. At first, a project subject was assigned. However, several problems occurred: For example, the students became absorbed in programming rather than design and analysis activities. Therefore, the curriculum changed from project subjects to contest-based learning. Business management, marketing, and accounting subjects were added to the new curriculum, and students made information technology (IT) business plans using their knowledge of software engineering and business management. The IT business plans were submitted to various contests held by public newspaper companies and the federation of economic organizations in Japan. As a result, in the 10 years of the contest-based learning implementation, 20 teams have received awards in various IT business plan contests. We investigated 10 persons who had experience submitting business plans. We confirmed that contest-based learning had clearer goals, such as to win the contest prize, compared to project-based learning. Further, the abilities to solve problems and to investigate increased more in comparison with lecture-style and project-style education.","","","10.1109/ICSE.2015.340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202986","Contest;IT business plan;blending education;marketing;accounting;business management","Software;Education;Software engineering;Programming profession;Companies","computer science education;human factors;management accounting;management education;marketing;software engineering","contest based learning;blending software engineering;business management;student high motivation;high practice ability;accounting subjects;marketing;information technology;IT business plans;project-based learning;project-style education;lecture-style education","","1","10","","","","","IEEE","IEEE Conferences"
"Code Hunt: Experience with Coding Contests at Scale","J. Bishop; R. N. Horspool; T. Xie; N. Tillmann; J. d. Halleux","Microsoft Res., Redmond, WA, USA; Univ. of Victoria, Victoria, BC, Canada; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Jonathan de Halleux Microsoft Res., Redmond, WA, USA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","398","407","Mastering a complex skill like programming takes many hours. In order to encourage students to put in these hours, we built Code Hunt, a game that enables players to program against the computer with clues provided as unit tests. The game has become very popular and we are now running worldwide contests where students have a fixed amount of time to solve a set of puzzles. This paper describes Code Hunt and the contest experience it offers. We then show some early results that demonstrate how Code Hunt can accurately discriminate between good and bad coders. The challenges of creating and selecting puzzles for contests are covered. We end up with a short description of our course experience, and some figures that show that Code Hunt is enjoyed by women and men alike.","","","10.1109/ICSE.2015.172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202990","Programming contests;unit tests;symbolic execution;Code Hunt game","Games;Encoding;Joints;Training;Algorithm design and analysis;Programming profession","computer aided instruction;computer games;computer science education;programming","programming skill;Code Hunt game;contest experience;coding contest","","19","20","","","","","IEEE","IEEE Conferences"
"Chiminey: Reliable Computing and Data Management Platform in the Cloud","I. I. Yusuf; I. E. Thomas; M. Spichkova; S. Androulakis; G. R. Meyer; D. W. Drumm; G. Opletal; S. P. Russo; A. M. Buckle; H. W. Schmidt","Appl. Data Sci., Australia; RMIT Univ., Melbourne, VIC, Australia; RMIT Univ., Melbourne, VIC, Australia; Monash Univ., Melbourne, VIC, Australia; Monash Univ., Melbourne, VIC, Australia; RMIT Univ., Melbourne, VIC, Australia; RMIT Univ., Melbourne, VIC, Australia; RMIT Univ., Melbourne, VIC, Australia; Monash Univ., Melbourne, VIC, Australia; RMIT Univ., Melbourne, VIC, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","677","680","The enabling of scientific experiments that are embarrassingly parallel, long running and data-intensive into a cloud-based execution environment is a desirable, though complex undertaking for many researchers. The management of such virtual environments is cumbersome and not necessarily within the core skill set for scientists and engineers. We present here Chiminey, a software platform that enables researchers to (i) run applications on both traditional high-performance computing and cloud-based computing infrastructures, (ii) handle failure during execution, (iii) curate and visualise execution outputs, (iv) share such data with collaborators or the public, and (v) search for publicly available data.","","","10.1109/ICSE.2015.221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203041","Cloud computing;HPC;reliability;fault tolerance;data management;data curation;data publication;data discovery;visualisation","Data visualization;Connectors;Cloud computing;Fault tolerance;Fault tolerant systems;Physics","cloud computing;data handling;parallel processing;software reliability;virtualisation","Chiminey;software platform;software reliability;data management platform;cloud-based computing infrastructure;high-performance computing;virtual environment","","12","13","","","","","IEEE","IEEE Conferences"
"From Developer Networks to Verified Communities: A Fine-Grained Approach","M. Joblin; W. Mauerer; S. Apel; J. Siegmund; D. Riehle","Siemens AG, Erlangen, Germany; OTH Regensburg, Siemens AG, Regensburg, Germany; Univ. of Passau, Passau, Germany; Univ. of Passau, Passau, Germany; Friedrich-Alexander-Univ., Erlangen, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","563","573","Effective software engineering demands a coordinated effort. Unfortunately, a comprehensive view on developer coordination is rarely available to support software-engineering decisions, despite the significant implications on software quality, software architecture, and developer productivity. We present a fine-grained, verifiable, and fully automated approach to capture a view on developer coordination, based on commit information and source-code structure, mined from version-control systems. We apply methodology from network analysis and machine learning to identify developer communities automatically. Compared to previous work, our approach is fine-grained, and identifies statistically significant communities using order-statistics and a community-verification technique based on graph conductance. To demonstrate the scalability and generality of our approach, we analyze ten open-source projects with complex and active histories, written in various programming languages. By surveying 53 open-source developers from the ten projects, we validate the authenticity of inferred community structure with respect to reality. Our results indicate that developers of open-source projects form statistically significant community structures and this particular view on collaboration largely coincides with developers' perceptions of real-world collaboration.","","","10.1109/ICSE.2015.73","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194606","","Collaboration;Open source software;Measurement;Computer languages;Standards;Software systems","configuration management;graph theory;learning (artificial intelligence);software architecture;software quality;source code (software);statistics","software developer networks;software engineering;software developer coordination;software quality;software architecture;software developer productivity;source-code structure;version-control systems;network analysis;machine learning;order-statistics;community-verification technique;graph conductance","","19","34","","","","","IEEE","IEEE Conferences"
"Alloy*: A General-Purpose Higher-Order Relational Constraint Solver","A. Milicevic; J. P. Near; E. Kang; D. Jackson","Massachusetts Inst. of Technol., Cambridge, MA, USA; Massachusetts Inst. of Technol., Cambridge, MA, USA; Massachusetts Inst. of Technol., Cambridge, MA, USA; Massachusetts Inst. of Technol., Cambridge, MA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","609","619","The last decade has seen a dramatic growth in the use of constraint solvers as a computational mechanism, not only for analysis of software, but also at runtime. Solvers are available for a variety of logics but are generally restricted to first-order formulas. Some tasks, however, most notably those involving synthesis, are inherently higher order; these are typically handled by embedding a first-order solver (such as a SAT or SMT solver) in a domain-specific algorithm. Using strategies similar to those used in such algorithms, we show how to extend a first-order solver (in this case Kodkod, a model finder for relational logic used as the engine of the Alloy Analyzer) so that it can handle quantifications over higher-order structures. The resulting solver is sufficiently general that it can be applied to a range of problems; it is higher order, so that it can be applied directly, without embedding in another algorithm; and it performs well enough to be competitive with specialized tools. Just as the identification of first-order solvers as reusable backends advanced the performance of specialized tools and simplified their architecture, factoring out higher-order solvers may bring similar benefits to a new class of tools.","","","10.1109/ICSE.2015.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194610","alloy;constraint solving;higher-order","Metals;Syntactics;Semantics;Data structures;Boolean functions;Concrete;Engines","constraint handling","general-purpose higher-order relational constraint solver;software analysis;runtime analysis;first-order solver;domain-specific algorithm;Kodkod model;relational logic;Alloy Analyzer engine","","31","43","","","","","IEEE","IEEE Conferences"
"Lightweight Adaptive Filtering for Efficient Learning and Updating of Probabilistic Models","A. Filieri; L. Grunske; A. Leva","Univ. of Stuttgart, Stuttgart, Germany; Univ. of Stuttgart, Stuttgart, Germany; Politec. di Milano, Milan, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","200","211","Adaptive software systems are designed to cope with unpredictable and evolving usage behaviors and environmental conditions. For these systems reasoning mechanisms are needed to drive evolution, which are usually based on models capturing relevant aspects of the running software. The continuous update of these models in evolving environments requires efficient learning procedures, having low overhead and being robust to changes. Most of the available approaches achieve one of these goals at the price of the other. In this paper we propose a lightweight adaptive filter to accurately learn time-varying transition probabilities of discrete time Markov models, which provides robustness to noise and fast adaptation to changes with a very low overhead. A formal stability, unbiasedness and consistency assessment of the learning approach is provided, as well as an experimental comparison with state-of-the-art alternatives.","","","10.1109/ICSE.2015.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194574","","Estimation;Noise;Asymptotic stability;Markov processes;Current measurement;Probabilistic logic;Robustness","adaptive filters;learning (artificial intelligence);Markov processes;mathematics computing;signal denoising","lightweight adaptive filtering;probabilistic model learning;probabilistic model updating;adaptive software systems;reasoning mechanisms;learning procedures;discrete time Markov models;time-varying transition probabilities;learning approach","","20","48","","","","","IEEE","IEEE Conferences"
"Striving for Failure: An Industrial Case Study about Test Failure Prediction","J. Anderson; S. Salem; H. Do","NA; NA; NA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","49","58","Software regression testing is an important, yet very costly, part of most major software projects. When regression tests run, any failures that are found help catch bugs early and smooth the future development work. The act of executing large numbers of tests takes significant resources that could, otherwise, be applied elsewhere. If tests could be accurately classified as likely to pass or fail prior to the run, it could save significant time while maintaining the benefits of early bug detection. In this paper, we present a case study to build a classifier for regression tests based on industrial software, Microsoft Dynamics AX. In this study, we examine the effectiveness of this classification as well as which aspects of the software are the most important in predicting regression test failures.","","","10.1109/ICSE.2015.134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202949","Test failure prediction;data-mining software repositories;regression testing;case study","Software;Predictive models;Complexity theory;History;Prediction algorithms;Testing;Software engineering","pattern classification;program testing;regression analysis;software reliability","regression test failure prediction;software regression testing;software projects;early bug detection;Microsoft Dynamics AX industrial software;software classification","","5","26","","","","","IEEE","IEEE Conferences"
"Merits of Organizational Metrics in Defect Prediction: An Industrial Replication","B. Caglayan; B. Turhan; A. Bener; M. Habayeb; A. Miransky; E. Cialini","Dept. of Math., Ryerson Univ., Toronto, ON, Canada; Dept. of Inf. Process. Sci., Univ. of Oulu, Oulu, Finland; Mech. & Ind. Eng., Ryerson Univ., Toronto, ON, Canada; Mech. & Ind. Eng., Ryerson Univ., Toronto, ON, Canada; Dept. of Comput. Sci., Ryerson Univ., Toronto, ON, Canada; IBM Toronto Software Lab., Toronto, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","89","98","Defect prediction models presented in the literature lack generalization unless the original study can be replicated using new datasets and in different organizational settings. Practitioners can also benefit from replicating studies in their own environment by gaining insights and comparing their findings with those reported. In this work, we replicated an earlier study in order to investigate the merits of organizational metrics in building defect prediction models for large-scale enterprise software. We mined the organizational, code complexity, code churn and pre-release bug metrics of that large scale software and built defect prediction models for each metric set. In the original study, organizational metrics were found to achieve the highest performance. In our case, models based on organizational metrics performed better than models based on churn metrics but were outperformed by pre-release metric models. Further, we verified four individual organizational metrics as indicators for defects. We conclude that the performance of different metric sets in building defect prediction models depends on the project's characteristics and the targeted prediction level. Our replication of earlier research enabled assessing the validity and limitations of organizational metrics in a different context.","","","10.1109/ICSE.2015.138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202953","software engineering;replication;organizational metrics;defect prediction;model comparison","Measurement;Software;Organizations;Software engineering;Predictive models;Context;Principal component analysis","software metrics;software reliability","organizational metrics;defect prediction models;large-scale enterprise software;organizational metric;code complexity metric;code churn metric;pre-release bug metric","","8","25","","","","","IEEE","IEEE Conferences"
"SOA4DM: Applying an SOA Paradigm to Coordination in Humanitarian Disaster Response","K. Lyons; C. Oh","Fac. of Inf., Univ. of Toronto, Toronto, ON, Canada; Fac. of Inf., Univ. of Toronto, Toronto, ON, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","519","522","Despite efforts to achieve a sustainable state of control over the management of global crises, disasters are occurring with greater frequency, intensity, and affecting many more people than ever before while the resources to deal with them do not grow apace. As we enter 2015, with continued concerns that mega-crises may become the new normal, we need to develop novel methods to improve the efficiency and effectiveness of our management of disasters. Software engineering as a discipline has long had an impact on society beyond its role in the development of software systems. In fact, software engineers have been described as the developers of prototypes for future knowledge workers; tools such as Github and Stack Overflow have demonstrated applications beyond the domain of software engineering. In this paper, we take the potential influence of software engineering one-step further and propose using the software service engineering paradigm as a new approach to managing disasters. Specifically, we show how the underlying principles of service-oriented architectures (SOA) can be applied to the coordination of disaster response operations. We describe key challenges in coordinating disaster response and discuss how an SOA approach can address those challenges.","","","10.1109/ICSE.2015.186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203004","SOA;Disaster Response","Societies;Software engineering;Communities;Conferences;Indexes;Economics;Semiconductor optical amplifiers","emergency management;service-oriented architecture","SOA4DM;SOA paradigm;humanitarian disaster response;sustainable state;global crises management;disaster management;efficiency improvement;effectiveness improvement;software system development;knowledge workers;github overflow;stack overflow;software service engineering paradigm;service-oriented architectures;disaster response operation coordination","","1","34","","","","","IEEE","IEEE Conferences"
"The Development of a Dashboard Tool for Visualising Online Teamwork Discussions","R. Vivian; H. Tarmazdi; K. Falkner; N. Falkner; C. Szabo","Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","380","388","Many software development organisations today adopt global software engineering (GSE) and agile models, requiring software engineers to collaborate and develop software in flexible, distributed, online teams. However, many employers have expressed concern that graduates lack teamwork skills and one of the most commonly occurring problems with GSE models are issues with project management. Team managers and educators often oversee a number of teams and the large corpus of data, in combination with agile models, make it difficult to efficiently assess factors such as team role distribution and emotional climate. Current methods and tools for monitoring software engineering (SE) teamwork in both industry and education settings typically focus on member contributions, reflection, or product outcomes, which are limited in terms of real-time feedback and accurate behavioural analysis. We have created a dashboard that extracts and communicates team role distribution and team emotion information in real-time. Our proof of concept provides a real-time analysis of teamwork discussions and visualises team member emotions, the roles they have adopted and overall team sentiment during the course of a collaborative problem-solving project. We demonstrate and discuss how such a tool could be useful for SE team management and training and the development of teamwork skills in SE university courses.","","","10.1109/ICSE.2015.170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202988","","Teamwork;Software;Monitoring;Training;Industries","computer science education;data visualisation;groupware;project management;software development management;software prototyping;software tools","SE university courses;teamwork skill development;training;SE team management;collaborative problem-solving project;real-time analysis;behavioural analysis;real-time feedback;software engineering teamwork monitoring;emotional climate;team role distribution;project management;agile models;GSE;global software engineering;software development organisations;online teamwork discussion visualisation;dashboard tool development","","7","41","","","","","IEEE","IEEE Conferences"
"Active and Inductive Learning in Software Engineering Education","Y. Sedelmaier; D. Landes","Fac. of Electr. Eng. & Inf., Univ. of Appl. Sci. & Arts, Coburg, Germany; Fac. of Electr. Eng. & Inf., Univ. of Appl. Sci. & Arts, Coburg, Germany","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","418","427","If software engineering education is done in a traditional lecture-oriented style students have no other choice than believing that the solutions they are told actually work for a problem that they never encountered themselves. In order to overcome this problem, this paper describes an approach which allows students to better understand why software engineering and several of its core methods and techniques are needed, thus preparing them better for their professional life. This approach builds on active and inductive learning. Exercises that make students actively discover relevant software engineering issues are described in detail together with their pedagogical underpinning.","","","10.1109/ICSE.2015.174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202992","software engineering education;didactical approach;inductive learning;active learning;higher education","Software;Education;Programming profession;Vehicles;Capability maturity model","computer science education;software engineering","inductive learning;active learning;software engineering education;lecture-oriented style students","","10","20","","","","","IEEE","IEEE Conferences"
"Database-Backed Program Analysis for Scalable Error Propagation","C. Weiss; C. Rubio-Gonz√°lez; B. Liblit","NA; Univ. of California, Davis, Davis, CA, USA; Univ. of Wisconsin - Madison, Madison, WI, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","586","597","Software is rapidly increasing in size and complexity. Static analyses must be designed to scale well if they are to be usable with realistic applications, but prior efforts have often been limited by available memory. We propose a database-backed strategy for large program analysis based on graph algorithms, using a Semantic Web database to manage representations of the program under analysis. Our approach is applicable to a variety of interprocedural finite distributive subset (IFDS) dataflow problems; we focus on error propagation as a motivating example. Our implementation analyzes multi-million-line programs quickly and in just a fraction of the memory required by prior approaches. When memory alone is insufficient, our approach falls back on disk using several hybrid configurations tuned to put all available resources to good use.","","","10.1109/ICSE.2015.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194608","","Databases;Scalability;Linux;Pattern matching;Memory management;Kernel","data flow computing;graph theory;program diagnostics;semantic Web","database-backed program analysis;error propagation;static analyses;database-backed strategy;graph algorithms;semantic Web database;program representation management;interprocedural finite distributive subset dataflow problems;IFDS dataflow problems;multimillion-line programs","","6","75","","","","","IEEE","IEEE Conferences"
"Compositional Symbolic Execution with Memoized Replay","R. Qiu; G. Yang; C. S. Pasareanu; S. Khurshid","Univ. of Texas, Austin, TX, USA; Texas State Univ., San Marcos, TX, USA; NASA Ames Res. Center, Carnegie Mellon Univ., Moffett Field, CA, USA; Univ. of Texas, Austin, TX, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","632","642","Symbolic execution is a powerful, systematic analysis that has received much visibility in the last decade. Scalability however remains a major challenge for symbolic execution. Compositional analysis is a well-known general purpose methodology for increasing scalability. This paper introduces a new approach for compositional symbolic execution. Our key insight is that we can summarize each analyzed method as a memoization tree that captures the crucial elements of symbolic execution, and leverage these memoization trees to efficiently replay the symbolic execution of the corresponding methods with respect to their calling contexts. Memoization trees offer a natural way to compose in the presence of heap operations, which cannot be dealt with by previous work that uses logical formulas as summaries for compositional symbolic execution. Our approach also enables efficient target oriented symbolic execution for error detection or program coverage. Initial experimental evaluation based on a prototype implementation in Symbolic Path Finder shows that our approach can be up to an order of magnitude faster than traditional non-compositional symbolic execution.","","","10.1109/ICSE.2015.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194612","","Context;Concrete;Scalability;Systematics;Data structures;Prototypes","error detection;program diagnostics;trees (mathematics)","compositional symbolic execution;memoized replay;memoization trees;heap operations;target oriented symbolic execution;error detection;program coverage;symbolic path finder","","12","25","","","","","IEEE","IEEE Conferences"
"Supporting Selective Undo in a Code Editor","Y. Yoon; B. A. Myers","Inst. for Software Res., Carnegie Mellon Univ., Pittsburgh, PA, USA; Human-Comput. Interaction Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","223","233","Programmers often need to revert some code to an earlier state, or restore a block of code that was deleted a while ago. However, support for this backtracking in modern programming environments is limited. Many of the backtracking tasks can be accomplished by having a selective undo feature in code editors, but this has major challenges: there can be conflicts among edit operations, and it is difficult to provide usable interfaces for selective undo. In this paper, we present AZURITE, an Eclipse plug-in that allows programmers to selectively undo fine-grained code changes made in the code editor. With AZURITE, programmers can easily perform backtracking tasks, even when the desired code is not in the undo stack or a version control system. AZURITE also provides novel user interfaces specifically designed for selective undo, which were iteratively improved through user feedback gathered from actual users in a preliminary field trial. A formal lab study showed that programmers can successfully use AZURITE, and were twice as fast as when limited to conventional features.","","","10.1109/ICSE.2015.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194576","selective undo;backtracking","History;Layout;Encoding;Control systems;Graphical user interfaces","programming environments;text editing;user interfaces","selective undo;code editor;programming environments;backtracking tasks;AZURITE;Eclipse plug-in;user interfaces;user feedback","","19","39","","","","","IEEE","IEEE Conferences"
"An Information Retrieval Approach for Regression Test Prioritization Based on Program Changes","R. K. Saha; L. Zhang; S. Khurshid; D. E. Perry","Electr. & Comput. Eng., Univ. of Texas at Austin, Austin, TX, USA; Dept. of Comput. Sci., Univ. of Texas at Dallas, Dallas, TX, USA; Electr. & Comput. Eng., Univ. of Texas at Austin, Austin, TX, USA; Electr. & Comput. Eng., Univ. of Texas at Austin, Austin, TX, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","268","279","Regression testing is widely used in practice for validating program changes. However, running large regression suites can be costly. Researchers have developed several techniques for prioritizing tests such that the higher-priority tests have a higher likelihood of finding bugs. A vast majority of these techniques are based on dynamic analysis, which can be precise but can also have significant overhead (e.g., for program instrumentation and test-coverage collection). We introduce a new approach, REPiR, to address the problem of regression test prioritization by reducing it to a standard Information Retrieval problem such that the differences between two program versions form the query and the tests constitute the document collection. REPiR does not require any dynamic profiling or static program analysis. As an enabling technology we leverage the open-source IR toolkit Indri. An empirical evaluation using eight open-source Java projects shows that REPiR is computationally efficient and performs better than existing (dynamic or static) techniques for the majority of subject systems.","","","10.1109/ICSE.2015.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194580","Regression Testing;Test Prioritization;Information Retrieval","Software engineering;Information retrieval;Testing;Standards;Open source software;Natural languages","information retrieval;program debugging;program testing;public domain software;system monitoring","information retrieval approach;regression test prioritization;program changes;regression testing;regression suites;bugs;dynamic analysis;REPiR;open-source IR toolkit Indri;open-source Java projects","","25","67","","","","","IEEE","IEEE Conferences"
"Measuring Dependency Freshness in Software Systems","J. Cox; E. Bouwers; M. v. Eekelen; J. Visser","Inst. for Comput. & Inf. Sci., Radboud Univ. Nijmegen, Nijmegen, Netherlands; Software Improvement Group, Amsterdam, Netherlands; NA; Inst. for Comput. & Inf. Sci., Radboud Univ. Nijmegen, Nijmegen, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","109","118","Modern software systems often make use of third-party components to speed-up development and reduce maintenance costs. In return, developers need to update to new releases of these dependencies to avoid, for example, security and compatibility risks. In practice, prioritizing these updates is difficult because the use of outdated dependencies is often opaque. In this paper we aim to make this concept more transparent by introducing metrics to quantify the use of recent versions of dependencies, i.e. The system's ""dependency freshness"". We propose and investigate a system-level metric based on an industry benchmark. We validate the usefulness of the metric using interviews, analyze the variance of the metric through time, and investigate the relationship between outdated dependencies and security vulnerabilities. The results show that the measurements are considered useful, and that systems using outdated dependencies four times as likely to have security issues as opposed to systems that are up-to-date.","","","10.1109/ICSE.2015.140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202955","software metrics;software maintenance","Software engineering;Software systems;Security;Context;Industries;Software measurement","cost reduction;object-oriented programming;security of data;software maintenance;software metrics","dependency freshness measurement;software systems;third-party components;maintenance cost reduction;system-level metric;industry benchmark;outdated dependencies;security vulnerabilities","","12","15","","","","","IEEE","IEEE Conferences"
"Dementia and Social Sustainability: Challenges for Software Engineering","P. Sawyer; A. Sutcliffe; P. Rayson; C. Bull","Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK; Sch. of Comput. & Commun., Lancaster Univ., Lancaster, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","527","530","Dementia is a serious threat to social sustainability. As life expectancy increases, more people are developing dementia. At the same time, demographic change is reducing the economically active part of the population. Care of people with dementia imposes great emotional and financial strain on sufferers, their families and society at large. In response, significant research resources are being focused on dementia. One research thread is focused on using computer technology to monitor people in at-risk groups to improve rates of early diagnosis. In this paper we provide an overview of dementia monitoring research and identify a set of scientific challenges for the engineering of dementia-monitoring software, with implications for other mental health self-management systems.","","","10.1109/ICSE.2015.188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203006","Software engineering;Dementia;Social sustainability","Dementia;Monitoring;Software;Games;Computers;Software engineering","medical computing;social sciences computing;software engineering","software engineering;social sustainability;demographic change;computer technology;dementia monitoring research;mental health self-management systems","","5","24","","","","","IEEE","IEEE Conferences"
"CodeAware: Sensor-Based Fine-Grained Monitoring and Management of Software Artifacts","R. Abreu; H. Erdogmus; A. Perez","Palo Alto Res. Center, Palo Alto, CA, USA; Carnegie Mellon Univ. - Silicon Valley, Moffett Field, CA, USA; Palo Alto Res. Center, Palo Alto, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","551","554","Current continuous integration (CI) tools, although extensible, can be limiting in terms of flexibility. In particular, artifact analysis capabilities available through plug in mechanisms are both coarse-grained and centralized. To address this limitation, this paper introduces a new paradigm, Code Aware, for distributed and fine-grained artifact analysis. Code Aware is an ecosystem inspired by sensor networks, consisting of monitors and actuators, aimed at improving code quality and team productivity. Code ware's vision entails (a) the ability to probe software artifacts of any granularity and localization, from variables to classes or files to entire systems, (b) the ability to perform both static and dynamic analyses on these artifacts, and (c) the ability to describe targeted remediation actions, for example to notify interested developers, through automated actuators. We provide motivational examples for the use of Code Aware that leverage current CI solutions, sketch the architecture of its underlying ecosystem, and outline research challenges.","","","10.1109/ICSE.2015.192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203010","","Probes;Software;Ecosystems;Software engineering;Monitoring;Electronic mail;DSL","productivity;program diagnostics;software quality","CodeAware;sensor-based fine-grained monitoring;software artifact management;continuous integration tools;CI tools;artifact analysis capabilities;plug in mechanisms;distributed artifact analysis;fine-grained artifact analysis;ecosystem;monitors;code quality improvement;team productivity improvement;static analysis;dynamic analysis;automated actuators","","5","9","","","","","IEEE","IEEE Conferences"
"Experiences in Developing and Delivering a Programme of Part-Time Education in Software and Systems Security","A. Simpson; A. Martin; C. Cremers; I. Flechais; I. Martinovic; K. Rasmussen","Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK; Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","435","444","We report upon our experiences in developing and delivering a programme of part-time education in Software and Systems Security at the University of Oxford. The MSc in Software and Systems Security is delivered as part of the Software Engineering Programme at Oxford - a collection of one-week intensive courses aimed at individuals who are responsible for the procurement, development, deployment and maintenance of large-scale software-based systems. We expect that our experiences will be useful to those considering a similar journey.","","","10.1109/ICSE.2015.176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202994","software engineering education;security education","Software engineering;Software;Education;Data privacy;Access control;Context","computer science education;educational courses;security of data;software maintenance","large-scale software-based systems;software maintenance;software deployment;software development;one-week intensive courses;software engineering programme;MSc;University of Oxford;systems security;software security;part-time education","","1","36","","","","","IEEE","IEEE Conferences"
"Combining Symbolic Execution and Model Checking for Data Flow Testing","T. Su; Z. Fu; G. Pu; J. He; Z. Su","Shanghai Key Lab. of Trustworthy Comput., East China Normal Univ., Shanghai, China; Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Shanghai Key Lab. of Trustworthy Comput., East China Normal Univ., Shanghai, China; Shanghai Key Lab. of Trustworthy Comput., East China Normal Univ., Shanghai, China; Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","654","665","Data flow testing (DFT) focuses on the flow of data through a program. Despite its higher fault-detection ability over other structural testing techniques, practical DFT remains a significant challenge. This paper tackles this challenge by introducing a hybrid DFT framework: (1) The core of our framework is based on dynamic symbolic execution (DSE), enhanced with a novel guided path search to improve testing performance, and (2) we systematically cast the DFT problem as reach ability checking in software model checking to complement our DSE-based approach, yielding a practical hybrid DFT technique that combines the two approaches' respective strengths. Evaluated on both open source and industrial programs, our DSE-based approach improves DFT performance by 60~80% in terms of testing time compared with state-of-the-art search strategies, while our combined technique further reduces 40% testing time and improves data-flow coverage by 20% by eliminating infeasible test objectives. This combined approach also enables the cross-checking of each component for reliable and robust testing results.","","","10.1109/ICSE.2015.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194614","symbolic execution;model checking;data flow coverage;data flow testing;coverage criteria","Search problems;Model checking;Discrete Fourier transforms;Software;Engines;Safety","data flow computing;formal verification;program testing;public domain software;software fault tolerance;software performance evaluation","data flow testing;fault-detection ability;structural testing;hybrid DFT framework;dynamic symbolic execution;DSE;guided path search;performance testing;software model checking;open source program;industrial program","","7","61","","","","","IEEE","IEEE Conferences"
"A Comprehensive Framework for the Development of Dynamic Smart Spaces","A. Shahzada","Dipt. di Elettron., Inf. e Bioingegneria, Politec. di Milano, Milan, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","927","930","The conception of reliable smart spaces requires a suitable and comprehensive framework for their design, implementation, testing, and deployment. Numerous solutions have been proposed to solve different aspects related to smart spaces, but we still lack a concrete framework that provides solutions suitable for the whole development life-cycle. This work aims to fill the gap and proposes a framework that provides: (i) well-defined abstractions for designing smart spaces, (ii) a middleware infrastructure to implement them and plug physical objects, (iii) a semantic layer to support heterogeneous elements, and (iv) plugs to integrate external simulators and be able to always work on ""complete'' systems in the different phases of the development.","","","10.1109/ICSE.2015.294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203116","","Buildings;Middleware;Conferences;Semantics;Intelligent sensors;Context","middleware","dynamic smart space development;development life-cycle;smart space designing;middleware infrastructure;semantic layer;heterogeneous elements;external simulators","","1","11","","","","","IEEE","IEEE Conferences"
"RECONTEST: Effective Regression Testing of Concurrent Programs","V. Terragni; S. Cheung; C. Zhang","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","246","256","Concurrent programs proliferate as multi-core technologies advance. The regression testing of concurrent programs often requires running a failing test for weeks before catching a faulty interleaving, due to the myriad of possible interleavings of memory accesses arising from concurrent program executions. As a result, the conventional approach that selects a sub-set of test cases for regression testing without considering interleavings is insufficient. In this paper we present RECONTEST to address the problem by selecting the new interleavings that arise due to code changes. These interleavings must be explored in order to uncover regression bugs. RECONTEST efficiently selects new interleavings by first identifying shared memory accesses that are affected by the changes, and then exploring only those problematic interleavings that contain at least one of these accesses. We have implemented RECONTEST as an automated tool and evaluated it using 13 real-world concurrent program subjects. Our results show that RECONTEST can significantly reduce the regression testing cost without missing any faulty interleavings induced by code changes.","","","10.1109/ICSE.2015.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194578","","Concurrent computing;Testing;Programming;Message systems;Synchronization;Computer bugs;Integrated circuits","concurrency control;program testing","RECONTEST framework;regression concurrency testing framework;concurrent programs;multicore technologies;memory access;regression bugs;shared memory access identification;code changes","","10","49","","","","","IEEE","IEEE Conferences"
"Do Security Patterns Really Help Designers?","K. Yskout; R. Scandariato; W. Joosen","iMinds-DistriNet, KU Leuven, Leuven, Belgium; iMinds-DistriNet, KU Leuven, Leuven, Belgium; iMinds-DistriNet, KU Leuven, Leuven, Belgium","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","292","302","Security patterns are well-known solutions to security-specific problems. They are often claimed to benefit designers without much security expertise. We have performed an empirical study to investigate whether the usage of security patterns by such an audience leads to a more secure design, or to an increased productivity of the designers. Our study involved 32 teams of master students enrolled in a course on software architecture, working on the design of a realistically-sized banking system. Irrespective of whether the teams were using security patterns, we have not been able to detect a difference between the two treatment groups. However, the teams prefer to work with the support of security patterns.","","","10.1109/ICSE.2015.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194582","","Security;Banking;Training;IEEE catalogs;Software;Context;Productivity","security of data;software architecture","security pattern;software design;software architecture;realistically-sized banking system","","16","20","","","","","IEEE","IEEE Conferences"
"Metamorphic Model-Based Testing Applied on NASA DAT -- An Experience Report","M. Lindvall; D. Ganesan; R. √Årdal; R. E. Wiegand","Fraunhofer USA Center for Exp. Software Eng. (CESE), MD, USA; Fraunhofer USA Center for Exp. Software Eng. (CESE), MD, USA; Fraunhofer USA Center for Exp. Software Eng. (CESE), MD, USA; NASA Goddard Space Flight Center, Greenbelt, MD, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","129","138","Testing is necessary for all types of systems, but becomes difficult when the tester cannot easily determine whether the system delivers the correct result or not. NASA's Data Access Toolkit allows NASA analysts to query a large database of telemetry data. Since the user is unfamiliar with the data and several data transformations can occur, it is impossible to determine whether the system behaves correctly or not in full scale production situations. Small scale testing was already conducted manually by other teams and unit testing was conducted on individual functions. However, there was still a need for full scale acceptance testing on a broad scale. We describe how we addressed this testing problem by applying the idea of metamorphic testing [1]. Specifically, we base it on equivalence of queries and by using the system itself for testing. The approach is implemented using a model-based testing approach in combination with a test data generation and test case outcome analysis strategy. We also discuss some of the issues that were detected using this approach.","","","10.1109/ICSE.2015.348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202957","","Testing;Databases;Grammar;Telemetry;NASA;Software engineering;Computational modeling","aerospace computing;program testing;query processing","metamorphic model-based testing;NASA DAT;systems testing;NASA data access toolkit;query;large database;telemetry data;data transformations;small scale testing;unit testing;full scale acceptance testing;test data generation;test case outcome analysis strategy","","27","12","","","","","IEEE","IEEE Conferences"
"Industry Practices and Event Logging: Assessment of a Critical Software Development Process","A. Pecchia; M. Cinque; G. Carrozza; D. Cotroneo","Dipt. di Ing. Elettr. e Tecnol. dell'Inf., Univ. degli Studi di Napoli Federico II, Naples, Italy; Dipt. di Ing. Elettr. e Tecnol. dell'Inf., Univ. degli Studi di Napoli Federico II, Naples, Italy; Selex ES S.p.A., Finmeccanica Co., Rome, Italy; Dipt. di Ing. Elettr. e Tecnol. dell'Inf., Univ. degli Studi di Napoli Federico II, Naples, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","169","178","Practitioners widely recognize the importance of event logging for a variety of tasks, such as accounting, system measurements and troubleshooting. Nevertheless, in spite of the importance of the tasks based on the logs collected under real workload conditions, event logging lacks systematic design and implementation practices. The implementation of the logging mechanism strongly relies on the human expertise. This paper proposes a measurement study of event logging practices in a critical industrial domain. We assess a software development process at Selex ES, a leading Finmeccanica company in electronic and information solutions for critical systems. Our study combines source code analysis, inspection of around 2.3 millions log entries, and direct feedback from the development team to gain process-wide insights ranging from programming practices, logging objectives and issues impacting log analysis. The findings of our study were extremely valuable to prioritize event logging reengineering tasks at Selex ES.","","","10.1109/ICSE.2015.145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202961","Source code analysis;Event logging;Development process;Coding practices;Industry domain","Software;Inspection;Programming;Encoding;Industries;Runtime","program diagnostics;software engineering;system monitoring","critical software development process assessment;event logging mechanism;measurement study;event logging practices;critical industrial domain;Selex ES;electronic and information solutions;source code analysis;log entry inspection;log analysis;event logging reengineering tasks","","22","31","","","","","IEEE","IEEE Conferences"
"New Initiative: The Naturalness of Software","P. Devanbu","Dept. of Comput. Sci., UC Davis, Davis, CA, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","543","546","This paper describes a new research consortium, studying the Naturalness of Software. This initiative is supported by a pair of grants by the US National Science Foundation, totaling $2,600,000: the first, exploratory (""EAGER"") grant of $600,000 helped kickstart an inter-disciplinary effort, and demonstrate feasibility; a follow-on full grant of $2,000,000 was recently awarded. The initiative is led by the author, who is at UC Davis, and includes investigators from Iowa State University and Carnegie-Mellon University (Language Technologies Institute).","","","10.1109/ICSE.2015.190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203008","language modeling;NLP;software engineering;big code","Software;Pragmatics;Java;Software engineering;Programming;Predictive models;Computers","computational linguistics;software engineering","software naturalness;US National Science Foundation;EAGER;UC Davis;Iowa State University;Carnegie-Mellon University;Language Technologies Institute","","3","24","","","","","IEEE","IEEE Conferences"
"How (Much) Do Developers Test?","M. Beller; G. Gousios; A. Zaidman","Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","559","562","What do we know about software testing in the real world? It seems we know from Fred Brooks' seminal work ""The Mythical Man-Month"" that 50% of project effort is spent on testing. However, due to the enormous advances in software engineering in the past 40 years, the question stands: Is this observation still true? In fact, was it ever true? The vision for our research is to settle the discussion about Brooks' estimation once and for all: How much do developers test? Does developers' estimation on how much they test match reality? How frequently do they execute their tests, and is there a relationship between test runtime and execution frequency? What are the typical reactions to failing tests? Do developers solve actual defects in the production code, or do they merely relax their test assertions? Emerging results from 40 software engineering students show that students overestimate their testing time threefold, and 50% of them test as little as 4% of their time, or less. Having proven the scalability of our infrastructure, we are now extending our case study with professional software engineers from open-source and industrial organizations.","","","10.1109/ICSE.2015.193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203012","","Testing;Production;Software engineering;Java;Estimation;Open source software","program testing","software testing;test runtime;execution frequency;production code;professional software engineers;open-source organizations;industrial organizations","","20","14","","","","","IEEE","IEEE Conferences"
"CS/SE Instructors Can Improve Student Writing without Reducing Class Time Devoted to Technical Content: Experimental Results","P. V. Anderson; S. Heckman; M. Vouk; D. Wright; M. Carter; J. E. Burge; G. C. Gannod","Elon Univ., Elon, NC, USA; North Carolina State Univ., Raleigh, NC, USA; North Carolina State Univ., Raleigh, NC, USA; North Carolina State Univ., Raleigh, NC, USA; North Carolina State Univ., Raleigh, NC, USA; Wesleyan Univ., Middletown, CT, USA; Miami Univ., Oxford, OH, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","455","464","The Computer Science and Software Engineering (CS/SE) profession reports that new college graduates lack the communication skills needed for personal and organizational success. Many CS/SE faculty may omit communication instruction from their courses because they do not want to reduce technical content. We experimented in a software-engineering-intensive second-semester programming course with strategies for improving students' writing of black box test plans that included no instruction on writing the plans beyond the standard lecture on testing. The treatment version of the course used 1) a modified assignment that focused on the plan's readers, 2) a model plan students could consult online, and 3) a modified grading rubric that identified the readers' needs. Three external raters found that students in the treatment sections outperformed students in the control sections on writing for five of nine criteria on rubrics for evaluating the plans and on the raters' holistic impression of the students' technical and communication abilities from the perspectives of a manager and a tester.","","","10.1109/ICSE.2015.178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202996","communication across the curriculum;software engineering education;black box test plans","Writing;Software testing;Software engineering;Employment;Programming;Education","computer science education;educational courses;software engineering","CS-SE instructors;student writing improvement;computer science and software engineering profession;communication instruction;software-engineering-intensive second-semester programming course;black box test plans","","1","24","","","","","IEEE","IEEE Conferences"
"Why Good Developers Write Bad Code: An Observational Case Study of the Impacts of Organizational Factors on Software Quality","M. Lavall√©e; P. N. Robillard","Dept. de Genie Inf. et Genie Logiciel, Polytech. Montreal, Montr√©al, QC, Canada; Dept. de Genie Inf. et Genie Logiciel, Polytech. Montreal, Montr√©al, QC, Canada","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","677","687","How can organizational factors such as structure and culture have an impact on the working conditions of developers? This study is based on ten months of observation of an in-house software development project within a large telecommunications company. The observation was conducted during mandatory weekly status meetings, where technical and managerial issues were raised and discussed. Preliminary results show that many decisions made under the pressure of certain organizational factors negatively affected software quality. This paper describes cases depicting the complexity of organizational factors and reports on ten issues that have had a negative impact on quality, followed by suggested avenues for corrective action.","","","10.1109/ICSE.2015.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194616","Organizational factors;software quality;observational case study","Software;Companies;Testing;Contracts;Documentation;Software engineering","organisational aspects;software development management;software quality","organizational factors;software quality;in-house software development project;technical issues;managerial issues;corrective action","","11","26","","","","","IEEE","IEEE Conferences"
"Empirical Study Towards a Leading Indicator for Cost of Formal Software Verification","D. Matichuk; T. Murray; J. Andronick; R. Jeffery; G. Klein; M. Staples","NICTA, Sydney, NSW, Australia; NICTA, Sydney, NSW, Australia; NICTA, Sydney, NSW, Australia; NICTA, Sydney, NSW, Australia; NICTA, Sydney, NSW, Australia; NICTA, Sydney, NSW, Australia","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","722","732","Formal verification can provide the highest degree of software assurance. Demand for it is growing, but there are still few projects that have successfully applied it to sizeable, real-world systems. This lack of experience makes it hard to predict the size, effort and duration of verification projects. In this paper, we aim to better understand possible leading indicators of proof size. We present an empirical analysis of proofs from the landmark formal verification of the seL4 microkernel and the two largest software verification proof developments in the Archive of Formal Proofs. Together, these comprise 15,018 individual lemmas and approximately 215,000 lines of proof script. We find a consistent quadratic relationship between the size of the formal statement of a property, and the final size of its formal proof in the interactive theorem prover Isabelle. Combined with our prior work, which has indicated that there is a strong linear relationship between proof effort and proof size, these results pave the way for effort estimation models to support the management of large-scale formal verification projects.","","","10.1109/ICSE.2015.85","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194620","seL4;Isabelle;proof engineering;formal verification","Size measurement;Software;Complexity theory;Estimation;Approximation methods;Mathematical model","formal verification;theorem proving","cost indicator;formal software verification;software assurance;formal proof;interactive theorem prover;Isabelle","","11","36","","","","","IEEE","IEEE Conferences"
"Multi-objective Integer Programming Approaches for Solving Optimal Feature Selection Problem: A New Perspective on Multi-objective Optimization Problems in SBSE","Y. Xue; Y. Li","Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Ind. Eng., Tsinghua Univ., Beijing, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1231","1242","The optimal feature selection problem in software product line is typically addressed by the approaches based on Indicator-based Evolutionary Algorithm (IBEA). In this study, we first expose the mathematical nature of this problem - multi-objective binary integer linear programming. Then, we implement/propose three mathematical programming approaches to solve this problem at different scales. For small-scale problems (roughly, less than 100 features), we implement two established approaches to find all exact solutions. For medium-to-large problems (roughly, more than 100 features), we propose one efficient approach that can generate a representation of the entire Pareto front in linear time complexity. The empirical results show that our proposed method can find significantly more non-dominated solutions in similar or less execution time, in comparison with IBEA and its recent enhancement (i.e., IBED that combines IBEA and Differential Evolution).","","","10.1145/3180155.3180257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453205","Optimal Feature Selection Problem;Multi Objective Optimization(MOO);Multi Objective Integer Programming (MOIP);Indicator Based Evolutionary Algorithm (IBEA);IBED","Feature extraction;Linear programming;IP networks;Optimization;Software;Encryption;Graphical user interfaces","computational complexity;evolutionary computation;integer programming;Pareto optimisation","optimal feature selection problem;multiobjective optimization problems;software product line;IBEA;multiobjective binary integer linear programming;mathematical programming approaches;small-scale problems;medium-to-large problems;indicator-based evolutionary algorithm;SBSE;Pareto front;linear time complexity","","1","55","","","","","IEEE","IEEE Conferences"
"Nomen est Omen: Exploring and Exploiting Similarities between Argument and Parameter Names","H. Liu; Q. Liu; C. Staicu; M. Pradel; Y. Luo","Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China; Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China; Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany; Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany; Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1063","1073","Programmer-provided identifier names convey information about the semantics of a program. This information can complement traditional program analyses in various software engineering tasks, such as bug finding, code completion, and documentation. Even though identifier names appear to be a rich source of information, little is known about their properties and their potential usefulness. This paper presents an empirical study of the lexical similarity between arguments and parameters of methods, which is one prominent situation where names can provide otherwise missing information. The study involves 60 real-world Java programs. We find that, for most arguments, the similarity is either very high or very low, and that short and generic names often cause low similarities. Furthermore, we show that inferring a set of low-similarity parameter names from one set of programs allows for pruning such names in another set of programs. Finally, the study shows that many arguments are more similar to thecorresponding parameter than any alternative argument available in the call site's scope. As applications of our findings, we present an anomaly detection technique that identifies 144 renaming opportunities and incorrect arguments in 14 programs, and a code recommendation system that suggests correct arguments with a precision of 83%.","","","10.1145/2884781.2884841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886980","","Semantics;Java;Documentation;Open source software;Data collection","Java;program diagnostics;software engineering;text analysis","software engineering;lexical similarity;real-world Java programs;low-similarity parameter names;anomaly detection technique;code recommendation system;name-based program analysis","","8","33","","","","","IEEE","IEEE Conferences"
"Finding and Analyzing Compiler Warning Defects","C. Sun; V. Le; Z. Su","Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","203","213","Good compiler diagnostic warnings facilitate software development as they indicate likely programming mistakes or code smells. However, due to compiler bugs, the warnings may be erroneous, superfluous or missing, even for mature production compilers like GCC and Clang. In this paper, we (1) propose the first randomized differential testing technique to detect compiler warning defects and (2) describe our extensive evaluation in finding warning defects in widely-used C compilers.At the high level, our technique starts with generating random programs to trigger compilers to emit a variety of compiler warnings, aligns the warnings from different compilers, and identifies inconsistencies as potential bugs. We develop effective techniques to overcome three specific challenges: (1) How to generate random programs, (2) how to align textual warnings, and (3) how to reduce test programs for bug reporting?Our technique is very effective - we have found and reported 60 bugs for GCC (38 confirmed, assigned or fixed) and 39 for Clang (14 confirmed or fixed). This case study not only demonstrates our technique's effectiveness, but also highlights the need to continue improving compilers' warning support, an essential, but rather neglected aspect of compilers.","","","10.1145/2884781.2884879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886904","compiler warnings;compiler testing;differential testing","Computer bugs;Program processors;Testing;Security;Production;Maintenance engineering","program compilers;program debugging","randomized differential testing technique;compiler warning defects;C compilers;bugs;random programs;textual warning alignment;GCC;Clang","","5","39","","","","","IEEE","IEEE Conferences"
"A Combinatorial Approach for Exposing Off-Nominal Behaviors","K. Madala; H. Do; D. Aceituna","Univ. of North Texas, Denton, TX, USA; Univ. of North Texas, Denton, TX, USA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","910","920","Off-nominal behaviors (ONBs) have been a major concern in the areas of embedded systems and safety-critical systems. To address ONB problems, some researchers have proposed model-based approaches that can expose ONBs by analyzing natural language requirements documents. While these approaches produced promising results, they require a lot of human effort and time. In this paper, to reduce human effort and time, we propose a combinatorial-based approach, Combinatorial Causal Component Model (Combi-CCM), which uses structured requirements patterns and combinations generated using the IPOG algorithm. We conducted an empirical study using several requirements documents to evaluate our approach, and our results indicate that the proposed approach can reduce human effort and time while maintaining the same ONB exposure ability obtained by the control techniques.","","","10.1145/3180155.3180204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453169","Off-Nominal Behaviors;Requirements Verification;Combinatorial Approach;Model-based Approach","Ear;Electronic countermeasures;Robot sensing systems;Natural languages;Analytical models;Writing","combinatorial mathematics;embedded systems;formal specification;formal verification;natural language processing;safety-critical software","off-nominal behaviors;embedded systems;safety-critical systems;ONB problems;natural language requirements documents;combinatorial-based approach;requirements patterns;ONB exposure ability;combinatorial approach;combinatorial causal component model;IPOG algorithm","","2","47","","","","","IEEE","IEEE Conferences"
"Multi-objective Software Effort Estimation","F. Sarro; A. Petrozziello; M. Harman","Univ. Coll. London, London, UK; Univ. of Portsmouth, Portsmouth, UK; Univ. Coll. London, London, UK","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","619","630","We introduce a bi-objective effort estimation algorithm that combines Confidence Interval Analysis and assessment of Mean Absolute Error. We evaluate our proposed algorithm on three different alternative formulations, baseline comparators and current state-of-the-art effort estimators applied to five real-world datasets from the PROMISE repository, involving 724 different software projects in total. The results reveal that our algorithm outperforms the baseline, state-of-the-art and all three alternative formulations, statistically significantly (p <; 0.001) and with large effect size (A12 ‚â• 0.9) over all five datasets. We also provide evidence that our algorithm creates a new state-of-the-art, which lies within currently claimed industrial human-expert-based thresholds, thereby demonstrating that our findings have actionable conclusions for practicing software engineers.","","","10.1145/2884781.2884830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886939","Software effort estimation;multi-objective evolutionary algorithm;confidence interval;estimates uncertainty","Estimation;Software;Uncertainty;Predictive models;Mathematical model;Software algorithms;Software engineering","software engineering","multi objective software effort estimation;confidence interval analysis;mean absolute error;software projects;software engineers","","17","92","","","","","IEEE","IEEE Conferences"
"Feature-Model Interfaces: The Highway to Compositional Analyses of Highly-Configurable Systems","R. Schr√∂ter; S. Krieter; T. Th√ºm; F. Benduhn; G. Saake","Univ. of Magdeburg, Magdeburg, Germany; Univ. of Magdeburg, Magdeburg, Germany; Tech. Univ. Braunschweig, Braunschweig, Germany; Univ. of Magdeburg, Magdeburg, Germany; Univ. of Magdeburg, Magdeburg, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","667","678","Today's software systems are often customizable by means of load-time or compile-time configuration options. These options are typically not independent and their dependencies can be specified by means of feature models. As many industrial systems contain thousands of options, the maintenance and utilization of feature models is a challenge for all stakeholders. In the last two decades, numerous approaches have been presented to support stakeholders in analyzing feature models. Such analyses are commonly reduced to satisfiability problems, which suffer from the growing number of options. While first attempts have been made to decompose feature models into smaller parts, they still require to compose all parts for analysis. We propose the concept of a feature-model interface that only consists of a subset of features, typically selected by experts, and hides all other features and dependencies. Based on a formalization of feature-model interfaces, we prove compositionality properties. We evaluate feature-model interfaces using a three-month history of an industrial feature model from the automotive domain with 18,616 features. Our results indicate performance benefits especially under evolution as often only parts of the feature model need to be analyzed again.","","","10.1145/2884781.2884823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886943","Configurable Software;Software Product Line;Variability Modeling;Feature Model;Modularity;Compositionality","Analytical models;Indexes;Load modeling;Stakeholders;Software systems;Automotive engineering","program diagnostics","feature-model interface;compositional analysis;highly-configurable systems;load-time configuration option;compile-time configuration option;satisfiability problems;compositionality properties","","1","53","","","","","IEEE","IEEE Conferences"
"When Testing Meets Code Review: Why and How Developers Review Tests","D. Spadini; M. Aniche; M. Storey; M. Bruntink; A. Bacchelli","Software Improvement Group, Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Univ. of Victoria, Victoria, BC, Canada; Software Improvement Group, Amsterdam, Netherlands; Univ. of Zurich, Zurich, Switzerland","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","677","687","Automated testing is considered an essential process for ensuring software quality. However, writing and maintaining high-quality test code is challenging and frequently considered of secondary importance. For production code, many open source and industrial software projects employ code review, a well-established software quality practice, but the question remains whether and how code review is also used for ensuring the quality of test code. The aim of this research is to answer this question and to increase our understanding of what developers think and do when it comes to reviewing test code. We conducted both quantitative and qualitative methods to analyze more than 300,000 code reviews, and interviewed 12 developers about how they review test files. This work resulted in an overview of current code reviewing practices, a set of identified obstacles limiting the review of test code, and a set of issues that developers would like to see improved in code review tools. The study reveals that reviewing test files is very different from reviewing production files, and that the navigation within the review itself is one of the main issues developers currently face. Based on our findings, we propose a series of recommendations and suggestions for the design of tools and future research.","","","10.1145/3180155.3180192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453136","software testing;automated testing;code review;Gerrit","Production;Computer bugs;Testing;Tools;Software quality;Measurement","program testing;software quality","developer review tests;code review tools;current code reviewing practices;review test files;software quality practice;production code;high-quality test code;automated testing","","3","","","","","","IEEE","IEEE Conferences"
"Revisiting Code Ownership and Its Relationship with Software Quality in the Scope of Modern Code Review","P. Thongtanunam; S. McIntosh; A. E. Hassan; H. Iida","Nara Inst. of Sci. & Technol., Nara, Japan; McGill Univ., Montreal, QC, Canada; Queen's Univ., Kingston, ON, Canada; Nara Inst. of Sci. & Technol., Nara, Japan","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1039","1050","Code ownership establishes a chain of responsibility for modules in large software systems. Although prior work uncovers a link between code ownership heuristics and software quality, these heuristics rely solely on the authorship of code changes. In addition to authoring code changes, developers also make important contributions to a module by reviewing code changes. Indeed, recent work shows that reviewers are highly active in modern code review processes, often suggesting alternative solutions or providing updates to the code changes. In this paper, we complement traditional code ownership heuristics using code review activity. Through a case study of six releases of the large Qt and OpenStack systems, we find that: (1) 67%-86% of developers did not author any code changes for a module, but still actively contributed by reviewing 21%-39% of the code changes, (2) code ownership heuristics that are aware of reviewing activity share a relationship with software quality, and (3) the proportion of reviewers without expertise shares a strong, increasing relationship with the likelihood of having post-release defects. Our results suggest that reviewing activity captures an important aspect of code ownership, and should be included in approximations of it in future studies.","","","10.1145/2884781.2884852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886978","Ownership;Expertise;Software Quality","Software quality;Birds;Software systems;Software design;Organizations;Conferences","software quality;source code (software)","large software systems;code ownership heuristics;code change authorship;modern code review processes;code review activity;large Qt systems;OpenStack systems;software quality;post-release defects","","11","55","","","","","IEEE","IEEE Conferences"
"Automatically Generating Search Heuristics for Concolic Testing","S. Cha; S. Hong; J. Lee; H. Oh","Korea Univ., Seoul, South Korea; Korea Univ., Seoul, South Korea; Korea Univ., Seoul, South Korea; Korea Univ., Seoul, South Korea","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1244","1254","We present a technique to automatically generate search heuristics for concolic testing. A key challenge in concolic testing is how to effectively explore the program's execution paths to achieve high code coverage in a limited time budget. Concolic testing employs a search heuristic to address this challenge, which favors exploring particular types of paths that are most likely to maximize the final coverage. However, manually designing a good search heuristic is nontrivial and typically ends up with suboptimal and unstable outcomes. The goal of this paper is to overcome this shortcoming of concolic testing by automatically generating search heuristics. We define a class of search heuristics, namely a parameterized heuristic, and present an algorithm that efficiently finds an optimal heuristic for each subject program. Experimental results with open-source C programs show that our technique successfully generates search heuristics that significantly outperform existing manually-crafted heuristics in terms of branch coverage and bug-finding.","","","10.1145/3180155.3180166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453207","Software Testing;Concolic Testing;Search Heuristics","Heuristic algorithms;Manuals;Software engineering;Software algorithms;Software;Software testing","program debugging;program testing;search problems","concolic testing;good search heuristic;manually-crafted heuristics;program execution path","","","33","","","","","IEEE","IEEE Conferences"
"Crowdsourcing Program Preconditions via a Classification Game","D. Fava; D. Shapiro; J. Osborn; M. Schaef; E. J. Whitehead","Univ. of California Santa Cruz, Santa Cruz, CA, USA; Univ. of California Santa Cruz, Santa Cruz, CA, USA; Univ. of California Santa Cruz, Santa Cruz, CA, USA; SRI Int., Menlo Park, CA, USA; Univ. of California Santa Cruz, Santa Cruz, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1086","1096","Invariant discovery is one of the central problems in software verification. This paper reports on an approach that addresses this problem in a novel way; it crowdsources logical expressions for likely invariants by turning invariant discovery into a computer game. The game, called Binary Fission, employs a classification model. In it, players compose preconditions by separating program states that preserve or violate program assertions. The players have no special expertise in formal methods or programming, and are not specifically aware they are solving verification tasks. We show that Binary Fission players discover concise, general, novel, and human readable program preconditions. Our proof of concept suggests that crowdsourcing offers a feasible and promising path towards the practical application of verification technology.","","","10.1145/2884781.2884865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886982","crowdsourcing;software verification;invariant discovery;game with a purpose","Games;Crowdsourcing;Software;Technological innovation;Computers;Gold;Software engineering","computer games;crowdsourcing;pattern classification;program verification","program precondition crowdsourcing;classification game;invariant discovery;computer game;Binary Fission;program assertions;verification technology","","1","30","","","","","IEEE","IEEE Conferences"
"Energy Profiles of Java Collections Classes","S. Hasan; Z. King; M. Hafiz; M. Sayagh; B. Adams; A. Hindle","NA; NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","225","236","We created detailed profiles of the energy consumed by common operations done on Java List, Map, and Set abstractions. The results show that the alternative data types for these abstractions differ significantly in terms of energy consumption depending on the operations. For example, an ArrayList consumes less energy than a LinkedList if items are inserted at the middle or at the end, but consumes more energy than a LinkedList if items are inserted at the start of the list. To explain the results, we explored the memory usage and the bytecode executed during an operation. Expensive computation tasks in the analyzed bytecode traces appeared to have an energy impact, but memory usage did not contribute. We evaluated our profiles by using them to selectively replace Collections types used in six applications and libraries. We found that choosing the wrong Collections type, as indicated by our profiles, can cost even 300% more energy than the most efficient choice. Our work shows that the usage context of a data structure and our measured energy profiles can be used to decide between alternative Collections implementations.","","","10.1145/2884781.2884869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886906","Energy Profile;Collections;API;Java","Energy consumption;Java;Energy measurement;Encoding;Software engineering;Semiconductor device measurement;Software","Java","Java collections classes;energy profiles;ArrayList;Java List;Set abstractions;LinkedList","","22","54","","","","","IEEE","IEEE Conferences"
"Overcoming Open Source Project Entry Barriers with a Portal for Newcomers","I. Steinmacher; T. U. Conte; C. Treude; M. A. Gerosa","Dept. of Comput., Fed. Univ. of Technol., Paran√°, Brazil; Inst. of Comput., Fed. Univ. of Amazonas, Manaus, Brazil; Inst. of Math. & Stat., Univ. of Sao Paulo, Sao Paulo, Brazil; Inst. of Math. & Stat., Univ. of Sao Paulo, Sao Paulo, Brazil","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","273","284","Community-based Open Source Software (OSS) projects are usually self-organized and dynamic, receiving contributions from distributed volunteers. Newcomer are important to the survival, long-term success, and continuity of these communities. However, newcomers face many barriers when making their first contribution to an OSS project, leading in many cases to dropouts. Therefore, a major challenge for OSS projects is to provide ways to support newcomers during their first contribution. In this paper, we propose and evaluate FLOSScoach, a portal created to support newcomers to OSS projects. FLOSScoach was designed based on a conceptual model of barriers created in our previous work. To evaluate the portal, we conducted a study with 65 students, relying on qualitative data from diaries, self-efficacy questionnaires, and the Technology Acceptance Model. The results indicate that FLOSScoach played an important role in guiding newcomers and in lowering barriers related to the orientation and contribution process, whereas it was not effective in lowering technical barriers. We also found that FLOSScoach is useful, easy to use, and increased newcomers' confidence to contribute. Our results can help project maintainers on deciding the points that need more attention in order to help OSS project newcomers overcome entry barriers.","","","10.1145/2884781.2884806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886910","Newcomers;Newbies;Novices;Beginners;Open Source Software;Barriers;Obstacles;Onboarding;Joining Process","Portals;Documentation;Computer bugs;Joining processes;Industries;Open source software","portals;public domain software","open source project entry barriers;community-based open source software projects;OSS projects;FLOSScoach;technology acceptance model;Web portal","","11","52","","","","","IEEE","IEEE Conferences"
"Generalized Data Structure Synthesis","C. Loncaric; M. D. Ernst; E. Torlak","Paul G. Allen Sch. of Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA; Paul G. Allen Sch. of Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA; Paul G. Allen Sch. of Comput. Sci. & Eng., Univ. of Washington, Seattle, WA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","958","968","Data structure synthesis is the task of generating data structure implementations from high-level specifications. Recent work in this area has shown potential to save programmer time and reduce the risk of defects. Existing techniques focus on data structures for manipulating subsets of a single collection, but real-world programs often track multiple related collections and aggregate properties such as sums, counts, minimums, and maximums. This paper shows how to synthesize data structures that track subsets and aggregations of multiple related collections. Our technique decomposes the synthesis task into alternating steps of query synthesis and incrementalization. The query synthesis step implements pure operations over the data structure state by leveraging existing enumerative synthesis techniques, specialized to the data structures domain. The incrementalization step implements imperative state modifications by re-framing them as fresh queries that determine what to change, coupled with a small amount of code to apply the change. As an added benefit of this approach over previous work, the synthesized data structure is optimized for not only the queries in the specification but also the required update operations. We have evaluated our approach in four large case studies, demonstrating that these extensions are broadly applicable.","","","10.1145/3180155.3180211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453175","Program synthesis;automatic programming;data structures","Data structures;Synthesizers;Task analysis;Software;Servers;Tools","data structures;query processing;reasoning about programs;set theory","data structure implementations;track subsets;incrementalization;data structure state;data structures domain;data structure synthesis;query synthesis;aggregations;re-framing;code","","1","","","","","","IEEE","IEEE Conferences"
"Sentiment Analysis for Software Engineering: How Far Can We Go?","B. Lin; F. Zampetti; G. Bavota; M. Di Penta; M. Lanza; R. Oliveto","Software Inst., Univ. della Svizzera italiana, Lugano, Switzerland; Dept. of Eng., Univ. of Sannio, Benevento, Italy; Software Inst., Univ. della Svizzera italiana, Lugano, Switzerland; Dept. of Eng., Univ. of Sannio, Benevento, Italy; Software Inst., Univ. della Svizzera italiana, Lugano, Switzerland; STAKE Lab., Univ. of Molise, Pesche, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","94","104","Sentiment analysis has been applied to various software engineering (SE) tasks, such as evaluating app reviews or analyzing developers' emotions in commit messages. Studies indicate that sentiment analysis tools provide unreliable results when used out-of-the-box, since they are not designed to process SE datasets. The silver bullet for a successful application of sentiment analysis tools to SE datasets might be their customization to the specific usage context. We describe our experience in building a software library recommender exploiting crowdsourced opinions mined from Stack Overflow (e.g., what is the sentiment of developers about the usability of a library). To reach our goal, we retrained-on a set of 40k manually labeled sentences/words extracted from Stack Overflow-a state-of-the-art sentiment analysis tool exploiting deep learning. Despite such an effort- and time-consuming training process, the results were negative. We changed our focus and performed a thorough investigation of the accuracy of these tools on a variety of SE datasets. Our results should warn the research community about the strong limitations of current sentiment analysis tools.","","","10.1145/3180155.3180195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453067","sentiment analysis;software engineering;NLP","Sentiment analysis;Tools;Software engineering;Software;Task analysis;Training;Motion pictures","data analysis;data mining;learning (artificial intelligence);sentiment analysis;social networking (online);software engineering;software libraries","sentiment analysis tools;app reviews evaluation;commit messages;out-of-the-box;silver bullet;crowdsourced opinions mined;stack overflow;deep learning;time-consuming training process;effort training process;research community;developers emotions analyzing;software engineering tasks;SE datasets;software library recommender","","10","","","","","","IEEE","IEEE Conferences"
"Semantic Program Repair Using a Reference Implementation","S. Mechtaev; M. Nguyen; Y. Noller; L. Grunske; A. Roychoudhury","Nat. Univ. of Singapore, Singapore, Singapore; Nat. Univ. of Singapore, Singapore, Singapore; Humboldt Univ. of Berlin, Berlin, Germany; Humboldt Univ. of Berlin, Berlin, Germany; Nat. Univ. of Singapore, Singapore, Singapore","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","129","139","Automated program repair has been studied via the use of techniques involving search, semantic analysis and artificial intelligence. Most of these techniques rely on tests as the correctness criteria, which causes the test overfitting problem. Although various approaches such as learning from code corpus have been proposed to address this problem, they are unable to guarantee that the generated patches generalize beyond the given tests. This work studies automated repair of errors using a reference implementation. The reference implementation is symbolically analyzed to automatically infer a specification of the intended behavior. This specification is then used to synthesize a patch that enforces conditional equivalence of the patched and the reference programs. The use of the reference implementation as an implicit correctness criterion alleviates overfitting in test-based repair. Besides, since we generate patches by semantic analysis, the reference program may have a substantially different implementation from the patched program, which distinguishes our approach from existing techniques for regression repair like Relifix. Our experiments in repairing the embedded Linux Busybox with GNU Coreutils as reference (and vice-versa) revealed that the proposed approach scales to real-world programs and enables the generation of more correct patches.","","","10.1145/3180155.3180247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453071","Debugging;Program repair;Verification","Maintenance engineering;Software;Semantics;Forestry;Instruments;Signal processing algorithms;Scalability","embedded systems;learning (artificial intelligence);Linux;program diagnostics;program testing;public domain software;regression analysis;software maintenance","semantic program repair;reference implementation;automated program repair;semantic analysis;test overfitting problem;reference program;test-based repair;patched program;regression repair;GNU Coreutils;Linux Busybox;code corpus learning","","8","49","","","","","IEEE","IEEE Conferences"
"Angelix: Scalable Multiline Program Patch Synthesis via Symbolic Analysis","S. Mechtaev; J. Yi; A. Roychoudhury","Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","691","701","Since debugging is a time-consuming activity, automated program repair tools such as GenProg have garnered interest. A recent study revealed that the majority of GenProg repairs avoid bugs simply by deleting functionality. We found that SPR, a state-of-the-art repair tool proposed in 2015, still deletes functionality in their many ""plausible"" repairs. Unlike generate-and-validate systems such as GenProg and SPR, semantic analysis based repair techniques synthesize a repair based on semantic information of the program. While such semantics-based repair methods show promise in terms of quality of generated repairs, their scalability has been a concern so far. In this paper, we present Angelix, a novel semantics-based repair method that scales up to programs of similar size as are handled by search-based repair tools such as GenProg and SPR. This shows that Angelix is more scalable than previously proposed semantics based repair methods such as SemFix and DirectFix. Furthermore, our repair method can repair multiple buggy locations that are dependent on each other. Such repairs are hard to achieve using SPR and GenProg. In our experiments, Angelix generated repairs from large-scale real-world software such as wireshark and php, and these generated repairs include multi-location repairs. We also report our experience in automatically repairing the well-known Heartbleed vulnerability.","","","10.1145/2884781.2884807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886945","Automated program repair;Semantic analysis","Maintenance engineering;Semantics;Computer bugs;Software;Testing;Scalability;Software engineering","program debugging;program diagnostics","Angelix method;scalable multiline program patch synthesis;symbolic analysis;program repair tools;program debugging;SPR tool;generate-and-validate systems;semantic analysis;semantic information;multilocation repairs;Heartbleed vulnerability","","54","40","","","","","IEEE","IEEE Conferences"
"Fixing Deadlocks via Lock Pre-Acquisitions","Y. Cai; L. Cao","State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China; State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1109","1120","Manual deadlock fixing is error-prone and time-consuming. Exist-ing generic approach (GA) simply inserts gate locks to fix dead-locks by serializing executions, which could introduce various new deadlocks and incur high runtime overhead. We propose a novel approach DFixer to fix deadlocks without introducing any new deadlocks by design. DFixer only selects one thread of a deadlock to pre-acquire a lock w together with another lock h, where before fixing, the deadlock occurs when the thread holds lock h and waits for lock w. As such, DFixer eliminates a hold-and-wait necessary condition, preventing the deadlock from occurring. The thread per-forming pre-acquisition is carefully selected such that no other syn-chronization exists in between the two original acquisitions. Other-wise, DFixer further introduces a context-aware conditional protect-ed by above lock w to guarantee the correctness of DFixer. The evaluation is on 20 deadlocks, including 17 from widely-used real-world C/C++ programs. It shows that DFixer successfully fixed all deadlocks. Whereas GA introduced 9 new deadlocks; a latest work Grail failed to fix 8 deadlocks and introduced 3 new deadlocks on others. On average, DFixer incurred only 2.1% overhead, where GA and Grail incurred 15.8% and 11.5% overhead, respectively.","","","10.1145/2884781.2884819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886984","Deadlock;fixing;multithreaded program;lock order","System recovery;Message systems;Computer bugs;Logic gates;Concurrent computing;Synchronization;Software","concurrency control;system recovery","manual deadlock fixing;lock pre-acquisitions;DFixer;C++ programs;C programs","","5","64","","","","","IEEE","IEEE Conferences"
"Automated Energy Optimization of HTTP Requests for Mobile Applications","D. Li; Y. Lyu; J. Gui; W. G. J. Halfond","Univ. of Southern California, Los Angeles, CA, USA; Univ. of Southern California, Los Angeles, CA, USA; Univ. of Southern California, Los Angeles, CA, USA; Univ. of Southern California, Los Angeles, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","249","260","Energy is a critical resource for apps that run on mobile devices. Among all operations, making HTTP requests is one of the most energy consuming. Previous studies have shown that bundling smaller HTTP requests into a single larger HTTP request can be an effective way to improve energy efficiency of network communication, but have not defined an automated way to detect when apps can be bundled nor to transform the apps to do this bundling. In this paper we propose an approach to reduce the energy consumption of HTTP requests in Android apps by automatically detecting and then bundling multiple HTTP requests. Our approach first detects HTTP requests that can be bundled using static analysis, then uses a proxy based technique to bundle HTTP requests at runtime. We evaluated our approach on a set of real world marketplace Android apps. In this evaluation, our approach achieved an average energy reduction of 15% for the subject apps and did not impose a significant runtime overhead on the optimized apps.","","","10.1145/2884781.2884867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886908","Energy optimization;Mobile apps;HTTP requests","Mobile communication;Uniform resource locators;Runtime;Energy consumption;Optimization;Protocols;Servers","energy conservation;mobile computing;power aware computing;program diagnostics","energy optimization;HTTP requests;mobile applications;mobile devices;network communication;energy efficiency;Android applications;static analysis;proxy based technique","","29","54","","","","","IEEE","IEEE Conferences"
"Automatically Learning Semantic Features for Defect Prediction","S. Wang; T. Liu; L. Tan","Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada; Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada; Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","297","308","Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models. To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs). Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision, 11.5% in recall, and 14.2% in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1.","","","10.1145/2884781.2884804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886912","defect prediction;feature generation;deep learning","Semantics;Feature extraction;Training;Predictive models;Buildings;Syntactics;Data models","belief networks;neural nets;program diagnostics;programming language semantics;public domain software;source code (software)","semantic feature learning;software defect prediction;representation-learning algorithm;deep learning;programs semantic representation;source code;deep belief network;token vectors;abstract syntax trees;DBN;AST;open source projects;within-project defect prediction;cross-project defect prediction;WPDP;CPDP","","60","70","","","","","IEEE","IEEE Conferences"
"Automatically Finding Bugs in a Commercial Cyber-Physical System Development Tool Chain With SLforge","S. A. Chowdhury; S. Mohian; S. Mehra; S. Gawsane; T. T. Johnson; C. Csallner","Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA; Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA; Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA; Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA; EECS Dept., Vanderbilt Univ., Nashville, TN, USA; Comput. Sci. & Eng. Dept., Univ. of Texas at Arlington, Arlington, TX, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","981","992","Cyber-physical system (CPS) development tool chains are widely used in the design, simulation, and verification of CPS data-flow models. Commercial CPS tool chains such as MathWorks' Simulink generate artifacts such as code binaries that are widely deployed in embedded systems. Hardening such tool chains by testing is crucial since formally verifying them is currently infeasible. Existing differential testing frameworks such as CyFuzz can not generate models rich in language features, partly because these tool chains do not leverage the available informal Simulink specifications. Furthermore, no study of existing Simulink models is available, which could guide CyFuzz to generate realistic models. To address these shortcomings, we created the first large collection of public Simulink models and used the collected models' properties to guide random model generation. To further guide model generation we systematically collected semi-formal Simulink specifications. In our experiments on several hundred models, the resulting SLforge generator was more effective and efficient than the state-of-the-art tool CyFuzz. SLforge also found 8 new confirmed bugs in Simulink.","","","10.1145/3180155.3180231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453177","cyber-physical system;Simulink;differential testing;tool chain bug","Software packages;Tools;Testing;Computer bugs;Object oriented modeling;Numerical models;Cyber-physical systems","embedded systems;formal verification;mathematics computing;program debugging;program testing","CPS data-flow models;commercial CPS tool chains;embedded systems;differential testing frameworks;available informal Simulink specifications;realistic models;public Simulink models;random model generation;semiformal Simulink specifications;finding bugs;commercial cyber-physical system development tool chain;cyber-physical system development tool chains;MathWork Simulink;CyFuzz;SLforge generator","","1","60","","","","","IEEE","IEEE Conferences"
"To Preserve or Not to Preserve Invalid Solutions in Search-Based Software Engineering: A Case Study in Software Product Lines","J. Guo; K. Shi","Alibaba Group, Hangzhou, China; East China Univ. of Sci. & Technol., Shanghai, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1027","1038","Multi-objective evolutionary algorithms (MOEAs) have been successfully applied for software product lines (SPLs) to search for optimal or near-optimal solutions that balance multiple objectives. However, MOEAs usually produce invalid solutions that violate the constraints predefined. As invalid solutions are unbuildable in practice, we debate the preservation of invalid solutions during the search. We conduct experiments on seven real-world SPLs, including five largest SPLs hitherto reported and two SPLs with realistic values and constraints of quality attributes. We identify three potential limitations of preserving invalid solutions. Furthermore, based on the state-of-the-art, we design five algorithm variants that adopt different evolutionary operators. By performance evaluation, we provide empirical guidance on how to preserve valid solutions. Our empirical study demonstrates that whether or not to preserve invalid solutions deserves more attention in the community, and in some cases, we have to preserve valid solutions all along the way.","","","10.1145/3180155.3180163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453181","Search-based software engineering;software product lines;multi objective evolutionary algorithms;constraint solving;validity","Optimization;Sociology;Statistics;Software;Search problems;Software product lines","evolutionary computation;search problems;software engineering;software product lines","near-optimal solutions;search-based software engineering;software product lines;multiobjective evolutionary algorithms;MOEA;SPL","","","78","","","","","IEEE","IEEE Conferences"
"Static Automated Program Repair for Heap Properties","R. van Tonder; C. Le Goues","NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","151","162","Static analysis tools have demonstrated effectiveness at finding bugs in real world code. Such tools are increasingly widely adopted to improve software quality in practice. Automated Program Repair (APR) has the potential to further cut down on the cost of improving software quality. However, there is a disconnect between these effective bug-finding tools and APR. Recent advances in APR rely on test cases, making them inapplicable to newly discovered bugs or bugs difficult to test for deterministically (like memory leaks). Additionally, the quality of patches generated to satisfy a test suite is a key challenge. We address these challenges by adapting advances in practical static analysis and verification techniques to enable a new technique that finds and then accurately fixes real bugs without test cases. We present a new automated program repair technique using Separation Logic. At a high-level, our technique reasons over semantic effects of existing program fragments to fix faults related to general pointer safety properties: resource leaks, memory leaks, and null dereferences. The procedure automatically translates identified fragments into source-level patches, and verifies patch correctness with respect to reported faults. In this work we conduct the largest study of automatically fixing undiscovered bugs in real-world code to date. We demonstrate our approach by correctly fixing 55 bugs, including 11 previously undiscovered bugs, in 11 real-world projects.","","","10.1145/3180155.3180250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453073","Automated Program Repair;Separation Logic","Computer bugs;Maintenance engineering;Tools;Static analysis;Semantics;Software;Safety","formal verification;program debugging;program diagnostics;program testing;program verification;software quality;software tools","bug-finding tools;static analysis;real-world code;undiscovered bugs;source-level patches;resource leaks;general pointer safety properties;program fragments;semantic effects;automated program repair technique;verification techniques;test suite;memory leaks;software quality;static analysis tools;heap properties;static automated Program Repair","","3","","","","","","IEEE","IEEE Conferences"
"PAC Learning-Based Verification and Model Synthesis","Y. Chen; C. Hsieh; O. Leng√°l; T. Lii; M. Tsai; B. Wang; F. Wang","NA; Nat. Taiwan Univ., Taipei, Taiwan; NA; Nat. Taiwan Univ., Taipei, Taiwan; NA; NA; Nat. Taiwan Univ., Taipei, Taiwan","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","714","724","We introduce a novel technique for verification and model synthesis of sequential programs. Our technique is based on learning an approximate regular model of the set of feasible paths in a program, and testing whether this model contains an incorrect behavior. Exact learning algorithms require checking equivalence between the model and the program, which is a difficult problem, in general undecidable. Our learning procedure is therefore based on the framework of probably approximately correct (PAC) learning, which uses sampling instead, and provides correctness guarantees expressed using the terms error probability and confidence. Besides the verification result, our procedure also outputs the model with the said correctness guarantees. Obtained preliminary experiments show encouraging results, in some cases even outperforming mature software verifiers.","","","10.1145/2884781.2884860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886947","model synthesis;PAC learning;finite automata;program verification","Picture archiving and communication systems;Software;Testing;Approximation algorithms;Syntactics;Frequency modulation;Software engineering","error statistics;learning (artificial intelligence);program verification","PAC learning-based verification;model synthesis;sequential programs;probably approximately correct learning;sampling;error probability;confidence;software verification","","1","23","","","","","IEEE","IEEE Conferences"
"Multi-granular Conflict and Dependency Analysis in Software Engineering Based on Graph Transformation","L. Lambers; D. Str√ºber; G. Taentzer; K. Born; J. Huebert","Hasso-Plattner-Inst. Potsdam, Potsdam, Germany; Univ. Koblenz-Landau, Koblenz, Germany; Univ. Marburg, Marburg, Germany; Univ. Marburg, Marburg, Germany; Univ. Marburg, Marburg, Germany","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","716","727","Conflict and dependency analysis (CDA) of graph transformation has been shown to be a versatile foundation for understanding interactions in many software engineering domains, including software analysis and design, model-driven engineering, and testing. In this paper, we propose a novel static CDA technique that is multi-granular in the sense that it can detect all conflicts and dependencies on multiple granularity levels. Specifically, we provide an efficient algorithm suite for computing binary, coarse-grained, and fine-grained conflicts and dependencies: Binary granularity indicates the presence or absence of conflicts and dependencies, coarse granularity focuses on root causes for conflicts and dependencies, and fine granularity shows each conflict and dependency in full detail. Doing so, we can address specific performance and usability requirements that we identified in a literature survey of CDA usage scenarios. In an experimental evaluation, our algorithm suite computes conflicts and dependencies rapidly. Finally, we present a user study, in which the participants found our coarse-grained results more understandable than the fine-grained ones reported in a state-of-the-art tool. Our overall contribution is twofold: (i) we significantly speed up the computation of fine-grained and binary CDA results and, (ii) complement them with coarse-grained ones, which offer usability benefits for numerous use cases.","","","10.1145/3180155.3180258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453144","automated static analysis","Software engineering;Data mining;Usability;Task analysis;Model driven engineering","graph theory;program testing;software engineering","graph transformation;software engineering domains;model-driven engineering;multiple granularity levels;coarse granularity;CDA usage scenarios;fine granularity;multigranular conflict and dependency analysis;software testing;static CDA technique;binary granularity","","","","","","","","IEEE","IEEE Conferences"
"Locking Discipline Inference and Checking","M. D. Ernst; A. Lovato; D. Macedonio; F. Spoto; J. Thaine","Univ. of Washington, Seattle, WA, USA; Univ. di Verona, Verona, Italy; Julia Srl, Italy; Univ. di Verona, Verona, Italy; Univ. of Washington, Seattle, WA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1133","1144","Concurrency is a requirement for much modern software, but the implementation of multithreaded algorithms comes at the risk of errors such as data races.Programmers can prevent data races by documenting and obeying a locking discipline, which indicates which locks must be held in order to access which data.This paper introduces a formal semantics for locking specifications that gives a guarantee of race freedom.A notable difference from most other semantics is that it is in terms of values (which is what the runtime system locks) rather than variables.The paper also shows how to express the formal semantics in two different styles of analysis:abstract interpretation and type theory.We have implemented both analyses, in tools that operate on Java.To the best of our knowledge, these are the first tools that can soundly infer and check a locking discipline for Java.Our experiments compare the implementations with one another and with annotations written by programmers, showing that the ambiguities and unsoundness of previous formulations are a problem in practice.","","","10.1145/2884781.2884882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886986","","Synchronization;Semantics;Java;Concurrent computing;Monitoring;Software;Runtime","concurrency control;formal specification;Java;multi-threading","software concurrency;multithreaded algorithms;locking discipline;formal semantics;locking specifications;abstract interpretation;type theory;Java","","","49","","","","","IEEE","IEEE Conferences"
"Shadow of a Doubt: Testing for Divergences between Software Versions","H. Palikareva; T. Kuchta; C. Cadar","Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1181","1192","While developers are aware of the importance of comprehensively testing patches, the large effort involved in coming up with relevant test cases means that such testing rarely happens in practice. Furthermore, even when test cases are written to cover the patch, they often exercise the same behaviour in the old and the new version of the code. In this paper, we present a symbolic execution-based technique that is designed to generate test inputs that cover the new program behaviours introduced by a patch. The technique works by executing both the old and the new version in the same symbolic execution instance, with the old version shadowing the new one. During this combined shadow execution, whenever a branch point is reached where the old and the new version diverge, we generate a test case exercising the divergence and comprehensively test the new behaviours of the new version. We evaluate our technique on the Coreutils patches from the CoREBench suite of regression bugs, and show that it is able to generate test inputs that exercise newly added behaviours and expose some of the regression bugs.","","","10.1145/2884781.2884845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886990","","Testing;Software;Computer bugs;Concrete;Random access memory;Shadow mapping;Performance analysis","program debugging;program testing","divergence testing;software versions;symbolic execution-based technique;shadow execution;Coreutils patches;CoREBench;regression bugs","","4","31","","","","","IEEE","IEEE Conferences"
"Automated Parameter Optimization of Classification Techniques for Defect Prediction Models","C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto","Nara Inst. of Sci. & Technol., Nara, Japan; McGill Univ., Montreal, QC, Canada; Queen's Univ., Kingston, ON, Canada; Nara Inst. of Sci. & Technol., Nara, Japan","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","321","332","Defect prediction models are classifiers that are trained to identify defect-prone software modules. Such classifiers have configurable parameters that control their characteristics (e.g., the number of trees in a random forest classifier). Recent studies show that these classifiers may underperform due to the use of suboptimal default parameter settings. However, it is impractical to assess all of the possible settings in the parameter spaces. In this paper, we investigate the performance of defect prediction models where Caret - an automated parameter optimization technique - has been applied. Through a case study of 18 datasets from systems that span both proprietary and open source domains, we find that (1) Caret improves the AUC performance of defect prediction models by as much as 40 percentage points; (2) Caret-optimized classifiers are at least as stable as (with 35% of them being more stable than) classifiers that are trained using the default settings; and (3) Caret increases the likelihood of producing a top-performing classifier by as much as 83%. Hence, we conclude that parameter settings can indeed have a large impact on the performance of defect prediction models, suggesting that researchers should experiment with the parameters of the classification techniques. Since automated parameter optimization techniques like Caret yield substantially benefits in terms of performance improvement and stability, while incurring a manageable additional computational cost, they should be included in future defect prediction studies.","","","10.1145/2884781.2884857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886914","software defect prediction;experimental design;classification techniques;parameter optimization","Predictive models;Vegetation;Optimization;Boosting;Decision trees;Kernel","pattern classification;public domain software;software fault tolerance;software quality","parameter optimization;classification techniques;defect prediction models;configurable parameters;Caret technique;proprietary domain;open source domain;Caret-optimized classifiers","","38","64","","","","","IEEE","IEEE Conferences"
"Is ""Better Data"" Better Than ""Better Data Miners""?","A. Agrawal; T. Menzies","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1050","1061","We report and fix an important systematic error in prior studies that ranked classifiers for software analytics. Those studies did not (a) assess classifiers on multiple criteria and they did not (b) study how variations in the data affect the results. Hence, this paper applies (a) multi-performance criteria while (b) fixing the weaker regions of the training data (using SMOTUNED, which is an auto-tuning version of SMOTE). This approach leads to dramatically large increases in software defect predictions when applied in a 5*5 cross-validation study for 3,681 JAVA classes (containing over a million lines of code) from open source systems, SMOTUNED increased AUC and recall by 60% and 20% respectively. These improvements are independent of the classifier used to predict for defects. Same kind of pattern (improvement) was observed when a comparative analysis of SMOTE and SMOTUNED was done against the most recent class imbalance technique. In conclusion, for software analytic tasks like defect prediction, (1) data pre-processing can be more important than classifier choice, (2) ranking studies are incomplete without such pre-processing, and (3) SMOTUNED is a promising candidate for pre-processing.","","","10.1145/3180155.3180197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453183","Search based SE;defect prediction;classification;data analytics for software engineering;SMOTE;imbalanced data;preprocessing","Software;Measurement;Couplings;Tuning;Task analysis;Complexity theory;Software engineering","data mining;Java;learning (artificial intelligence);pattern classification","dramatically large increases;software defect predictions;open source systems;SMOTE;recent class imbalance technique;software analytic tasks;defect prediction;classifier choice;data miners;important systematic error;software analytics;multiperformance criteria;training data;JAVA classes;SMOTUNED","","2","71","","","","","IEEE","IEEE Conferences"
"Accurate and Efficient Refactoring Detection in Commit History","N. Tsantalis; M. Mansouri; L. Eshkevari; D. Mazinanian; D. Dig","Concordia Univ., Montreal, QC, Canada; Concordia Univ., Montreal, QC, Canada; Concordia Univ., Montreal, QC, Canada; Concordia Univ., Montreal, QC, Canada; Oregon State Univ., Corvallis, OR, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","483","494","Refactoring detection algorithms have been crucial to a variety of applications: (i) empirical studies about the evolution of code, tests, and faults, (ii) tools for library API migration, (iii) improving the comprehension of changes and code reviews, etc. However, recent research has questioned the accuracy of the state-of-the-art refactoring detection tools, which poses threats to the reliability of their application. Moreover, previous refactoring detection tools are very sensitive to user-provided similarity thresholds, which further reduces their practical accuracy. In addition, their requirement to build the project versions/revisions under analysis makes them inapplicable in many real-world scenarios. To reinvigorate a previously fruitful line of research that has stifled, we designed, implemented, and evaluated RMiner, a technique that overcomes the above limitations. At the heart of RMiner is an AST-based statement matching algorithm that determines refactoring candidates without requiring user-defined thresholds. To empirically evaluate RMiner, we created the most comprehensive oracle to date that uses triangulation to create a dataset with considerably reduced bias, representing 3,188 refactorings from 185 open-source projects. Using this oracle, we found that RMiner has a precision of 98% and recall of 87%, which is a significant improvement over the previous state-of-the-art.","","","10.1145/3180155.3180206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453111","Refactoring;Commit;Git;Abstract Syntax Tree;Oracle;Accuracy","Tools;History;Open source software;Software systems;Java;Software engineering","application program interfaces;data mining;Java;public domain software;software libraries;software maintenance;software quality","comprehensive oracle;RMiner;commit history;detection algorithms;empirical studies;library API migration;code reviews;user-provided similarity thresholds;AST-based statement matching algorithm;user-defined thresholds;refactoring detection tools","","16","80","","","","","IEEE","IEEE Conferences"
"The Evolution of C Programming Practices: A Study of the Unix Operating System 1973-2015","D. Spinellis; P. Louridas; M. Kechagia","Dept. of Manage. Sci. & Technol., Athens Univ. of Econ. & Bus., Athens, Greece; Dept. of Manage. Sci. & Technol., Athens Univ. of Econ. & Bus., Athens, Greece; Dept. of Manage. Sci. & Technol., Athens Univ. of Econ. & Bus., Athens, Greece","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","748","759","Tracking long-term progress in engineering and applied science allows us to take stock of things we have achieved, appreciate the factors that led to them, and set realistic goals for where we want to go. We formulate seven hypotheses associated with the long term evolution of C programming in the Unix operating system, and examine them by extracting, aggregating, and synthesising metrics from 66 snapshots obtained from a synthetic software configuration management repository covering a period of four decades. We found that over the years developers of the Unix operating system appear to have evolved their coding style in tandem with advancements in hardware technology, promoted modularity to tame rising complexity, adopted valuable new language features, allowed compilers to allocate registers on their behalf, and reached broad agreement regarding code formatting. The progress we have observed appears to be slowing or even reversing prompting the need for new sources of innovation to be discovered and followed.","","","10.1145/2884781.2884799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886953","C;coding style;coding practices;Unix;BSD;FreeBSD","Software;Measurement;Complexity theory;Registers;Programming profession;Encoding","C language;configuration management;Unix","C programming;Unix operating system;synthetic software configuration management repository","","4","63","","","","","IEEE","IEEE Conferences"
"SourcererCC: Scaling Code Clone Detection to Big-Code","H. Sajnani; V. Saini; J. Svajlenko; C. K. Roy; C. V. Lopes","Sch. of Inf. & Comput. Sci., UC Irvine, Irvine, CA, USA; Sch. of Inf. & Comput. Sci., UC Irvine, Irvine, CA, USA; Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada; Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada; Sch. of Inf. & Comput. Sci., UC Irvine, Irvine, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1157","1168","Despite a decade of active research, there has been a marked lack in clone detection techniques that scale to large repositories for detecting near-miss clones. In this paper, we present a token-based clone detector, SourcererCC, that can detect both exact and near-miss clones from large inter-project repositories using a standard workstation. It exploits an optimized inverted-index to quickly query the potential clones of a given code block. Filtering heuristics based on token ordering are used to significantly reduce the size of the index, the number of code-block comparisons needed to detect the clones, as well as the number of required token-comparisons needed to judge a potential clone. We evaluate the scalability, execution time, recall and precision of SourcererCC, and compare it to four publicly available and state-of-the-art tools. To measure recall, we use two recent benchmarks: (1) a big benchmark of real clones, BigCloneBench, and (2) a Mutation/Injection-based framework of thousands of fine-grained artificial clones. We find SourcererCC has both high recall and precision, and is able to scale to a large inter-project repository (25K projects, 250MLOC) using a standard workstation.","","","10.1145/2884781.2884877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886988","clone detection;large software repositories;software repositories;code clones;recall;precision;scalability;large-scale;big-code","Cloning;Indexes;Detectors;Benchmark testing;Scalability;Software;Standards","Java;software engineering","SourcererCC;code clone detection technique;big-code;code-block comparisons;token-comparisons;BigCloneBench;mutation-injection-based framework;open-source Java systems","","63","42","","","","","IEEE","IEEE Conferences"
"Program Synthesis Using Natural Language","A. Desai; S. Gulwani; V. Hingorani; N. Jain; A. Karkare; M. Marron; S. R.; S. Roy","IIT Kanpur; MSR Redmond; IIT Kanpur; IIT Kanpur; IIT Kanpur; MSR Redmond; IIT Kanpur; IIT Kanpur","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","345","356","Interacting with computers is a ubiquitous activity for millions of people. Repetitive or specialized tasks often require creation of small, often one-off, programs. End-users struggle with learning and using the myriad of domain-specific languages (DSLs) to effectively accomplish these tasks. We present a general framework for constructing program synthesizers that take natural language (NL) inputs and produce expressions in a target DSL. The framework takes as input a DSL definition and training data consisting of NL/DSL pairs. From these it constructs a synthesizer by learning optimal weights and classifiers (using NLP features) that rank the outputs of a keyword-programming based translation. We applied our framework to three domains: repetitive text editing, an intelligent tutoring system, and flight information queries. On 1200+ English descriptions, the respective synthesizers rank the desired program as the top-1 and top-3 for 80% and 90% descriptions respectively.","","","10.1145/2884781.2884786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886916","Program Synthesis;Natrual Language Programming;Domain Specific Languages;End-user Programming;User Intent","DSL;Benchmark testing;Synthesizers;Automata;Training data;Training;Natural languages","formal specification;intelligent tutoring systems;natural language processing;query processing","program synthesis;natural language;domain-specific languages;DSL;keyword-programming based translation;repetitive text editing;intelligent tutoring system;flight information queries","","5","57","","","","","IEEE","IEEE Conferences"
"Augmenting API Documentation with Insights from Stack Overflow","C. Treude; M. P. Robillard","Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; Sch. of Comput. Sci., McGill Univ., Montr√©al, QC, Canada","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","392","403","Software developers need access to different kinds of information which is often dispersed among different documentation sources, such as API documentation or Stack Overflow. We present an approach to automatically augment API documentation with ""insight sentences"" from Stack Overflow -- sentences that are related to a particular API type and that provide insight not contained in the API documentation of that type. Based on a development set of 1,574 sentences, we compare the performance of two state-of-the-art summarization techniques as well as a pattern-based approach for insight sentence extraction. We then present SISE, a novel machine learning based approach that uses as features the sentences themselves, their formatting, their question, their answer, and their authors as well as part-of-speech tags and the similarity of a sentence to the corresponding API documentation. With SISE, we were able to achieve a precision of 0.64 and a coverage of 0.7 on the development set. In a comparative study with eight software developers, we found that SISE resulted in the highest number of sentences that were considered to add useful information not found in the API documentation. These results indicate that taking into account the meta data available on Stack Overflow as well as part-of-speech tags can significantly improve unsupervised extraction approaches when applied to Stack Overflow data.","","","10.1145/2884781.2884800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886920","API documentation;Stack Overflow;insight sentences","Documentation;Java;Software;Data mining;Joining processes;Feature extraction;Uniform resource locators","application program interfaces;learning (artificial intelligence)","API documentation augmentation;application program interface;Stack overflow;insight sentences;summarization techniques;pattern-based approach;insight sentence extraction;SISE approach;machine learning based approach","","36","41","","","","","IEEE","IEEE Conferences"
"FAST Approaches to Scalable Similarity-Based Test Case Prioritization","B. Miranda; E. Cruciani; R. Verdecchia; A. Bertolino","Fed. Univ. of Pernambuco, Recife, Brazil; Gran Sasso Sci. Inst., L'Aquila, Italy; Gran Sasso Sci. Inst., L'Aquila, Italy; ISTI, Pisa, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","222","232","Many test case prioritization criteria have been proposed for speeding up fault detection. Among them, similarity-based approaches give priority to the test cases that are the most dissimilar from those already selected. However, the proposed criteria do not scale up to handle the many thousands or even some millions test suite sizes of modern industrial systems and simple heuristics are used instead. We introduce the FAST family of test case prioritization techniques that radically changes this landscape by borrowing algorithms commonly exploited in the big data domain to find similar items. FAST techniques provide scalable similarity-based test case prioritization in both white-box and black-box fashion. The results from experimentation on real world C and Java subjects show that the fastest members of the family outperform other black-box approaches in efficiency with no significant impact on effectiveness, and also outperform white-box approaches, including greedy ones, if preparation time is not counted. A simulation study of scalability shows that one FAST technique can prioritize a million test cases in less than 20 minutes.","","","10.1145/3180155.3180210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453081","locality sensitive hashing;minhashing;scalability;similarity;software testing;test case prioritization","Scalability;History;Fault detection;Big Data;Software testing;Data mining","fault diagnosis;greedy algorithms;Java;program testing","test case prioritization criteria;similarity-based approaches;test case prioritization techniques;FAST technique;scalable similarity-based test case prioritization;black-box fashion;black-box approaches;white-box approaches;FAST approaches","","3","34","","","","","IEEE","IEEE Conferences"
"Understanding and Fixing Multiple Language Interoperability Issues: The C/Fortran Case","N. Sultana; J. Middleton; J. Overbey; M. Hafiz","Dept. of Comput. Sci. & Software Eng., Auburn Univ., Auburn, AL, USA; Dept. of Comput. Sci. & Software Eng., Auburn Univ., Auburn, AL, USA; Dept. of Comput. Sci. & Software Eng., Auburn Univ., Auburn, AL, USA; Dept. of Comput. Sci. & Software Eng., Auburn Univ., Auburn, AL, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","772","783","We performed an empirical study to understand interoperability issues in C and Fortran programs. C/Fortran interoperability is very common and is representative of general language interoperability issues, such as how interfaces between languages are defined and how data types are shared. Fortran presents an additional challenge, since several ad hoc approaches to C/Fortran interoperability were in use long before a standard mechanism was defined. We explored 20 applications, automatically analyzing over 12 million lines of code. We found that only 3% of interoperability instances follow the ISO standard to describe interfaces; the rest follow a combination of compiler-dependent ad hoc approaches. Several parameters in cross-language functions did not have standards-compliant interoperable types, and about one-fourth of the parameters that were passed by reference could be passed by value. We propose that automated refactoring tools may provide a viable way to migrate programs to use the new interoperability features. We present two refactorings to transform code for this purpose and one refactoring to evolve code thereafter; all of these are instances of multiple language refactorings.","","","10.1145/2884781.2884858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886955","C;Fortran;language interoperability;polyglot;refactoring","Interoperability;Java;Security;ISO Standards;Software engineering;Transforms","C language;FORTRAN;ISO standards;open systems;program compilers","multiple language interoperability issues;Fortran programs;C programs;ISO standard;compiler-dependent ad hoc approaches;cross-language functions;multiple language refactorings","","","40","","","","","IEEE","IEEE Conferences"
"Debugging Data Flows in Reactive Programs","H. Banken; E. Meijer; G. Gousios","Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","752","763","Reactive Programming is a style of programming that provides developers with a set of abstractions that facilitate event handling and stream processing. Traditional debug tools lack support for Reactive Programming, leading developers to fallback to the most rudimentary debug tool available: logging to the console. In this paper, we present the design and implementation of RxFiddle, a visualization and debugging tool targeted to Rx, the most popular form of Reactive Programming. RxFiddle visualizes the dependencies and structure of the data flow, as well as the data inside the flow. We evaluate RxFiddle with an experiment involving 111 developers. The results show that RxFiddle can help developers finish debugging tasks faster than with traditional debugging tools.","","","10.1145/3180155.3180156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453148","reactive programming;debugging;visualization;program comprehension","Debugging;Programming;Tools;Observers;Libraries;Companies;Interviews","program debugging;program visualisation","debugging tool;RxFiddle;data flow;debugging tasks;traditional debugging tools;stream processing;traditional debug tools;rudimentary debug tool;reactive programming","","2","52","","","","","IEEE","IEEE Conferences"
"Identifying Patch Correctness in Test-Based Program Repair","Y. Xiong; X. Liu; M. Zeng; L. Zhang; G. Huang","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","789","799","Test-based automatic program repair has attracted a lot of attention in recent years However, the test suites in practice are often too weak to guarantee correctness and existing approaches often generate a large number of incorrect patches. To reduce the number of incorrect patches generated, we propose a novel approach that heuristically determines the correctness of the generated patches. The core idea is to exploit the behavior similarity of test case executions. The passing tests on original and patched programs are likely to behave similarly while the failing tests on original and patched programs are likely to behave differently. Also, if two tests exhibit similar runtime behavior, the two tests are likely to have the same test results. Based on these observations, we generate new test inputs to enhance the test suites and use their behavior similarity to determine patch correctness. Our approach is evaluated on a dataset consisting of 139 patches generated from existing program repair systems including jGenProg, Nopol, jKali, ACS, and HDRepair. Our approach successfully prevented 56.3% of the incorrect patches to be generated, without blocking any correct patches.","","","10.1145/3180155.3180182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453152","Test based program repair;patch correctness;patch classification;test generation","Maintenance engineering;Search problems;Software;Computer crashes;Null value;Runtime","automatic programming;program debugging;program diagnostics;program testing;software maintenance","identifying patch correctness;test-based program repair;automatic program repair;incorrect patches;generated patches;behavior similarity;test case executions;passing tests;original programs;patched programs;similar runtime behavior;correct patches;program repair systems;jGenProg","","10","","","","","","IEEE","IEEE Conferences"
"Cross-Supervised Synthesis of Web-Crawlers","A. Omari; S. Shoham; E. Yahav","NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","368","379","A web-crawler is a program that automatically and systematically tracks the links of a website and extracts information from its pages. Due to the different formats of websites, the crawling scheme for different sites can differ dramatically. Manually customizing a crawler for each specific site is time consuming and error-prone. Furthermore, because sites periodically change their format and presentation, crawling schemes have to be manually updated and adjusted. In this paper, we present a technique for automatic synthesis of web-crawlers from examples. The main idea is to use hand-crafted (possibly partial) crawlers for some websites as the basis for crawling other sites that contain the same kind of information. Technically, we use the data on one site to identify data on another site. We then use the identified data to learn the website structure and synthesize an appropriate extraction scheme. We iterate this process, as synthesized extraction schemes result in additional data to be used for re-learning the website structure. We implemented our approach and automatically synthesized 30 crawlers for websites from nine different categories: books, TVs, conferences, universities, cameras, phones, movies, songs, and hotels.","","","10.1145/2884781.2884842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886918","Data extraction;wrapper;synthesis;scarpper","Crawlers;Data mining;Containers;Layout;Database languages;Glass;Concrete","information retrieval;Internet","cross-supervised synthesis;Web crawler;information extraction;crawler customization;crawling schemes","","1","41","","","","","IEEE","IEEE Conferences"
"Learning API Usages from Bytecode: A Statistical Approach","T. T. Nguyen; H. V. Pham; P. M. Vu; T. T. Nguyen","NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","416","427","Mobile app developers rely heavily on standard API frameworks and libraries. However, learning API usages is often challenging due to the fast-changing nature of API frameworks for mobile systems and the insufficiency of API documentation and source code examples. In this paper, we propose a novel approach to learn API usages from bytecode of Android mobile apps. Our core contributions include HAPI, a statistical model of API usages and three algorithms to extract method call sequences from apps' bytecode, to train HAPI based on those sequences, and to recommend method calls in code completion using the trained HAPIs. Our empirical evaluation shows that our prototype tool can effectively learn API usages from 200 thousand apps containing 350 million method sequences. It recommends next method calls with top-3 accuracy of 90% and outperforms baseline approaches on average 10-20%.","","","10.1145/2884781.2884873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886922","Statistical model;API usage;mobile apps","Hidden Markov models;Mobile communication;Androids;Humanoid robots;Algorithm design and analysis;Documentation;Probabilistic logic","application program interfaces;mobile computing;statistical analysis","API usages learning;Bytecode;statistical approach;mobile app developers;application program interface;API frameworks;API documentation;HAPI model;code completion","","10","45","","","","","IEEE","IEEE Conferences"
"Assessing the Threat of Untracked Changes in Software Evolution","A. Hora; D. Silva; M. T. Valente; R. Robbes","FACOM, UFMS, Campo Grande, Brazil; Valente ASERG Group, UFMG, Valente, Brazil; Valente ASERG Group, UFMG, Valente, Brazil; SwSE Group, Free Univ. of Bozen-Bolzano, Bolzano, Italy","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1102","1113","While refactoring is extensively performed by practitioners, many Mining Software Repositories (MSR) approaches do not detect nor keep track of refactorings when performing source code evolution analysis. In the best case, keeping track of refactorings could be unnecessary work; in the worst case, these untracked changes could significantly affect the performance of MSR approaches. Since the extent of the threat is unknown, the goal of this paper is to assess whether it is significant. Based on an extensive empirical study, we answer positively: we found that between 10 and 21% of changes at the method level in 15 large Java systems are untracked. This results in a large proportion (25%) of entities that may have their histories split by these changes, and a measurable effect on at least two MSR approaches. We conclude that handling untracked changes should be systematically considered by MSR studies.","","","10.1145/3180155.3180212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453191","Mining Software Repositories;Software Evolution;Refactoring","Blogs;Software;Tracking;Bars;History;Tools;Computer bugs","data mining;Java;public domain software;software maintenance","software evolution;software repository approache mining;source code evolution analysis;MSR studies;extensive empirical study;MSR approaches;untracked changes","","1","69","","","","","IEEE","IEEE Conferences"
"Mining Sandboxes","K. Jamrozik; P. von Styp-Rekowsky; A. Zeller","Center for IT-Security, Privacy & Accountability, Saarbrucken, Germany; Center for IT-Security, Privacy & Accountability, Saarbrucken, Germany; Center for IT-Security, Privacy & Accountability, Saarbrucken, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","37","48","We present sandbox mining, a technique to confine an application to resources accessed during automatic testing. Sandbox mining first explores software behavior by means of automatic test generation, and extracts the set of resources accessed during these tests. This set is then used as a sandbox, blocking access to resources not used during testing. The mined sandbox thus protects against behavior changes such as the activation of latent malware, infections, targeted attacks, or malicious updates. The use of test generation makes sandbox mining a fully automatic process that can be run by vendors and end users alike. Our BOXMATE prototype requires less than one hour to extract a sandbox from an Android app, with few to no confirmations required for frequently used functionality.","","","10.1145/2884781.2884782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886890","specification mining;sandboxing;test generation;program analysis;dynamic analysis;android;security;policy enforcement","Testing;Androids;Humanoid robots;Monitoring;Smart phones;Generators;Graphical user interfaces","data mining;program testing","sandbox mining technique;automatic test generation;resource extraction;test generation;BOXMATE;Android application","","11","38","","","","","IEEE","IEEE Conferences"
"Debugging for Reactive Programming","G. Salvaneschi; M. Mezini","Tech. Univ. of Darmstadt, Darmstadt, Germany; Tech. Univ. of Darmstadt, Darmstadt, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","796","807","Reactive programming is a recent programming technique that provides dedicated language abstractions for reactive software. Reactive programming relieves developers from manually updating outputs when the inputs of a computation change, it overcomes a number of well-know issues of the Observer design pattern, and it makes programs more comprehensible. Unfortunately, complementing the new paradigm with proper tools is a vastly unexplored area. Hence, as of now, developers can embrace reactive programming only at the cost of a more challenging development process. In this paper, we investigate a primary issue in the field: debugging programs in the reactive style. We analyze the problem of debugging reactive programs, show that the reactive style requires a paradigm shift in the concepts needed for debugging, and propose RP Debugging, a methodology for effectively debugging reactive programs. These ideas are implemented in Reactive Inspector, a debugger for reactive programs integrated with the Eclipse Scala IDE. Evaluation based on a controlled experiment shows that RP Debugging outperforms traditional debugging techniques.","","","10.1145/2884781.2884815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886957","Functional-reactive Programming;Debugging","Debugging;Programming;Reactive power;Runtime;Observers;Libraries;Data models","program debugging;programming environments","reactive programming;RP Debugging;Reactive Inspector;Eclipse Scala IDE","","4","49","","","","","IEEE","IEEE Conferences"
"Probing for Requirements Knowledge to Stimulate Architectural Thinking","P. R. Anish; B. Balasubramaniam; A. Sainani; J. Cleland-Huang; M. Daneva; R. J. Wieringa; S. Ghaisas","TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India; TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India; TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India; Syst. & Requirements Eng. Center, DePaul Univ., Chicago, IL, USA; Univ. of Twente, Enschede, Netherlands; Univ. of Twente, Enschede, Netherlands; TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","843","854","Software requirements specifications (SRSs) often lack the detail needed to make informed architectural decisions. Architects therefore either make assumptions, which can lead to incorrect decisions, or conduct additional stakeholder interviews, resulting in potential project delays. We previously observed that software architects ask Probing Questions (PQs) to gather information crucial to architectural decision-making. Our goal is to equip Business Analysts with appropriate PQs so that they can ask these questions themselves. We report a new study with over 40 experienced architects to identify reusable PQs for five areas of functionality and organize them into structured flows. These PQflows can be used by Business Analysts to elicit and specify architecturally relevant information. Additionally, we leverage machine learning techniques to determine when a PQ-flow is appropriate for use in a project, and to annotate individual PQs with relevant information extracted from the existing SRS. We trained and evaluated our approach on over 8,000 individual requirements from 114 requirements specifications and also conducted a pilot study to validate its usefulness.","","","10.1145/2884781.2884801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886961","Architecturally significant requirements;automated requirement classification;functional requirements;requirements knowledge;Probing Questions (PQs);PQ-flows","Interviews;Barium;Software;Stakeholders;Batch production systems;Requirements engineering","formal specification;learning (artificial intelligence);software architecture","requirements knowledge;architecturally significant requirements;probing questions;PQ-flow;machine learning techniques;software requirements specifications;SRS","","3","52","","","","","IEEE","IEEE Conferences"
"Speedoo: Prioritizing Performance Optimization Opportunities","Z. Chen; B. Chen; L. Xiao; X. Wang; L. Chen; Y. Liu; B. Xu","State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China; Shanghai Key Lab. of Data Sci., Fudan Univ., Shanghai, China; Sch. of Syst. & Enterprises, Stevens Inst. of Technol., Hoboken, NJ, USA; Sch. of Syst. & Enterprises, Stevens Inst. of Technol., Hoboken, NJ, USA; State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China; Sch. of Comput. Sci. & Eng., Nanyang Technol. Univ., Singapore, Singapore; State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","811","821","Performance problems widely exist in modern software systems. Existing performance optimization techniques, including profiling-based and pattern-based techniques, usually fail to consider the architectural impacts among methods that easily slow down the overall system performance. This paper contributes a new approach, named Speedoo, to identify groups of methods that should be treated together and deserve high priorities for performance optimization. The uniqueness of Speedoo is to measure and rank the performance optimization opportunities of a method based on 1) the architectural impact and 2) the optimization potential. For each highly ranked method, we locate a respective Optimization Space based on 5 performance patterns generalized from empirical observations. The top ranked optimization spaces are suggested to developers as potential optimization opportunities. Our evaluation on three real-life projects has demonstrated that 18.52% to 42.86% of methods in the top ranked optimization spaces indeed undertook performance optimization in the projects. This outperforms one of the state-of-the-art profiling tools YourKit by 2 to 3 times. An important implication of this study is that developers should treat methods in an optimization space together as a group rather than as individuals in performance optimization. The proposed approach can provide guidelines and reduce developers' manual effort.","","","10.1145/3180155.3180229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453154","Performance;Metrics;Architecture","Optimization;Measurement;Software;System performance;Computer architecture;Complexity theory;Manuals","optimisation;program diagnostics;software performance evaluation","Speedoo;performance optimization techniques;pattern-based techniques;architectural impact;system performance;optimization potential;software systems;optimization space;profiling-based techniques","","2","60","","","","","IEEE","IEEE Conferences"
"Code Anomalies Flock Together: Exploring Code Anomaly Agglomerations for Locating Design Problems","W. Oizumi; A. Garcia; L. d. S. Sousa; B. Cafeo; Y. Zhao","Inf. Dept., PUC-Rio Rio de Janeiro, Rio de Janeiro, Brazil; Inf. Dept., PUC-Rio Rio de Janeiro, Rio de Janeiro, Brazil; NA; Inf. Dept., PUC-Rio Rio de Janeiro, Rio de Janeiro, Brazil; Dept. of Comput. Sci., USC, Los Angeles, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","440","451","Design problems affect every software system. Diverse software systems have been discontinued or reengineered due to design problems. As design documentation is often informal or nonexistent, design problems need to be located in the source code. The main difficulty to identify a design problem in the implementation stems from the fact that such problem is often scattered through several program elements. Previous work assumed that code anomalies -- popularly known as code smells -- may provide sufficient hints about the location of a design problem. However, each code anomaly alone may represent only a partial embodiment of a design problem. In this paper, we hypothesize that code anomalies tend to ``flock together'' to realize a design problem. We analyze to what extent groups of inter-related code anomalies, named agglomerations, suffice to locate design problems. We analyze more than 2200 agglomerations found in seven software systems of different sizes and from different domains. Our analysis indicates that certain forms of agglomerations are consistent indicators of both congenital and evolutionary design problems, with accuracy often higher than 80%.","","","10.1145/2884781.2884868","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886924","agglomeration;code anomaly;desing problem","Fats;Syntactics;Software systems;Surgery;Documentation;Semantics","software engineering","code anomaly agglomerations;software design;diverse software systems;design documentation;code smells;congenital design problems;evolutionary design problems","","9","45","","","","","IEEE","IEEE Conferences"
"HireBuild: An Automatic Approach to History-Driven Repair of Build Scripts","F. Hassan; X. Wang","NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1078","1089","Advancements in software build tools such as Maven reduce build management effort, but developers still need specialized knowledge and long time to maintain build scripts and resolve build failures. More recent build tools such as Gradle give developers greater extent of customization flexibility, but can be even more difficult to maintain. According to the TravisTorrent dataset of open-source software continuous integration, 22% of code commits include changes in build script files to maintain build scripts or to resolve build failures. Automated program repair techniques have great potential to reduce cost of resolving software failures, but the existing techniques mostly focus on repairing source code so that they cannot directly help resolving software build failures. To address this limitation, we propose HireBuild: History-Driven Repair of Build Scripts, the first approach to automatic patch generation for build scripts, using fix patterns automatically generated from existing build script fixes and recommending fix patterns based on build log similarity. From TravisTorrent dataset, we extracted 175 build failures and their corresponding fixes which revise Gradle build scripts. Among these 175 build failures, we used the 135 earlier build fixes for automatic fix-pattern generation and the more recent 40 build failures (fixes) for evaluation of our approach. Our experiment shows that our approach can fix 11 of 24 reproducible build failures, or 45% of the reproducible build failures, within comparable time of manual fixes.","","","10.1145/3180155.3180181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453189","Patch Generation;Software Build Scripts;Build Logs","Maintenance engineering;Software;Tools;Task analysis;Computer bugs;Data mining;Software engineering","software fault tolerance;software maintenance;software tools;source code (software)","software build failures;History-Driven Repair;build log similarity;Gradle build scripts;software build tools;build script files;fix patterns;reproducible build failures;HireBuild;Automated program repair techniques;source code;automatic patch generation;build script fixes","","6","51","","","","","IEEE","IEEE Conferences"
"Release Planning of Mobile Apps Based on User Reviews","L. Villarroel; G. Bavota; B. Russo; R. Oliveto; M. Di Penta","Free Univ. of Bozen-Bolzano, Bolzano, Italy; Free Univ. of Bozen-Bolzano, Bolzano, Italy; Free Univ. of Bozen-Bolzano, Bolzano, Italy; Univ. of Molise, Pesche, Italy; Univ. of Sannio, Benevento, Italy","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","14","24","Developers have to to constantly improve their apps by fixing critical bugs and implementing the most desired features in order to gain shares in the continuously increasing and competitive market of mobile apps. A precious source of information to plan such activities is represented by reviews left by users on the app store. However, in order to exploit such information developers need to manually analyze such reviews. This is something not doable if, as frequently happens, the app receives hundreds of reviews per day. In this paper we introduce CLAP (Crowd Listener for releAse Planning), a thorough solution to (i) categorize user reviews based on the information they carry out (e.g., bug reporting), (ii) cluster together related reviews (e.g., all reviews reporting the same bug), and (iii) automatically prioritize the clusters of reviews to be implemented when planning the subsequent app release. We evaluated all the steps behind CLAP, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. Also, given the availability of CLAP as a working tool, we assessed its practical applicability in industrial environments.","","","10.1145/2884781.2884818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886888","","Computer bugs;Mobile communication;Planning;Thesauri;Software;Machine learning algorithms;Merging","mobile computing;software maintenance","release planning;mobile applications;user review;app store;information source;CLAP;crowd listener for release planning","","41","31","","","","","IEEE","IEEE Conferences"
"Goal-Conflict Likelihood Assessment Based on Model Counting","R. Degiovanni; P. Castro; M. Arroyo; M. Ruiz; N. Aguirre; M. Frias","Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina; Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina; Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina; Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina; Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina; Univ. Nac. de Rio Cuarto, Rio Cuarto, Argentina","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1125","1135","In goal-oriented requirements engineering approaches, conflict analysis has been proposed as an abstraction for risk analysis. Intuitively, given a set of expected goals to be achieved by the system-to-be, a conflict represents a subtle situation that makes goals diverge, i.e., not be satisfiable as a whole. Conflict analysis is typically driven by the identify-assess-control cycle, aimed at identifying, assessing and resolving conflicts that may obstruct the satisfaction of the expected goals. In particular, the assessment step is concerned with evaluating how likely the identified conflicts are, and how likely and severe are their consequences. So far, existing assessment approaches restrict their analysis to obstacles (conflicts that prevent the satisfaction of a single goal), and assume that certain probabilistic information on the domain is provided, that needs to be previously elicited from experienced users, statistical data or simulations. In this paper, we present a novel automated approach to assess how likely a conflict is, that applies to general conflicts (not only obstacles) without requiring probabilistic information on the domain. Intuitively, given the LTL formulation of the domain and of a set of goals to be achieved, we compute goal conflicts, and exploit string model counting techniques to estimate the likelihood of the occurrence of the corresponding conflicting situations and the severity in which these affect the satisfaction of the goals. This information can then be used to prioritize conflicts to be resolved, and suggest which goals to drive attention to for refinements.","","","10.1145/3180155.3180261","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453193","Goal Conflicts;Risk Likelihood Assessment;Model Counting","Analytical models;Boundary conditions;Software;Probabilistic logic;Computational modeling;Software engineering;Requirements engineering","formal specification;formal verification;maximum likelihood estimation;risk analysis;systems analysis","goal-conflict likelihood assessment;conflict analysis;risk analysis;goal-oriented requirements engineering","","","45","","","","","IEEE","IEEE Conferences"
"Adding Sparkle to Social Coding: An Empirical Study of Repository Badges in the npm Ecosystem","A. Trockman; S. Zhou; C. K√§stner; B. Vasilescu","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","511","522","In fast-paced, reuse-heavy, and distributed software development, the transparency provided by social coding platforms like GitHub is essential to decision making. Developers infer the quality of projects using visible cues, known as signals, collected from personal profile and repository pages. We report on a large-scale, mixed-methods empirical study of npm packages that explores the emerging phenomenon of repository badges, with which maintainers signal underlying qualities about their projects to contributors and users. We investigate which qualities maintainers intend to signal and how well badges correlate with those qualities. After surveying developers, mining 294,941 repositories, and applying statistical modeling and time-series analyses, we find that non-trivial badges, which display the build status, test coverage, and up-to-dateness of dependencies, are mostly reliable signals, correlating with more tests, better pull requests, and fresher dependencies. Displaying such badges correlates with best practices, but the effects do not always persist.","","","10.1145/3180155.3180209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453117","repository badge;signaling theory;regression discontinuity design;mining software repositories;dependency manager","Reliability;Encoding;Ecosystems;Open source software;Tools;Best practices","","","","2","65","","","","","IEEE","IEEE Conferences"
"Performance Issues and Optimizations in JavaScript: An Empirical Study","M. Selakovic; M. Pradel","Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany; Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","61","72","As JavaScript is becoming increasingly popular, the performance of JavaScript programs is crucial to ensure the responsiveness and energy-efficiency of thousands of pro- grams. Yet, little is known about performance issues that developers face in practice and they address these issues. This paper presents an empirical study of 98 fixed performance issues from 16 popular client-side and server-side JavaScript projects. We identify eight root causes of issues and show that inefficient usage of APIs is the most prevalent root cause. Furthermore, we find that most is- sues are addressed by optimizations that modify only a few lines of code, without significantly affecting the complexity of the source code. By studying the performance impact of optimizations on several versions of the SpiderMonkey and V8 engines, we find that only 42.68% of all optimizations improve performance consistently across all versions of both engines. Finally, we observe that many optimizations are instances of patterns applicable across projects, as evidenced by 139 previously unknown optimization opportunities that we find based on the patterns identified during the study. The results of the study help application developers to avoid common mistakes, researchers to develop performance-related techniques that address relevant problems, and engine developers to address prevalent bottleneck patterns.","","","10.1145/2884781.2884829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886892","JavaScript;Empirical study;Performance issue;Optimization","Optimization;Engines;Servers;Libraries;Computer bugs;Reliability;Computer science","Java;software performance evaluation","JavaScript programs;API;SpiderMonkey;V8 engines;JavaScript performance","","9","44","","","","","IEEE","IEEE Conferences"
"Are Mutation Scores Correlated with Real Fault Detection? A Large Scale Empirical Study on the Relationship Between Mutants and Real Faults","M. Papadakis; D. Shin; S. Yoo; D. Bae","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","537","548","Empirical validation of software testing studies is increasingly relying on mutants. This practice is motivated by the strong correlation between mutant scores and real fault detection that is reported in the literature. In contrast, our study shows that correlations are the results of the confounding effects of the test suite size. In particular, we investigate the relation between two independent variables, mutation score and test suite size, with one dependent variable the detection of (real) faults. We use two data sets, CoreBench and De-fects4J, with large C and Java programs and real faults and provide evidence that all correlations between mutation scores and real fault detection are weak when controlling for test suite size. We also found that both independent variables significantly influence the dependent one, with significantly better fits, but overall with relative low prediction power. By measuring the fault detection capability of the top ranked, according to mutation score, test suites (opposed to randomly selected test suites of the same size), we found that achieving higher mutation scores improves significantly the fault detection. Taken together, our data suggest that mutants provide good guidance for improving the fault detection of test suites, but their correlation with fault detection are weak.","","","10.1145/3180155.3180183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453121","mutation testing;real faults;test suite effectiveness","Fault detection;Correlation;Java;Measurement;Software testing;Software engineering","Java;program testing","mutation score;randomly selected test suites;higher mutation scores;mutation scores correlated;real fault detection;scale empirical study;empirical validation;software testing studies;mutant scores;test suite size;dependent variable the detection;fault detection capability","","4","","","","","","IEEE","IEEE Conferences"
"RETracer: Triaging Crashes by Reverse Execution from Partial Memory Dumps","W. Cui; M. Peinado; S. K. Cha; Y. Fratantonio; V. P. Kemerlis","NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","820","831","Many software providers operate crash reporting services to automatically collect crashes from millions of customers and file bug reports. Precisely triaging crashes is necessary and important for software providers because the millions of crashes that may be reported every day are critical in identifying high impact bugs. However, the triaging accuracy of existing systems is limited, as they rely only on the syntactic information of the stack trace at the moment of a crash without analyzing program semantics. In this paper, we present RETracer, the first system to triage software crashes based on program semantics reconstructed from memory dumps. RETracer was designed to meet the requirements of large-scale crash reporting services. RETracer performs binary-level backward taint analysis without a recorded execution trace to understand how functions on the stack contribute to the crash. The main challenge is that the machine state at an earlier time cannot be recovered completely from a memory dump, since most instructions are information destroying. We have implemented RETracer for x86 and x86-64 native code, and compared it with the existing crash triaging tool used by Microsoft. We found that RETracer eliminates two thirds of triage errors based on a manual analysis of 140 bugs fixed in Microsoft Windows and Office. RETracer has been deployed as the main crash triaging system on Microsoft's crash reporting service.","","","10.1145/2884781.2884844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886959","triaging;backward taint analysis;reverse execution","Computer bugs;Registers;Semantics;Instruction sets","program debugging;program diagnostics;programming language semantics","RETracer;software crashes triage;program semantics;large-scale crash reporting services;binary-level backward taint analysis;machine state;x86-64 native code;x86 native code;software crash triaging;file bug reports;Microsoft Windows;Microsoft Office;Microsoft crash reporting service;high impact bugs;syntactic information;stack trace;reverse execution;partial memory dumps;software providers","","8","52","","","","","IEEE","IEEE Conferences"
"Discovering ""Unknown Known"" Security Requirements","A. Rashid; S. A. A. Naqvi; R. Ramdhany; M. Edwards; R. Chitchyan; M. A. Babar","Security Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Security Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Security Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Security Lancaster Res. Centre, Lancaster Univ., Lancaster, UK; Dept. of Comput. Sci., Univ. of Leicester, Leicester, UK; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","866","876","Security is one of the biggest challenges facing organisations in the modern hyper-connected world. A number of theoretical security models are available that provide best practice security guidelines and are widely utilised as a basis to identify and operationalise security requirements. Such models often capture high-level security concepts (e.g., whitelisting, secure configurations, wireless access control, data recovery, etc.), strategies for operationalising such concepts through specific security controls, and relationships between the various concepts and controls. The threat landscape, however, evolves leading to new tacit knowledge that is embedded in or across a variety of security incidents. These unknown knowns alter, or at least demand reconsideration of the theoretical security models underpinning security requirements. In this paper, we present an approach to discover such unknown knowns through multi-incident analysis. The approach is based on a novel combination of grounded theory and incident fault trees. We demonstrate the effectiveness of the approach through its application to identify revisions to a theoretical security model widely used in industry.","","","10.1145/2884781.2884785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886963","Security requirements;incident analysis;grounded theory","Security;Fault trees;Biological system modeling;Logic gates;Guidelines;Industries;Adaptation models","fault trees;formal specification;security of data","security requirements;multiincident analysis;grounded theory;incident fault trees;theoretical security model","","2","23","","","","","IEEE","IEEE Conferences"
"RFC-Directed Differential Testing of Certificate Validation in SSL/TLS Implementations","C. Chen; C. Tian; Z. Duan; L. Zhao","ICTT & ISN Lab., Xidian Univ. Xi'an, Xi'an, China; ICTT & ISN Lab., Xidian Univ. Xi'an, Xi'an, China; ICTT & ISN Lab., Xidian Univ. Xi'an, Xi'an, China; ICTT & ISN Lab., Xidian Univ. Xi'an, Xi'an, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","859","870","Certificate validation in Secure Socket Layer or Transport Layer Security protocol (SSL/TLS) is critical to Internet security. Thus, it is significant to check whether certificate validation in SSL/TLS is correctly implemented. With this motivation, we propose a novel differential testing approach which is directed by the standard Request For Comments (RFC). First, rules of certificates are extracted automatically from RFCs. Second, low-level test cases are generated through dynamic symbolic execution. Third, high-level test cases, i.e. certificates, are assembled automatically. Finally, with the assembled certificates being test cases, certificate validations in SSL/TLS implementations are tested to reveal latent vulnerabilities or bugs. Our approach named RFCcert has the following advantages: (1) certificates of RFCcert are discrepancy-targeted since they are assembled according to standards instead of genetics; (2) with the obtained certificates, RFCcert not only reveals the invalidity of traditional differential testing but also is able to conduct testing that traditional differential testing cannot do; and (3) the supporting tool of RFCcert has been implemented and extensive experiments show that the approach is effective in finding bugs of SSL/TLS implementations.","","","10.1145/3180155.3180226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453160","Differential testing;certificate validation;SSL/TLS;dynamic symbolic execution;Request For Comments","Testing;Computer bugs;Public key;Standards;Servers;Protocols","certification;computer network security;Internet;program testing;protocols;security of data","RFC-directed differential testing;certificate validation;Internet security;novel differential testing approach;low-level test cases;high-level test cases;assembled certificates;RFCcert;traditional differential testing;secure socket layer;transport layer security protocol;SSL-TLS implementations","","1","","","","","","IEEE","IEEE Conferences"
"CUSTODES: Automatic Spreadsheet Cell Clustering and Smell Detection Using Strong and Weak Features","S. Cheung; W. Chen; Y. Liu; C. Xu","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Tech., Nanjing Univ., Nanjing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","464","475","Various techniques have been proposed to detect smells in spreadsheets, which are susceptible to errors. These techniques typically detect spreadsheet smells through a mechanism based on a fixed set of patterns or metric thresholds. Unlike conventional programs, tabulation styles vary greatly across spreadsheets. Smell detection based on fixed patterns or metric thresholds, which are insensitive to the varying tabulation styles, can miss many smells in one spreadsheet while reporting many spurious smells in another. In this paper, we propose CUSTODES to effectively cluster spreadsheet cells and detect smells in these clusters. The clustering mechanism can automatically adapt to the tabulation styles of each spreadsheet using strong and weak features. These strong and weak features capture the invariant and variant parts of tabulation styles, respectively. As smelly cells in a spreadsheet normally occur in minority, they can be mechanically detected as clusters' outliers in feature spaces. We implemented and applied CUSTODES to 70 spreadsheets files randomly sampled from the EUSES corpus. These spreadsheets contain 1,610 formula cell clusters. Experimental results confirmed that CUSTODES is effective. It successfully detected harmful smells that can induce computation anomalies in spreadsheets with an F-measure of 0.72, outperforming state-of-the-art techniques.","","","10.1145/2884781.2884796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886926","Spreadsheets;cell clustering;smell detection;feature modeling;end-user programming","Feature extraction;Measurement;Adaptation models;Software;Computers;Computational modeling;Quality assurance","pattern clustering;program diagnostics;spreadsheet programs","automatic spreadsheet cell clustering;smell detection;tabulation styles;CUSTODES;EUSES corpus;F-measure","","8","49","","","","","IEEE","IEEE Conferences"
"On The Limits of Mutation Reduction Strategies","R. Gopinath; M. A. Alipour; I. Ahmed; C. Jensen; A. Groce","NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","511","522","Although mutation analysis is considered the best way to evaluate the effectiveness of a test suite, hefty computational cost often limits its use. To address this problem, various mutation reduction strategies have been proposed, all seeking to reduce the number of mutants while maintaining the representativeness of an exhaustive mutation analysis. While research has focused on the reduction achieved, the effectiveness of these strategies in selecting representative mutants, and the limits in doing so have not been investigated, either theoretically or empirically. We investigate the practical limits to the effectiveness of mutation reduction strategies, and provide a simple theoretical framework for thinking about the absolute limits. Our results show that the limit in improvement of effectiveness over random sampling for real-world open source programs is a mean of only 13.078%. Interestingly, there is no limit to the improvement that can be made by addition of new mutation operators. Given that this is the maximum that can be achieved with perfect advance knowledge of mutation kills, what can be practically achieved may be much worse. We conclude that more effort should be focused on enhancing mutations than removing operators in the name of selective mutation for questionable benefit.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886930","software testing; statistical analysis; theoretical analysis; mutation analysis","Sociology;Software engineering;Testing;Computer bugs;Syntactics;Correlation","program diagnostics;program testing;public domain software","software testing;mutation operators;open source programs;random sampling;mutation reduction strategies","","4","54","","","","","IEEE","IEEE Conferences"
"A Static Verification Framework for Message Passing in Go Using Behavioural Types","J. Lange; N. Ng; B. Toninho; N. Yoshida","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1137","1148","The Go programming language has been heavily adopted in industry as a language that efficiently combines systems programming with concurrency. Go's concurrency primitives, inspired by process calculi such as CCS and CSP, feature channel-based communication and lightweight threads, providing a distinct means of structuring concurrent software. Despite its popularity, the Go programming ecosystem offers little to no support for guaranteeing the correctness of message-passing concurrent programs. This work proposes a practical verification framework for message passing concurrency in Go by developing a robust static analysis that infers an abstract model of a program's communication behaviour in the form of a behavioural type, a powerful process calculi typing discipline. We make use of our analysis to deploy a model and termination checking based verification of the inferred behavioural type that is suitable for a range of safety and liveness properties of Go programs, providing several improvements over existing approaches. We evaluate our framework and its implementation on publicly available real-world Go code.","","","10.1145/3180155.3180157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453195","concurrency;static analysis;behavioural types;model checking;go programming language","Concurrent computing;System recovery;Programming;Safety;Message systems;Software;Computer languages","concurrency control;formal verification;message passing;program diagnostics;program verification","static verification framework;Go programming language;concurrency primitives;feature channel-based communication;lightweight threads;concurrent software;Go programming ecosystem;message-passing concurrent programs;practical verification framework;message passing concurrency;robust static analysis;powerful process calculi;termination checking based verification;inferred behavioural type","","1","45","","","","","IEEE","IEEE Conferences"
"Optimizing Selection of Competing Services with Probabilistic Hierarchical Refinement","T. H. Tan; M. Chen; J. Sun; Y. Liu; √â. Andr√©; Y. Xue; J. S. Dong","NA; NA; NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","85","95","Recently, many large enterprises (e.g., Netflix, Amazon) have decomposed their monolithic application into services, and composed them to fulfill their business functionalities. Many hosting services on the cloud, with different Quality of Service (QoS) (e.g., availability, cost), can be used to host the services. This is an example of competing services. QoS is crucial for the satisfaction of users. It is important to choose a set of services that maximize the overall QoS, and satisfy all QoS requirements for the service composition. This problem, known as optimal service selection, is NP-hard. Therefore, an effective method for reducing the search space and guiding the search process is highly desirable. To this end, we introduce a novel technique, called Probabilistic Hierarchical Refinement (PROHR). PROHR effectively reduces the search space by removing competing services that cannot be part of the selection. PROHR provides two methods, probabilistic ranking and hierarchical refinement, that enable smart exploration of the reduced search space. Unlike existing approaches that perform poorly when QoS requirements become stricter, PROHR maintains high performance and accuracy, independent of the strictness of the QoS requirements. PROHR has been evaluated on a publicly available dataset, and has shown significant improvement over existing approaches.","","","10.1145/2884781.2884861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886894","Service Selection;Service Composition;Mixed Integer Programming","Quality of service;Concrete;Time factors;Probabilistic logic;Web services;Automobiles","computational complexity;probability;quality of service;Web services","probabilistic hierarchical refinement;business functionalities;hosting services;cloud computing;quality of service;QoS;user satisfaction;optimal service selection problem;NP-hard problem;PROHR technique;probabilistic ranking technique;hierarchical refinement technique","","6","38","","","","","IEEE","IEEE Conferences"
"Augusto: Exploiting Popular Functionalities for the Generation of Semantic GUI Tests with Oracles","L. Mariani; M. Pezz√®; D. Zuddas","NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","280","290","Testing software applications by interacting with their graphical user interface (GUI) is an expensive and complex process. Current automatic test case generation techniques implement explorative approaches that, although producing useful test cases, have a limited capability of covering semantically relevant interactions, thus frequently missing important testing scenarios. These techniques typically interact with the available widgets following the structure of the GUI, without any guess about the functions that are executed. In this paper we propose Augusto, a test case generation technique that exploits a built-in knowledge of the semantics associated with popular and well-known functionalities, such as CRUD operations, to automatically generate effective test cases with automated functional oracles. Empirical results indicate that Augusto can reveal faults that cannot be revealed with state of the art techniques.","","","10.1145/3180155.3180162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453087","GUI testing;automatic test case generation;semantics;oracles","Graphical user interfaces;Semantics;Testing;Software;Authentication;Pattern matching;Adaptation models","graphical user interfaces;program testing","useful test cases;semantically relevant interactions;important testing scenarios;Augusto;test case generation technique;semantics;effective test cases;automated functional oracles;popular functionalities;semantic GUI tests;software applications;graphical user interface;expensive process;complex process;current automatic test case generation techniques","","2","","","","","","IEEE","IEEE Conferences"
"Spatio-Temporal Context Reduction: A Pointer-Analysis-Based Static Approach for Detecting Use-After-Free Vulnerabilities","H. Yan; Y. Sui; S. Chen; J. Xue","Sch. of Comput. Sci. & Eng., Univ. of New South Wales, Sydney, NSW, Australia; Centre for Artificial Intell. & Sch. of Software, Univ. of Technol., Sydney, NSW, Australia; Data61, CSIRO, Australia; Sch. of Comput. Sci. & Eng., Univ. of New South Wales, Sydney, NSW, Australia","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","327","337","Zero-day Use-After-Free (UAF) vulnerabilities are increasingly popular and highly dangerous, but few mitigations exist. We introduce a new pointer-analysis-based static analysis, CRed, for finding UAF bugs in multi-MLOC C source code efficiently and effectively. Cred achieves this by making three advances: (i) a spatio-temporal context reduction technique for scaling down soundly and precisely the exponential number of contexts that would otherwise be considered at a pair of free and use sites, (ii) a multi-stage analysis for filtering out false alarms efficiently, and (iii) a path-sensitive demand-driven approach for finding the points-to information required. We have implemented CRed in LLVM-3.8.0 and compared it with four different state-of-the-art static tools: CBMC (model checking), Clang (abstract interpretation), Coccinelle (pattern matching), and Supa (pointer analysis) using all the C test cases in Juliet Test Suite (JTS) and 10 open-source C applications. For the ground-truth validated with JTS, CRed detects all the 138 known UAF bugs as CBMC and Supa do while Clang and Coccinelle miss some bugs, with no false alarms from any tool. For practicality validated with the 10 applications (totaling 3+ MLOC), CRed reports 132 warnings including 85 bugs in 7.6 hours while the existing tools are either unscalable by terminating within 3 days only for one application (CBMC) or impractical by finding virtually no bugs (Clang and Coccinelle) or issuing an excessive number of false alarms (Supa).","","","10.1145/3180155.3180178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453091","use after free;program analysis;bug detection","Computer bugs;Tools;Correlation;Australia;Pattern matching;Software;Static analysis","C language;pattern matching;program compilers;program debugging;program diagnostics;program verification","Coccinelle;false alarms;pointer-analysis-based static approach;zero-day Use-After-Free vulnerabilities;pointer-analysis-based static analysis;finding UAF bugs;multiMLOC C source code;spatio-temporal context reduction technique;multistage analysis;path-sensitive demand-driven approach;CBMC;Supa;Juliet Test Suite;open-source C applications;UAF bugs","","3","","","","","","IEEE","IEEE Conferences"
"Efficient Large-Scale Trace Checking Using MapReduce","M. M. Bersani; D. Bianculli; C. Ghezzi; S. Krstic; P. San Pietro","DEEPSE group - DEIB, Politec. di Milano, Milan, Italy; SnT Centre, Univ. of Luxembourg, Luxembourg, Luxembourg; DEEPSE group - DEIB, Politec. di Milano, Milan, Italy; DEEPSE group - DEIB, Politec. di Milano, Milan, Italy; DEEPSE group - DEIB, Politec. di Milano, Milan, Italy","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","888","898","The problem of checking a logged event trace against a temporal logic specification arises in many practical cases. Unfortunately, known algorithms for an expressive logic like MTL (Metric Temporal Logic) do not scale with respect to two crucial dimensions: the length of the trace and the size of the time interval of the formula to be checked. The former issue can be addressed by distributed and parallel trace checking algorithms that can take advantage of modern cloud computing and programming frameworks like MapReduce. Still, the latter issue remains open with current state-of-the-art approaches. In this paper we address this memory scalability issue by proposing a new semantics for MTL, called lazy semantics. This semantics can evaluate temporal formulae and boolean combinations of temporal-only formulae at any arbitrary time instant. We prove that lazy semantics is more expressive than point-based semantics and that it can be used as a basis for a correct parametric decomposition of any MTL formula into an equivalent one with smaller, bounded time intervals. We use lazy semantics to extend our previous distributed trace checking algorithm for MTL. The evaluation shows that the proposed algorithm can check formulae with large intervals, on large traces, in a memory-efficient way.","","","10.1145/2884781.2884832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886965","metric temporal logic;trace checking;MapReduce","Semantics;Programming;Scalability;Clustering algorithms;Measurement;Data models;Heuristic algorithms","formal specification;parallel algorithms;temporal logic","large-scale trace checking;MapReduce;temporal logic specification;MTL logic;metric temporal logic;parallel trace checking algorithms;distributed trace checking algorithms;memory scalability issue;lazy semantics;Boolean combination;point-based semantics","","1","29","","","","","IEEE","IEEE Conferences"
"A Temporal Permission Analysis and Enforcement Framework for Android","A. Sadeghi; R. Jabbarvand; N. Ghorbani; H. Bagheri; S. Malek","Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Comput. Sci. & Eng., Univ. of Nebraska, Lincoln, NE, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","846","857","Permission-induced attacks, i.e., security breaches enabled by permission misuse, are among the most critical and frequent issues threatening the security of Android devices. By ignoring the temporal aspects of an attack during the analysis and enforcement, the state-of-the-art approaches aimed at protecting the users against such attacks are prone to have low-coverage in detection and high-disruption in prevention of permission-induced attacks. To address the aforementioned shortcomings, we present TERMINATOR, a temporal permission analysis and enforcement framework for Android. Leveraging temporal logic model checking, TERMINATOR's analyzer identifies permission-induced threats with respect to dynamic permission states of the apps. At runtime, TERMINATOR's enforcer selectively leases (i.e., temporarily grants) permissions to apps when the system is in a safe state, and revokes the permissions when the system moves to an unsafe state realizing the identified threats. The results of our experiments, conducted over thousands of apps, indicate that TERMINATOR is able to provide an effective, yet non-disruptive defense against permission-induced attacks. We also show that our approach, which does not require modification to the Android framework or apps' implementation logic, is highly reliable and widely applicable.","","","10.1145/3180155.3180172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453158","Android;Access Control (Permission);Temporal Logic","Androids;Humanoid robots;Security;Informatics;Malware;Analytical models;Tools","Android (operating system);authorisation;data privacy;temporal logic","permission misuse;temporal aspects;permission-induced attacks;temporal permission analysis;enforcement framework;temporal logic model checking;permission-induced threats;dynamic permission states;Android framework;TERMINATOR enforcer","","1","","","","","","IEEE","IEEE Conferences"
"Identifying and Quantifying Architectural Debt","L. Xiao; Y. Cai; R. Kazman; R. Mo; Q. Feng","Drexel Univ. Philadelphia, Philadelphia, PA, USA; Drexel Univ. Philadelphia, Philadelphia, PA, USA; SEI, Univ. of Hawaii, Honolulu, HI, USA; Drexel Univ. Philadelphia, Philadelphia, PA, USA; SEI, Univ. of Hawaii, Honolulu, HI, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","488","498","Our prior work showed that the majority of error-prone source files in a software system are architecturally connected. Flawed architectural relations propagate defectsamong these files and accumulate high maintenance costs over time, just like debts accumulate interest. We model groups of architecturally connected files that accumulate high maintenance costs as architectural debts. To quantify such debts, we formally define architectural debt, and show how to automatically identify debts, quantify their maintenance costs, and model these costs over time. We describe a novel history coupling probability matrix for this purpose, and identify architecture debts using 4 patterns of architectural flaws shown to correlate with reduced software quality. We evaluate our approach on 7 large-scale open source projects, and show that a significant portion of total project maintenance effort is consumed by paying interest on architectural debts. The top 5 architectural debts, covering a small portion (8% to 25%) of each project's error-prone files, capture a significant portion (20% to 61%) of each project's maintenance effort. Finally, we show that our approach reveals how architectural issues evolve into debts over time.","","","10.1145/2884781.2884822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886928","","Maintenance engineering;History;Computer architecture;Couplings;Software;Economic indicators;Software architecture","costing;software architecture;software maintenance;software quality","architectural debt identification;architectural debt quantification;error-prone source files;software system;architecturally connected files;maintenance costs;history coupling probability matrix;software quality;total project maintenance effort","","17","28","","","","","IEEE","IEEE Conferences"
"How Does Regression Test Prioritization Perform in Real-World Software Evolution?","Y. Lu; Y. Lou; S. Cheng; L. Zhang; D. Hao; Y. Zhou; L. Zhang","Dept. of Comput. Sci., Univ. of Texas at Dallas, Dallas, TX, USA; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Dept. of Comput. Sci., Univ. of Texas at Dallas, Dallas, TX, USA; Dept. of Comput. Sci., Univ. of Texas at Dallas, Dallas, TX, USA; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Sch. of Comput. Sci., Fudan Univ., Shanghai, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","535","546","In recent years, researchers have intensively investigated various topics in test prioritization, which aims to re-order tests to increase the rate of fault detection during regression testing. While the main research focus in test prioritization is on proposing novel prioritization techniques and evaluating on more and larger subject systems, little effort has been put on investigating the threats to validity in existing work on test prioritization. One main threat to validity is that existing work mainly evaluates prioritization techniques based on simple artificial changes on the source code and tests. For example, the changes in the source code usually include only seeded program faults, whereas the test suite is usually not augmented at all. On the contrary, in real-world software development, software systems usually undergo various changes on the source code and test suite augmentation. Therefore, it is not clear whether the conclusions drawn by existing work in test prioritization from the artificial changes are still valid for real-world software evolution. In this paper, we present the first empirical study to investigate this important threat to validity in test prioritization. We reimplemented 24 variant techniques of both the traditional and time-aware test prioritization, and investigated the impacts of software evolution on those techniques based on the version history of 8 real-world Java programs from GitHub. The results show that for both traditional and time-aware test prioritization, test suite augmentation significantly hampers their effectiveness, whereas source code changes alone do not influence their effectiveness much.","","","10.1145/2884781.2884874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886932","","Testing;Software systems;Schedules;Time factors;Instruments;Software engineering","program testing;software engineering","regression test prioritization;real-world software evolution;fault detection;prioritization techniques;software development;test suite augmentation;GitHub","","9","67","","","","","IEEE","IEEE Conferences"
"DroidStar: Callback Typestates for Android Classes","A. Radhakrishna; N. V. Lewchenko; S. Meier; S. Mover; K. C. Sripada; D. Zufferey; B. E. Chang; P. Cern√Ω","NA; NA; NA; NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1160","1170","Event-driven programming frameworks, such as Android, are based on components with asynchronous interfaces. The protocols for interacting with these components can often be described by finite-state machines we dub *callback typestates. Callback typestates are akin to classical typestates, with the difference that their outputs (callbacks) are produced asynchronously. While useful, these specifications are not commonly available, because writing them is difficult and error-prone. Our goal is to make the task of producing callback typestates significantly easier. We present a callback typestate assistant tool, DroidStar, that requires only limited user interaction to produce a callback typestate. Our approach is based on an active learning algorithm, L*. We improved the scalability of equivalence queries (a key component of L*), thus making active learning tractable on the Android system. We use DroidStar to learn callback typestates for Android classes both for cases where one is already provided by the documentation, and for cases where the documentation is unclear. The results show that DroidStar learns callback typestates accurately and efficiently. Moreover, in several cases, the synthesized callback typestates uncovered surprising and undocumented behaviors.","","","10.1145/3180155.3180232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453197","typestate;specification inference;Android;active learning","Androids;Humanoid robots;Protocols;Tools;Documentation;Learning automata;Task analysis","learning (artificial intelligence);program diagnostics","DroidStar;callback typestate assistant tool;synthesized callback typestates;dub *callback typestates","","","41","","","","","IEEE","IEEE Conferences"
"Belief & Evidence in Empirical Software Engineering","P. Devanbu; T. Zimmermann; C. Bird","Dept. of Comput. Sci., UC Davis, Davis, CA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","108","119","Empirical software engineering has produced a steady stream of evidence-based results concerning the factors that affect important outcomes such as cost, quality, and interval. However, programmers often also have strongly-held a priori opinions about these issues. These opinions are important, since developers are highlytrained professionals whose beliefs would doubtless affect their practice. As in evidence-based medicine, disseminating empirical findings to developers is a key step in ensuring that the findings impact practice. In this paper, we describe a case study, on the prior beliefs of developers at Microsoft, and the relationship of these beliefs to actual empirical data on the projects in which these developers work. Our findings are that a) programmers do indeed have very strong beliefs on certain topics b) their beliefs are primarily formed based on personal experience, rather than on findings in empirical research and c) beliefs can vary with each project, but do not necessarily correspond with actual evidence in that project. Our findings suggest that more effort should be taken to disseminate empirical findings to developers and that more in-depth study the interplay of belief and evidence in software practice is needed.","","","10.1145/2884781.2884812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886896","Practitioner Belief;Empirical Evidence;Empirical Software Engineering.","Bayes methods;Software engineering;Software;Media;Computer science;Immune system","software engineering","empirical software engineering;Microsoft;empirical research;software practice","","20","59","","","","","IEEE","IEEE Conferences"
"DeepTest: Automated Testing of Deep-Neural-Network-Driven Autonomous Cars","Y. Tian; K. Pei; S. Jana; B. Ray","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","303","314","Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.","","","10.1145/3180155.3180220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453089","deep learning;testing;self-driving cars;deep neural networks;autonomous vehicle;neuron coverage","Neurons;Autonomous automobiles;Software;Testing;Automobiles;Sensors;Computer architecture","automobiles;intelligent transportation systems;neural nets;program testing;road accidents;road safety","DeepTest;automated testing;deep-neural-network-driven autonomous cars;recent advances;DNN-driven autonomous cars;human intervention;autonomous vehicles;US states;potentially fatal collisions;DNN-driven vehicles;test conditions increases;systematic testing tool;erroneous behaviors;automatically generated test cases;DNN logic;test inputs;potentially fatal crashes;Udacity self-driving car challenge;deep neural networks;driving conditions;realistic driving conditions;Waymo-Google","","48","87","","","","","IEEE","IEEE Conferences"
"Chopped Symbolic Execution","D. Trabish; A. Mattavelli; N. Rinetzky; C. Cadar","Tel Aviv Univ., Tel Aviv, Israel; Imperial Coll. London, London, UK; Tel Aviv Univ., Tel Aviv, Israel; Imperial Coll. London, London, UK","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","350","360","Symbolic execution is a powerful program analysis technique that systematically explores multiple program paths. However, despite important technical advances, symbolic execution often struggles to reach deep parts of the code due to the well-known path explosion problem and constraint solving limitations. In this paper, we propose chopped symbolic execution, a novel form of symbolic execution that allows users to specify uninter-esting parts of the code to exclude during the analysis, thus only targeting the exploration to paths of importance. However, the excluded parts are not summarily ignored, as this may lead to both false positives and false negatives. Instead, they are executed lazily, when their effect may be observable by code under anal-ysis. Chopped symbolic execution leverages various on-demand static analyses at runtime to automatically exclude code fragments while resolving their side effects, thus avoiding expensive manual annotations and imprecision. Our preliminary results show that the approach can effectively improve the effectiveness of symbolic execution in several different scenarios, including failure reproduction and test suite augmentation.","","","10.1145/3180155.3180251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453093","Symbolic execution;Static analysis;Program slicing","Explosions;Engines;Computer bugs;Static analysis;Runtime;Software","program diagnostics;program testing;program verification","multiple program paths;chopped symbolic execution leverages;powerful program analysis technique;constraint solving limitations","","1","45","","","","","IEEE","IEEE Conferences"
"DoubleTake: Fast and Precise Error Detection via Evidence-Based Dynamic Analysis","T. Liu; C. Curtsinger; E. D. Berger","Dept. of Comput. Sci., Univ. of Texas at San Antonio, San Antonio, TX, USA; Dept. of Comput. Sci., Grinnell Coll., Grinnell, IA, USA; Coll. of Inf. & Comput. Sci., Univ. of Massachusetts, Amherst, MA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","911","922","Programs written in unsafe languages like C and C++ often suffer from errors like buffer overflows, dangling pointers, and memory leaks. Dynamic analysis tools like Valgrind can detect these errors, but their overhead - primarily due to the cost of instrumenting every memory read and write - makes them too heavyweight for use in deployed applications and makes testing with them painfully slow. The result is that much deployed software remains susceptible to these bugs, which are notoriously difficult to track down.This paper presents evidence-based dynamic analysis, an approach that enables these analyses while imposing minimal overhead (under 5%), making it practical for the first time to perform these analyses in deployed settings. The key insight of evidence-based dynamic analysis is that for a class of errors, it is possible to ensure that evidence that they happened at some point in the past remains for later detection. Evidence-based dynamic analysis allows execution to proceed at nearly full speed until the end of an epoch (e.g., a heavyweight system call). It then examines program state to check for evidence that an error occurred at some time during that epoch. If so, it rolls back execution and re-executes the code with instrumentation activated to pinpoint the error.We present DoubleTake, a prototype evidence-based dynamic analysis framework. DoubleTake is practical and easy to deploy, requiring neither custom hardware, compiler, nor operating system support. We demonstrate DoubleTake's generality and efficiency by building dynamic analyses that find buffer overflows, memory use-after-free errors, and memory leaks. Our evaluation shows that DoubleTake is efficient, imposing under 5% overhead on average, making it the fastest such system to date. It is also precise: DoubleTake pinpoints the location of these errors to the exact line and memory addresses where they occur, providing valuable debugging information to programmers.","","","10.1145/2884781.2884784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886967","Dynamic Analysis;Software Quality;Testing;Debugging;Leak Detection;Buffer Overflow Detection;Use-After-Free Detection","Instruments;Testing;Detectors;Hardware;Operating systems;Resource management;Software engineering","program debugging;program diagnostics","error detection;evidence-based dynamic analysis;Valgrind tool;DoubleTake;buffer overflow;memory use-after-free errors;memory leaks;debugging information","","8","43","","","","","IEEE","IEEE Conferences"
"Reference Hijacking: Patching, Protecting and Analyzing on Unmodified and Non-rooted Android Devices","W. You; B. Liang; W. Shi; S. Zhu; P. Wang; S. Xie; X. Zhang","Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","959","970","Many efforts have been paid to enhance the security of Android. However, less attention has been given to how to practically adopt the enhancements on off-the-shelf devices. In particular, securing Android devices often requires modifying their write-protected underlying system component files (especially the system libraries) by flashing or rooting devices, which is unacceptable in many realistic cases. In this paper, a novel technique, called reference hijacking, is presented to address the problem. By introducing a specially designed reset procedure, a new execution environment is constructed for the target application, in which the reference to the underlying system libraries will be redirected to the security-enhanced alternatives. The technique can be applicable to both the Dalvik and Android Runtime (ART) environments and to almost all mainstream Android versions (2.x to 5.x). To demonstrate the capability of reference hijacking, we develop three prototype systems, PatchMan, ControlMan, and TaintMan, to enforce specific security enhancements, involving patching vulnerabilities, protecting inter-component communications, and performing dynamic taint analysis for the target application. These three prototypes have been successfully deployed on a number of popular Android devices from different manufacturers, without modifying the underlying system. The evaluation results show that they are effective and do not introduce noticeable overhead. They strongly support that reference hijacking can substantially improve the practicability of many security enhancement efforts for Android.","","","10.1145/2884781.2884863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886971","Android;Security enhancement;Practicability","Libraries;Androids;Humanoid robots;Prototypes;Malware;Access control","Android (operating system);mobile computing;security of data","reference hijacking technique;Android devices;Android security;reset procedure;security-enhanced alternatives;Dalvik environment;Android Runtime environment;PatchMan system;ControlMan system;TaintMan system;security enhancements","","4","55","","","","","IEEE","IEEE Conferences"
"GUILeak: Tracing Privacy Policy Claims on User Input Data for Android Applications","X. Wang; X. Qin; M. Bokaei Hosseini; R. Slavin; T. D. Breaux; J. Niu","Univ. of Texas at San Antonio, San Antonio, TX, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","37","47","The Android mobile platform supports billions of devices across more than 190 countries around the world. This popularity coupled with user data collection by Android apps has made privacy protection a well-known challenge in the Android ecosystem. In practice, app producers provide privacy policies disclosing what information is collected and processed by the app. However, it is difficult to trace such claims to the corresponding app code to verify whether the implementation is consistent with the policy. Existing approaches for privacy policy alignment focus on information directly accessed through the Android platform (e.g., location and device ID), but are unable to handle user input, a major source of private information. In this paper, we propose a novel approach that automatically detects privacy leaks of user-entered data for a given Android app and determines whether such leakage may violate the app's privacy policy claims. For evaluation, we applied our approach to 120 popular apps from three privacy-relevant app categories: finance, health, and dating. The results show that our approach was able to detect 21 strong violations and 18 weak violations from the studied apps.","","","10.1145/3180155.3180196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453060","Mobile privacy policy;Android application;User input","Graphical user interfaces;Ontologies;Privacy;Data privacy;Androids;Humanoid robots;Layout","data privacy;mobile computing","privacy protection;Android ecosystem;app producers;privacy policies;private information;privacy-relevant app categories;privacy policy claims;android applications;Android mobile platform;user data collection;Android apps;app code;privacy leaks detection;privacy policy alignment","","2","","","","","","IEEE","IEEE Conferences"
"Reducing Combinatorics in GUI Testing of Android Applications","N. Mirzaei; J. Garcia; H. Bagheri; A. Sadeghi; S. Malek","NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","559","570","The rising popularity of Android and the GUI-driven nature of its apps have motivated the need for applicable automated GUI testing techniques. Although exhaustive testing of all possible combinations is the ideal upper bound in combinatorial testing, it is often infeasible, due to the combinatorial explosion of test cases. This paper presents TrimDroid, a framework for GUI testing of Android apps that uses a novel strategy to generate tests in a combinatorial, yet scalable, fashion. It is backed with automated program analysis and formally rigorous test generation engines. TrimDroid relies on program analysis to extract formal specifications. These specifications express the app's behavior (i.e., control flow between the various app screens) as well as the GUI elements and their dependencies. The dependencies among the GUI elements comprising the app are used to reduce the number of combinations with the help of a solver. Our experiments have corroborated TrimDroid's ability to achieve a comparable coverage as that possible under exhaustive GUI testing using significantly fewer test cases.","","","10.1145/2884781.2884853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886934","Android;Software Testing;Input Generation","Testing;Graphical user interfaces;Androids;Humanoid robots;Erbium;Smart phones","formal specification;graphical user interfaces;mobile computing;program diagnostics;program testing","GUI testing;graphical user interface;Android applications;combinatorial testing;TrimDroid framework;test generation;program analysis;formal specifications","","20","39","","","","","IEEE","IEEE Conferences"
"On the Techniques We Create, the Tools We Build, and Their Misalignments: A Study of KLEE","E. F. Rizzi; S. Elbaum; M. B. Dwyer","Grammatech Inc., Ithaca, NY, USA; Univ. of Nebraska - Lincoln, Lincoln, NE, USA; Univ. of Nebraska - Lincoln, Lincoln, NE, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","132","143","Our community constantly pushes the state-of-the-art by introducing ‚Äúnew‚Äù techniques. These techniques often build on top of, and are compared against, existing systems that realize previously published techniques. The underlying assumption is that existing systems correctly represent the techniques they implement. This pa- per examines that assumption through a study of KLEE, a popular and well-cited tool in our community. We briefly describe six improvements we made to KLEE, none of which can be considered ‚Äúnew‚Äù techniques, that provide order-of-magnitude performance gains. Given these improvements, we then investigate how the results and conclusions of a sample of papers that cite KLEE are affected. Our findings indicate that the strong emphasis on introducing ‚Äúnew‚Äù techniques may lead to wasted effort, missed opportunities for progress, an accretion of artifact complexity, and questionable research conclusions (in our study, 27% of the papers that depend on KLEE can be questioned). We conclude by revisiting initiatives that may help to realign the incentives to better support the foundations on which we build.","","","10.1145/2884781.2884835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886898","Research incentives;research tools and infrastructure;replication","Optimization;Computer bugs;Software engineering;Buildings;Software;Complexity theory;Engineering profession","software engineering","KLEE tool;software techniques;performance gain;artifact complexity","","2","86","","","","","IEEE","IEEE Conferences"
"Collective Program Analysis","G. Upadhyaya; H. Rajan","Dept. of Comput. Sci., Iowa State Univ. Ames, Ames, IA, USA; Dept. of Comput. Sci., Iowa State Univ. Ames, Ames, IA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","620","631","Popularity of data-driven software engineering has led to an increasing demand on the infrastructures to support efficient execution of tasks that require deeper source code analysis. While task optimization and parallelization are the adopted solutions, other research directions are less explored. We present collective program analysis (CPA), a technique for scaling large scale source code analyses, especially those that make use of control and data flow analysis, by leveraging analysis specific similarity. Analysis specific similarity is about, whether two or more programs can be considered similar for a given analysis. The key idea of collective program analysis is to cluster programs based on analysis specific similarity, such that running the analysis on one candidate in each cluster is sufficient to produce the result for others. For determining analysis specific similarity and clustering analysis-equivalent programs, we use a sparse representation and a canonical labeling scheme. Our evaluation shows that for a variety of source code analyses on a large dataset of programs, substantial reduction in the analysis time can be achieved; on average a 69% reduction when compared to a baseline and on average a 36% reduction when compared to a prior technique. We also found that a large amount of analysis-equivalent programs exists in large datasets.","","","10.1145/3180155.3180252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453131","Source code analysis;Clustering;Boa","Transfer functions;Cloning;Software engineering;Task analysis;Syntactics;Analytical models;Labeling","data flow analysis;pattern clustering;software engineering","collective program analysis;cluster programs;data-driven software engineering;deeper source code analysis;scale source code analyses;data flow analysis","","","","","","","","IEEE","IEEE Conferences"
"""Jumping Through Hoops"": Why do Java Developers Struggle with Cryptography APIs?","S. Nadi; S. Kr√ºger; M. Mezini; E. Bodden","NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","935","946","To protect sensitive data processed by current applications, developers, whether security experts or not, have to rely on cryptography. While cryptography algorithms have become increasingly advanced, many data breaches occur because developers do not correctly use the corresponding APIs. To guide future research into practical solutions to this problem, we perform an empirical investigation into the obstacles developers face while using the Java cryptography APIs, the tasks they use the APIs for, and the kind of (tool) support they desire. We triangulate data from four separate studies that include the analysis of 100 StackOverflow posts, 100 GitHub repositories, and survey input from 48 developers. We find that while developers find it difficult to use certain cryptographic algorithms correctly, they feel surprisingly confident in selecting the right cryptography concepts (e.g., encryption vs. signatures). We also find that the APIs are generally perceived to be too low-level and that developers prefer more task-based solutions.","","","10.1145/2884781.2884790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886969","Cryptography;API misuse;empirical software engineering","Java;Encryption;Face;Public key;Libraries;Complexity theory","application program interfaces;cryptography;Java","Java developers;cryptography API;application program interface;sensitive data protection;cryptography algorithms;StackOverflow;GitHub repositories","","34","37","","","","","IEEE","IEEE Conferences"
"The Challenges of Staying Together While Moving Fast: An Exploratory Study","J. Rubin; M. Rinard","Massachusetts Inst. of Technol., Cambridge, MA, USA; Massachusetts Inst. of Technol., Cambridge, MA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","982","993","We report on the results of an empirical study conducted with 35 experienced software developers from 22 high-tech companies, including Google, Facebook, Microsoft, Intel, and others. The goal of the study was to elicit challenges that these developers face, potential solutions that they envision to these challenges, and research initiatives that they think would deliver useful results. Challenges identified by the majority of the study participants relate to the collaborative nature of the work: the availability and discoverability of information, communication, collaborative planning and integration with work of others. Almost all participants also addressed the advantages and disadvantages of the current ‚Äúfast to the market‚Äù trend, and the toll it takes on the quality of the software that they are able to deliver and on their professional and personal satisfaction as software engineers. We describe in depth the identified challenges, supporting our findings with explicit quotes from the study participants. We also put these findings in context of work done by the software engineering community and outline a roadmap for possible future research initiatives.","","","10.1145/2884781.2884871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886973","empirical study;industrial software development;challenges","Software;Companies;Interviews;Software engineering;Face;Research initiatives","software development management;software quality","software developers;Google;Facebook;Microsoft;Intel;information availability;information discoverability;software quality;software engineering","","9","56","","","","","IEEE","IEEE Conferences"
"Synthesizing Qualitative Research in Software Engineering: A Critical Review","X. Huang; H. Zhang; X. Zhou; M. Ali Babar; S. Yang","State Key Lab. of Novel Software Technol., Nanjing Univ., Nanjing, China; State Key Lab. of Novel Software Technol., Nanjing Univ., Nanjing, China; State Key Lab. of Novel Software Technol., Nanjing Univ., Nanjing, China; Sch. of Comput. Sci., Univ. of Adelaide, Adelaide, SA, Australia; State Key Lab. of Novel Software Technol., Nanjing Univ., Nanjing, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1207","1218","Synthesizing data extracted from primary studies is an integral component of the methodologies in support of Evidence Based Software Engineering (EBSE) such as System Literature Review (SLR). Since a large and increasing number of studies in Software Engineering (SE) incorporate qualitative data, it is important to systematically review and understand different aspects of the Qualitative Research Synthesis (QRS) being used in SE. We have reviewed the use of QRS methods in 328 SLRs published between 2005 and 2015. We also inquired the authors of 274 SLRs to confrm whether or not any QRS methods were used in their respective reviews. 116 of them provided the responses, which were included in our analysis. We found eight QRS methods applied in SE research, two of which, narrative synthesis and thematic synthesis, have been predominantly adopted by SE researchers for synthesizing qualitative data. Our study determines that a signifcant amount of missing knowledge and incomplete understanding of the defned QRS methods in the community. Our effort also identifes an initial set factors that may in?uence the selection and use of appropriate QRS methods in SE.","","","10.1145/3180155.3180235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453202","research synthesis;qualitative (synthesis) methods;systematic (literature) review;evidence-based software engineering","Software engineering;Data mining;Bibliographies;Software;Systematics;Tools;Data models","reviews;software engineering","Software Engineering;critical Review;primary studies;integral component;System Literature Review;qualitative data;Qualitative Research Synthesis;SE research;SE researchers;defned QRS methods;appropriate QRS methods;SLR","","","67","","","","","IEEE","IEEE Conferences"
"Type-Aware Concolic Testing of JavaScript Programs","M. Dhok; M. K. Ramanathan; N. Sinha","NA; NA; IBM Res., Bangalore, India","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","168","179","Conventional concolic testing has been used to provide high coverage of paths in statically typed languages. While it has also been applied in the context of JavaScript (JS) programs, we observe that applying concolic testing to dynamically-typed JS programs involves tackling unique problems to ensure scalability. In particular, a naive type-agnostic extension of concolic testing to JS programs causes generation of large number of inputs. Consequently, many executions operate on undefined values and repeatedly explore same paths resulting in redundant tests, thus diminishing the scalability of testing drastically. In this paper, we address this problem by proposing a simple yet effective approach that incorporates type-awareness intelligently in conventional concolic testing to reduce the number of generated inputs for JS programs. We extend our approach inter-procedurally by generating preconditions for each function that provide a summary of the relation between the variable types and paths. Employing the function preconditions when testing reduces the number of inputs generated even further. We implement our ideas and validate it on a number of open-source JS programs (and libraries). For a significant percentage (on average 50%) of the functions, we observe that type-aware concolic testing generates a minuscule percentage (less than 5%) of the inputs as compared to conventional concolic testing approach implemented on top of Jalangi. On average, this approach achieves over 97% of line coverage and over 94% of branch coverage for all the functions across all benchmarks. Moreover, the use of function preconditions reduces the number of inputs generated by 50%. We also demonstrate the use of function preconditions in automatically avoiding real crashes due to incorrectly typed objects.","","","10.1145/2884781.2884859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886901","Dynamic Analysis;JavaScript;Testing","Testing;Computer crashes;Algorithm design and analysis;Scalability;Libraries;Runtime;Redundancy","Java;object-oriented programming;program testing","type-aware concolic testing;JavaScript programs;dynamically-typed JS programs;open-source JS programs","","2","40","","","","","IEEE","IEEE Conferences"
"Are Code Examples on an Online Q&A Forum Reliable?: A Study of API Misuse on Stack Overflow","T. Zhang; G. Upadhyaya; A. Reinhardt; H. Rajan; M. Kim","NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","886","896","Programmers often consult an online Q&A forum such as Stack Overflow to learn new APIs. This paper presents an empirical study on the prevalence and severity of API misuse on Stack Overflow. To reduce manual assessment effort, we design ExampleCheck, an API usage mining framework that extracts patterns from over 380K Java repositories on GitHub and subsequently reports potential API usage violations in Stack Overflow posts. We analyze 217,818 Stack Overflow posts using ExampleCheck and find that 31% may have potential API usage violations that could produce unexpected behavior such as program crashes and resource leaks. Such API misuse is caused by three main reasons-missing control constructs, missing or incorrect order of API calls, and incorrect guard conditions. Even the posts that are accepted as correct answers or upvoted by other programmers are not necessarily more reliable than other posts in terms of API misuse. This study result calls for a new approach to augment Stack Overflow with alternative API usage details that are not typically shown in curated examples.","","","10.1145/3180155.3180260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453166","online Q&A forums;API usage pattern;code example assessment","Data mining;Java;Software;Software reliability;Syntactics;Libraries","application program interfaces;data mining;Java;learning (artificial intelligence);program diagnostics;public domain software;question answering (information retrieval);Web sites","API misuse;API usage mining framework;potential API usage violations;API calls;alternative API usage details;Stack Overflow posts","","9","","","","","","IEEE","IEEE Conferences"
"VDTest: An Automated Framework to Support Testing for Virtual Devices","T. Yu; X. Qu; M. B. Cohen","Dept. of Comp. Sci., Univ. of Kentucky, Lexington, KY, USA; ABB Corp. Res., Raleigh, NC, USA; Dept. of Comp. Sci. & Eng., Univ. of Nebraska - Lincoln, Lincoln, NE, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","583","594","The use of virtual devices in place of physical hardware is increasing in activities such as design, testing and debugging. Yet virtual devices are simply software applications, and like all software they are prone to faults. A full system simulator (FSS), is a class of virtual machine that includes a large set of virtual devices - enough to run the full target software stack. Defects in an FSS virtual device may have cascading effects as the incorrect behavior can be propagated forward to many different platforms as well as to guest programs. In this work we present VDTest, a novel framework for testing virtual devices within an FSS. VDTest begins by generat- ing a test specification obtained through static analysis. It then employs a two-phase testing approach to test virtual components both individually and in combination. It lever- ages a differential oracle strategy, taking advantage of the existence of a physical or golden device to eliminate the need for manually generating test oracles. In an empirical study using both open source and commercial FSSs, we found 64 faults, 83% more than random testing.","","","10.1145/2884781.2884866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886936","Testing;Virtual Devices;Device Drivers;Test Oracles","Registers;Testing;Frequency selective surfaces;Software;Hardware;Computers;Debugging","formal specification;program diagnostics;program testing;virtual machines","virtual device testing;VDTest;full system simulator;virtual machine;FSS;test specification;static analysis;two-phase testing;differential oracle strategy","","","37","","","","","IEEE","IEEE Conferences"
"A Practical Guide to Select Quality Indicators for Assessing Pareto-Based Search Algorithms in Search-Based Software Engineering","S. Wang; S. Ali; T. Yue; Y. Li; M. Liaaen","Simula Res. Lab., Oslo, Norway; Simula Res. Lab., Oslo, Norway; Simula Res. Lab., Oslo, Norway; Beihang Univ., Beijing, China; Cisco Syst., Oslo, Norway","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","631","642","Many software engineering problems are multi-objective in nature, which has been largely recognized by the Search-based Software Engineering (SBSE) community. In this regard, Pareto- based search algorithms, e.g., Non-dominated Sorting Genetic Algorithm II, have already shown good performance for solving multi-objective optimization problems. These algorithms produce Pareto fronts, where each Pareto front consists of a set of non- dominated solutions. Eventually, a user selects one or more of the solutions from a Pareto front for their specific problems. A key challenge of applying Pareto-based search algorithms is to select appropriate quality indicators, e.g., hypervolume, to assess the quality of Pareto fronts. Based on the results of an extended literature review, we found that the current literature and practice in SBSE lacks a practical guide for selecting quality indicators despite a large number of published SBSE works. In this direction, the paper presents a practical guide for the SBSE community to select quality indicators for assessing Pareto-based search algorithms in different software engineering contexts. The practical guide is derived from the following complementary theoretical and empirical methods: 1) key theoretical foundations of quality indicators; 2) evidence from an extended literature review; and 3) evidence collected from an extensive experiment that was conducted to evaluate eight quality indicators from four different categories with six Pareto-based search algorithms using three real industrial problems from two diverse domains.","","","10.1145/2884781.2884880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886940","Quality Indicators;Multi-objective Software Engineering Problems;Pareto-based Search Algorithms;Practical Guide","Classification algorithms;Search problems;Convergence;Software engineering;Software algorithms;Bibliographies;Sociology","Pareto optimisation;search problems;software quality","quality indicators;Pareto-based search algorithms;search-based software engineering;SBSE community;nondominated sorting genetic algorithm II;multiobjective optimization problems;Pareto front","","16","65","","","","","IEEE","IEEE Conferences"
"Launch-Mode-Aware Context-Sensitive Activity Transition Analysis","Y. Zhang; Y. Sui; J. Xue","UNSW Sydney, Sydney, NSW, Australia; Univ. of Technol. Sydney, Sydney, NSW, Australia; UNSW Sydney, Sydney, NSW, Australia","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","598","608","Existing static analyses model activity transitions in Android apps context-insensitively, making it impossible to distinguish different activity launch modes, reducing the pointer analysis precision for an activity's callbacks, and potentially resulting in infeasible activity transition paths. In this paper, we introduce Chime, a launch-mode-aware context-sensitive activity transition analysis that models different instances of an activity class according to its launch mode and the transitions between activities context-sensitively, by working together with an object-sensitive pointer analysis. Our evaluation shows that our context-sensitive activity transition analysis is more precise than its context-insensitive counterpart in capturing activity transitions, facilitating GUI testing, and improving the pointer analysis precision.","","","10.1145/3180155.3180188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453129","Android;Pointer Analysis;Activity Transition Analysis","Androids;Humanoid robots;Context modeling;Standards;Analytical models;Graphical user interfaces;Navigation","mobile computing;program diagnostics","infeasible activity transition paths;launch-mode-aware context-sensitive activity transition analysis;activity class;launch mode;activities context-sensitively;object-sensitive pointer analysis;pointer analysis precision;static analyses model activity transitions;Android apps context-insensitively","","2","34","","","","","IEEE","IEEE Conferences"
"Exploring Language Support for Immutability","M. Coblenz; J. Sunshine; J. Aldrich; B. Myers; S. Weber; F. Shull","Carnegie Mellon Univ., Pittsburgh, PA, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Software Eng. Inst., Pittsburgh, PA, USA; Software Eng. Inst., Pittsburgh, PA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","736","747","Programming languages can restrict state change by preventing it entirely (immutability) or by restricting which clients may modify state (read-only restrictions). The benefits of immutability and read-only restrictions in software structures have been long-argued by practicing software engineers, researchers, and programming language designers. However, there are many proposals for language mechanisms for restricting state change, with a remarkable diversity of techniques and goals, and there is little empirical data regarding what practicing software engineers want in their tools and what would benefit them. We systematized the large collection of techniques used by programming languages to help programmers prevent undesired changes in state. We interviewed expert software engineers to discover their expectations and requirements, and found that important requirements, such as expressing immutability constraints, were not reflected in features available in the languages participants used. The interview results informed our design of a new language extension for specifying immutability in Java. Through an iterative, participatory design process, we created a tool that reflects requirements from both our interviews and the research literature.","","","10.1145/2884781.2884798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886832","Programming language design;Programming language usability;Immutability;Mutability;Programmer productivity;Empirical studies of programmers","Java;Software;Data structures;Interviews;C++ languages;Concrete","Java","immutability;language extension;Java;programming language","","7","45","","","","","IEEE","IEEE Conferences"
"Quantifying and Mitigating Turnover-Induced Knowledge Loss: Case Studies of Chrome and a Project at Avaya","P. C. Rigby; Y. C. Zhu; S. M. Donadelli; A. Mockus","Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada; Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada; Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada; Dept. Electr. Eng. & Comput. Sci., Univ. of Tennessee, Knoxville, TN, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1006","1016","The utility of source code, as of other knowledge artifacts, is predicated on the existence of individuals skilled enough to derive value by using or improving it. Developers leaving a software project deprive the project of the knowledge of the decisions they have made. Previous research shows that the survivors and newcomers maintaining abandoned code have reduced productivity and are more likely to make mistakes. We focus on quantifying the extent of abandoned source files and adapt methods from financial risk analysis to assess the susceptibility of the project to developer turnover. In particular, we measure the historical loss distribution and find (1) that projects are susceptible to losses that are more than three times larger than the expected loss. Using historical simulations we find (2) that projects are susceptible to large losses that are over five times larger than the expected loss. We use Monte Carlo simulations of disaster loss scenarios and find (3) that simplistic estimates of the `truck factor' exaggerate the potential for loss. To mitigate loss from developer turnover, we modify Cataldo et al's coordination requirements matrices. We find (4) that we can recommend the correct successor 34% to 48% of the time. We also find that having successors reduces the expected loss by as much as 15%. Our approach helps large projects assess the risk of turnover thereby making risk more transparent and manageable.","","","10.1145/2884781.2884851","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886975","Quantitative Risk Management;Mining Software Repositories;Knowledge Distribution;Truck Factor;Successors;Turnover","Loss measurement;Software;Risk management;Software engineering;Productivity;Adaptation models;Monte Carlo methods","knowledge management;Monte Carlo methods;project management;software development management","turnover-induced knowledge loss;Chrome;source code utility;knowledge artifacts;software project;financial risk analysis;historical loss distribution;Monte Carlo simulation;truck factor estimation","","7","31","","","","","IEEE","IEEE Conferences"
"Termination-Checking for LLVM Peephole Optimizations","D. Menendez; S. Nagarakatte","NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","191","202","Mainstream compilers contain a large number of peephole optimizations, which perform algebraic simplification of the input program with local rewriting of the code. These optimizations are a persistent source of bugs. Our recent research on Alive, a domain-specific language for expressing peephole optimizations in LLVM, addresses a part of the problem by automatically verifying the correctness of these optimizations and generating C++ code for use with LLVM. This paper identifies a class of non-termination bugs that arise when a suite of peephole optimizations is executed until a fixed point. An optimization can undo the effect of another optimization in the suite, which results in non-terminating compilation. This paper (1) proposes a methodology to detect non-termination bugs with a suite of peephole optimizations, (2) identifies the necessary condition to ensure termination while composing peephole optimizations, and (3) provides debugging support by generating concrete input programs that cause non-terminating compilation. We have discovered 184 optimization sequences, involving 38 optimizations, that cause non-terminating compilation in LLVM with Alive-generated C++ code.","","","10.1145/2884781.2884809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886903","Compiler Verification;Peephole Optimization;Alive;Termination","Optimization;Computer bugs;C++ languages;Semantics;Concrete;Toxicology;Pattern matching","C++ language;program compilers;program debugging","termination-checking;LLVM peephole optimizations;nontermination bugs;nonterminating compilation;debugging;input programs;Alive-generated C++ code","","","40","","","","","IEEE","IEEE Conferences"
"Propagating Configuration Decisions with Modal Implication Graphs","S. Krieter; T. Th√ºm; S. Schulze; R. Schr√∂ter; G. Saake","Univ. of Magdeburg, Magdeburg, Germany; Tech. Univ. Braunschweig, Braunschweig, Germany; Univ. of Magdeburg, Magdeburg, Germany; Univ. of Magdeburg, Magdeburg, Germany; Univ. of Magdeburg, Magdeburg, Germany","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","898","909","Highly-configurable systems encompass thousands of interdependent configuration options, which require a non-trivial configuration process. Decision propagation enables a backtracking-free configuration process by computing values implied by user decisions. However, employing decision propagation for large-scale systems is a time-consuming task and, thus, can be a bottleneck in interactive configuration processes and analyses alike. We propose modal implication graphs to improve the performance of decision propagation by precomputing intermediate values used in the process. Our evaluation results show a significant improvement over state-of-the-art algorithms for 120 real-world systems.","","","10.1145/3180155.3180159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453168","Software product line;Configuration;Decision Propagation","Servers;Frequency modulation;Hafnium;Operating systems;Monitoring;Task analysis","backtracking;configuration management;graph theory;large-scale systems;performance evaluation","modal implication graphs;interdependent configuration options;nontrivial configuration process;decision propagation;backtracking-free configuration process;large-scale systems;interactive configuration processes;configuration decisions","","2","","","","","","IEEE","IEEE Conferences"
"Deep Code Search","X. Gu; H. Zhang; S. Kim","Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Univ. of Newcastle, Callaghan, NSW, Australia; Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","933","944","To implement a program functionality, developers can reuse previously written code snippets by searching through a large-scale codebase. Over the years, many code search tools have been proposed to help developers. The existing approaches often treat source code as textual documents and utilize information retrieval models to retrieve relevant code snippets that match a given query. These approaches mainly rely on the textual similarity between source code and natural language query. They lack a deep understanding of the semantics of queries and source code. In this paper, we propose a novel deep neural network named CODEnn (Code-Description Embedding Neural Network). Instead of matching text similarity, CODEnn jointly embeds code snippets and natural language descriptions into a high-dimensional vector space, in such a way that code snippet and its corresponding description have similar vectors. Using the unified vector representation, code snippets related to a natural language query can be retrieved according to their vectors. Semantically related words can also be recognized and irrelevant/noisy keywords in queries can be handled. As a proof-of-concept application, we implement a code search tool named DeepCS using the proposed CODEnn model. We empirically evaluate DeepCS on a large scale codebase collected from GitHub. The experimental results show that our approach can effectively retrieve relevant code snippets and outperforms previous techniques.","","","10.1145/3180155.3180167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453172","code search;deep learning;joint embedding","Natural languages;XML;Tools;Semantics;Machine learning;Recurrent neural networks","natural language processing;neural nets;query processing;text analysis","code search tool;source code;information retrieval models;relevant code snippets;natural language query;deep neural network;DeepCS;deep code search;large-scale codebase;code-description embedding neural network;CODEnn model;DeepCS;textual documents;matching text similarity","","21","","","","","","IEEE","IEEE Conferences"
"Automated Localization for Unreproducible Builds","Z. Ren; H. Jiang; J. Xuan; Z. Yang","Key Lab. for Ubiquitous Network & Service Software of Liaoning Province, Dalian Univ. of Technol., Dalian, China; Key Lab. for Ubiquitous Network & Service Software of Liaoning Province, Dalian Univ. of Technol., Dalian, China; Sch. of Comput. Sci., Wuhan Univ., Wuhan, China; Dept. of Comput. Sci., Western Michigan Univ., Kalamazoo, MI, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","71","81","Reproducibility is the ability of recreating identical binaries under pre-defined build environments. Due to the need of quality assurance and the benefit of better detecting attacks against build environments, the practice of reproducible builds has gained popularity in many open-source software repositories such as Debian and Bitcoin. However, identifying the unreproducible issues remains a labour intensive and time consuming challenge, because of the lacking of information to guide the search and the diversity of the causes that may lead to the unreproducible binaries. In this paper we propose an automated framework called RepLoc to localize the problematic files for unreproducible builds. RepLoc features a query augmentation component that utilizes the information extracted from the build logs, and a heuristic rule-based filtering component that narrows the search scope. By integrating the two components with a weighted file ranking module, RepLoc is able to automatically produce a ranked list of files that are helpful in locating the problematic files for the unreproducible builds. We have implemented a prototype and conducted extensive experiments over 671 real-world unreproducible Debian packages in four different categories. By considering the topmost ranked file only, RepLoc achieves an accuracy rate of 47.09%. If we expand our examination to the top ten ranked files in the list produced by RepLoc, the accuracy rate becomes 79.28%. Considering that there are hundreds of source code, scripts, Makefiles, etc., in a package, RepLoc significantly reduces the scope of localizing problematic files. Moreover, with the help of RepLoc, we successfully identified and fixed six new unreproducible packages from Debian and Guix.","","","10.1145/3180155.3180224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453064","Unreproducible Build;Localization;Software Maintenance","Software;Task analysis;Feature extraction;Filtering;Hafnium;Software engineering;Computer science","program diagnostics;public domain software;query processing;security of data;software maintenance","detecting attacks;open-source software repositories;unreproducible binaries;problematic files;query augmentation component;build logs;heuristic rule-based filtering component;search scope;weighted file ranking module;ranked list;topmost ranked file;automated localization;unreproducible builds;pre-defined build environments;quality assurance;Bitcoin;Guix;RepLoc features;unreproducible Debian packages","","2","","","","","","IEEE","IEEE Conferences"
"Missing Data Imputation Based on Low-Rank Recovery and Semi-Supervised Regression for Software Effort Estimation","X. Jing; F. Qi; F. Wu; B. Xu","State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China; State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China; State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China; Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","607","618","Software effort estimation (SEE) is a crucial step in software development. Effort data missing usually occurs in real-world data collection. Focusing on the missing data problem, existing SEE methods employ the deletion, ignoring, or imputation strategy to address the problem, where the imputation strategy was found to be more helpful for improving the estimation performance. Current imputation methods in SEE use classical imputation techniques for missing data imputation, yet these imputation techniques have their respective disadvantages and might not be appropriate for effort data. In this paper, we aim to provide an effective solution for the effort data missing problem. Incompletion includes the drive factor missing case and effort label missing case. We introduce the low-rank recovery technique for addressing the drive factor missing case. And we employ the semi-supervised regression technique to perform imputation in the case of effort label missing. We then propose a novel effort data imputation approach, named low-rank recovery and semi-supervised regression imputation (LRSRI). Experiments on 7 widely used software effort datasets indicate that: (1) the proposed approach can obtain better effort data imputation effects than other methods; (2) the imputed data using our approach can apply to multiple estimators well.","","","10.1145/2884781.2884827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886938","Software effort estimation;Missing data problem;Drive factor missing case;Effort label missing case;Low-rank recovery and semi-supervised regression imputation (LRSRI)","Estimation;Software;Data models;Adaptation models;Software engineering;Focusing;Organizations","data handling;regression analysis;software engineering","missing data imputation;low-rank recovery;semisupervised regression;software effort estimation;SEE;software development;data collection;deletion strategy;ignoring strategy;imputation strategy;drive factor missing case;effort label missing case;LRSRI","","3","62","","","","","IEEE","IEEE Conferences"
"Featured Model-Based Mutation Analysis","X. Devroey; G. Perrouin; M. Papadakis; A. Legay; P. Schobbens; P. Heymans","PReCISE Res. Center, Univ. of Namur, Namur, Belgium; PReCISE Res. Center, Univ. of Namur, Namur, Belgium; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; INRIA, Rennes, France; PReCISE Res. Center, Univ. of Namur, Namur, Belgium; PReCISE Res. Center, Univ. of Namur, Namur, Belgium","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","655","666","Model-based mutation analysis is a powerful but expensive testing technique. We tackle its high computation cost by proposing an optimization technique that drastically speeds up the mutant execution process. Central to this approach is the Featured Mutant Model, a modelling framework for mutation analysis inspired by the software product line paradigm. It uses behavioural variability models, viz., Featured Transition Systems, which enable the optimized generation, configuration and execution of mutants. We provide results, based on models with thousands of transitions, suggesting that our technique is fast and scalable. We found that it outperforms previous approaches by several orders of magnitude and that it makes higher-order mutation practically applicable.","","","10.1145/2884781.2884821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886942","Mutation Analysis;Variability;Featured Transition Systems","Testing;Unified modeling language;Computational modeling;Analytical models;Software product lines;Software;Scalability","program diagnostics;software product lines","featured model-based mutation analysis;optimization technique;mutant execution process;featured mutant model;software product line paradigm;behavioural variability models;featured transition systems;mutant generation;mutant configuration;mutant execution","","9","63","","","","","IEEE","IEEE Conferences"
"Code Review Quality: How Developers See It","O. Kononenko; O. Baysal; M. W. Godfrey","Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada; Sch. of Comput. Sci., Carleton Univ., Ottawa, ON, Canada; Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1028","1038","In a large, long-lived project, an effective code review process is key to ensuring the long-term quality of the code base. In this work, we study code review practices of a large, open source project, and we investigate how the developers themselves perceive code review quality. We present a qualitative study that summarizes the results from a survey of 88 Mozilla core developers. The results provide developer insights into how they define review quality, what factors contribute to how they evaluate submitted code, and what challenges they face when performing review tasks. We found that the review quality is primarily associated with the thoroughness of the feedback, the reviewer's familiarity with the code, and the perceived quality of the code itself. Also, we found that while different factors are perceived to contribute to the review quality, reviewers often find it difficult to keep their technical skills up-to-date, manage personal priorities, and mitigate context switching.","","","10.1145/2884781.2884840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886977","Code review;review quality;survey;developer perception","Software;Data mining;Computer science;Face;Computer bugs;Measurement;Electronic mail","software quality","effective code review process;long-term quality;Mozilla core developers;open source project","","10","32","","","","","IEEE","IEEE Conferences"
"Floating-Point Precision Tuning Using Blame Analysis","C. Rubio-Gonz√°lez; C. Nguyen; B. Mehne; K. Sen; J. Demmel; W. Kahan; C. Iancu; W. Lavrijsen; D. H. Bailey; D. Hough","Univ. of California, Davis, Davis, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Lawrence Berkeley Nat. Lab., Berkeley, CA, USA; Lawrence Berkeley Nat. Lab., Berkeley, CA, USA; Lawrence Berkeley Nat. Lab., Berkeley, CA, USA; Oracle Corp., USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1074","1085","While tremendously useful, automated techniques for tuning the precision of floating-point programs face important scalability challenges. We present Blame Analysis, a novel dynamic approach that speeds up precision tuning. Blame Analysis performs floating-point instructions using different levels of accuracy for their operands. The analysis determines the precision of all operands such that a given precision is achieved in the final result of the program. Our evaluation on ten scientific programs shows that Blame Analysis is successful in lowering operand precision. As it executes the program only once, the analysis is particularly useful when targeting reductions in execution time. In such case, the analysis needs to be combined with search-based tools such as Precimonious. Our experiments show that combining Blame Analysis with Precimonious leads to obtaining better results with significant reduction in analysis time: the optimized programs execute faster (in three cases, we observe as high as 39.9% program speedup) and the combined analysis time is 9√ó faster on average, and up to 38√ó faster than Precimonious alone.","","","10.1145/2884781.2884850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886981","floating point;mixed precision;program optimization","Tuning;Scalability;Government;Performance analysis;Search problems;Software;Numerical analysis","program diagnostics","floating-point precision tuning;blame analysis approach;floating-point instructions;operand precision;Precimonious tool","","7","46","","","","","IEEE","IEEE Conferences"
"iDice: Problem Identification for Emerging Issues","Q. Lin; J. Lou; H. Zhang; D. Zhang","Microsoft Res., Beijing, China; Microsoft Res., Beijing, China; Microsoft Res., Beijing, China; Microsoft Res., Beijing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","214","224","One challenge for maintaining a large-scale software system, especially an online service system, is to quickly respond to customer issues. The issue reports typically have many categorical attributes that reflect the characteristics of the issues. For a commercial system, most of the time the volume of reported issues is relatively constant. Sometimes, there are emerging issues that lead to significant volume increase. It is important for support engineers to efficiently and effectively identify and resolve such emerging issues, since they have impacted a large number of customers. Currently, problem identification for an emerging issue is a tedious and error-prone process, because it requires support engineers to manually identify a particular attribute combination that characterizes the emerging issue among a large number of attribute combinations. We call such an attribute combination effective combination, which is important for issue isolation and diagnosis. In this paper, we propose iDice, an approach that can identify the effective combination for an emerging issue with high quality and performance. We evaluate the effectiveness and efficiency of iDice through experiments. We have also successfully applied iDice to several Microsoft online service systems in production. The results confirm that iDice can help identify emerging issues and reduce maintenance effort.","","","10.1145/2884781.2884795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886905","Emerging issues;problem identification;effective combination;problem diagnostic;issue reports","Manuals;Software systems;Maintenance engineering;Time series analysis;Market research;Software engineering","software maintenance","iDice;large-scale software system;software system maintenance;categorical attributes;problem identification;attribute combination effective combination;Microsoft online service systems","","4","30","","","","","IEEE","IEEE Conferences"
"FaCoY ‚Äì A Code-to-Code Search Engine","K. Kim; D. Kim; T. F. Bissyand√©; E. Choi; L. Li; J. Klein; Y. Le Traon","SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; Nara Inst. of Sci. & Technol., Nara, Japan; Fac. of Inf. Technol., Monash Univ., Clayton, VIC, Australia; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT, Univ. of Luxembourg, Luxembourg City, Luxembourg","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","946","957","Code search is an unavoidable activity in software development. Various approaches and techniques have been explored in the literature to support code search tasks. Most of these approaches focus on serving user queries provided as natural language free-form input. However, there exists a wide range of use-case scenarios where a code-to-code approach would be most beneficial. For example, research directions in code transplantation, code diversity, patch recommendation can leverage a code-to-code search engine to find essential ingredients for their techniques. In this paper, we propose FaCoY, a novel approach for statically finding code fragments which may be semantically similar to user input code. FaCoY implements a query alternation strategy: instead of directly matching code query tokens with code in the search space, FaCoY first attempts to identify other tokens which may also be relevant in implementing the functional behavior of the input code. With various experiments, we show that (1) FaCoY is more effective than online code-to-code search engines; (2) FaCoY can detect more semantic code clones (i.e., Type-4) in BigCloneBench than the state-of-the-art; (3) FaCoY, while static, can detect code fragments which are indeed similar with respect to runtime execution behavior; and (4) FaCoY can be useful in code/patch recommendation.","","","10.1145/3180155.3180187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453174","code search;semantic clones;code to code search","Cloning;Search engines;Semantics;Software;Natural languages;Syntactics;Runtime","query processing;search engines;software engineering;software maintenance","code-to-code search engine;code search tasks;code-to-code approach;code-patch recommendation;FaCoY;semantic code clones;directly matching code query tokens;user input code;statically finding code fragments;code diversity;code transplantation","","2","","","","","","IEEE","IEEE Conferences"
"A Large-Scale Empirical Study on the Effects of Code Obfuscations on Android Apps and Anti-Malware Products","M. Hammad; J. Garcia; S. Malek","Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA; Dept. of Inf., Univ. of California, Irvine, Irvine, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","421","431","The Android platform has been the dominant mobile platform in recent years resulting in millions of apps and security threats against those apps. Anti-malware products aim to protect smartphone users from these threats, especially from malicious apps. However, malware authors use code obfuscation on their apps to evade detection by anti-malware products. To assess the effects of code obfuscation on Android apps and anti-malware products, we have conducted a large-scale empirical study that evaluates the effectiveness of the top anti-malware products against various obfuscation tools and strategies. To that end, we have obfuscated 3,000 benign apps and 3,000 malicious apps and generated 73,362 obfuscated apps using 29 obfuscation strategies from 7 open-source, academic, and commercial obfuscation tools. The findings of our study indicate that (1) code obfuscation significantly impacts Android anti-malware products; (2) the majority of anti-malware products are severely impacted by even trivial obfuscations; (3) in general, combined obfuscation strategies do not successfully evade anti-malware products more than individual strategies; (4) the detection of anti-malware products depend not only on the applied obfuscation strategy but also on the leveraged obfuscation tool; (5) anti-malware products are slow to adopt signatures of malicious apps; and (6) code obfuscation often results in changes to an app's semantic behaviors.","","","10.1145/3180155.3180228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453102","Android;empirical study;Security;Code Obfuscation;Anti malware products","Androids;Humanoid robots;Tools;Malware;Cryptography;Reflection;Java","Android (operating system);invasive software;smart phones","code obfuscation effects;code obfuscation effects;smartphone users;Android anti-malware products;Android apps","","1","49","","","","","IEEE","IEEE Conferences"
"How Does the Degree of Variability Affect Bug Finding?","J. Melo; C. Brabrand; A. Wasowski","IT Univ. of Copenhagen, Copenhagen, Denmark; IT Univ. of Copenhagen, Copenhagen, Denmark; IT Univ. of Copenhagen, Copenhagen, Denmark","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","679","690","Software projects embrace variability to increase adaptability and to lower cost; however, others blame variability for increasing complexity and making reasoning about programs more difficult. We carry out a controlled experiment to quantify the impact of variability on debugging of preprocessor- based programs. We measure speed and precision for bug finding tasks defined at three different degrees of variability on several subject programs derived from real systems. The results show that the speed of bug finding decreases linearly with the degree of variability, while effectiveness of finding bugs is relatively independent of the degree of variability. Still, identifying the set of configurations in which the bug manifests itself is difficult already for a low degree of variability. Surprisingly, identifying the exact set of affected configurations appears to be harder than finding the bug in the first place. The difficulty in reasoning about several configurations is a likely reason why the variability bugs are actually introduced in configurable programs. We hope that the detailed findings presented here will inspire the creation of programmer support tools addressing the challenges faced by developers when reasoning about configurations, contributing to more effective debugging and, ultimately, fewer bugs in highly-configurable systems.","","","10.1145/2884781.2884831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886944","Variability;Preprocessors;Bug Finding","Computer bugs;Debugging;Linux;Cognition;Kernel;Color","program debugging","variability degree;bug finding;software projects;preprocessor-based program debugging;configurable program","","5","36","","","","","IEEE","IEEE Conferences"
"IntEQ: Recognizing Benign Integer Overflows via Equivalence Checking across Multiple Precisions","H. Sun; X. Zhang; Y. Zheng; Q. Zeng","State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China; Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China; Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA; IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1051","1062","Integer overflow (IO) vulnerabilities can be exploited by attackers to compromise computer systems. In the meantime, IOs can be used intentionally by programmers for benign purposes such as hashing and random number generation. Hence, differentiating exploitable and harmful IOs from intentional and benign ones is an important challenge. It allows reducing the number of false positives produced by IO vulnerability detection techniques, helping developers or security analysts to focus on fxing critical IOs without inspecting the numerous false alarms. The difficulty of recognizing benign IOs mainly lies in inferring the intent of programmers from source code. In this paper, we present a novel technique to recognize benign IOs via equivalence checking across multiple precisions. We determine if an IO is benign by comparing the effects of an overflowed integer arithmetic operation in the actual world (with limited precision) and the same operation in the ideal world (with sufficient precision to evade the IO). Specifically, we first extract the data flow path from the overflowed integer arithmetic operation to a security-related program point (i.e., sink) and then create a new version of the path using more precise types with sufficient bits to represent integers so that the IO can be avoided. Using theorem proving we check whether these two versions are equivalent, that is, if they yield the same values at the sink under all possible inputs. If so, the IO is benign. We implement a prototype, named IntEQ, based on the GCC compiler and the Z3 solver, and evaluate it using 26 harmful IO vulnerabilities from 20 real-world programs, and 444 benign IOs from SPECINT 2000, SPECINT 2006, and 7 real-world applications. The experimental results show that IntEQ does not misclassify any harmful IO bugs (no false negatives) and recognizes 355 out of 444 (about 79.95%) benign IOs, whereas the state of the art can only recognize 19 benign IOs.","","","10.1145/2884781.2884820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886979","Integer Overflow;benign;equivalence checking;precision","Software;Random number generation;Computer bugs;Indexing;Encoding;Computer science","data flow analysis;program debugging;program verification;security of data","IntEQ;benign integer overflow recognition;equivalence checking;random number generation;IO vulnerability detection techniques;security analysts;overflowed integer arithmetic operation;data flow path extraction;GCC compiler;SPECINT;harmful IO bugs","","2","57","","","","","IEEE","IEEE Conferences"
"Scalable Thread Sharing Analysis","J. Huang","Parasol Lab., Texas A&M Univ., College Station, TX, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1097","1108","We present two scalable algorithms for identifying program locations that access thread-shared data in concurrent programs. The static algorithm, though simple, and without performing the expensive whole program information flow analysis, is much more efficient, less memory-demanding, and even more precise than the classical escape analysis algorithm. The dynamic algorithm, powered by a location- based approach, achieves significant runtime speedups over a precise dynamic escape analysis. Our evaluation on a set of large real world complex multithreaded systems such as Apache Derby and Eclipse shows that our algorithms achieve unprecedented scalability. Used by client applications, our algorithms reduce the recording overhead of a record-replay system by 9X on average (as much as 16X) and increase the runtime logging speed of a data race detector by 32% on average (as much as 52%).","","","10.1145/2884781.2884811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886983","","Heuristic algorithms;Algorithm design and analysis;Arrays;Instruction sets;Runtime;Detectors;Java","multi-threading;program diagnostics","thread sharing analysis;scalable algorithms;program locations identification;thread-shared data access;concurrent programs;static algorithm;program information flow analysis;location-based approach;dynamic algorithm;multithreaded systems;Apache Derby;Eclipse;record-replay system;data race detector","","3","42","","","","","IEEE","IEEE Conferences"
"An Empirical Study of Practitioners' Perspectives on Green Software Engineering","I. Manotas; C. Bird; R. Zhang; D. Shepherd; C. Jaspan; C. Sadowski; L. Pollock; J. Clause","Univ. of Delaware, Newark, DE, USA; Microsoft Res., Redmond, WA, USA; IBM Res. - Almaden, San Jose, CA, USA; ABB Corp. Res., Raleigh, NC, USA; Google, Inc., Mountain View, CA, USA; Google, Inc., Mountain View, CA, USA; Univ. of Delaware, Newark, DE, USA; Univ. of Delaware, Newark, DE, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","237","248","The energy consumption of software is an increasing concern as the use of mobile applications, embedded systems, and data center-based services expands. While research in green software engineering is correspondingly increasing, little is known about the current practices and perspectives of software engineers in the field. This paper describes the first empirical study of how practitioners think about energy when they write requirements, design, construct, test, and maintain their software. We report findings from a quantitative,targeted survey of 464 practitioners from ABB, Google, IBM, and Microsoft, which was motivated by and supported with qualitative data from 18 in-depth interviews with Microsoft employees. The major findings and implications from the collected data contextualize existing green software engineering research and suggest directions for researchers aiming to develop strategies and tools to help practitioners improve the energy usage of their applications.","","","10.1145/2884781.2884810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886907","Green Software Engineering;Empirical Study;Survey","Interviews;Software engineering;Software;Google;Encoding;Green products;Conferences","energy consumption;green computing;software engineering","practitioner perspective;green software engineering;energy consumption;mobile applications;embedded systems;data center-based services;ABB;Google;IBM;Microsoft;energy usage","","15","60","","","","","IEEE","IEEE Conferences"
"Work Practices and Challenges in Pull-Based Development: The Contributor's Perspective","G. Gousios; M. Storey; A. Bacchelli","Radboud Univ. Nijmegen, Nijmegen, Netherlands; Univ. of Victoria, Victoria, BC, Canada; Delft Univ. of Technol., Delft, Netherlands","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","285","296","The pull-based development model is an emerging way of contributing to distributed software projects that is gaining enormous popularity within the open source software (OSS) world. Previous work has examined this model by focusing on projects and their owners-we complement it by examining the work practices of project contributors and the challenges they face.We conducted a survey with 645 top contributors to active OSS projects using the pull-based model on GitHub, the prevalent social coding site. We also analyzed traces extracted from corresponding GitHub repositories. Our research shows that: contributors have a strong interest in maintaining awareness of project status to get inspiration and avoid duplicating work, but they do not actively propagate information; communication within pull requests is reportedly limited to low-level concerns and contributors often use communication channels external to pull requests; challenges are mostly social in nature, with most reporting poor responsiveness from integrators; and the increased transparency of this setting is a confirmed motivation to contribute. Based on these findings, we present recommendations for practitioners to streamline the contribution process and discuss potential future research directions.","","","10.1145/2884781.2884826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886911","pull-based development;open source contribution;pull request;dis- tributed software development;GitHub","Encoding;Software;Face;Collaboration;Electronic mail;Software engineering;Focusing","public domain software;software engineering","pull-based development model;distributed software projects;open source software;OSS;GitHub;project status awareness;contribution process","","29","54","","","","","IEEE","IEEE Conferences"
"A Graph Solver for the Automated Generation of Consistent Domain-Specific Models","O. Semer√°th; A. S. Nagy; D. Varr√≥","MTA-BME Lendulet Cyber-Phys. Syst. Res. Group, Budapest, Hungary; MTA-BME Lendulet Cyber-Phys. Syst. Res. Group, Budapest, Hungary; McGill Univ., Montreal, QC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","969","980","Many testing and benchmarking scenarios in software and systems engineering depend on the systematic generation of graph models. For instance, tool qualification necessitated by safety standards would require a large set of consistent (well-formed or malformed) instance models specific to a domain. However, automatically generating consistent graph models which comply with a metamodel and satisfy all well-formedness constraints of industrial domains is a significant challenge. Existing solutions which map graph models into first-order logic specification to use back-end logic solvers (like Alloy or Z3) have severe scalability issues. In the paper, we propose a graph solver framework for the automated generation of consistent domain-specific instance models which operates directly over graphs by combining advanced techniques such as refinement of partial models, shape analysis, incremental graph query evaluation, and rule-based design space exploration to provide a more efficient guidance. Our initial performance evaluation carried out in four domains demonstrates that our approach is able to generate models which are 1-2 orders of magnitude larger (with 500 to 6000 objects!) compared to mapping-based approaches natively using Alloy.","","","10.1145/3180155.3180186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453176","Graph generation;Test generation;Domain Specific Modeling Languages;Logic Solver;Graph Solver","Analytical models;Object oriented modeling;Tools;Biological system modeling;IP networks;Testing","formal logic;formal specification;formal verification;graph theory;query processing;specification languages","consistent domain-specific models;automated model generation;software engineering;graph models;domain-specific instance models;mapping-based approach;incremental graph query evaluation;graph solver framework;back-end logic solvers;first-order logic specification;safety standards;tool qualification;systematic generation;systems engineering","","4","","","","","","IEEE","IEEE Conferences"
"Testing Vision-Based Control Systems Using Learnable Evolutionary Algorithms","R. Ben Abdessalem; S. Nejati; L. C. Briand; T. Stifter","SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; IEE S.A., Luxembourg","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1016","1026","Vision-based control systems are key enablers of many autonomous vehicular systems, including self-driving cars. Testing such systems is complicated by complex and multidimensional input spaces. We propose an automated testing algorithm that builds on learnable evolutionary algorithms. These algorithms rely on machine learning or a combination of machine learning and Darwinian genetic operators to guide the generation of new solutions (test scenarios in our context). Our approach combines multiobjective population-based search algorithms and decision tree classification models to achieve the following goals: First, classification models guide the search-based generation of tests faster towards critical test scenarios (i.e., test scenarios leading to failures). Second, search algorithms refine classification models so that the models can accurately characterize critical regions (i.e., the regions of a test input space that are likely to contain most critical test scenarios). Our evaluation performed on an industrial automotive automotive system shows that: (1) Our algorithm outperforms a baseline evolutionary search algorithm and generates 78% more distinct, critical test scenarios compared to the baseline algorithm. (2) Our algorithm accurately characterizes critical regions of the system under test, thus identifying the conditions that are likely to lead to system failures.","","","10.1145/3180155.3180160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453180","Search-based Software Engineering;Evolutionary algorithms;Software Testing;Automotive Software Systems","Testing;Classification algorithms;Roads;Control systems;Evolutionary computation;Decision trees;Automotive engineering","decision trees;evolutionary computation;genetic algorithms;learning (artificial intelligence);mobile robots;robot vision;search problems","vision-based control systems;learnable evolutionary algorithms;autonomous vehicular systems;complex input spaces;multidimensional input spaces;automated testing algorithm;machine learning;multiobjective population-based search algorithms;decision tree classification models;search-based generation;search algorithms refine classification models;test input space;industrial automotive automotive system;baseline evolutionary search algorithm;distinct test scenarios","","13","39","","","","","IEEE","IEEE Conferences"
"An Analysis of the Search Spaces for Generate and Validate Patch Generation Systems","F. Long; M. Rinard","EECS, MIT, Cambridge, MA, USA; EECS, MIT, Cambridge, MA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","702","713","We present the first systematic analysis of key characteristics of patch search spaces for automatic patch generation systems. We analyze sixteen different configurations of the patch search spaces of SPR and Prophet, two current state-of-the-art patch generation systems. The analysis shows that 1) correct patches are sparse in the search spaces (typically at most one correct patch per search space per defect), 2) incorrect patches that nevertheless pass all of the test cases in the validation test suite are typically orders of magnitude more abundant, and 3) leveraging information other than the test suite is therefore critical for enabling the system to successfully isolate correct patches. We also characterize a key tradeoff in the structure of the search spaces. Larger and richer search spaces that contain correct patches for more defects can actually cause systems to find fewer, not more, correct patches. We identify two reasons for this phenomenon: 1) increased validation times because of the presence of more candidate patches and 2) more incorrect patches that pass the test suite and block the discovery of correct patches. These fundamental properties, which are all characterized for the first time in this paper, help explain why past systems often fail to generate correct patches and help identify challenges, opportunities, and productive future directions for the field.","","","10.1145/2884781.2884872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886946","Program repair;Patch generation;Search space","Benchmark testing;Space exploration;Systematics;Software;Software engineering;Scalability;Conferences","program diagnostics;software maintenance","automatic patch generation systems;SPR;Prophet;program repair","","20","41","","","","","IEEE","IEEE Conferences"
"Coverage-Driven Test Code Generation for Concurrent Classes","V. Terragni; S. Cheung","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1121","1132","Previous techniques on concurrency testing have mainly focused on exploring the interleaving space of manually written test code to expose faulty interleavings of shared memory accesses. These techniques assume the availability of failure-inducing tests. In this paper, we present AutoConTest, a coverage-driven approach to generate effective concurrent test code that achieve high interleaving coverage. AutoConTest consists of three components. First, it computes the coverage requirements dynamically and iteratively during sequential test code generation, using a coverage metric that captures the execution context of shared memory accesses. Second, it smartly selects these sequential codes based on the computed result and assembles them for concurrent tests, achieving increased context-sensitive interleaving coverage. Third, it explores the newly covered interleavings. We have implemented AutoConTest as an automated tool and evaluated it using 6 real-world concurrent Java subjects. The results show that AutoConTest is able to generate effective concurrent tests that achieve high interleaving coverage and expose concurrency faults quickly. AutoConTest took less than 65 seconds (including program analysis, test generation and execution) to expose the faults in the program subjects.","","","10.1145/2884781.2884876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886985","Automated test generation;Interleaving coverage criteria","Concurrent computing;Space exploration;Instruction sets;Testing;Synchronization;Programming","concurrency (computers);program testing;sequential codes;shared memory systems","coverage-driven test code generation;AutoConTest;concurrent test code;sequential test code generation;coverage metric;shared memory accesses;context-sensitive interleaving coverage","","4","68","","","","","IEEE","IEEE Conferences"
"Too Long; Didn't Watch! Extracting Relevant Fragments from Software Development Video Tutorials","L. Ponzanelli; G. Bavota; A. Mocci; M. Di Penta; R. Oliveto; M. Hasan; B. Russo; S. Haiduc; M. Lanza","Univ. della Svizzera Italiana, Lugano, Switzerland; Free Univ. of Bozen-Bolzano, Bolzano, Italy; Univ. della Svizzera Italiana, Lugano, Switzerland; Univ. of Sannio, Benevento, Italy; Univ. of Molise, Pesche, Italy; Florida State Univ., Tallahassee, FL, USA; Free Univ. of Bozen-Bolzano, Bolzano, Italy; Florida State Univ., Tallahassee, FL, USA; Univ. della Svizzera Italiana, Lugano, Switzerland","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","261","272","When knowledgeable colleagues are not available, developers resort to offline and online resources, e.g., tutorials, mailing lists, and Q&A websites. These, however, need to be found, read, and understood, which takes its toll in terms of time and mental energy. A more immediate and accessible resource are video tutorials found on the web, which in recent years have seen a steep increase in popularity. Nonetheless, videos are an intrinsically noisy data source, and finding the right piece of information might be even more cumbersome than using the previously mentioned resources. We present CodeTube, an approach which mines video tutorials found on the web, and enables developers to query their contents. The video tutorials are split into coherent fragments, to return only fragments related to the query. These are complemented with information from additional sources, such as Stack Overflow discussions. The results of two studies to assess CodeTube indicate that video tutorials-if appropriately processed-represent a useful, yet still under-utilized source of information for software development.","","","10.1145/2884781.2884824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886909","","Tutorials;Streaming media;Optical character recognition software;Java;YouTube;Data mining","data mining;software engineering","software development video tutorials;CodeTube;data mining","","7","44","","","","","IEEE","IEEE Conferences"
"Cross-Project Defect Prediction Using a Connectivity-Based Unsupervised Classifier","F. Zhang; Q. Zheng; Y. Zou; A. E. Hassan","Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada; Dept. of Electr. & Comput. Eng., Queen's Univ., Kingston, ON, Canada; Sch. of Comput., Queen's Univ., Kingston, ON, Canada","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","309","320","Defect prediction on projects with limited historical data has attracted great interest from both researchers and practitioners. Cross-project defect prediction has been the main area of progress by reusing classifiers from other projects. However, existing approaches require some degree of homogeneity (e.g., a similar distribution of metric values) between the training projects and the target project. Satisfying the homogeneity requirement often requires significant effort (currently a very active area of research). An unsupervised classifier does not require any training data, therefore the heterogeneity challenge is no longer an issue. In this paper, we examine two types of unsupervised classifiers: a) distance-based classifiers (e.g., k-means); and b) connectivity-based classifiers. While distance-based unsupervised classifiers have been previously used in the defect prediction literature with disappointing performance, connectivity-based classifiers have never been explored before in our community. We compare the performance of unsupervised classifiers versus supervised classifiers using data from 26 projects from three publicly available datasets (i.e., AEEEM, NASA, and PROMISE). In the cross-project setting, our proposed connectivity-based classifier (via spectral clustering) ranks as one of the top classifiers among five widely-used supervised classifiers (i.e., random forest, naive Bayes, logistic regression, decision tree, and logistic model tree) and five unsupervised classifiers (i.e., k-means, partition around medoids, fuzzy C-means, neural-gas, and spectral clustering). In the within-project setting (i.e., models are built and applied on the same project), our spectral classifier ranks in the second tier, while only random forest ranks in the first tier. Hence, connectivity-based unsupervised classifiers offer a viable solution for cross and within project defect predictions.","","","10.1145/2884781.2884839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886913","defect prediction;heterogeneity;cross-project;unsupervised;spectral clustering;graph mining","Software;Training;Predictive models;Software metrics;Training data;Clustering algorithms","pattern classification;public domain software;software maintenance;unsupervised learning","cross-project defect prediction;connectivity-based unsupervised classifier;homogeneity degree;distance-based classifiers;connectivity-based classifiers","","27","66","","","","","IEEE","IEEE Conferences"
"Nemo: Multi-criteria Test-Suite Minimization with Integer Nonlinear Programming","J. Lin; R. Jabbarvand; J. Garcia; S. Malek","Univ. of California, Irvine, Irvine, CA, USA; Univ. of California, Irvine, Irvine, CA, USA; Univ. of California, Irvine, Irvine, CA, USA; Univ. of California, Irvine, Irvine, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1039","1049","Multi-criteria test-suite minimization aims to remove redundant test cases from a test suite based on some criteria such as code coverage, while trying to optimally maintain the capability of the reduced suite based on other criteria such as fault-detection effectiveness. Existing techniques addressing this problem with integer linear programming claim to produce optimal solutions. However, the multi-criteria test-suite minimization problem is inherently nonlinear, due to the fact that test cases are often dependent on each other in terms of test-case criteria. In this paper, we propose a framework that formulates the multi-criteria test-suite minimization problem as an integer nonlinear programming problem. To solve this problem optimally, we programmatically transform this nonlinear problem into a linear one and then solve the problem using modern linear solvers. We have implemented our framework as a tool, called Nemo, that supports a number of modern linear and nonlinear solvers. We have evaluated Nemo with a publicly available dataset and minimization problems involving multiple criteria including statement coverage, fault-revealing capability, and test execution time. The experimental results show that Nemo can be used to efficiently find an optimal solution for multi-criteria test-suite minimization problems with modern solvers, and the optimal solutions outperform the suboptimal ones by up to 164.29% in terms of the criteria considered in the problem.","","","10.1145/3180155.3180174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453182","Test-suite minimization;integer programming","Minimization;Linear programming;Optimization;Mathematical model;Tools;Testing;Programming","integer programming;linear programming;minimisation;nonlinear programming;program testing","redundant test cases;optimal solution;multicriteria test-suite minimization problem;test-case criteria;integer nonlinear programming problem","","1","","","","","","IEEE","IEEE Conferences"
"Time to Clean Your Test Objectives","M. Marcozzi; S. Bardin; N. Kosmatov; M. Papadakis; V. Prevosto; L. Correnson","Dept. of Comput., Imperial Coll. London, London, UK; List Software Safety & Security Lab., CEA, Gif-sur-Yvette, France; List Software Safety & Security Lab., CEA, Gif-sur-Yvette, France; SnT, Univ. of Luxembourg, Luxembourg, Luxembourg; List Software Safety & Security Lab., CEA, Gif-sur-Yvette, France; List Software Safety & Security Lab., CEA, Gif-sur-Yvette, France","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","456","467","Testing is the primary approach for detecting software defects. A major challenge faced by testers lies in crafting efficient test suites, able to detect a maximum number of bugs with manageable effort. To do so, they rely on coverage criteria, which define some precise test objectives to be covered. However, many common criteria specify a significant number of objectives that occur to be infeasible or redundant in practice, like covering dead code or semantically equal mutants. Such objectives are well-known to be harmful to the design of test suites, impacting both the efficiency and precision of the tester's effort. This work introduces a sound and scalable technique to prune out a significant part of the infeasible and redundant objectives produced by a panel of white-box criteria. In a nutshell, we reduce this task to proving the validity of logical assertions in the code under test. The technique is implemented in a tool that relies on weakest-precondition calculus and SMT solving for proving the assertions. The tool is built on top of the Frama-C verification platform, which we carefully tune for our specific scalability needs. The experiments reveal that the pruning capabilities of the tool can reduce the number of targeted test objectives in a program by up to 27% and scale to real programs of 200K lines, making it possible to automate a painstaking part of their current testing process.","","","10.1145/3180155.3180191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453106","Coverage Criteria;Infeasible Objectives;Redundant Objectives","Tools;Software safety;Security;Software testing;Scalability","program diagnostics;program testing;program verification","significant number;dead code;semantically equal mutants;scalable technique;infeasible objectives;redundant objectives;white-box criteria;logical assertions;targeted test objectives;current testing process;primary approach;detecting software defects;efficient test suites;coverage criteria;precise test objectives","","","","","","","","IEEE","IEEE Conferences"
"Improving Refactoring Speed by 10X","J. Kim; D. Batory; D. Dig; M. Azanza","NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1145","1156","Refactoring engines are standard tools in today's Integrated Development Environments (IDEs). They allow programmers to perform one refactoring at a time, but programmers need more. Most design patterns in the Gang-of-Four text can be written as a refactoring script - a programmatic sequence of refactorings. In this paper, we present R3, a new Java refactoring engine that supports refactoring scripts. It builds a main-memory, non-persistent database to encode Java entity declarations (e.g., packages, classes, methods), their containment relationships, and language features such as inheritance and modifiers. Unlike classical refactoring engines that modify Abstract Syntax Trees (ASTs), R3 refactorings modify only the database; refactored code is produced only when pretty-printing ASTs that reference database changes. R3 performs comparable precondition checks to those of the Eclipse Java Development Tools (JDT) but R3's codebase is about half the size of the JDT refactoring engine and runs an order of magnitude faster. Further, a user study shows that R3 improved the success rate of retrofitting design patterns by 25% up to 50%.","","","10.1145/2884781.2884802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886987","","Java;Engines;Databases;Graphics;Computer bugs;Graphical user interfaces;Maintenance engineering","Java;software maintenance","refactoring speed;integrated development environment;IDE;Gang-of-Four text;refactoring script;refactoring sequence;Java refactoring engine;Java entity declarations;abstract syntax trees;AST;Eclipse Java development tools;JDT;retrofitting design patterns","","5","57","","","","","IEEE","IEEE Conferences"
"AntMiner: Mining More Bugs by Reducing Noise Interference","B. Liang; P. Bian; Y. Zhang; W. Shi; W. You; Y. Cai","Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; Key Lab. of Data Eng. & Knowledge Eng., Renmin Univ. of China, Beijing, China; State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","333","344","Detecting bugs with code mining has proven to be an effective approach. However, the existing methods suffer from reporting serious false positives and false negatives. In this paper, we developed an approach called AntMiner to improve the precision of code mining by carefully preprocessing the source code. Specifically, we employ the program slicing technique to decompose the original source repository into independent sub-repositories, taking critical operations (automatically extracted from source code) as slicing criteria. In this way, the statements irrelevant to a critical operation are excluded from the corresponding sub-repository. Besides, various semantics-equivalent representations are normalized into a canonical form. Eventually, the mining process can be performed on a refined code database, and false positives and false negatives can be significantly pruned. We have implemented AntMiner and applied it to detect bugs in the Linux kernel. It reported 52 violations that have been either confirmed as real bugs by the kernel development community or fixed in new kernel versions. Among them, 41 cannot be detected by a widely used representative analysis tool Coverity. Besides, the result of a comparative analysis shows that our approach can effectively improve the precision of code mining and detect subtle bugs that have previously been missed.","","","10.1145/2884781.2884870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886915","Bug detection;Code mining;Program slicing","Computer bugs;Data mining;Kernel;Programming;Linux;Databases","data mining;Linux;operating system kernels;program debugging;program slicing","AntMiner approach;noise interference reduction;bug detection;code mining;source code preprocessing;program slicing technique;semantics-equivalent representation;Linux kernel;Coverity tool","","5","50","","","","","IEEE","IEEE Conferences"
"Automated Reporting of GUI Design Violations for Mobile Apps","K. Moran; B. Li; C. Bernal-C√°rdenas; D. Jelf; D. Poshyvanyk","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","165","175","The inception of a mobile app often takes form of a mock-up of the Graphical User Interface (GUI), represented as a static image delineating the proper layout and style of GUI widgets that satisfy requirements. Following this initial mock-up, the design artifacts are then handed off to developers whose goal is to accurately implement these GUIs and the desired functionality in code. Given the sizable abstraction gap between mock-ups and code, developers often introduce mistakes related to the GUI that can negatively impact an app's success in highly competitive marketplaces. Moreover, such mistakes are common in the evolutionary context of rapidly changing apps. This leads to the time-consuming and laborious task of design teams verifying that each screen of an app was implemented according to intended design specifications. This paper introduces a novel, automated approach for verifying whether the GUI of a mobile app was implemented according to its intended design. Our approach resolves GUI-related information from both implemented apps and mock-ups and uses computer vision techniques to identify common errors in the implementations of mobile GUIs. We implemented this approach for Android in a tool called GVT and carried out both a controlled empirical evaluation with open-source apps as well as an industrial evaluation with designers and developers from Huawei. The results show that GVT solves an important, difficult, and highly practical problem with remarkable efficiency and accuracy and is both useful and scalable from the point of view of industrial designers and developers. The tool is currently used by over one-thousand industrial designers and developers at Huawei to improve the quality of their mobile apps.","","","10.1145/3180155.3180246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453076","GUI;design;Mobile Apps;Android;Computer Vision","Graphical user interfaces;Tools;Androids;Humanoid robots;Visualization;Layout;Computer vision","graphical user interfaces;mobile computing","GUI design violations;mobile app;design artifacts;mock-ups;intended design specifications;open-source apps;mobile GUI","","4","","","","","","IEEE","IEEE Conferences"
"Fine-Grained Test Minimization","A. Vahabzadeh; A. Stocco; A. Mesbah","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","210","221","As a software system evolves, its test suite can accumulate redundancies over time. Test minimization aims at removing redundant test cases. However, current techniques remove whole test cases from the test suite using test adequacy criteria, such as code coverage. This has two limitations, namely (1) by removing a whole test case the corresponding test assertions are also lost, which can inhibit test suite effectiveness, (2) the issue of partly redundant test cases, i.e., tests with redundant test statements, is ignored. We propose a novel approach for fine-grained test case minimization. Our analysis is based on the inference of a test suite model that enables automated test reorganization within test cases. It enables removing redundancies at the test statement level, while preserving the coverage and test assertions of the test suite. We evaluated our approach, implemented in a tool called Testler, on the test suites of 15 open source projects. Our analysis shows that over 4,639 (24%) of the tests in these test suites are partly redundant, with over 11,819 redundant test statements in total. Our results show that Testler removes 43% of the redundant test statements, reducing the number of partly redundant tests by 52%. As a result, test suite execution time is reduced by up to 37% (20% on average), while maintaining the original statement coverage, branch coverage, test assertions, and fault detection capability.","","","10.1145/3180155.3180203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453080","test minization;test reduction;test redundancy;test model","Production;Minimization;Redundancy;Analytical models;Computational modeling;Software engineering;Software systems","program testing","test minimization;test adequacy criteria;corresponding test assertions;test suite effectiveness;partly redundant test cases;fine-grained test case minimization;test suite model;test reorganization;test statement level;partly redundant tests;test suite execution time;redundant test statements","","","","","","","","IEEE","IEEE Conferences"
"An Empirical Study on the Impact of C++ Lambdas and Programmer Experience","P. M. Uesbeck; A. Stefik; S. Hanenberg; J. Pedersen; P. Daleiden","Dept. of Comput. Sci., Univ. of Nevada, Las Vegas, Las Vegas, NV, USA; Dept. of Comput. Sci., Univ. of Nevada, Las Vegas, Las Vegas, NV, USA; Inst. for Comput. Sci. & Bus. Inf. Syst., Univ. of Duisburg-Essen, Essen, Germany; Dept. of Comput. Sci., Univ. of Nevada, Las Vegas, Las Vegas, NV, USA; Dept. of Comput. Sci., Univ. of Nevada, Las Vegas, Las Vegas, NV, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","760","771","Lambdas have seen increasing use in mainstream programming languages, notably in Java 8 and C++ 11. While the technical aspects of lambdas are known, we conducted the first randomized controlled trial on the human factors impact of C++ 11 lambdas compared to iterators. Because there has been recent debate on having students or professionals in experiments, we recruited undergraduates across the academic pipeline and professional programmers to evaluate these findings in a broader context. Results afford some doubt that lambdas benefit developers and show evidence that students are negatively impacted in regard to how quickly they can write correct programs to a test specification and whether they can complete a task. Analysis from log data shows that participants spent more time with compiler errors, and have more errors, when using lambdas as compared to iterators, suggesting difficulty with the syntax chosen for C++. Finally, experienced users were more likely to complete tasks, with or without lambdas, and could do so more quickly, with experience as a factor explaining 45.7% of the variance in our sample in regard to completion time.","","","10.1145/2884781.2884849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886954","Lambda Expressions;Human Factors;C++11","C++ languages;Java;Syntactics;Context;Algorithm design and analysis;Libraries","C++ language;formal specification","C++ lambda;programmer experience;mainstream programming languages;Java 8 languages;C++ 11 languages;test specification","","9","59","","","","","IEEE","IEEE Conferences"
"ConflictJS: Finding and Understanding Conflicts Between JavaScript Libraries","J. Patra; P. N. Dixit; M. Pradel","NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","741","751","It is a common practice for client-side web applications to build on various third-party JavaScript libraries. Due to the lack of namespaces in JavaScript, these libraries all share the same global namespace. As a result, one library may inadvertently modify or even delete the APIs of another library, causing unexpected behavior of library clients. Given the quickly increasing number of libraries, manually keeping track of such conflicts is practically impossible both for library developers and users. This paper presents ConflictJS, an automated and scalable approach to analyze libraries for conflicts. The key idea is to tackle the huge search space of possible conflicts in two phases. At first, a dynamic analysis of individual libraries identifies pairs of potentially conflicting libraries. Then, targeted test synthesis validates potential conflicts by creating a client application that suffers from a conflict. The overall approach is free of false positives, in the sense that it reports a problem only when such a client exists. We use ConflictJS to analyze and study conflicts among 951 real-world libraries. The results show that one out of four libraries is potentially conflicting and that 166 libraries are involved in at least one certain conflict. The detected conflicts cause crashes and other kinds of unexpected behavior. Our work helps library developers to prevent conflicts, library users to avoid combining conflicting libraries, and provides evidence that designing a language without explicit namespaces has undesirable effects.","","","10.1145/3180155.3180184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453147","JavaScript libraries;testing","Libraries;Loading;Computer crashes;Cryptography;Content distribution networks;Servers","application program interfaces;Internet;Java;libraries;system monitoring","ConflictJS;JavaScript libraries;client-side web applications;global namespace;search space;dynamic analysis","","2","","","","","","IEEE","IEEE Conferences"
"Understanding Asynchronous Interactions in Full-Stack JavaScript","S. Alimadadi; A. Mesbah; K. Pattabiraman","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada; Univ. of British Columbia, Vancouver, BC, Canada","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1169","1180","JavaScript has become one of the most popular languages in practice. Developers now use JavaScript not only for the client-side but also for server-side programming, leading to ""full-stack"" applications written entirely in JavaScript. Understanding such applications is challenging for developers, due to the temporal and implicit relations of asynchronous and event-driven entities spread over the client and server side. We propose a technique for capturing a behavioural model of full-stack JavaScript applications' execution. The model is temporal and context-sensitive to accommodate asynchronous events, as well as the scheduling and execution of lifelines of callbacks. We present a visualization of the model to facilitate program understanding for developers. We implement our approach in a tool, called Sahand, and evaluate it through a controlled experiment. The results show that Sahand improves developers' performance in completing program comprehension tasks by increasing their accuracy by a factor of three.","","","10.1145/2884781.2884864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886989","Program comprehension;asynchronicity;full-stack JavaScript","Servers;Context modeling;Reactive power;Visualization;Writing;Concurrent computing","Java;object-oriented programming","asynchronous interaction;full-stack JavaScript;server-side programming;asynchronous events;program understanding;Sahand;program comprehension task","","8","48","","","","","IEEE","IEEE Conferences"
"SWIM: Synthesizing What I Mean - Code Search and Idiomatic Snippet Synthesis","M. Raghothaman; Y. Wei; Y. Hamadi","Univ. of Pennsylvania, Philadelphia, PA, USA; Microsoft Res., Cambridge, UK; Lab. d'Inf., Ecole Polytech., Palaiseau, France","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","357","367","Modern programming frameworks come with large libraries, with diverse applications such as for matching regular expressions, parsing XML files and sending email. Programmers often use search engines such as Google and Bing to learn about existing APIs. In this paper, we describe SWIM, a tool which suggests code snippets given API-related natural language queries such as ‚Äúgenerate md5 hash code‚Äù. The query does not need to contain framework-specific trivia such as the type names or methods of interest. We translate user queries into the APIs of interest using clickthrough data from the Bing search engine. Then, based on patterns learned from open-source code repositories, we synthesize idiomatic code describing the use of these APIs. We introduce structured call sequences to capture API-usage patterns. Structured call sequences are a generalized form of method call sequences, with if-branches and while-loops to represent conditional and repeated API usage patterns, and are simple to extract and amenable to synthesis. We evaluated SWIM with 30 common C# API-related queries received by Bing. For 70% of the queries, the first suggested snippet was a relevant solution, and a relevant solution was present in the top 10 results for all benchmarked queries. The online portion of the workflow is also very responsive, at an average of 1.5 seconds per snippet.","","","10.1145/2884781.2884808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886917","Free form queries;code search;idiomatic snippet synthesis;structured call sequences","Natural languages;Pattern matching;Search engines;C# languages;Data models;Libraries;Web pages","application program interfaces;query processing;search engines","SWIM framework;synthesizing what i mean;code search;idiomatic snippet synthesis;programming framework;search engines;Google;Bing;API-related natural language queries;application program interface;method call sequences;API usage patterns","","18","28","","","","","IEEE","IEEE Conferences"
"From Word Embeddings to Document Similarities for Improved Information Retrieval in Software Engineering","X. Ye; H. Shen; X. Ma; R. Bunescu; C. Liu","Sch. of Electr. Eng. & Comput. Sci., Ohio Univ. Athens, Athens, OH, USA; Sch. of Electr. Eng. & Comput. Sci., Ohio Univ. Athens, Athens, OH, USA; Sch. of Electr. Eng. & Comput. Sci., Ohio Univ. Athens, Athens, OH, USA; Sch. of Electr. Eng. & Comput. Sci., Ohio Univ. Athens, Athens, OH, USA; Sch. of Electr. Eng. & Comput. Sci., Ohio Univ. Athens, Athens, OH, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","404","415","The application of information retrieval techniques to search tasks in software engineering is made difficult by the lexical gap between search queries, usually expressed in natural language (e.g. English), and retrieved documents, usually expressed in code (e.g. programming languages). This is often the case in bug and feature location, community question answering, or more generally the communication between technical personnel and non-technical stake holders in a software project. In this paper, we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space. In the proposed architecture, word embeddings are rst trained on API documents, tutorials, and reference documents, and then aggregated in order to estimate semantic similarities between documents. Empirical evaluations show that the learned vector space embeddings lead to improvements in a previously explored bug localization task and a newly de ned task of linking API documents to computer programming questions.","","","10.1145/2884781.2884862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886921","word embeddings;skip-gram model;bug localization;bug reports;API documents","Computer bugs;Natural languages;Context;Semantics;Mathematical model;Software;Vocabulary","application program interfaces;document handling;information retrieval;natural language processing;software engineering;system documentation","word embeddings;document similarities;information retrieval techniques;software engineering;natural language statements;code snippets;API documents;tutorials;reference documents;vector space embeddings;bug localization task","","40","47","","","","","IEEE","IEEE Conferences"
"The Road to Live Programming: Insights from the Practice","J. Kubelka; R. Robbes; A. Bergel","NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1090","1101","Live Programming environments allow programmers to get feedback instantly while changing software. Liveness is gaining attention among industrial and open-source communities; several IDEs offer high degrees of liveness. While several studies looked at how programmers work during software evolution tasks, none of them consider live environments. We conduct such a study based on an analysis of 17 programming sessions of practitioners using Pharo, a mature Live Programming environment. The study is complemented by a survey and subsequent analysis of 16 programming sessions in additional languages, e.g., JavaScript. We document the approaches taken by developers during their work. We find that some liveness features are extensively used, and have an impact on the way developers navigate source code and objects in their work.","","","10.1145/3180155.3180200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453190","Live Programming;Software Evolution;Exploratory Study","Programming;Tools;Task analysis;Software;Programming environments;Navigation;Visualization","Java;programming environments;public domain software;software engineering;software maintenance","open-source communities;software evolution tasks;live environments;mature Live Programming environment;subsequent analysis;liveness features;programming sessions;developer navigate source code","","2","","","","","","IEEE","IEEE Conferences"
"Repairing Crashes in Android Apps","S. H. Tan; Z. Dong; X. Gao; A. Roychoudhury","Southern Univ. of Sci. & Technol., Shenzhen, China; Nat. Univ. of Singapore, Singapore, Singapore; Nat. Univ. of Singapore, Singapore, Singapore; Nat. Univ. of Singapore, Singapore, Singapore","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","187","198","Android apps are omnipresent, and frequently suffer from crashes - leading to poor user experience and economic loss. Past work focused on automated test generation to detect crashes in Android apps. However, automated repair of crashes has not been studied. In this paper, we propose the first approach to automatically repair Android apps, specifically we propose a technique for fixing crashes in Android apps. Unlike most test-based repair approaches, we do not need a test-suite; instead a single failing test is meticulously analyzed for crash locations and reasons behind these crashes. Our approach hinges on a careful empirical study which seeks to establish common root-causes for crashes in Android apps, and then distills the remedy of these root-causes in the form of eight generic transformation operators. These operators are applied using a search-based repair framework embodied in our repair tool Droix. We also prepare a benchmark DroixBench capturing reproducible crashes in Android apps. Our evaluation of Droix on DroixBench reveals that the automatically produced patches are often syntactically identical to the human patch, and on some rare occasion even better than the human patch (in terms of avoiding regressions). These results confirm our intuition that our proposed transformations form a sufficient set of operators to patch crashes in Android.","","","10.1145/3180155.3180243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453078","Automated repair;Android apps;Crash;SBSE","Computer crashes;Androids;Humanoid robots;Maintenance engineering;Mobile applications;Transistors;Testing","Android (operating system);program testing","Android apps;test-based repair approaches;benchmark DroixBench capturing reproducible crashes","","6","","","","","","IEEE","IEEE Conferences"
"Towards Refactoring-Aware Regression Test Selection","K. Wang; C. Zhu; A. Celik; J. Kim; D. Batory; M. Gligoric","NA; NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","233","244","Regression testing checks that recent project changes do not break previously working functionality. Although important, regression testing is costly when changes are frequent. Regression test selection (RTS) optimizes regression testing by running only tests whose results might be affected by a change. Traditionally, RTS collects dependencies (e.g., on files) for each test and skips the tests, at a new project revision, whose dependencies did not change. Existing RTS techniques do not differentiate behavior-preserving transformations (i.e., refactorings) from other code changes. As a result, tests are run more frequently than necessary. We present the first step towards a refactoring-aware RTS technique, dubbed Reks, which skips tests affected only by behavior-preserving changes. Reks defines rules to update the test dependencies without running the tests. To ensure that Reks does not hide any bug introduced by the refactoring engines, we integrate Reks only in the pre-submit testing phase, which happens on the developers' machines. We evaluate Reks by measuring the savings in the testing effort. Specifically, we reproduce 100 refactoring tasks performed by developers of 37 projects on GitHub. Our results show that Reks would not run, on average, 33% of available tests (that would be run by a refactoring-unaware RTS technique). Additionally, we systematically run 27 refactoring types on ten projects. The results, based on 74,160 refactoring tasks, show that Reks would not run, on average, 16% of tests (max: 97% and SD: 24%). Finally, our results show that the Reks update rules are efficient.","","","10.1145/3180155.3180254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453082","Regression test selection;Behavior-preserving changes;Reks","Testing;Computer bugs;Task analysis;Engines;Software;Google;Tools","program testing;regression analysis;software maintenance","Reks update rules;refactoring-aware regression test selection;regression testing checks;recent project changes;RTS techniques;code changes;refactoring-aware RTS technique;dubbed Reks;behavior-preserving changes;test dependencies;refactoring engines;testing effort;refactoring-unaware RTS technique;refactoring tasks","","5","80","","","","","IEEE","IEEE Conferences"
"BigDebug: Debugging Primitives for Interactive Big Data Processing in Spark","M. A. Gulzar; M. Interlandi; S. Yoo; S. D. Tetali; T. Condie; T. Millstein; M. Kim","Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA; Univ. of California, Los Angeles, Los Angeles, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","784","795","Developers use cloud computing platforms to process a large quantity of data in parallel when developing big data analytics. Debugging the massive parallel computations that run in today's data-centers is time consuming and error-prone. To address this challenge, we design a set of interactive, real-time debugging primitives for big data processing in Apache Spark, the next generation data-intensive scalable cloud computing platform. This requires re-thinking the notion of step-through debugging in a traditional debugger such as gdb, because pausing the entire computation across distributed worker nodes causes significant delay and naively inspecting millions of records using a watchpoint is too time consuming for an end user.First, BigDebug's simulated breakpoints and on-demand watchpoints allow users to selectively examine distributed, intermediate data on the cloud with little overhead. Second, a user can also pinpoint a crash-inducing record and selectively resume relevant sub-computations after a quick fix. Third, a user can determine the root causes of errors (or delays) at the level of individual records through a fine-grained data provenance capability. Our evaluation shows that BigDebug scales to terabytes and its record-level tracing incurs less than 25% overhead on average. It determines crash culprits orders of magnitude more accurately and provides up to 100% time saving compared to the baseline replay debugger. The results show that BigDebug supports debugging at interactive speeds with minimal performance impact.","","","10.1145/2884781.2884813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886956","Debugging;big data analytics;interactive tools;data-intensive scalable computing (DISC);fault localization and recovery","Sparks;Debugging;Big Data;Cloud computing;Distributed databases;Computer crashes;Delays","Big Data;computer centres;interactive systems;program debugging","BigDebug;debugging primitives;interactive big data processing;cloud computing platforms;big data analytics;data-centers;Apache Spark;distributed worker nodes;intermediate data;distributed data;crash-inducing record;fine-grained data provenance capability;record-level tracing","","4","40","","","","","IEEE","IEEE Conferences"
"Are ""Non-functional"" Requirements really Non-functional? An Investigation of Non-functional Requirements in Practice","J. Eckhardt; A. Vogelsang; D. M. Fern√°ndez","Tech. Univ. Munchen, Munich, Germany; Tech. Univ. Munchen, Munich, Germany; Tech. Univ. Munchen, Munich, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","832","842","Non-functional requirements (NFRs) are commonly distinguished from functional requirements by differentiating how the system shall do something in contrast to what the system shall do. This distinction is not only prevalent in research, but also influences how requirements are handled in practice. NFRs are usually documented separately from functional requirements, without quantitative measures, and with relatively vague descriptions.As a result, they remain difficult to analyze and test.Several authors argue, however, that many so-called NFRs actually describe behavioral properties and may be treated the same way as functional requirements. In this paper, we empirically investigate this point of view and aim to increase our understanding on the nature of NFRs addressing system properties. We report on the classification of 530 NFRs extracted from 11 industrial requirements specifications and analyze to which extent these NFRs describe system behavior.Our results suggest that most ""non-functional"" requirements are not non-functional as they describe behavior of a system. Consequently, we argue that many so-called NFRs can be handled similarly to functional requirements.","","","10.1145/2884781.2884788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886960","Non-functional requirements;classification;model-based development;empirical studies","Software;Unified modeling language;Software engineering;Interviews;Documentation;Security","software engineering","nonfunctional requirements;NFR;quantitative measures","","8","31","","","","","IEEE","IEEE Conferences"
"Automatic Model Generation from Documentation for Java API Functions","J. Zhai; J. Huang; S. Ma; X. Zhang; L. Tan; J. Zhao; F. Qin","NA; NA; NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","380","391","Modern software systems are becoming increasingly complex, relying on a lot of third-party library support. Library behaviors are hence an integral part of software behaviors. Analyzing them is as important as analyzing the software itself. However, analyzing libraries is highly challenging due to the lack of source code, implementation in different languages, and complex optimizations. We observe that many Java library functions provide excellent documentation, which concisely describes the functionalities of the functions. We develop a novel technique that can construct models for Java API functions by analyzing the documentation. These models are simpler implementations in Java compared to the original ones and hence easier to analyze. More importantly, they provide the same functionalities as the original functions. Our technique successfully models 326 functions from 14 widely used Java classes. We also use these models in static taint analysis on Android apps and dynamic slicing for Java programs, demonstrating the effectiveness and efficiency of our models.","","","10.1145/2884781.2884881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886919","documentation analysis;environment modeling;natural language processing;auto-testing","Libraries;Java;Indexes;Analytical models;Documentation;Software;Generators","application program interfaces;Java;program slicing","automatic model generation;Java API functions;application program interfaces;library behavior;Java library functions;documentation analysis;Java classes;static taint analysis;Android applications;dynamic slicing;Java programs","","9","37","","","","","IEEE","IEEE Conferences"
"On the ""Naturalness"" of Buggy Code","B. Ray; V. Hellendoorn; S. Godhane; Z. Tu; A. Bacchelli; P. Devanbu","NA; NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","428","439","Real software, the kind working programmers produce by the kLOC to solve real-world problems, tends to be ‚Äúnatural‚Äù, like speech or natural language; it tends to be highly repetitive and predictable. Researchers have captured this naturalness of software through statistical models and used them to good effect in suggestion engines, porting tools, coding standards checkers, and idiom miners. This suggests that code that appears improbable, or surprising, to a good statistical language model is ‚Äúunnatural‚Äù in some sense, and thus possibly suspicious. In this paper, we investigate this hypothesis. We consider a large corpus of bug fix commits (ca. 7,139), from 10 different Java projects, and focus on its language statistics, evaluating the naturalness of buggy code and the corresponding fixes. We find that code with bugs tends to be more entropic (i.e. unnatural), becoming less so as bugs are fixed. Ordering files for inspection by their average entropy yields cost-effectiveness scores comparable to popular defect prediction methods. At a finer granularity, focusing on highly entropic lines is similar in cost-effectiveness to some well-known static bug finders (PMD, FindBugs) and or- dering warnings from these bug finders using an entropy measure improves the cost-effectiveness of inspecting code implicated in warnings. This suggests that entropy may be a valid, simple way to complement the effectiveness of PMD or FindBugs, and that search-based bug-fixing methods may benefit from using entropy both for fault-localization and searching for fixes.","","","10.1145/2884781.2884848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886923","","Computer bugs;Biological system modeling;Entropy;Predictive models;Inspection;Software;Standards","program debugging","buggy code naturalness;software naturalness;statistical language model;bug fix commits;Java projects;language statistics;cost-effectiveness score;bug finders;entropy measure;PMD;FindBugs","","29","57","","","","","IEEE","IEEE Conferences"
"CCAligner: A Token Based Large-Gap Clone Detector","P. Wang; J. Svajlenko; Y. Wu; Y. Xu; C. K. Roy","Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada; Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Hefei, China; Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1066","1077","Copying code and then pasting with large number of edits is a common activity in software development, and the pasted code is a kind of complicated Type-3 clone. Due to large number of edits, we consider the clone as a large-gap clone. Large-gap clone can reflect the extension of code, such as change and improvement. The existing state-of-the-art clone detectors suffer from several limitations in detecting large-gap clones. In this paper, we propose a tool, CCAligner, using code window that considers e edit distance for matching to detect large-gap clones. In our approach, a novel e-mismatch index is designed and the asymmetric similarity coefficient is used for similarity measure. We thoroughly evaluate CCAligner both for large-gap clone detection, and for general Type-1, Type-2 and Type-3 clone detection. The results show that CCAligner performs better than other competing tools in large-gap clone detection, and has the best execution time for 10MLOC input with good precision and recall in general Type-1 to Type-3 clone detection. Compared with existing state-of-the-art tools, CCAligner is the best performing large-gap clone detection tool, and remains competitive with the best clone detectors in general Type-1, Type-2 and Type-3 clone detection.","","","10.1145/3180155.3180179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453188","Clone Detection;Large-gap Clone;Evaluation","Cloning;Tools;Detectors;Software;Computer science;Software engineering;Indexes","public domain software;software maintenance;software reusability","pasted code;CCAligner;Type-3 clone detection;performing large-gap clone detection tool;large-gap clone detector","","7","57","","","","","IEEE","IEEE Conferences"
"PRADA: Prioritizing Android Devices for Apps by Mining Large-Scale Usage Data","X. Lu; X. Liu; H. Li; T. Xie; Q. Mei; D. Hao; G. Huang; F. Feng","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA; Univ. of Michigan, Ann Arbor, MI, USA; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Wandoujia Lab., Beijing, China","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","3","13","Selecting and prioritizing major device models are critical for mobile app developers to select testbeds and optimize resources such as marketing and quality-assurance resources. The heavily fragmented distribution of Android devices makes it challenging to select a few major device models out of thousands of models available on the market. Currently app developers usually rely on some reported or estimated general market share of device models. However, these estimates can be quite inaccurate, and more problematically, can be irrelevant to the particular app under consideration. To address this issue, we propose PRADA, the first approach to prioritizing Android device models for individual apps, based on mining large-scale usage data. PRADA adapts the concept of operational profiling (popularly used in software reliability engineering) for mobile apps - the usage of an app on a specific device model reflects the importance of that device model for the app. PRADA includes a collaborative filtering technique to predict the usage of an app on different device models, even if the app is entirely new (without its actual usage in the market yet), based on the usage data of a large collection of apps. We empirically demonstrate the effectiveness of PRADA over two popular app categories, i.e., Game and Media, covering over 3.86 million users and 14,000 device models collected through a leading Android management app in China.","","","10.1145/2884781.2884828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886887","Mobile apps;Android fragmentation;prioritization;usage data","Androids;Humanoid robots;Data models;Games;Testing;Data mining;Mobile communication","collaborative filtering;data mining;smart phones","PRADA;prioritizing android devices for apps;large-scale usage data mining;operational profiling;mobile apps;collaborative filtering technique;Android management app","","10","41","","","","","IEEE","IEEE Conferences"
"Programming Not Only by Example","H. Peleg; S. Shoham; E. Yahav","NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1114","1124","Recent years have seen great progress in automated synthesis techniques that can automatically generate code based on some intent expressed by the programmer, but communicating this intent remains a major challenge. When the expressed intent is coarse-grained (for example, restriction on the expected type of an expression), the synthesizer often produces a long list of results for the programmer to choose from, shifting the heavy-lifting to the user. An alternative approach, successfully used in end-user synthesis, is programming by example (PBE), where the user leverages examples to interactively and iteratively refine the intent. However, using only examples is not expressive enough for programmers, who can observe the generated program and refine the intent by directly relating to parts of the generated program. We present a novel approach to interacting with a synthesizer using a granular interaction model. Our approach employs a rich interaction model where (i) the synthesizer decorates a candidate program with debug information that assists in understanding the program and identifying good or bad parts, and (ii) the user is allowed to provide feedback not only on the expected output of a program but also on the program itself. After identifying a program as (partially) correct or incorrect, the user can also explicitly indicate the good or bad parts, to allow the synthesizer to accept or discard parts of the program instead of discarding the program as a whole. We show the value of our approach in a controlled user study. Our study shows that participants have a strong preference for granular feedback instead of examples and can provide granular feedback much faster.","","","10.1145/3180155.3180189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453192","program synthesis;programming by example","Synthesizers;Task analysis;Programming;Object oriented modeling;Tools;Agriculture;Vocabulary","automatic programming;program compilers;program debugging","granular feedback;automated synthesis techniques;end-user synthesis;granular interaction model;programming by example;debug information","","","41","","","","","IEEE","IEEE Conferences"
"How Modern News Aggregators Help Development Communities Shape and Share Knowledge","M. Aniche; C. Treude; I. Steinmacher; I. Wiese; G. Pinto; M. Storey; M. A. Gerosa","NA; NA; NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","499","510","Many developers rely on modern news aggregator sites such as reddit and hn to stay up to date with the latest technological developments and trends. In order to understand what motivates developers to contribute, what kind of content is shared, and how knowledge is shaped by the community, we interviewed and surveyed developers that participate on the reddit programming subreddit and we analyzed a sample of posts on both reddit and hn. We learned what kind of content is shared in these websites and developer motivations for posting, sharing, discussing, evaluating, and aggregating knowledge on these aggregators, while revealing challenges developers face in terms of how content and participant behavior is moderated. Our insights aim to improve the practices developers follow when using news aggregators, as well as guide tool makers on how to improve their tools. Our findings are also relevant to researchers that study developer communities of practice.","","","10.1145/3180155.3180180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453116","News aggregators;development communities;knowledge sharing;social computing","Computer hacking;Interviews;Software;Programming;Communication channels;Europe;Shape","social networking (online)","modern news aggregator sites;reddit programming subreddit;developer motivations;development communities;Websites;participant behavior","","3","","","","","","IEEE","IEEE Conferences"
"Generating Performance Distributions via Probabilistic Symbolic Execution","B. Chen; Y. Liu; W. Le","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Dept. of Comput. Sci., Iowa State Univ., Ames, IA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","49","60","Analyzing performance and understanding the potential best-case, worst-case and distribution of program execution times are very important software engineering tasks. There have been model-based and program analysis-based approaches for performance analysis. Model-based approaches rely on analytical or design models derived from mathematical theories or software architecture abstraction, which are typically coarse-grained and could be imprecise. Program analysis-based approaches collect program profiles to identify performance bottlenecks, which often fail to capture the overall program performance. In this paper, we propose a performance analysis framework PerfPlotter. It takes the program source code and usage profile as inputs and generates a performance distribution that captures the input probability distribution over execution times for the program. It heuristically explores high-probability and low-probability paths through probabilistic symbolic execution. Once a path is explored, it generates and runs a set of test inputs to model the performance of the path. Finally, it constructs the performance distribution for the program. We have implemented PerfPlotter based on the Symbolic PathFinder infrastructure, and experimentally demonstrated that PerfPlotter could accurately capture the best-case, worst-case and distribution of program execution times. We also show that performance distributions can be applied to various important tasks such as performance understanding, bug validation, and algorithm selection.","","","10.1145/2884781.2884794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886891","Performance Analysis;Symbolic Execution","Analytical models;Mathematical model;Probabilistic logic;Performance analysis;Computational modeling;Software engineering;Algorithm design and analysis","program diagnostics;software architecture","performance distribution generation;probabilistic symbolic execution;software engineering;program analysis-based approach;software architecture abstraction;model-based analysis approach;PerfPlotter framework;probability distribution;Symbolic PathFinder infrastructure;performance understanding;bug validation;algorithm selection","","7","61","","","","","IEEE","IEEE Conferences"
"Almost There: A Study on Quasi-Contributors in Open-Source Software Projects","I. Steinmacher; G. Pinto; I. S. Wiese; M. A. Gerosa","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","256","266","Recent studies suggest that well-known OSS projects struggle to find the needed workforce to continue evolving-in part because external developers fail to overcome their first contribution barriers. In this paper, we investigate how and why quasi-contributors (external developers who did not succeed in getting their contributions accepted to an OSS project) fail. To achieve our goal, we collected data from 21 popular, non-trivial GitHub projects, identified quasi-contributors, and analyzed their pull-requests. In addition, we conducted surveys with quasi-contributors, and projects' integrators, to understand their perceptions about nonacceptance.We found 10,099 quasi-contributors - about 70% of the total actual contributors - that submitted 12,367 non-accepted pull-requests. In five projects, we found more quasi-contributors than actual contributors. About one-third of the developers who took our survey disagreed with the nonacceptance, and around 30% declared the nonacceptance demotivated or prevented them from placing another pull-request. The main reasons for pull-request nonacceptance from the quasi-contributors' perspective were ""superseded/duplicated pull-request"" and ""mismatch between developer's and team's vision/opinion."" A manual analysis of a representative sample of 263 pull-requests corroborated with this finding. We also found reasons related to the relationship with the community and lack of experience or commitment from the quasi-contributors. This empirical study is particularly relevant to those interested in fostering developers' participation and retention in OSS communities.","","","10.1145/3180155.3180208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453084","pull-requests;quasi contributors;newcomers;open source software","Open source software;Computer languages;Software engineering;Face;Analytical models;Encoding","project management;public domain software;software management","OSS project;open-source software projects;manual analysis;quasicontributors;GitHub projects","","8","","","","","","IEEE","IEEE Conferences"
"Revisit of Automatic Debugging via Human Focus-Tracking Analysis","X. Xie; Z. Liu; S. Song; Z. Chen; J. Xuan; B. Xu","NA; NA; NA; NA; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","808","819","In many fields of software engineering, studies on human behavior have attracted a lot of attention; however, few such studies exist in automated debugging. Parnin and Orso conducted a pioneering study comparing the performance of programmers in debugging with and without a ranking-based fault localization technique, namely Spectrum-Based Fault Localization (SBFL). In this paper, we revisit the actual helpfulness of SBFL, by addressing some major problems that were not resolved in Parnin and Orso's study. Our investigation involved 207 participants and 17 debugging tasks. A user-friendly SBFL tool was adopted. It was found that SBFL tended not to be helpful in improving the efficiency of debugging. By tracking and analyzing programmers' focus of attention, we characterized their source code navigation patterns and provided in-depth explanations to the observations. Results indicated that (1) a short ‚Äúfirst scan‚Äù on the source code tended to result in inefficient debugging; and (2) inspections on the pinpointed statements during the ‚Äúfollow-up browsing‚Äù were normally just quick skimming. Moreover, we found that the SBFL assistbrowsing‚Äù were normally just quick skimming. Moreover, we found that the SBFL assistanceance may even slightly weaken programmers' abilities in fault detection. Our observations imply interference between the mechanism of automated fault localization and the actual assistance needed by programmers in debugging. To resolve this interference, we provide several insights and suggestions.","","","10.1145/2884781.2884834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886958","Automated debugging;spectrum-based fault localization;user studies;attention tracking;navigation pattern;fault comprehension","Debugging;Software;Software engineering;Navigation;Computer bugs;Interference;Fault detection","program debugging;program diagnostics","automatic debugging;human focus-tracking analysis;software engineering;human behavior;ranking-based fault localization technique;spectrum-based fault localization;debugging efficiency;follow-up browsing;SBFL assist browsing","","12","40","","","","","IEEE","IEEE Conferences"
"Risk-Driven Revision of Requirements Models","D. Alrajeh; A. van Lamsweerde; J. Kramer; A. Russo; S. Uchitel","Dept. of Comput., Imperial Coll. London, London, UK; ICTEAM, Univ. Catholique de Louvain, Louvain, Belgium; Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","855","865","Requirements incompleteness is often the result of unanticipated adverse conditions which prevent the software and its environment from behaving as expected. These conditions represent risks that can cause severe software failures. The identification and resolution of such risks is therefore a crucial step towards requirements completeness. Obstacle analysis is a goal-driven form of risk analysis that aims at detecting missing conditions that can obstruct goals from being satisfied in a given domain, and resolving them. This paper proposes an approach for automatically revising goals that may be under-specified or (partially) wrong to resolve obstructions in a given domain. The approach deploys a learning-based revision methodology in which obstructed goals in a goal model are iteratively revised from traces exemplifying obstruction and non-obstruction occurrences. Our revision methodology computes domain-consistent, obstruction-free revisions that are automatically propagated to other goals in the model in order to preserve the correctness of goal models whilst guaranteeing minimal change to the original model. We present the formal foundations of our learning-based approach, and show that it preserves the properties of our formal framework. We validate it against the benchmarking case study of the London Ambulance Service.","","","10.1145/2884781.2884838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886962","","Computational modeling;Software;Analytical models;Automobiles;Requirements engineering;Government;Risk analysis","formal specification;iterative methods;learning (artificial intelligence)","risk-driven revision;requirements models;obstacle analysis;learning-based revision methodology;learning-based approach;London Ambulance Service;iterative method","","2","37","","","","","IEEE","IEEE Conferences"
"Using (Bio)Metrics to Predict Code Quality Online","S. C. M√ºller; T. Fritz","Dept. of Inf., Univ. of Zurich, Zurich, Switzerland; Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","452","463","Finding and fixing code quality concerns, such as defects or poor understandability of code, decreases software development and evolution costs. A common industrial practice to identify code quality concerns early on are code reviews. While code reviews help to identify problems early on, they also impose costs on development and only take place after a code change is already completed. The goal of our research is to automatically identify code quality concerns while a developer is making a change to the code. By using biometrics, such as heart rate variability, we aim to determine the difficulty a developer experiences working on a part of the code as well as identify and help to fix code quality concerns before they are even committed to the repository. In a field study with ten professional developers over a two-week period we investigated the use of biometrics to determine code quality concerns. Our results show that biometrics are indeed able to predict quality concerns of parts of the code while a developer is working on, improving upon a naive classifier by more than 26% and outperforming classifiers based on more traditional metrics. In a second study with five professional developers from a different country and company, we found evidence that some of our findings from our initial study can be replicated. Overall, the results from the presented studies suggest that biometrics have the potential to predict code quality concerns online and thus lower development and evolution costs.","","","10.1145/2884781.2884803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886925","","Biometrics (access control);Software;Heart rate variability;Companies;Manuals;Temperature measurement","software quality","code quality prediction;code understandability;software development costs;software evolution costs;code reviews;biometrics;heart rate variability","","10","77","","","","","IEEE","IEEE Conferences"
"Toward a Framework for Detecting Privacy Policy Violations in Android Application Code","R. Slavin; X. Wang; M. B. Hosseini; J. Hester; R. Krishnan; J. Bhatia; T. D. Breaux; J. Niu","Univ. of Texas at San Antonio, San Antonio, TX, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA; Univ. of Texas at Dallas, Dallas, TX, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Carnegie Mellon Univ., Pittsburgh, PA, USA; Univ. of Texas at San Antonio, San Antonio, TX, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","25","36","Mobile applications frequently access sensitive personal information to meet user or business requirements. Because such information is sensitive in general, regulators increasingly require mobile-app developers to publish privacy policies that describe what information is collected. Furthermore, regulators have fined companies when these policies are inconsistent with the actual data practices of mobile apps. To help mobile-app developers check their privacy policies against their apps' code for consistency, we propose a semi-automated framework that consists of a policy terminology- API method map that links policy phrases to API methods that produce sensitive information, and information flow analysis to detect misalignments. We present an implementation of our framework based on a privacy-policy-phrase ontology and a collection of map- pings from API methods to policy phrases. Our empirical evaluation on 477 top Android apps discovered 341 potential privacy policy violations.","","","10.1145/2884781.2884855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886889","Privacy Policies;Android Applications;Violation Detection","Privacy;Androids;Humanoid robots;Mobile communication;Ontologies;Natural languages;Google","Android (operating system);application program interfaces;data privacy;mobile computing","privacy policy violation detection;Android application code;mobile applications;semiautomated framework;API method map;information flow analysis;privacy-policy-phrase ontology;map-ping collection","","13","42","","","","","IEEE","IEEE Conferences"
"""Was My Contribution Fairly Reviewed?"" A Framework to Study the Perception of Fairness in Modern Code Reviews","D. M. German; G. Robles; G. Poo-Caama√±o; X. Yang; H. Iida; K. Inoue","Univ. of Victoria, Victoria, BC, Canada; Univ. Rey Juan Carlos, Mostoles, Spain; Univ. of Victoria, Victoria, BC, Canada; Osaka Univ., Suita, Japan; Nara Inst. of Technol., Nara, Japan; Osaka Univ., Suita, Japan","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","523","534","Modern code reviews improve the quality of software products. Although modern code reviews rely heavily on human interactions, little is known regarding whether they are performed fairly. Fairness plays a role in any process where decisions that affect others are made. When a system is perceived to be unfair, it affects negatively the productivity and motivation of its participants. In this paper, using fairness theory we create a framework that describes how fairness affects modern code reviews. To demonstrate its applicability, and the importance of fairness in code reviews, we conducted an em-pirical study that asked developers of a large industrial open source ecosystem (OpenStack) what their perceptions are regarding fairness in their code reviewing process. Our study shows that, in general, the code review process in OpenStack is perceived as fair; however, a significant portion of respondents perceive it as unfair. We also show that the variability in the way they prioritize code reviews signals a lack of consistency and the existence of bias (potentially increasing the perception of unfairness). The contributions of this paper are: (1) we propose a framework-based on fairness theory-for studying and managing social behaviour in modern code reviews, (2) we provide support for the framework through the results of a case study on a large industrial-backed open source project, (3) we present evidence that fairness is an issue in the code review process of a large open source ecosystem, and, (4) we present a set of guidelines for practitioners to address unfairness in modern code reviews.","","","10.1145/3180155.3180217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453118","Fairness;Software Development;Code Reviews;Open source software;human and social aspects;transparency","Process control;Organizations;Software reviews;Standards organizations;Guidelines;Ecosystems","organisational aspects;public domain software;software quality","modern code reviews;code review process;code review signals;software product quality;industrial open source ecosystem;OpenStack","","3","79","","","","","IEEE","IEEE Conferences"
"Reliability of Run-Time Quality-of-Service Evaluation Using Parametric Model Checking","G. Su; D. S. Rosenblum; G. Tamburrelli","Nat. Univ. of Singapore, Singapore, Singapore; Nat. Univ. of Singapore, Singapore, Singapore; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","73","84","Run-time Quality-of-Service (QoS) assurance is crucial for business-critical systems. Complex behavioral performance metrics (PMs) are useful but often difficult to monitor or measure. Probabilistic model checking, especially parametric model checking, can support the computation of aggre- gate functions for a broad range of those PMs. In practice, those PMs may be defined with parameters determined by run-time data. In this paper, we address the reliability of QoS evaluation using parametric model checking. Due to the imprecision with the instantiation of parameters, an evaluation outcome may mislead the judgment about requirement violations. Based on a general assumption of run-time data distribution, we present a novel framework that contains light-weight statistical inference methods to analyze the re- liability of a parametric model checking output with respect to an intuitive criterion. We also present case studies in which we test the stability and accuracy of our inference methods and describe an application of our framework to a cloud server management problem.","","","10.1145/2884781.2884814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886893","Data distribution;probabilistic model checking;Quality-of-Service;reliability;run-time evaluation","Quality of service;Reliability;Parametric statistics;Probabilistic logic;Model checking;Unified modeling language;Random variables","business data processing;cloud computing;formal verification;probability;quality of service","run-time quality-of-service evaluation reliability;parametric model checking;run-time quality-of-service assurance;business-critical systems;complex behavioral performance metrics;probabilistic model checking;QoS evaluation reliability;requirement violations;run-time data distribution;lightweight statistical inference method;cloud server management","","5","31","","","","","IEEE","IEEE Conferences"
"To Distribute or Not to Distribute? Why Licensing Bugs Matter","C. Vendome; D. German; M. Di Penta; G. Bavota; M. Linares-V√°squez; D. Poshyvanyk","Coll. of William & Mary Williamsburg, Williamsburg, VA, USA; Univ. of Victoria, Victoria, BC, Canada; Univ. of Sannio, Benevento, Italy; Univ. della Svizzera italiana (USI), Lugano, Switzerland; Univ. de los Andes, Bogota, Colombia; Coll. of William & Mary Williamsburg, Williamsburg, VA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","268","279","Software licenses dictate how source code or binaries can be modified, reused, and redistributed. In the case of open source projects, software licenses generally fit into two main categories, permissive and restrictive, depending on the degree to which they allow redistribution or modification under licenses different from the original one(s). Developers and organizations can also modify existing licenses, creating custom licenses with specific permissive/restrictive terms. Having such a variety of software licenses can create confusion among software developers, and can easily result in the introduction of licensing bugs, not necessarily limited to well-known license incompatibilities. In this work, we report a study aimed at characterizing licensing bugs by (i) building a catalog categorizing the types of licensing bugs developers and other stakeholders face, and (ii) understanding the implications licensing bugs have on the software projects they affect. The presented study is the result of the manual analysis of 1,200 discussions related to licensing bugs carried out in issue trackers and in five legal mailing lists of open source communities. Our findings uncover new types of licensing bugs not addressed in prior literature, and a detailed assessment of their implications.","","","10.1145/3180155.3180221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453086","Software Licenses;Empirical Studies;Open Source Practices","Licenses;Computer bugs;Software;Law;Guidelines;Stakeholders","program debugging;project management;public domain software;software engineering","software projects;software licenses;custom licenses;software developers;license incompatibilities;licensing bug developers","","1","","","","","","IEEE","IEEE Conferences"
"Behavioral Log Analysis with Statistical Guarantees","N. Busany; S. Maoz","Sch. of Comput. Sci., Tel Aviv Univ., Tel Aviv, Israel; Sch. of Comput. Sci., Tel Aviv Univ., Tel Aviv, Israel","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","877","887","Scalability is a major challenge for existing behavioral log analysis algorithms, which extract finite-state automaton models or temporal properties from logs generated by running systems. In this paper we present statistical log analysis, which addresses scalability using statistical tools. The key to our approach is to consider behavioral log analysis as a statistical experiment.Rather than analyzing the entire log, we suggest to analyze only a sample of traces from the log and, most importantly, provide means to compute statistical guarantees for the correctness of the analysis result.We present the theoretical foundations of our approach and describe two example applications, to the classic k-Tails algorithm and to the recently presented BEAR algorithm.Finally, based on experiments with logs generated from real-world models and with real-world logs provided to us by our industrial partners, we present extensive evidence for the need for scalable log analysis and for the effectiveness of statistical log analysis.","","","10.1145/2884781.2884805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886964","Log analysis;specification mining;statistical guarantees","Algorithm design and analysis;Scalability;Analytical models;Computational modeling;Context;Software algorithms;Software","program diagnostics;statistical analysis","BEAR algorithm;k-tails algorithm;statistical log analysis;statistical guarantees;behavioral log analysis algorithm","","6","36","","","","","IEEE","IEEE Conferences"
"Traceability in the Wild: Automatically Augmenting Incomplete Trace Links","M. Rath; J. Rendall; J. L. C. Guo; J. Cleland-Huang; P. M√§der","Tech. Univ. Ilmenau, Ilmenau, Germany; Univ. of Notre Dame, Bend, OR, USA; McGill Univ., Montreal, QC, Canada; Univ. of Notre Dame, Bend, OR, USA; Tech. Univ. Ilmenau, Ilmenau, Germany","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","834","845","Software and systems traceability is widely accepted as an essential element for supporting many software development tasks. Today's version control systems provide inbuilt features that allow developers to tag each commit with one or more issue ID, thereby providing the building blocks from which project-wide traceability can be established between feature requests, bug fixes, commits, source code, and specific developers. However, our analysis of six open source projects showed that on average only 60% of the commits were linked to specific issues. Without these fundamental links the entire set of project-wide links will be incomplete, and therefore not trustworthy. In this paper we address the fundamental problem of missing links between commits and issues. Our approach leverages a combination of process and text-related features characterizing issues and code changes to train a classifier to identify missing issue tags in commit messages, thereby generating the missing links. We conducted a series of experiments to evaluate our approach against six open source projects and showed that it was able to effectively recommend links for tagging issues at an average of 96% recall and 33% precision. In a related task for augmenting a set of existing trace links, the classifier returned precision at levels greater than 89% in all projects and recall of 50%.","","","10.1145/3180155.3180207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453157","Traceability;Link Recovery;Machine Learning;Open Source","Computer bugs;Software;Control systems;Task analysis;Software engineering;Jacobian matrices;Tagging","program debugging;public domain software;software maintenance","open source projects;systems traceability;software development tasks;project-wide traceability;source code;project-wide links;text-related features;code changes;missing issue tags identification","","5","63","","","","","IEEE","IEEE Conferences"
"Symbolic Verification of Regular Properties","H. Yu; Z. Chen; J. Wang; Z. Su; W. Dong","Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China; Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","871","881","Verifying the regular properties of programs has been a significant challenge. This paper tackles this challenge by presenting symbolic regular verification (SRV) that offers significant speedups over the state-of-the-art. SRV is based on dynamic symbolic execution (DSE) and enabled by novel techniques for mitigating path explosion: (1) a regular property-oriented path slicing algorithm, and (2) a synergistic combination of property-oriented path slicing and guiding. Slicing prunes redundant paths, while guiding boosts the search for counterexamples. We have implemented SRV for Java and evaluated it on 15 real-world open-source Java programs (totaling 259K lines of code). Our evaluation results demonstrate the effectiveness and efficiency of SRV. Compared with the state-of-the-art - pure DSE, pure guiding, and pure path slicing - SRV achieves average speedups of more than 8.4X, 8.6X, and 7X, respectively, making symbolic regular property verification significantly more practical.","","","10.1145/3180155.3180227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453161","Regular property;Verification;Dynamic Symbolic Execution;Slicing;Guiding","Java;Software engineering;Software;Task analysis;History;Explosions;Heuristic algorithms","Java;program slicing;program verification;public domain software","symbolic regular verification;SRV;dynamic symbolic execution;regular property-oriented path slicing algorithm;real-world open-source Java programs;symbolic regular property verification;program verification;path explosion mitigation","","","49","","","","","IEEE","IEEE Conferences"
"Disseminating Architectural Knowledge on Open-Source Projects: A Case Study of the Book ""Architecture of Open-Source Applications""","M. P. Robillard; N. Medvidovic","Sch. of Comput. Sci., McGill Univ., Montr√©al, QC, Canada; Comput. Sci. Dept., Univ. of Southern California, Los Angeles, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","476","487","This paper reports on an interview-based study of 18 authors of different chapters of the two-volume book ""Architecture of Open-Source Applications"". The main contributions are a synthesis of the process of authoring essay-style documents (ESDs) on software architecture, a series of observations on important factors that influence the content and presentation of architectural knowledge in this documentation form, and a set of recommendations for readers and writers of ESDs on software architecture. We analyzed the influence of three factors in particular: the evolution of a system, the community involvement in the project, and the personal characteristics of the author. This study provides the first systematic investigation of the creation of ESDs on software architecture. The observations we collected have implications for both readers and writers of ESDs, and for architecture documentation in general.","","","10.1145/2884781.2884792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886927","Architecture Description;Open-Source Software","Interviews;Computer architecture;Software architecture;Documentation;Software;Electrostatic discharges;Context","public domain software;software architecture","architectural knowledge dissemination;open-source projects;Architecture of Open-Source Applications;ESD;essay-style documents;software architecture;architecture documentation","","1","58","","","","","IEEE","IEEE Conferences"
"Comparing White-Box and Black-Box Test Prioritization","C. Henard; M. Papadakis; M. Harman; Y. Jia; Y. Le Traon","Univ. of Luxembourg, Luxembourg City, Luxembourg; Univ. of Luxembourg, Luxembourg City, Luxembourg; Univ. Coll. London, London, UK; Univ. Coll. London, London, UK; Univ. of Luxembourg, Luxembourg City, Luxembourg","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","523","534","Although white-box regression test prioritization has been well-studied, the more recently introduced black-box prioritization approaches have neither been compared against each other nor against more well-established white-box techniques. We present a comprehensive experimental comparison of several test prioritization techniques, including well-established white-box strategies and more recently introduced black-box approaches. We found that Combinatorial Interaction Testing and diversity-based techniques (Input Model Diversity and Input Test Set Diameter) perform best among the black-box approaches. Perhaps surprisingly, we found little difference between black-box and white-box performance (at most 4% fault detection rate difference). We also found the overlap between black- and white-box faults to be high: the first 10% of the prioritized test suites already agree on at least 60% of the faults found. These are positive findings for practicing regression testers who may not have source code available, thereby making white-box techniques inapplicable. We also found evidence that both black-box and white-box prioritization remain robust over multiple system releases.","","","10.1145/2884781.2884791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886931","Regression Testing;White-box;Black-box","Testing;Fault detection;Robustness;Flexible printed circuits;Software;Servers;Instruments","program testing;regression analysis","black-box test prioritization;white-box regression test prioritization;black-box prioritization approach;combinatorial interaction testing;diversity-based techniques;input model diversity;input test set diameter","","25","69","","","","","IEEE","IEEE Conferences"
"Inferring and Asserting Distributed System Invariants","S. Grant; H. Cech; I. Beschastnikh","Univ. of British Columbia, Vancouver, BC, Canada; Univ. of Bamberg, Bamberg, Germany; Univ. of British Columbia, Vancouver, BC, Canada","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1149","1159","Distributed systems are difficult to debug and understand. A key reason for this is distributed state, which is not easily accessible and must be pieced together from the states of the individual nodes in the system. We propose Dinv, an automatic approach to help developers of distributed systems uncover the runtime distributed state properties of their systems. Dinv uses static and dynamic program analyses to infer relations between variables at different nodes. For example, in a leader election algorithm, Dinv can relate the variable leader at different nodes to derive the invariant forall ‚àÄ nodes i, j, leader_i = leader_j. This can increase the developer's confidence in the correctness of their system. The developer can also use Dinv to convert an inferred invariant into a distributed runtime assertion on distributed state. We applied Dinv to several popular distributed systems, such as etcd Raft, Hashicorp Serf, and Taipei-Torrent, which have between 1.7K and 144K LOC and are widely used. Dinv derived useful invariants for these systems, including invariants that capture the correctness of distributed routing strategies, leadership, and key hash distribution. We also used Dinv to assert correctness of the inferred etcd Raft invariants at runtime, using these asserts to detect injected silent bugs.","","","10.1145/3180155.3180199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453196","distributed systems;specification mining;runtime checking;program analysis","Instruments;Clocks;Runtime;Tools;Lattices;Protocols;Computer bugs","dynamic programming;Java;peer-to-peer computing;program debugging;program diagnostics;program verification","Dinv;useful invariants;distributed routing strategies;key hash distribution;individual nodes;runtime distributed state properties;leader election algorithm;variable leader;inferred invariant;distributed runtime assertion","","1","59","","","","","IEEE","IEEE Conferences"
"The Emerging Role of Data Scientists on Software Development Teams","M. Kim; T. Zimmermann; R. DeLine; A. Begel","UCLA, Los Angeles, CA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","96","107","Creating and running software produces large amounts of raw data about the development process and the customer usage, which can be turned into actionable insight with the help of skilled data scientists. Unfortunately, data scientists with the analytical and software engineering skills to analyze these large data sets have been hard to come by; only recently have software companies started to develop competencies in software-oriented data analytics. To understand this emerging role, we interviewed data scientists across several product groups at Microsoft. In this paper, we describe their education and training background, their missions in software engineering contexts, and the type of problems on which they work. We identify five distinct working styles of data scientists: (1) Insight Providers, who work with engineers to collect the data needed to inform decisions that managers make; (2) Modeling Specialists, who use their machine learning expertise to build predictive models; (3) Platform Builders, who create data platforms, balancing both engineering and data analysis concerns; (4) Polymaths, who do all data science activities themselves; and (5) Team Leaders, who run teams of data scientists and spread best practices. We further describe a set of strategies that they employ to increase the impact and actionability of their work.","","","10.1145/2884781.2884783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886895","Data Science;Software Analytics;Data Scientist","Software;Data science;Interviews;Companies;Software engineering","software development management;team working","data scientists;software development teams;software creation;software development process;customer usage;software engineering skills;software-oriented data analytics;insight providers;modeling specialists;platform builders;polymaths;team leaders","","14","49","","","","","IEEE","IEEE Conferences"
"Understanding Developers' Needs on Deprecation as a Language Feature","A. A. Sawant; M. Aniche; A. van Deursen; A. Bacchelli","Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Univ. of Zurich, Zurich, Switzerland","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","561","571","Deprecation is a language feature that allows API producers to mark a feature as obsolete. We aim to gain a deep understanding of the needs of API producers and consumers alike regarding deprecation. To that end, we investigate why API producers deprecate features, whether they remove deprecated features, how they expect consumers to react, and what prompts an API consumer to react to deprecation. To achieve this goal we conduct semi-structured interviews with 17 third-party Java API producers and survey 170 Java developers. We observe that the current deprecation mechanism in Java and the proposal to enhance it does not address all the needs of a developer. This leads us to propose and evaluate three further enhancements to the deprecation mechanism.","","","10.1145/3180155.3180170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453124","API;deprecation;Java","Java;Interviews;Industries;Companies;Proposals;Guidelines;Software engineering","application program interfaces;Java;public domain software","Java developers;current deprecation mechanism;third-party Java API producers;API consumer;language feature","","2","","","","","","IEEE","IEEE Conferences"
"Towards Optimal Concolic Testing","X. Wang; J. Sun; Z. Chen; P. Zhang; J. Wang; Y. Lin","NA; NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","291","302","Concolic testing integrates concrete execution (e.g., random testing) and symbolic execution for test case generation. It is shown to be more cost-effective than random testing or symbolic execution sometimes. A concolic testing strategy is a function which decides when to apply random testing or symbolic execution, and if it is the latter case, which program path to symbolically execute. Many heuristics-based strategies have been proposed. It is still an open problem what is the optimal concolic testing strategy. In this work, we make two contributions towards solving this problem. First, we show the optimal strategy can be defined based on the probability of program paths and the cost of constraint solving. The problem of identifying the optimal strategy is then reduced to a model checking problem of Markov Decision Processes with Costs. Secondly, in view of the complexity in identifying the optimal strategy, we design a greedy algorithm for approximating the optimal strategy. We conduct two sets of experiments. One is based on randomly generated models and the other is based on a set of C programs. The results show that existing heuristics have much room to improve and our greedy algorithm often outperforms existing heuristics.","","","10.1145/3180155.3180177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453088","Concolic Testing;Markov Chain;Test Case Generation","Greedy algorithms;Cost accounting;Sun;Model checking;Probabilistic logic;Systematics","greedy algorithms;Markov processes;program diagnostics;program testing","concrete execution;random testing;test case generation;symbolic execution;program path;heuristics-based strategies;optimal concolic testing strategy;optimal strategy;optimal concolic testing","","1","","","","","","IEEE","IEEE Conferences"
"Program Splicing","Y. Lu; S. Chaudhuri; C. Jermaine; D. Melski","Rice Univ., Houston, TX, USA; Rice Univ., Houston, TX, USA; Rice Univ., Houston, TX, USA; Grammatech Inc., Ithaca, NY, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","338","349","We introduce program splicing, a programming methodology that aims to automate the work ow of copying, pasting, and modifying code available online. Here, the programmer starts by writing a ""draft"" that mixes un nished code, natural language comments, and correctness requirements. A program synthesizer that interacts with a large, searchable database of program snippets is used to automatically complete the draft into a program that meets the re-quirements. The synthesis process happens in two stages. First, the synthesizer identi es a small number of programs in the database that are relevant to the synthesis task. Next it uses an enumerative search to systematically ll the draft with expressions and statements from these relevant programs. The resulting program is returned to the programmer, who can modify it and possibly invoke additional rounds of synthesis. We present an implementation of program splicing, called Splicer, for the Java programming language. Splicer uses a corpus of over 3.5 million procedures from an open-source software repository. Our evaluation uses the system in a suite of everyday programming tasks, and includes a comparison with a state-of-the-art competing approach as well as a user study. The results point to the broad scope and scalability of program splicing and indicate that the approach can signi cantly boost programmer productivity.","","","10.1145/3180155.3180190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453092","Big Data;Program Synthesis","Splicing;Task analysis;Databases;Synthesizers;Programming;Java;Software engineering","Java;public domain software;software engineering","program splicing;programming methodology;program synthesizer;program snippets;relevant programs;resulting program;Java programming language;everyday programming tasks","","","","","","","","IEEE","IEEE Conferences"
"Feedback-Directed Instrumentation for Deployed JavaScript Applications","M. Madsen; F. Tip; E. Andreasen; K. Sen; A. M√∏ller","Univ. of Waterloo, Waterloo, ON, Canada; Samsung Res. America, Mountain View, CA, USA; Aarhus Univ., Aarhus, Denmark; EECS Dept., UC Berkeley, Berkeley, CA, USA; Aarhus Univ., Aarhus, Denmark","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","899","910","Many bugs in JavaScript applications manifest themselves as objects that have incorrect property values when a failure occurs. For this type of error, stack traces and log files are often insufficient for diagnosing problems. In such cases, it is helpful for developers to know the control flow path from the creation of an object to a crashing statement. Such crash paths are useful for understanding where the object originated and whether any properties of the object were corrupted since its creation.We present a feedback-directed instrumentation technique for computing crash paths that allows the instrumentation overhead to be distributed over a crowd of users and to reduce it for users who do not encounter the crash. We implemented our technique in a tool, Crowdie, and evaluated it on 10 real-world issues for which error messages and stack traces are insufficient to isolate the problem. Our results show that feedback-directed instrumentation requires 5% to 25% of the program to be instrumented, that the same crash must be observed 3 to 10 times to discover the crash path, and that feedback-directed instrumentation typically slows down execution by a factor 2x-9x compared to 8x-90x for an approach where applications are fully instrumented.","","","10.1145/2884781.2884846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886966","debugging;dynamic analysis;javascript;crowdsourcing;instrumentation","Instruments;Computer bugs;Reactive power;Debugging;Software;Servers","Java;system recovery","JavaScript applications;feedback-directed instrumentation technique;crash paths;instrumentation overhead;CROWDIE","","3","32","","","","","IEEE","IEEE Conferences"
"Finding Security Bugs in Web Applications Using a Catalog of Access Control Patterns","J. P. Near; D. Jackson","NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","947","958","We propose a specification-free technique for finding missing security checks in web applications using a catalog of access control patterns in which each pattern models a common access control use case. Our implementation, SPACE, checks that every data exposure allowed by an application's code matches an allowed exposure from a security pattern in our catalog. The only user-provided input is a mapping from application types to the types of the catalog; the rest of the process is entirely automatic. In an evaluation on the 50 most watched Ruby on Rails applications on Github, SPACE reported 33 possible bugs---23 previously unknown security bugs, and 10 false positives.","","","10.1145/2884781.2884836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886970","web application security;access control;bug finding","Computer bugs;Aerospace electronics;Databases;Access control;Rails;Open source software","authorisation;Internet;object-oriented programming;program debugging","security bugs;Web applications;access control patterns catalog;specification-free technique;access control use case;SPACE;data exposure;security pattern;Github","","3","37","","","","","IEEE","IEEE Conferences"
"Context-Aware Patch Generation for Better Automated Program Repair","M. Wen; J. Chen; R. Wu; D. Hao; S. Cheung","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China; Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China; Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1","11","The effectiveness of search-based automated program repair is limited in the number of correct patches that can be successfully generated. There are two causes of such limitation. First, the search space does not contain the correct patch. Second, the search space is huge and therefore the correct patch cannot be generated (ie correct patches are either generated after incorrect plausible ones or not generated within the time budget). To increase the likelihood of including the correct patches in the search space, we propose to work at a fine granularity in terms of AST nodes. This, however, will further enlarge the search space, increasing the challenge to find the correct patches. We address the challenge by devising a strategy to prioritize the candidate patches based on their likelihood of being correct. Specifically, we study the use of AST nodes' context information to estimate the likelihood. In this paper, we propose CapGen, a context-aware patch generation technique. The novelty which allows CapGen to produce more correct patches lies in three aspects: (1) The fine-granularity design enables it to find more correct fixing ingredients; (2) The context-aware prioritization of mutation operators enables it to constrain the search space; (3) Three context-aware models enable it to rank correct patches at high positions before incorrect plausible ones. We evaluate CapGen on Defects4J and compare it with the state-of-the-art program repair techniques. Our evaluation shows that CapGen outperforms and complements existing techniques. CapGen achieves a high precision of 84.00% and can prioritize the correct patches before 98.78% of the incorrect plausible ones.","","","10.1145/3180155.3180233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453055","Context-Aware;Automated Program Repair;Patch Prioritization","Computer bugs;Maintenance engineering;Search problems;Explosions;Context modeling;Software;Benchmark testing","maximum likelihood estimation;program diagnostics;search problems;ubiquitous computing","search-based automated program repair;context-aware patch generation technique;CapGen;likelihood estimation;AST nodes context information","","18","58","","","","","IEEE","IEEE Conferences"
"Decoupling Level: A New Metric for Architectural Maintenance Complexity","R. Mo; Y. Cai; R. Kazman; L. Xiao; Q. Feng","Drexel Univ., Philadelphia, PA, USA; Drexel Univ., Philadelphia, PA, USA; SEI/CMU, Univ. of Hawaii, Honolulu, HI, USA; Drexel Univ., Philadelphia, PA, USA; Drexel Univ., Philadelphia, PA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","499","510","Despite decades of research on software metrics, we still cannot reliably measure if one design is more maintainable than another. Software managers and architects need to understand whether their software architecture is ""good enough"", whether it is decaying over time and, if so, by how much. In this paper, we contribute a new architecture maintainability metric---Decoupling Level (DL)---derived from Baldwin andClark's option theory. Instead of measuring how coupled an architecture is, we measure how well the software can be decoupled into small and independently replaceable modules. We measured the DL for 108 open source projects and 21 industrial projects, each of which has multiple releases. Our main result shows that the larger the DL, the better thearchitecture. By ""better"" we mean: the more likely bugs and changes can be localized and separated, and the more likely that developers can make changes independently. The DL metric also opens the possibility of quantifying canonical principles of single responsibility and separation of concerns, aiding cross-project comparison and architecture decay monitoring.","","","10.1145/2884781.2884825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886929","Software Architecture;Software Quality;Software Metrics","Computer architecture;Software;Software measurement;Observers;Software architecture;Complexity theory","public domain software;software architecture;software maintenance;software metrics","architectural maintenance complexity metric;software metrics;software architecture;architecture maintainability metric;decoupling level metric;open source projects;canonical principles","","14","39","","","","","IEEE","IEEE Conferences"
"The Impact of Test Case Summaries on Bug Fixing Performance: An Empirical Investigation","S. Panichella; A. Panichella; M. Beller; A. Zaidman; H. C. Gall","Univ. of Zurich, Zurich, Switzerland; Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Univ. of Zurich, Zurich, Switzerland","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","547","558","Automated test generation tools have been widely investigated with the goal of reducing the cost of testing activities. However, generated tests have been shownnot to help developers in detecting and finding more bugs even though they reach higher structural coverage compared to manual testing. The main reason is that generated tests are difficult to understand and maintain. Our paper proposes an approach, coined TestDescriber, which automatically generates test case summaries of the portion of code exercised by each individual test, thereby improving understandability. We argue that this approach can complement the current techniques around automated unit test generation or search-based techniques designed to generate a possibly minimal set of test cases. In evaluating our approach we found that (1) developers find twice as many bugs, and (2) test case summaries significantly improve the comprehensibility of test cases, which is considered particularly useful by developers.","","","10.1145/2884781.2884847","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886933","Software testing;Test Case Summarization;Empirical Study","Testing;Computer bugs;Java;Software;Software engineering;Natural languages;Pragmatics","program debugging;program testing","test case summaries;bug fixing performance;automated test generation tools;TestDescriber approach;automated unit test generation;search-based techniques","","16","57","","","","","IEEE","IEEE Conferences"
"Grounded Theory in Software Engineering Research: A Critical Review and Guidelines","K. Stol; P. Ralph; B. Fitzgerald","Lero (Irish Software Res. Centre), Univ. of Limerick, Limerick, Ireland; Dept. of Comput. Sci., Univ. of Auckland, Auckland, New Zealand; Lero (Irish Software Res. Centre), Univ. of Limerick, Limerick, Ireland","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","120","131","Grounded Theory (GT) has proved an extremely useful research approach in several fields including medical sociology, nursing, education and management theory. However, GT is a complex method based on an inductive paradigm that is fundamentally different from the traditional hypothetico-deductive research model. As there are at least three variants of GT, some ostensibly GT research suffers from method slurring, where researchers adopt an arbitrary subset of GT practices that are not recognizable as GT. In this paper, we describe the variants of GT and identify the core set of GT practices. We then analyze the use of grounded theory in software engineering. We carefully and systematically selected 98 articles that mention GT, of which 52 explicitly claim to use GT, with the other 46 using GT techniques only. Only 16 articles provide detailed accounts of their research procedures. We offer guidelines to improve the quality of both conducting and reporting GT studies. The latter is an important extension since current GT guidelines in software engineering do not cover the reporting process, despite good reporting being necessary for evaluating a study and informing subsequent research.","","","10.1145/2884781.2884833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886897","Grounded theory;software engineering;review;guidelines","Software engineering;Software;Guidelines;Computer science;Interviews;Encoding;Sorting","software engineering","grounded theory;software engineering research;GT practices","","33","78","","","","","IEEE","IEEE Conferences"
"UFO: Predictive Concurrency Use-After-Free Detection","J. Huang","Parasol Lab., Texas A&M Univ., College Station, TX, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","609","619","Use-After-Free (UAF) vulnerabilities are caused by the program operating on a dangling pointer and can be exploited to compromise critical software systems. While there have been many tools to mitigate UAF vulnerabilities, UAF remains one of the most common attack vectors. UAF is particularly di cult to detect in concurrent programs, in which a UAF may only occur with rare thread schedules. In this paper, we present a novel technique, UFO, that can precisely predict UAFs based on a single observed execution trace with a provably higher detection capability than existing techniques with no false positives. The key technical advancement of UFO is an extended maximal thread causality model that captures the largest possible set of feasible traces that can be inferred from a given multithreaded execution trace. By formulating UAF detection as a constraint solving problem atop this model, we can explore a much larger thread scheduling space than classical happens-before based techniques. We have evaluated UFO on several real-world large complex C/C++ programs including Chromium and FireFox. UFO scales to real-world systems with hundreds of millions of events in their execution and has detected a large number of real concurrency UAFs.","","","10.1145/3180155.3180225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453130","UAF;Concurrency;Vulnerabilities;UFO","Instruction sets;Concurrent computing;Schedules;Browsers;Tools;Chromium;Encoding","multi-threading;program debugging;program diagnostics;scheduling;security of data","program operating;critical software systems;UAF vulnerabilities;common attack vectors;concurrent programs;rare thread schedules;single observed execution trace;provably higher detection capability;extended maximal thread causality model;UAF detection;larger thread scheduling space;UFO scales;concurrency use-after-free detection;use-after-free vulnerabilities;multithreaded execution trace;concurrency UAF","","2","","","","","","IEEE","IEEE Conferences"
"Perses: Syntax-Guided Program Reduction","C. Sun; Y. Li; Q. Zhang; T. Gu; Z. Su","Univ. of California, Davis, Davis, CA, USA; Univ. of California, Davis, Davis, CA, USA; Univ. of California, Davis, Davis, CA, USA; Univ. of California, Davis, Davis, CA, USA; Univ. of California, Davis, Davis, CA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","361","371","Given a program P that exhibits a certain property œà (e.g., a C program that crashes GCC when it is being compiled), the goal of program reduction is to minimize P to a smaller variant P? that still exhibits the same property, i.e., œà(P'). Program reduction is important and widely demanded for testing and debugging. For example, all compiler/interpreter development projects need effective program reduction to minimize failure-inducing test programs to ease debugging. However, state-of-the-art program reduction techniques - notably Delta Debugging (DD), Hierarchical Delta Debugging (HDD), and C-Reduce - do not perform well in terms of speed (reduction time) and quality (size of reduced programs), or are highly customized for certain languages and thus lack generality. This paper presents Perses, a novel framework for effective, efficient, and general program reduction. The key insight is to exploit, in a general manner, the formal syntax of the programs under reduction and ensure that each reduction step considers only smaller, syntactically valid variants to avoid futile efforts on syntactically invalid variants. Our framework supports not only deletion (as for DD and HDD), but also general, effective program transformations. We have designed and implemented Perses, and evaluated it for two language settings: C and Java. Our evaluation results on 20 C programs triggering bugs in GCC and Clang demonstrate Perses's strong practicality compared to the state-of-the-art: (1) smaller size - Perses's results are respectively 2% and 45% in size of those from DD and HDD; and (2) shorter reduction time - Perses takes 23% and 47% time taken by DD and HDD respectively. Even when compared to the highly customized and optimized C-Reduce for C/C++, Perses takes only 38-60% reduction time.","","","10.1145/3180155.3180236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453094","program reduction;delta debugging;debugging","Grammar;Debugging;Syntactics;Computer bugs;Program processors;Sun;Java","Java;program compilers;program debugging;program testing","DD;HDD;shorter reduction time - Perses;syntax-guided program reduction;C program;effective program reduction;failure-inducing test programs;reduced programs;general program reduction;reduction step;general program transformations;effective program transformations;compiler-interpreter development projects;program reduction techniques;hierarchical Delta debugging;efficient program reduction","","2","","","","","","IEEE","IEEE Conferences"
"Automated Partitioning of Android Applications for Trusted Execution Environments","K. Rubinov; L. Rosculete; T. Mitra; A. Roychoudhury","DeepSE Group at DEIB, Politec. di Milano, Milan, Italy; Applic. Threat Intell., Ixia, Bucharest, Romania; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore; Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","923","934","The co-existence of critical and non-critical applications on computing devices, such as mobile phones, is becoming commonplace. The sensitive segments of a critical application should be executed in isolation on Trusted Execution Environments (TEE) so that the associated code and data can be protected from malicious applications. TEE is supported by different technologies and platforms, such as ARM Trustzone, that allow logical separation of ""secure"" and ""normal"" worlds. We develop an approach for automated partitioning of critical Android applications into ""client"" code to be run in the ""normal"" world and ""TEE commands"" encapsulating the handling of confidential data to be run in the ""secure"" world. We also reduce the overhead due to transitions between the two worlds by choosing appropriate granularity for the TEE commands. The advantage of our proposed solution is evidenced by efficient partitioning of real-world applications.","","","10.1145/2884781.2884817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886968","","Security;Androids;Humanoid robots;Java;Google;Software;Hardware","Android (operating system);mobile computing;trusted computing","Android application partitioning;trusted execution environments;TEE;ARM Trustzone;confidential data handling","","1","42","","","","","IEEE","IEEE Conferences"
"Building a Theory of Job Rotation in Software Engineering from an Instrumental Case Study","R. E. S. Santos; F. Q. B. da Silva; C. V. C. de Magalh√£es; C. V. F. Monteiro","Centro de Inf., Univ. Fed. de Pernambuco, Recife, Brazil; Centro de Inf., Univ. Fed. de Pernambuco, Recife, Brazil; Centro de Inf., Univ. Fed. de Pernambuco, Recife, Brazil; Dept. de Estatistica e Inf., Univ. Fed. Rural de Pernambuco, Recife, Brazil","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","971","981","Job Rotation is an organizational practice in which individuals are frequently moved from a job (or project) to another in the same organization. Studies in other areas have found that this practice has both negative and positive effects on individuals' work. However, there are only few studies addressing this issue in software engineering so far. The goal of our study is to investigate the effects of job rotation on work related factors in software engineering by performing a qualitative case study on a large software organization that uses job rotation as an organizational practice. We interviewed senior managers, project managers, and software engineers that had experienced this practice. Altogether, 48 participants were involved in all phases of this research. Collected data was analyzed using qualitative coding techniques and the results were checked and validated with participants through member checking. Our findings suggest that it is necessary to find balance between the positive effects on work variety and learning opportunities, and negative effects on cognitive workload and performance. Further, the lack of feedback resulting from constant movement among projects and teams may have a negative impact on performance feedback. We conclude that job rotation is an important organizational practice with important positive results. However, managers must be aware of potential negative effects and deploy tactics to balance them. We discuss such tactics in this article.","","","10.1145/2884781.2884837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886972","job rotation;software teams;performance;software engineering;case study","Multiskilling;Software;Software engineering;Companies;Interviews;Context","organisational aspects;software development management","job rotation theory;software engineering;organizational practice;work related factors;qualitative case study;qualitative coding techniques;cognitive workload;cognitive performance","","2","39","","","","","IEEE","IEEE Conferences"
"Synthesizing Framework Models for Symbolic Execution","J. Jeon; X. Qiu; J. Fetter-Degges; J. S. Foster; A. Solar-Lezama","Univ. of Maryland, College Park, MD, USA; Massachusetts Inst. of Technol., Cambridge, MA, USA; Univ. of Maryland, College Park, MD, USA; Univ. of Maryland, College Park, MD, USA; Massachusetts Inst. of Technol., Cambridge, MA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","156","167","Symbolic execution is a powerful program analysis technique, but it is difficult to apply to programs built using frameworks such as Swing and Android, because the framework code itself is hard to symbolically execute. The standard solution is to manually create a framework model that can be symbolically executed, but developing and maintaining a model is difficult and error-prone. In this paper, we present Pasket, a new system that takes a first step toward automatically generating Java framework models to support symbolic execution. Pasket's focus is on creating models by instantiating design patterns. Pasket takes as input class, method, and type information from the framework API, together with tutorial programs that exercise the framework. From these artifacts and Pasket's internal knowledge of design patterns, Pasket synthesizes a framework model whose behavior on the tutorial programs matches that of the original framework. We evaluated Pasket by synthesizing models for subsets of Swing and Android. Our results show that the models derived by Pasket are sufficient to allow us to use off-the-shelf symbolic execution tools to analyze Java programs that rely on frameworks.","","","10.1145/2884781.2884856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886900","Program Synthesis;Framework Model;Symbolic Execution;Sketch","Tutorials;Java;Androids;Humanoid robots;Observers;Analytical models;Synthesizers","Java;object-oriented programming;program diagnostics","symbolic execution;program analysis;PASKET;Java framework models;design pattern instantiation;API;Swing;Android","","3","40","","","","","IEEE","IEEE Conferences"
"MobiPlay: A Remote Execution Based Record-and-Replay Tool for Mobile Applications","Z. Qin; Y. Tang; E. Novak; Q. Li","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA; Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","571","582","The record-and-replay approach for software testing is important and valuable for developers in designing mobile applications. However, the existing solutions for recording and replaying Android applications are far from perfect. When considering the richness of mobile phones' input capabilities including touch screen, sensors, GPS, etc., existing approaches either fall short of covering all these different input types, or require elevated privileges that are not easily attained and can be dangerous. In this paper, we present a novel system, called MobiPlay, which aims to improve record-and-replay testing. By collaborating between a mobile phone and a server, we are the first to capture all possible inputs by doing so at the application layer, instead of at the Android framework layer or the Linux kernel layer, which would be infeasible without a server. MobiPlay runs the to-be-tested application on the server under exactly the same environment as the mobile phone, and displays the GUI of the application in real time on a thin client application installed on the mobile phone. From the perspective of the mobile phone user, the application appears to be local. We have implemented our system and evaluated it with tens of popular mobile applications showing that MobiPlay is efficient, flexible, and comprehensive. It can record all input data, including all sensor data, all touchscreen gestures, and GPS. It is able to record and replay on both the mobile phone and the server. Furthermore, it is suitable for both white-box and black-box testing.","","","10.1145/2884781.2884854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886935","","Servers;Smart phones;Mobile communication;Sensors;Testing;Operating systems","graphical user interfaces;mobile computing;program testing","MobiPlay tool;remote execution;record-and-replay tool;mobile applications;software testing;Android applications;mobile phone;Linux kernel layer;GUI;graphical user interface;sensor data;touchscreen gestures;white-box testing;black-box testing","","14","36","","","","","IEEE","IEEE Conferences"
"Guiding Dynamic Symbolic Execution toward Unverified Program Executions","M. Christakis; P. M√ºller; V. W√ºstholz","Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland; Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","144","155","Most techniques to detect program errors, such as testing, code reviews, and static program analysis, do not fully verify all possible executions of a program. They leave executions unverified when they do not check certain properties, fail to verify properties, or check properties under certain unsound assumptions such as the absence of arithmetic overflow. In this paper, we present a technique to complement partial verification results by automatic test case generation. In contrast to existing work, our technique supports the common case that the verification results are based on unsound assumptions. We annotate programs to reflect which executions have been verified, and under which assumptions. These annotations are then used to guide dynamic symbolic execution toward unverified program executions. Our main technical contribution is a code instrumentation that causes dynamic symbolic execution to abort tests that lead to verified executions, to prune parts of the search space, and to prioritize tests that cover more properties that are not fully verified. We have implemented our technique for the .NET static analyzer Clousot and the dynamic symbolic execution tool Pex. It produces smaller test suites (by up to 19.2%), covers more unverified executions (by up to 7.1%), and reduces testing time (by up to 52.4%) compared to combining Clousot and Pex without our technique.","","","10.1145/2884781.2884843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886899","static analysis;program verification;testing;partial verification;dynamic symbolic execution","Testing;Instruments;Redundancy;Aerospace electronics;Conferences;Software engineering;Performance analysis","program testing","dynamic symbolic execution;unverified program execution;program error detection;program execution;arithmetic overflow;automatic test case generation;code instrumentation;Clousot;Pex tool","","5","41","","","","","IEEE","IEEE Conferences"
"Dataflow Tunneling: Mining Inter-Request Data Dependencies for Request-Based Applications","X. Yu; G. Jin","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA; Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","586","597","Request-based applications, e.g., most server-side applications, expose services to users in a request-based paradigm, in which requests are served by request-handler methods. An important task for request-based applications is inter-request analysis, which analyzes request-handler methods that are related by inter-request data dependencies together. However, in the request-based paradigm, data dependencies between related request-handler methods are implicitly established by the underlying frameworks that execute these methods. As a result, existing analysis tools are usually limited to the scope of each single method without the knowledge of dependencies between different methods. In this paper, we design an approach called dataflow tunneling to capture inter-request data dependencies from concrete application executions and produce data-dependency specifications. Our approach answers two key questions: (1) what request-handler methods have data dependencies and (2) what these data dependencies are. Our evaluation using applications developed with two representative and popular frameworks shows that our approach is general and accurate. We also present a characteristic study and a use case of cache tuning based on the mined specifications. We envision that our approach can provide key information to enable future inter-request analysis techniques.","","","10.1145/3180155.3180171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453128","web application;request based applications;web frameworks;inter request analysis;tracing","Data models;Java;Tunneling;Analytical models;Object recognition;Prototypes;Databases","cache storage;data mining","request-based applications;request-based paradigm;analyzes request-handler methods;single method;dataflow tunneling;concrete application executions;data-dependency specifications;future inter-request analysis techniques;inter-request data dependency mining","","","59","","","","","IEEE","IEEE Conferences"
"Statistical Learning of API Fully Qualified Names in Code Snippets of Online Forums","H. Phan; H. A. Nguyen; N. M. Tran; L. H. Truong; A. T. Nguyen; T. N. Nguyen","Iowa State Univ., Ames, IA, USA; Iowa State Univ., Ames, IA, USA; Univ. of Texas at Dallas, Dallas, TX, USA; Univ. of Texas at Dallas, Dallas, TX, USA; NA; Univ. of Texas at Dallas, Dallas, TX, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","632","642","Software developers often make use of the online forums such as StackOverflow to learn how to use software libraries and their APIs. However, the code snippets in such a forum often contain undeclared, ambiguous, or largely unqualified external references. Such declaration ambiguity and external reference ambiguity present challenges for developers in learning to correctly use the APIs. In this paper, we propose StatType, a statistical approach to resolve the fully qualified names (FQNs) for the API elements in such code snippets. Unlike existing approaches that are based on heuristics, StatType has two well-integrated factors. We first learn from a large training code corpus the FQNs that often co-occur. Then, to derive the FQN for an API name in a code snippet, we use that knowledge and leverage the context consisting of neighboring API names. To realize those factors, we treat the problem as statistical machine translation from source code with partially qualified names to source code with FQNs of the APIs. Our empirical evaluation on real-world code and StackOverflow posts shows that StatType achieves very high accuracy with 97.6% precision and 96.7% recall, which is 16.5% relatively higher than the state-of-the-art approach.","","","10.1145/3180155.3180230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453132","Type Resolution;Type Inference;Type Annotations;Partial Program Analysis;Statistical Machine Translation;Naturalness;Big Code","Computational modeling;Software libraries;Training;Software;Tools","application program interfaces;Internet;language translation;learning (artificial intelligence);software libraries;statistical analysis","machine translation;StackOverflow posts;API fully qualified names;statistical learning;partially qualified names;source code;API name;training code corpus;API elements;FQNs;statistical approach;StatType;external reference;declaration ambiguity;code snippet;software libraries;online forums;software developers","","3","","","","","","IEEE","IEEE Conferences"
"StubDroid: Automatic Inference of Precise Data-Flow Summaries for the Android Framework","S. Arzt; E. Bodden","Secure Software Eng. Group, Tech. Univ. Darmstadt, Darmstadt, Germany; Secure Software Eng. Group, Tech. Univ. Darmstadt, Darmstadt, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","725","735","Smartphone users suffer from insucient information on how commercial as well as malicious apps handle sensitive data stored on their phones. Automated taint analyses address this problem by allowing users to detect and investigate how applications access and handle this data. A current problem with virtually all those analysis approaches is, though, that they rely on explicit models of the Android runtime library. In most cases, the existence of those models is taken for granted, despite the fact that the models are hard to come by: Given the size and evolution speed of a modern smartphone operating system it is prohibitively expensive to derive models manually from code or documentation. In this work, we therefore present StubDroid, the first fully automated approach for inferring precise and efficient library models for taint-analysis problems. StubDroid automatically constructs these summaries from a binary distribution of the library. In our experiments, we use StubDroid-inferred models to prevent the static taint analysis FlowDroid from having to re-analyze the Android runtime library over and over again for each analyzed app. As the results show, the models make it possible to analyze apps in seconds whereas most complete re-analyses would time out after 30 minutes. Yet, StubDroid yields comparable precision. In comparison to manually crafted summaries, StubDroid's cause the analysis to be more precise and to use less time and memory.","","","10.1145/2884781.2884816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886831","Static analysis;summary;library;framework model;model inference","Libraries;Androids;Humanoid robots;Analytical models;Software engineering;Smart phones;Operating systems","Android (operating system);program diagnostics;smart phones","StubDroid approach;StubDroid-inferred models;smart phone operating system;Android runtime library;automated taint analysis;sensitive data handling;Android framework;precise data-flow summaries","","6","22","","","","","IEEE","IEEE Conferences"
"EnMobile: Entity-Based Characterization and Analysis of Mobile Malware","W. Yang; M. Prasad; T. Xie","NA; Fujitsu Labs. of America, Sunnyvale, CA, USA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","384","394","Modern mobile malware tend to conduct their malicious exploits through sophisticated patterns of interactions that involve multiple entities, e.g., the mobile platform, human users, and network locations. Such malware often evade the detection by existing approaches due to their limited expressiveness and accuracy in characterizing and detecting these malware. To address these issues, in this paper, we recognize entities in the environment of an app, the app's interactions with such entities, and the provenance of these interactions, i.e., the intent and ownership of each interaction, as the key to comprehensively characterizing modern mobile apps, and mobile malware in particular. With this insight, we propose a novel approach named EnMobile including a new entity-based characterization of mobile-app behaviors, and corresponding static analyses, to accurately characterize an app's interactions with entities. We implement EnMobile and provide a practical application of EnMobile in a signature-based scheme for detecting mobile malware. We evaluate EnMobile on a set of 6614 apps consisting of malware from Genome and Drebin along with benign apps from Google Play. Our results show that EnMobile detects malware with substantially higher precision and recall than four state-of-the-art approaches, namely Apposcopy, Drebin, MUDFLOW, and AppContext.","","","10.1145/3180155.3180223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453096","Program Analysis;Mobile Security","Malware;Servers;Security;Databases;Static analysis;Feature extraction","invasive software;mobile computing;program diagnostics","mobile-app behaviors;EnMobile;benign apps;entity-based characterization;modern mobile malware;mobile platform;modern mobile apps","","5","","","","","","IEEE","IEEE Conferences"
"The Sky Is Not the Limit: Multitasking Across GitHub Projects","B. Vasilescu; K. Blincoe; Q. Xuan; C. Casalnuovo; D. Damian; P. Devanbu; V. Filkov","Dept. Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Dept. Electr. & Comput. Eng., Univ. of Auckland, Auckland, New Zealand; Dept. Autom., Zhejiang Univ. of Technol., Hangzhou, China; Dept. Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Dept. Comput. Sci., Univ. of Victoria, Victoria, BC, Canada; Dept. Comput. Sci., Univ. of California, Davis, Davis, CA, USA; Dept. Comput. Sci., Univ. of California, Davis, Davis, CA, USA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","994","1005","Software development has always inherently required multitasking: developers switch between coding, reviewing, testing, designing, and meeting with colleagues. The advent of software ecosystems like GitHub has enabled something new: the ability to easily switch between projects. Developers also have social incentives to contribute to many projects; prolific contributors gain social recognition and (eventually) economic rewards. Multitasking, however, comes at a cognitive cost: frequent context-switches can lead to distraction, sub-standard work, and even greater stress. In this paper, we gather ecosystem-level data on a group of programmers working on a large collection of projects. We develop models and methods for measuring the rate and breadth of a developers' context-switching behavior, and we study how context-switching affects their productivity. We also survey developers to understand the reasons for and perceptions of multitasking. We find that the most common reason for multitasking is interrelationships and dependencies between projects. Notably, we find that the rate of switching and breadth (number of projects) of a developer's work matter. Developers who work on many projects have higher productivity if they focus on few projects per day. Developers that switch projects too much during the course of a day have lower productivity as they work on more projects overall. Despite these findings, developers perceptions of the benefits of multitasking are varied.","","","10.1145/2884781.2884875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886974","Multitasking;GitHub;productivity","Multitasking;Switches;Productivity;Software;Encoding;Context;Interrupters","project management;software development management","GitHub projects;software development;multitasking;ecosystem-level data gathering;context-switching behavior","","15","60","","","","","IEEE","IEEE Conferences"
"An Empirical Comparison of Compiler Testing Techniques","J. Chen; W. Hu; D. Hao; Y. Xiong; H. Zhang; L. Zhang; B. Xie","NA; NA; NA; NA; Microsoft Res., Beijing, China; NA; NA","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","180","190","Compilers, as one of the most important infrastructure of today's digital world, are expected to be trustworthy. Different testing techniques are developed for testing compilers automatically. However, it is unknown so far how these testing techniques compared to each other in terms of testing effectiveness: how many bugs a testing technique can find within a time limit. In this paper, we conduct a systematic and comprehensive empirical comparison of three compiler testing techniques, namely, Randomized Differential Testing (RDT), a variant of RDT-Different Optimization Levels (DOL), and Equivalence Modulo Inputs (EMI). Our results show that DOL is more effective at detecting bugs related to optimization, whereas RDT is more effective at detecting other types of bugs, and the three techniques can complement each other to a certain degree. Furthermore, in order to understand why their effectiveness differs, we investigate three factors that influence the effectiveness of compiler testing, namely, efficiency, strength of test oracles, and effectiveness of generated test programs. The results indicate that all the three factors are statistically significant, and efficiency has the most significant impact.","","","10.1145/2884781.2884878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886902","","Computer bugs;Testing;Program processors;Electromagnetic interference;Optimization;History","program compilers;program testing","compiler testing techniques;testing effectiveness;randomized differential testing;RDT;different optimization levels;DOL;equivalence modulo inputs;EMI;bug detection;test oracles;test program generation","","9","32","","","","","IEEE","IEEE Conferences"
"Software Protection on the Go: A Large-Scale Empirical Study on Mobile App Obfuscation","P. Wang; Q. Bao; L. Wang; S. Wang; Z. Chen; T. Wei; D. Wu","NA; NA; NA; NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","26","36","The prosperity of smartphone markets has raised new concerns about software security on mobile platforms, leading to a growing demand for effective software obfuscation techniques. Due to various differences between the mobile and desktop ecosystems, obfuscation faces both technical and non-technical challenges when applied to mobile software. Although there have been quite a few software security solution providers launching their mobile app obfuscation services, it is yet unclear how real-world mobile developers perform obfuscation as part of their software engineering practices. Our research takes a first step to systematically studying the deployment of software obfuscation techniques in mobile software development. With the help of an automated but coarse-grained method, we computed the likelihood of an app being obfuscated for over a million app samples crawled from Apple App Store. We then inspected the top 6600 instances and managed to identify 601 obfuscated versions of 539 iOS apps. By analyzing this sample set with extensive manual effort, we made various observations that reveal the status quo of mobile obfuscation in the real world, providing insights into understanding and improving the situation of software protection on mobile platforms.","","","10.1145/3180155.3180169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453059","obfuscation;reverse engineering;mobile app;empirical study","Software;Security;Androids;Humanoid robots;Libraries;Software protection;Manuals","computer crime;security of data;smart phones;software engineering","software protection;large-scale empirical study;smartphone markets;mobile platforms;effective software obfuscation techniques;mobile ecosystems;desktop ecosystems;nontechnical challenges;software security solution providers;mobile app obfuscation services;real-world mobile developers;mobile obfuscation;Apple App Store;million app samples;mobile software development;software engineering practices","","","","","","","","IEEE","IEEE Conferences"
"Neuro-Symbolic Program Corrector for Introductory Programming Assignments","S. Bhatia; P. Kohli; R. Singh","Netaji Subhas Inst. of Technol., Delhi, India; Google Deepmind, London, UK; Microsoft Res., Redmond, WA, USA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","60","70","Automatic correction of programs is a challenging problem with numerous real world applications in security, verification, and education. One application that is becoming increasingly important is the correction of student submissions in online courses for providing feedback. Most existing program repair techniques analyze Abstract Syntax Trees (ASTs) of programs, which are unfortunately unavailable for programs with syntax errors. In this paper, we propose a novel Neuro-symbolic approach that combines neural networks with constraint-based reasoning. Specifically, our method first uses a Recurrent Neural Network (RNN) to perform syntax repairs for the buggy programs; subsequently, the resulting syntactically-fixed programs are repaired using constraint-based techniques to ensure functional correctness. The RNNs are trained using a corpus of syntactically correct submissions for a given programming assignment, and are then queried to fix syntax errors in an incorrect programming submission by replacing or inserting the predicted tokens at the error location. We evaluate our technique on a dataset comprising of over 14,500 student submissions with syntax errors. Our method is able to repair syntax errors in 60% (8689) of submissions, and finds functionally correct repairs for 23.8% (3455) submissions.","","","10.1145/3180155.3180219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453063","Neural Program Correction;Automated Feedback Generation;Neural guided search","Syntactics;Maintenance engineering;Programming;Recurrent neural networks;Prediction algorithms;Semantics","computer aided instruction;educational courses;error handling;program debugging;program diagnostics;programming;recurrent neural nets;trees (mathematics)","program repair techniques;neuro-symbolic program corrector;introductory programming assignment;automatic program correction;Abstract Syntax Trees;online courses;error location;syntax errors;constraint-based techniques;syntactically-fixed programs;buggy programs;syntax repairs;Recurrent Neural Network;constraint-based reasoning","","","","","","","","IEEE","IEEE Conferences"
"Automated Test Suite Generation for Time-Continuous Simulink Models","R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann","SnT Centre, Univ. of Luxembourg, Luxembourg, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg, Luxembourg; Delphi Automotive Syst., Luxembourg","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","595","606","All engineering disciplines are founded and rely on models, although they may differ on purposes and usages of modeling. Interdisciplinary domains such as Cyber Physical Systems (CPSs) seek approaches that incorporate different modeling needs and usages. Specifically, the Simulink modeling platform greatly appeals to CPS engineers due to its seamless support for simulation and code generation. In this paper, we propose a test generation approach that is applicable to Simulink models built for both purposes of simulation and code generation. We define test inputs and outputs as signals that capture evolution of values over time. Our test generation approach is implemented as a meta-heuristic search algorithm and is guided to produce test outputs with diverse shapes according to our proposed notion of diversity. Our evaluation, performed on industrial and public domain models, demonstrates that: (1) In contrast to the existing tools for testing Simulink models that are only applicable to a subset of code generation models, our approach is applicable to both code generation and simulation Simulink models. (2) Our new notion of diversity for output signals outperforms random baseline testing and an existing notion of signal diversity in revealing faults in Simulink models. (3) The fault revealing ability of our test generation approach outperforms that of the Simulink Design Verifier, the only testing toolbox for Simulink.","","","10.1145/2884781.2884797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886937","Simulink models;Software testing;Time-continuous behaviors;Search-based software testing;Output diversity;Signal features;Structural coverage;Simulink Design Verifier (SLDV)","Software packages;Computational modeling;Fuels;Testing;Mathematical model;Shape","automatic testing;program compilers;program testing;search problems","automated test suite generation;time-continuous Simulink models;code generation;test inputs;test outputs;meta-heuristic search algorithm;industrial domain models;public domain models;simulation Simulink models;signal diversity;fault revealing ability","","10","61","","","","","IEEE","IEEE Conferences"
"A Comparison of 10 Sampling Algorithms for Configurable Systems","F. Medeiros; C. K√§stner; M. Ribeiro; R. Gheyi; S. Apel","Fed. Univ. of Campina Grande, Campina Grande, Brazil; Carnegie Mellon Univ. Pittsburgh, Pittsburgh, PA, USA; Fed. Univ. of Alagoas, Maceio, Brazil; Fed. Univ. of Campina Grande, Campina Grande, Brazil; Univ. Passau, Passau, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","643","654","Almost every software system provides configuration options to tailor the system to the target platform and application scenario. Often, this configurability renders the analysis of every individual system configuration infeasible. To address this problem, researchers have proposed a diverse set of sampling algorithms. We present a comparative study of 10 state-of-the-art sampling algorithms regarding their fault-detection capability and size of sample sets. The former is important to improve software quality and the latter to reduce the time of analysis. In a nutshell, we found that sampling algorithms with larger sample sets are able to detect higher numbers of faults, but simple algorithms with small sample sets, such as most-enabled-disabled, are the most efficient in most contexts. Furthermore, we observed that the limiting assumptions made in previous work influence the number of detected faults, the size of sample sets, and the ranking of algorithms. Finally, we have identified a number of technical challenges when trying to avoid the limiting assumptions, which questions the practicality of certain sampling algorithms.","","","10.1145/2884781.2884793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886941","Configurable Systems;Sampling Algorithms;Configuration-Related Faults","Algorithm design and analysis;Software algorithms;Software systems;Linux;Kernel;Fault detection;Software quality","program diagnostics;software quality","configurable systems;sampling algorithms;fault-detection capability;software quality;software system configuration","","13","58","","","","","IEEE","IEEE Conferences"
"Deuce: A Lightweight User Interface for Structured Editing","B. Hempel; J. Lubin; G. Lu; R. Chugh","NA; NA; NA; NA","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","654","664","We present a structure-aware code editor, called Deuce, that is equipped with direct manipulation capabilities for invoking automated program transformations. Compared to traditional refactoring environments, Deuce employs a direct manipulation interface that is tightly integrated within a text-based editing workflow. In particular, Deuce draws (i) clickable widgets atop the source code that allow the user to structurally select the unstructured text for subexpressions and other relevant features, and (ii) a lightweight, interactive menu of potential transformations based on the current selections. We implement and evaluate our design with mostly standard transformations in the context of a small functional programming language. A controlled user study with 21 participants demonstrates that structural selection is preferred to a more traditional text-selection interface and may be faster overall once users gain experience with the tool. These results accord with Deuce's aim to provide human-friendly structural interactions on top of familiar text-based editing.","","","10.1145/3180155.3180165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453134","Structured Editing;Refactoring;Sketch-n-Sketch","Tools;Syntactics;Human computer interaction;Task analysis;Software engineering;Visualization","functional programming;human computer interaction;interactive systems;source code (software);text analysis;text editing;user interfaces","direct manipulation interface;clickable widgets;source code;unstructured text;lightweight menu;interactive menu;functional programming language;structural selection;human-friendly structural interactions;lightweight user interface;structure-aware code editor;automated program transformations;Deuce;Structured Editing;refactoring environments;text-based editing workflow;text-selection interface","","","","","","","","IEEE","IEEE Conferences"
"Quality Experience: A Grounded Theory of Successful Agile Projects without Dedicated Testers","L. Prechelt; H. Schmeisky; F. Zieris","Freie Univ. Berlin, Berlin, Germany; Freie Univ. Berlin, Berlin, Germany; Freie Univ. Berlin, Berlin, Germany","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1017","1027","Context: While successful conventional software development regularly employs separate testing staff, there are successful agile teams with as well as without separate testers. Question: How does successful agile development work without separate testers? What are advantages and disadvantages? Method: A case study, based on Grounded Theory evaluation of interviews and direct observation of three agile teams; one having separate testers, two without. All teams perform long-term development of parts of e-business web portals. Results: Teams without testers use a quality experience work mode centered around a tight field-use feedback loop, driven by a feeling of responsibility, supported by test automation, resulting in frequent deployments. Conclusion: In the given domain, hand-overs to separate testers appear to hamper the feedback loop more than they contribute to quality, so working without testers is preferred. However, Quality Experience is achievable only with modular architectures and in suitable domains.","","","10.1145/2884781.2884789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886976","Agile Development;Software Quality Assurance;Industrial Case Study;Grounded Theory Methodology;Testing","Software;Testing;Interviews;Portals;Context;Companies;Data collection","program testing;quality of experience;software architecture;software prototyping","quality experience;agile projects;agile development;grounded theory evaluation;e-business Web portals;feedback loop;modular architectures","","1","27","","","","","IEEE","IEEE Conferences"
"Journal First Program Committee of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","41","41","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2019.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812104","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and Supporters of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","44","44","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","10.1109/ICSE.2019.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812036","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Web Chairs of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","29","29","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2019.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812087","","","","","","","","","","","","IEEE","IEEE Conferences"
"Organizing Committee of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","31","36","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2019.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811899","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Social Media Chairs of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","30","30","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2019.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812112","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Board of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","37","37","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2019.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812078","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Artifact Evaluation Chairs of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","28","28","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2019.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811926","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Committee of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","38","40","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2019.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812094","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Program Chairs of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","24","25","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2019.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812098","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Workshop Chairs of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","27","27","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2019.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812030","","","","","","","","","","","","IEEE","IEEE Conferences"
"Artifact Evaluation Committee of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","43","43","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2019.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811985","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Journal-First Chair of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","26","26","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2019.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811919","","","","","","","","","","","","IEEE","IEEE Conferences"
"Workshops Program Committee of ICSE 2019","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","42","42","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2019.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811958","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the ICSE 2019 General Chair","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","22","23","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2019.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811895","","","","","","","","","","","","IEEE","IEEE Conferences"
"Organizing Committee","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","xix","xxii","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2017.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985641","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Publisher's information]","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","786","786","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2017.78","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985714","","","","","","","","","","","","IEEE","IEEE Conferences"
"Foreword","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","xvi","xviii","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2017.5","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985640","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Committee","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","xxiii","xxvi","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2017.7","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985642","","","","","","","","","","","","IEEE","IEEE Conferences"
"Publicity Committee","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxxii","xxxii","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886882","","","","","","","","","","","","IEEE","IEEE Conferences"
"Workshops Committee","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxxiv","xxxiv","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886884","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and Supporters","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","45","45","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453054","","","","","","","","","","","","IEEE","IEEE Conferences"
"Web Committee","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxxi","xxxi","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886881","","","","","","","","","","","","IEEE","IEEE Conferences"
"Publications Committee","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxxiii","xxxiii","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886883","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Chairs - Volume 1","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","xiv","xvii","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2015.5","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194551","","","","","","","","","","","","IEEE","IEEE Conferences"
"Committees - Volume 2","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","xxviii","xlvi","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2015.112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202940","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Publisher's information - Vol 1]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","964","964","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2015.106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194642","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Publisher's information - Vol 2]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1032","1032","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2015.333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203160","","","","","","","","","","","","IEEE","IEEE Conferences"
"Committees - Volume 1","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","xviii","xxxvi","Provides a listing of current committee members and society officers.","","","10.1109/ICSE.2015.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194552","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the General and Program Chairs - Volume 2","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","xxiv","xxvii","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","10.1109/ICSE.2015.111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202939","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Publisher's information]","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1264","1264","The following topics are dealt with: program testing; software engineering; software maintenance; program debugging; program diagnostics; public domain software; Java; software quality; mobile computing; and application program interfaces.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453209","","","software engineering","program testing;software engineering;software maintenance;program debugging;program diagnostics;public domain software;Java;software quality;mobile computing;application program interfaces","","","","","","","","IEEE","IEEE Conferences"
"Program Committee","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxviii","xxx","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886880","","","","","","","","","","","","IEEE","IEEE Conferences"
"Organizing Committee","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxiii","xxvi","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886878","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Journal First Chair","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","28","28","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453050","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the General Chair","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","23","25","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453048","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Board","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","33","35","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453052","","","","","","","","","","","","IEEE","IEEE Conferences"
"Welcome Message from the Chairs","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xvii","xxii","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886877","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Board","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxvii","xxvii","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886879","","","","","","","","","","","","IEEE","IEEE Conferences"
"Organizing Committee","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","29","32","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453051","","","","","","","","","","","","IEEE","IEEE Conferences"
"Message from the Program Chairs","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","26","27","Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453049","","","","","","","","","","","","IEEE","IEEE Conferences"
"Program Committee","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","36","44","Provides a listing of current committee members and society officers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453053","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page i]","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1","1","Presents the title page of the proceedings record.","","","10.1109/ICSE.2019.00001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812055","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii]","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","3","3","Presents the title page of the proceedings record.","","","10.1109/ICSE.2019.00002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812089","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Front cover]","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","c1","c1","Presents the front cover or splash screen of the proceedings record.","","","10.1109/ICSE.2017.80","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985635","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii]","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","iii","iii","Presents the title page of the proceedings record.","","","10.1109/ICSE.2017.2","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985637","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","v","xv","The following topics are dealt with: traceability; documentation; refactoring; recommendation systems; software process; search-based software engineering; Web applications; concurrency; mobile application security; debugging; program synthesis; program repair; mining software repositories; program analysis; safety; privacy; development tools; testing; defect prediction; formal methods; and software evolution.","","","10.1109/ICSE.2017.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985639","","","concurrency (computers);Internet;maintenance engineering;mobile computing;program diagnostics;programming;recommender systems;security;software engineering;testing","software evolution;formal methods;defect prediction;testing;development tools;privacy;safety;program analysis;mining software repositories;program repair;program synthesis;debugging;mobile application security;concurrency;Web applications;search-based software engineering;software process;recommendation systems;refactoring;documentation;traceability","","","","","","","","IEEE","IEEE Conferences"
"Additional Reviewers","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","xxvii","xxviii","The conference offers a note of thanks and lists its reviewers.","","","10.1109/ICSE.2017.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985643","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page i]","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","i","i","Presents the title page of the proceedings record.","","","10.1109/ICSE.2017.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985636","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Copyright notice]","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","iv","iv","Presents the copyright information for the conference. May include reprint permission information.","","","10.1109/ICSE.2017.3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985638","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","781","784","Presents an index of the authors whose articles are published in the conference proceedings record.","","","10.1109/ICSE.2017.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985713","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and Benefactors","","","2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)","","2017","","","xxix","xxxii","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","10.1109/ICSE.2017.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985644","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","1269","1275","Presents an index of the authors whose articles are published in the conference proceedings record.","","","10.1109/ICSE.2019.00128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812142","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Copyright notice]","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","4","4","Presents the copyright information for the conference. May include reprint permission information.","","","10.1109/ICSE.2019.00003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811962","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index - Vol 2","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","1023","1030","Presents an index of the authors whose articles are published in the conference proceedings record.","","","10.1109/ICSE.2015.332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203159","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Copyright notice - Vol 1]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","iv","iv","Presents the copyright information for the conference. May include reprint permission information.","","","10.1109/ICSE.2015.3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194549","","","","","","","","","","","","IEEE","IEEE Conferences"
"Additional Reviewers - Volume 1","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","xxxvii","xxxix","The conference offers a note of thanks and lists its reviewers.","","","10.1109/ICSE.2015.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194553","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Front cover - Vol 2]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","C4","C4","Presents the front cover of the proceedings record.","","","10.1109/ICSE.2015.350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202934","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii - Vol 2]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","iii","iii","Presents the title page of the proceedings record.","","","10.1109/ICSE.2015.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202936","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents - Vol 2","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","v","xxiii","Presents the table of contents/splash page of the proceedings record.","","","10.1109/ICSE.2015.110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202938","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and Supporters - Volume 2","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","l","li","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","10.1109/ICSE.2015.127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202942","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Front cover - Vol 1]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","C4","C4","Presents the front cover of the proceedings record.","","","10.1109/ICSE.2015.349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194546","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents - Vol 1","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","v","xiii","Presents the table of contents/splash page of the proceedings record.","","","10.1109/ICSE.2015.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194550","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii - Vol 1]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","iii","iii","Presents the title page of the proceedings record.","","","10.1109/ICSE.2015.2","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194548","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and Supporters - Volume 1","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","xl","xli","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","10.1109/ICSE.2015.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194554","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page i - Vol 2]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","i","i","Presents the title page of the proceedings record.","","","10.1109/ICSE.2015.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202935","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Copyright notice - Vol 2]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","iv","iv","Presents the copyright information for the conference. May include reprint permission information.","","","10.1109/ICSE.2015.109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202937","","","","","","","","","","","","IEEE","IEEE Conferences"
"Additional Reviewers - Volume 2","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","2","","xlvii","xlvix","The conference offers a note of thanks and lists its reviewers.","","","10.1109/ICSE.2015.125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202941","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index - Vol 1","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","959","962","Presents an index of the authors whose articles are published in the conference proceedings record.","","","10.1109/ICSE.2015.105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194641","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents","","","2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)","","2019","","","5","21","The following topics are dealt with: program testing; program debugging; program diagnostics; Java; software maintenance; public domain software; learning (artificial intelligence); application program interfaces; data mining; mobile computing.","","","10.1109/ICSE.2019.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812059","","","Java;program debugging;program diagnostics;program testing;software maintenance","program testing;program debugging;program diagnostics;Java;software maintenance;public domain software;learning (artificial intelligence);application program interfaces;data mining;mobile computing","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii]","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","iii","iii","Presents the title page of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886874","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","v","xvi","Presents the table of contents/splash page of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886876","","","","","","","","","","","","IEEE","IEEE Conferences"
"Sponsors and supporters","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxxvii","xxxix","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886886","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page iii]","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","3","3","Presents the title page of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453046","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Copyright notice]","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","iv","iv","Presents the copyright information for the conference. May include reprint permission information.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886875","","","","","","","","","","","","IEEE","IEEE Conferences"
"Author index","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","1193","1197","Presents an index of the authors whose articles are published in the conference proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886991","","","","","","","","","","","","IEEE","IEEE Conferences"
"Additional Reviewers","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","xxxv","xxxv","The publication offers a note of thanks and lists its reviewers.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886885","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page i]","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1","1","Presents the title page of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453045","","","","","","","","","","","","IEEE","IEEE Conferences"
"[Title page i - Vol 1]","","","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","","2015","1","","i","i","The following topics are dealt with: software testing; mobile applications; software maintenance; adaptive systems; highly configurable systems; regression testing; data privacy; data security; variability-aware refactoring; data mining; analysis infrastructure; symbolic execution; human factors; organizational factors; prediction models; API; software specification and software verification.","","","10.1109/ICSE.2015.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194547","","","application program interfaces;data mining;data privacy;formal specification;groupware;human factors;mobile computing;program testing;program verification;security of data;software maintenance;statistical testing;symbol manipulation","software testing;mobile applications;software maintenance;adaptive systems;highly configurable systems;regression testing;data privacy;data security;variability-aware refactoring;data mining;analysis infrastructure;symbolic execution;human factors;organizational factors;prediction models;API;software specification;software verification","","","","","","","","IEEE","IEEE Conferences"
"[Title page i]","","","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","i","i","The following topics are dealt with: Android; software performance; symbolic execution; compilers and emerging trends; energy profiles; open source software; defect prediction; program synthesis; API; code smells; software architecture; software testing; software effort estimation; search algorithms; repair and model synthesis; and software product lines.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886873","","","Android (operating system);application program interfaces;power aware computing;program compilers;program diagnostics;program testing;public domain software;search problems;software architecture;software maintenance;software performance evaluation;software product lines;symbol manipulation","Android;software performance;symbolic execution;compilers;energy profiles;open source software;defect prediction;program synthesis;API;code smells;software architecture;software testing;software effort estimation;search algorithms;software maintenance;software product lines;model synthesis","","","","","","","","IEEE","IEEE Conferences"
"Author Index","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","1255","1262","Presents an index of the authors whose articles are published in the conference proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453208","","","","","","","","","","","","IEEE","IEEE Conferences"
"Table of contents","","","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","","2018","","","5","22","Presents the table of contents/splash page of the proceedings record.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453047","","","","","","","","","","","","IEEE","IEEE Conferences"
